[{"title":"Spring源码学习--Bean的生命周期","date":"2018-04-20T03:09:07.000Z","path":"2018/04/20/Spring源码学习-Bean的生命周期/","text":"Spring作为当前Java最流行、最强大的轻量级框架，受到了程序员的热烈欢迎。准确的了解Spring Bean的生命周期是非常必要的。我们通常使用ApplicationContext作为Spring容器。这里，我们讲的也是 ApplicationContext中Bean的生命周期。而实际上BeanFactory也是差不多的，只不过处理器需要手动注册。 一、生命周期流程图： Spring Bean的完整生命周期从创建Spring容器开始，直到最终Spring容器销毁Bean，这其中包含了一系列关键点。 若容器注册了以上各种接口，程序那么将会按照以上的流程进行。下面将仔细讲解各接口作用。 二、各种接口方法分类Bean的完整生命周期经历了各种方法调用，这些方法可以划分为以下几类： 1、Bean自身的方法 ： 这个包括了Bean本身调用的方法和通过配置文件中的init-method和destroy-method指定的方法 2、Bean级生命周期接口方法 ： 这个包括了BeanNameAware、BeanFactoryAware、InitializingBean和DiposableBean这些接口的方法 3、容器级生命周期接口方法 ： 这个包括了InstantiationAwareBeanPostProcessor 和 BeanPostProcessor 这两个接口实现，一般称它们的实现类为“后处理器”。 4、工厂后处理器接口方法 ： 这个包括了AspectJWeavingEnabler, ConfigurationClassPostProcessor, CustomAutowireConfigurer等等非常有用的工厂后处理器 接口的方法。工厂后处理器也是容器级的。在应用上下文装配配置文件之后立即调用。 三、演示我们用一个简单的Spring Bean来演示一下Spring Bean的生命周期。 1、首先是一个简单的Spring Bean，调用Bean自身的方法和Bean级生命周期接口方法，为了方便演示，它实现了BeanNameAware、BeanFactoryAware、InitializingBean和DiposableBean这4个接口，同时有2个方法，对应配置文件中的init-method和destroy-method。如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485 public class Person implements BeanFactoryAware, BeanNameAware, InitializingBean, DisposableBean &#123; private String name; private String address; private int phone; private BeanFactory beanFactory; private String beanName; public Person() &#123; System.out.println(&quot;【构造器】调用Person的构造器实例化&quot;); &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; System.out.println(&quot;【注入属性】注入属性name&quot;); this.name = name; &#125; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; System.out.println(&quot;【注入属性】注入属性address&quot;); this.address = address; &#125; public int getPhone() &#123; return phone; &#125; public void setPhone(int phone) &#123; System.out.println(&quot;【注入属性】注入属性phone&quot;); this.phone = phone; &#125; @Override public String toString() &#123; return &quot;Person [address=&quot; + address + &quot;, name=&quot; + name + &quot;, phone=&quot; + phone + &quot;]&quot;; &#125; // 这是BeanFactoryAware接口方法 @Override public void setBeanFactory(BeanFactory arg0) throws BeansException &#123; System.out .println(&quot;【BeanFactoryAware接口】调用BeanFactoryAware.setBeanFactory()&quot;); this.beanFactory = arg0; &#125; // 这是BeanNameAware接口方法 @Override public void setBeanName(String arg0) &#123; System.out.println(&quot;【BeanNameAware接口】调用BeanNameAware.setBeanName()&quot;); this.beanName = arg0; &#125; // 这是InitializingBean接口方法 @Override public void afterPropertiesSet() throws Exception &#123; System.out .println(&quot;【InitializingBean接口】调用InitializingBean.afterPropertiesSet()&quot;); &#125; // 这是DiposibleBean接口方法 @Override public void destroy() throws Exception &#123; System.out.println(&quot;【DiposibleBean接口】调用DiposibleBean.destory()&quot;); &#125; // 通过&lt;bean&gt;的init-method属性指定的初始化方法 public void myInit() &#123; System.out.println(&quot;【init-method】调用&lt;bean&gt;的init-method属性指定的初始化方法&quot;); &#125; // 通过&lt;bean&gt;的destroy-method属性指定的初始化方法 public void myDestory() &#123; System.out.println(&quot;【destroy-method】调用&lt;bean&gt;的destroy-method属性指定的初始化方法&quot;); &#125; &#125; 2、接下来是演示BeanPostProcessor接口的方法，如下：123456789101112131415161718192021222324public class MyBeanPostProcessor implements BeanPostProcessor &#123; public MyBeanPostProcessor() &#123; super(); System.out.println(&quot;这是BeanPostProcessor实现类构造器！！&quot;); // TODO Auto-generated constructor stub &#125; @Override public Object postProcessAfterInitialization(Object arg0, String arg1) throws BeansException &#123; System.out .println(&quot;BeanPostProcessor接口方法postProcessAfterInitialization对属性进行更改！&quot;); return arg0; &#125; @Override public Object postProcessBeforeInitialization(Object arg0, String arg1) throws BeansException &#123; System.out .println(&quot;BeanPostProcessor接口方法postProcessBeforeInitialization对属性进行更改！&quot;); return arg0; &#125; &#125; 如上，BeanPostProcessor接口包括2个方法postProcessAfterInitialization和postProcessBeforeInitialization，这两个方法的第一个参数都是要处理的Bean对象，第二个参数都是Bean的name。返回值也都是要处理的Bean对象。这里要注意。 3、InstantiationAwareBeanPostProcessor 接口本质是BeanPostProcessor的子接口，一般我们继承Spring为其提供的适配器类InstantiationAwareBeanPostProcessor Adapter来使用它，如下：12345678910111213141516171819202122232425262728293031323334353637 public class MyInstantiationAwareBeanPostProcessor extends InstantiationAwareBeanPostProcessorAdapter &#123; public MyInstantiationAwareBeanPostProcessor() &#123; super(); System.out .println(&quot;这是InstantiationAwareBeanPostProcessorAdapter实现类构造器！！&quot;); &#125; // 接口方法、实例化Bean之前调用 @Override public Object postProcessBeforeInstantiation(Class beanClass, String beanName) throws BeansException &#123; System.out .println(&quot;InstantiationAwareBeanPostProcessor调用postProcessBeforeInstantiation方法&quot;); return null; &#125; // 接口方法、实例化Bean之后调用 @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; System.out .println(&quot;InstantiationAwareBeanPostProcessor调用postProcessAfterInitialization方法&quot;); return bean; &#125; // 接口方法、设置某个属性时调用 @Override public PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException &#123; System.out .println(&quot;InstantiationAwareBeanPostProcessor调用postProcessPropertyValues方法&quot;); return pvs; &#125; &#125; 这个有3个方法，其中第二个方法postProcessAfterInitialization就是重写了BeanPostProcessor的方法。第三个方法postProcessPropertyValues用来操作属性，返回值也应该是PropertyValues对象。 4、演示工厂后处理器接口方法，如下：1234567891011121314151617public class MyBeanFactoryPostProcessor implements BeanFactoryPostProcessor &#123; public MyBeanFactoryPostProcessor() &#123; super(); System.out.println(&quot;这是BeanFactoryPostProcessor实现类构造器！！&quot;); &#125; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory arg0) throws BeansException &#123; System.out .println(&quot;BeanFactoryPostProcessor调用postProcessBeanFactory方法&quot;); BeanDefinition bd = arg0.getBeanDefinition(&quot;person&quot;); bd.getPropertyValues().addPropertyValue(&quot;phone&quot;, &quot;110&quot;); &#125; &#125; 5、配置文件如下beans.xml，很简单，使用ApplicationContext,处理器不用手动注册：123456789101112&lt;bean id=&quot;beanPostProcessor&quot; class=&quot;springBeanTest.MyBeanPostProcessor&quot;&gt; &lt;/bean&gt; &lt;bean id=&quot;instantiationAwareBeanPostProcessor&quot; class=&quot;springBeanTest.MyInstantiationAwareBeanPostProcessor&quot;&gt; &lt;/bean&gt; &lt;bean id=&quot;beanFactoryPostProcessor&quot; class=&quot;springBeanTest.MyBeanFactoryPostProcessor&quot;&gt; &lt;/bean&gt; &lt;bean id=&quot;person&quot; class=&quot;springBeanTest.Person&quot; init-method=&quot;myInit&quot; destroy-method=&quot;myDestory&quot; scope=&quot;singleton&quot; p:name=&quot;张三&quot; p:address=&quot;广州&quot; p:phone=&quot;15900000000&quot; /&gt; 6、下面测试一下：12345678910111213141516public class BeanLifeCycle &#123; public static void main(String[] args) &#123; System.out.println(&quot;现在开始初始化容器&quot;); ApplicationContext factory = new ClassPathXmlApplicationContext(&quot;springBeanTest/beans.xml&quot;); System.out.println(&quot;容器初始化成功&quot;); //得到Preson，并使用 Person person = factory.getBean(&quot;person&quot;,Person.class); System.out.println(person); System.out.println(&quot;现在开始关闭容器！&quot;); ((ClassPathXmlApplicationContext)factory).registerShutdownHook(); &#125; &#125; 关闭容器使用的是实际是AbstractApplicationContext的钩子方法。 我们来看一下结果： 1234567891011121314151617181920212223242526272829现在开始初始化容器2014-5-18 15:46:20 org.springframework.context.support.AbstractApplicationContext prepareRefresh信息: Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@19a0c7c: startup date [Sun May 18 15:46:20 CST 2014]; root of context hierarchy2014-5-18 15:46:20 org.springframework.beans.factory.xml.XmlBeanDefinitionReader loadBeanDefinitions信息: Loading XML bean definitions from class path resource [springBeanTest/beans.xml]这是BeanFactoryPostProcessor实现类构造器！！BeanFactoryPostProcessor调用postProcessBeanFactory方法这是BeanPostProcessor实现类构造器！！这是InstantiationAwareBeanPostProcessorAdapter实现类构造器！！2014-5-18 15:46:20 org.springframework.beans.factory.support.DefaultListableBeanFactory preInstantiateSingletons信息: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@9934d4: defining beans [beanPostProcessor,instantiationAwareBeanPostProcessor,beanFactoryPostProcessor,person]; root of factory hierarchyInstantiationAwareBeanPostProcessor调用postProcessBeforeInstantiation方法【构造器】调用Person的构造器实例化InstantiationAwareBeanPostProcessor调用postProcessPropertyValues方法【注入属性】注入属性address【注入属性】注入属性name【注入属性】注入属性phone【BeanNameAware接口】调用BeanNameAware.setBeanName()【BeanFactoryAware接口】调用BeanFactoryAware.setBeanFactory()BeanPostProcessor接口方法postProcessBeforeInitialization对属性进行更改！【InitializingBean接口】调用InitializingBean.afterPropertiesSet()【init-method】调用&lt;bean&gt;的init-method属性指定的初始化方法BeanPostProcessor接口方法postProcessAfterInitialization对属性进行更改！InstantiationAwareBeanPostProcessor调用postProcessAfterInitialization方法容器初始化成功Person [address=广州, name=张三, phone=110]现在开始关闭容器！【DiposibleBean接口】调用DiposibleBean.destory()【destroy-method】调用&lt;bean&gt;的destroy-method属性指定的初始化方法","tags":[]},{"title":"如何显示或者隐藏Ext.grid.Panel","date":"2018-04-19T09:33:29.000Z","path":"2018/04/19/如何显示或者隐藏Ext-grid-Panel/","text":"最近做项目遇到一个问题，如图所示，需要动态隐藏这个gridPanel, 在Ext api中找到grid.Panel的hide()方法，如图所示，发现panel隐藏了，但是标题却没有隐藏， 然后找到设置标题的方法setTitle(“”),发现文字隐藏掉了，但是后面的背景没有隐藏掉，显然也是不行的 /** * 创建tabPanel * * @param comp * 组件 * @param anchor * 组件宽高占比 * @return {Ext.ux.tab.Panel} panel */ createComTabPanel : function(comp, anchor) { var comTabPanel = Ext.create(&quot;Ext.ux.tab.Panel&quot;, { activeTab : 0, frame : true, plain : true, border : true, anchor : anchor || &apos;100% 100%&apos;, ui : &apos;neu-detail-tab&apos;, items : [ comp ] }); return comTabPanel; }, 后来查看代码，这个panel是在item数组里面的，我想是不是要把tab.Panel隐藏掉，查看api PlantGridPanel.findParentByType(Ext.TabPanel).hide();//隐藏 PlantGridPanel.findParentByType(Ext.TabPanel).show();//显示 找到Panel的父类进行隐藏，完美解决！","tags":[]},{"title":"springMVC通过Filter实现防止xss注入","date":"2018-04-17T01:54:33.000Z","path":"2018/04/17/springMVC通过Filter实现防止xss注入/","text":"跨站脚本工具（cross 斯特scripting），为不和层叠样式表（cascading style sheets,CSS）的缩写混淆，故将跨站脚本攻击缩写为XSS。恶意攻击者往web页面里插入恶意scriptScript代码，当用户浏览该页之时，嵌入其中Web里面的Script代码会被执行，从而达到恶意攻击用户的目的。防止XSS攻击简单的预防就是对Request请求中的一些参数去掉一些比较敏感的脚本命令。 原本是打算通过springMVC的HandlerInterceptor机制来实现的，通过获取request然后对request中的参数进行修改，结果虽然值修改了，但在Controller中获取的数值还是没有修改的。没办法就是要Filter来完成。简单来说就是创建一个新的httpRequest类XsslHttpServletRequestWrapper，然后重写一些get方法（获取参数时对参数进行XSS判断预防）。 @WebFilter(filterName=&quot;xssMyfilter&quot;,urlPatterns=&quot;/*&quot;) public class MyXssFilter implements Filter{ @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { XsslHttpServletRequestWrapper xssRequest = new XsslHttpServletRequestWrapper((HttpServletRequest)request); chain.doFilter(xssRequest , response); } @Override public void destroy() { } } XSS代码的过滤是在XsslHttpServletRequestWrapper中实现的，主要是覆盖实现了getParameter，getParameterValues，getHeader这几个方法，然后对获取的value值进行XSS处理。 public class XsslHttpServletRequestWrapper extends HttpServletRequestWrapper { HttpServletRequest xssRequest = null; public XsslHttpServletRequestWrapper(HttpServletRequest request) { super(request); xssRequest = request; } @Override public String getParameter(String name) { String value = super.getParameter(replaceXSS(name)); if (value != null) { value = replaceXSS(value); } return value; } @Override public String[] getParameterValues(String name) { String[] values = super.getParameterValues(replaceXSS(name)); if(values != null &amp;&amp; values.length &gt; 0){ for(int i =0; i&lt; values.length ;i++){ values[i] = replaceXSS(values[i]); } } return values; } @Override public String getHeader(String name) { String value = super.getHeader(replaceXSS(name)); if (value != null) { value = replaceXSS(value); } return value; } /** * 去除待带script、src的语句，转义替换后的value值 */ public static String replaceXSS(String value) { if (value != null) { try{ value = value.replace(&quot;+&quot;,&quot;%2B&quot;); //&apos;+&apos; replace to &apos;%2B&apos; value = URLDecoder.decode(value, &quot;utf-8&quot;); }catch(UnsupportedEncodingException e){ }catch(IllegalArgumentException e){ } // Avoid null characters value = value.replaceAll(&quot;\\0&quot;, &quot;&quot;); // Avoid anything between script tags Pattern scriptPattern = Pattern.compile(&quot;&lt;script&gt;(.*?)&lt;/script&gt;&quot;, Pattern.CASE_INSENSITIVE); value = scriptPattern.matcher(value).replaceAll(&quot;&quot;); // Avoid anything in a src=&apos;...&apos; type of e­xpression scriptPattern = Pattern.compile(&quot;src[\\r\\n]*=[\\r\\n]*\\\\\\&apos;(.*?)\\\\\\&apos;&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); value = scriptPattern.matcher(value).replaceAll(&quot;&quot;); scriptPattern = Pattern.compile(&quot;src[\\r\\n]*=[\\r\\n]*\\\\\\&quot;(.*?)\\\\\\&quot;&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); value = scriptPattern.matcher(value).replaceAll(&quot;&quot;); // Remove any lonesome &lt;/script&gt; tag scriptPattern = Pattern.compile(&quot;&lt;/script&gt;&quot;, Pattern.CASE_INSENSITIVE); value = scriptPattern.matcher(value).replaceAll(&quot;&quot;); // Remove any lonesome &lt;script ...&gt; tag scriptPattern = Pattern.compile(&quot;&lt;script(.*?)&gt;&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); value = scriptPattern.matcher(value).replaceAll(&quot;&quot;); // Avoid eval(...) e­xpressions scriptPattern = Pattern.compile(&quot;eval\\\\((.*?)\\\\)&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); value = scriptPattern.matcher(value).replaceAll(&quot;&quot;); // Avoid e­xpression(...) e­xpressions scriptPattern = Pattern.compile(&quot;e­xpression\\\\((.*?)\\\\)&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); value = scriptPattern.matcher(value).replaceAll(&quot;&quot;); // Avoid javascript:... e­xpressions scriptPattern = Pattern.compile(&quot;javascript:&quot;, Pattern.CASE_INSENSITIVE); value = scriptPattern.matcher(value).replaceAll(&quot;&quot;); // Avoid alert:... e­xpressions scriptPattern = Pattern.compile(&quot;alert&quot;, Pattern.CASE_INSENSITIVE); value = scriptPattern.matcher(value).replaceAll(&quot;&quot;); // Avoid onload= e­xpressions scriptPattern = Pattern.compile(&quot;onload(.*?)=&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); value = scriptPattern.matcher(value).replaceAll(&quot;&quot;); scriptPattern = Pattern.compile(&quot;vbscript[\\r\\n| | ]*:[\\r\\n| | ]*&quot;, Pattern.CASE_INSENSITIVE); value = scriptPattern.matcher(value).replaceAll(&quot;&quot;); } return filter(value); } /** * 过滤特殊字符 */ public static String filter(String value) { if (value == null) { return null; } StringBuffer result = new StringBuffer(value.length()); for (int i=0; i&lt;value.length(); ++i) { switch (value.charAt(i)) { case &apos;&lt;&apos;: result.append(&quot;&lt;&quot;); break; case &apos;&gt;&apos;: result.append(&quot;&gt;&quot;); break; case &apos;&quot;&apos;: result.append(&quot;&quot;&quot;); break; case &apos;\\&apos;&apos;: result.append(&quot;&apos;&quot;); break; case &apos;%&apos;: result.append(&quot;%&quot;); break; case &apos;;&apos;: result.append(&quot;;&quot;); break; case &apos;(&apos;: result.append(&quot;(&quot;); break; case &apos;)&apos;: result.append(&quot;)&quot;); break; case &apos;&amp;&apos;: result.append(&quot;&amp;&quot;); break; case &apos;+&apos;: result.append(&quot;+&quot;); break; default: result.append(value.charAt(i)); break; } } return result.toString(); } } 转载：https://blog.csdn.net/qq924862077/article/details/62053577","tags":[]},{"title":"Caused by: java.sql.SQLSyntaxErrorException: ORA-00932: 数据类型不一致: 应为 -, 但却获得 CLOB","date":"2018-04-09T09:50:07.000Z","path":"2018/04/09/Caused-by-java-sql-SQLSyntaxErrorException-ORA-00932-数据类型不一致-应为-但却获得-CLOB/","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211Internal Exception: java.sql.SQLSyntaxErrorException: ORA-00932: 数据类型不一致: 应为 -, 但却获得 CLOBError Code: 932Call: SELECT * FROM (SELECT a.*, ROWNUM rnum FROM (SELECT DISTINCT t0.PRICEINQUIRYID AS a1, t0.CLIENTCODE AS a2, t0.COSTPRICEQUO AS a3, t0.CREATETIME AS a4, t0.CREATEUSERID AS a5, t0.CREATEUSERNAME AS a6, t0.ENDTIME AS a7, t0.INQUIRYREQUIRE AS a8, t0.MODIFYTIME AS a9, t0.MODIFYUSERID AS a10, t0.MODIFYUSERNAME AS a11, t0.MROPRICEINQUIRYSTATE AS a12, t0.PRICEINQUIRYNO AS a13, t0.PRICEINQUIRYTITLE AS a14, t0.PRICEQUOTETEMPLATE AS a15, t0.PRICEQUOTETYPE AS a16, t0.PURCHASINGGROUPCODE AS a17, t0.PURCHASINGGROUPNAME AS a18, t0.PURCHASINGORGCODE AS a19, t0.PURCHASINGORGNAME AS a20, t0.STARTTIME AS a21 FROM d_xbj_mro_priceInquiry t0, d_xbj_mro_priceinquiryvendor t1 WHERE ((t1.MROPRICEINQUIRYVENDORSTATE = ?) AND (t1.priceInquiryId = t0.PRICEINQUIRYID)) ORDER BY t0.PRICEINQUIRYID DESC) a WHERE ROWNUM &lt;= ?) WHERE rnum &gt; ? bind =&gt; [0, 20, 0]Query: ReadAllQuery(referenceClass=MroPriceInquiry sql=&quot;SELECT * FROM (SELECT a.*, ROWNUM rnum FROM (SELECT DISTINCT t0.PRICEINQUIRYID AS a1, t0.CLIENTCODE AS a2, t0.COSTPRICEQUO AS a3, t0.CREATETIME AS a4, t0.CREATEUSERID AS a5, t0.CREATEUSERNAME AS a6, t0.ENDTIME AS a7, t0.INQUIRYREQUIRE AS a8, t0.MODIFYTIME AS a9, t0.MODIFYUSERID AS a10, t0.MODIFYUSERNAME AS a11, t0.MROPRICEINQUIRYSTATE AS a12, t0.PRICEINQUIRYNO AS a13, t0.PRICEINQUIRYTITLE AS a14, t0.PRICEQUOTETEMPLATE AS a15, t0.PRICEQUOTETYPE AS a16, t0.PURCHASINGGROUPCODE AS a17, t0.PURCHASINGGROUPNAME AS a18, t0.PURCHASINGORGCODE AS a19, t0.PURCHASINGORGNAME AS a20, t0.STARTTIME AS a21 FROM d_xbj_mro_priceInquiry t0, d_xbj_mro_priceinquiryvendor t1 WHERE ((t1.MROPRICEINQUIRYVENDORSTATE = ?) AND (t1.priceInquiryId = t0.PRICEINQUIRYID)) ORDER BY t0.PRICEINQUIRYID DESC) a WHERE ROWNUM &lt;= ?) WHERE rnum &gt; ?&quot;)[ERROR] DefaultDispatcherErrorHandler.error(CommonsLogger.java:42) - Exception occurred during processing request: EJB Exception: javax.ejb.EJBTransactionRolledbackException: EJB Exception: at weblogic.ejb.container.internal.BaseLocalObject.handleSystemException(BaseLocalObject.java:452) at weblogic.ejb.container.internal.BaseLocalObject.postInvoke1(BaseLocalObject.java:251) at weblogic.ejb.container.internal.BaseLocalObject.__WL_postInvokeTxRetry(BaseLocalObject.java:204) at weblogic.ejb.container.internal.SessionLocalMethodInvoker.invoke(SessionLocalMethodInvoker.java:46) at com.huiju.srm.e.ss.mro.inquiryquotation.eao.MroPriceInquiryEaoBean_jugebu_MroPriceInquiryEaoLocalImpl.findAll(Unknown Source) at com.huiju.module.data.logic.GenericLogicImpl.findAll(GenericLogicImpl.java:122) at sun.reflect.GeneratedMethodAccessor2231.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Method.java:498) at com.bea.core.repackaged.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:310) at com.bea.core.repackaged.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:182) at com.bea.core.repackaged.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:149) at com.oracle.pitchfork.intercept.MethodInvocationInvocationContext.proceed(MethodInvocationInvocationContext.java:100) at com.oracle.pitchfork.intercept.JeeInterceptorInterceptor.invoke(JeeInterceptorInterceptor.java:117) at com.bea.core.repackaged.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171) at com.bea.core.repackaged.springframework.aop.support.DelegatingIntroductionInterceptor.doProceed(DelegatingIntroductionInterceptor.java:131) at com.bea.core.repackaged.springframework.aop.support.DelegatingIntroductionInterceptor.invoke(DelegatingIntroductionInterceptor.java:119) at com.bea.core.repackaged.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171) at com.bea.core.repackaged.springframework.aop.framework.JdkDynamicAopProxy.invoke(Unknown Source) at com.sun.proxy.$Proxy537.findAll(Unknown Source) at com.huiju.srm.e.ss.mro.inquiryquotation.logic.MroPriceInquiryBean_ra0lj4_MroPriceInquiryRemoteImpl.__WL_invoke(Unknown Source) at weblogic.ejb.container.internal.SessionRemoteMethodInvoker.invoke(SessionRemoteMethodInvoker.java:34) at com.huiju.srm.e.ss.mro.inquiryquotation.logic.MroPriceInquiryBean_ra0lj4_MroPriceInquiryRemoteImpl.findAll(Unknown Source) at com.huiju.srm.e.ss.mro.inquiryquotation.logic.MroPriceInquiryBean_ra0lj4_MroPriceInquiryRemoteImpl_CBV.findAll(Unknown Source) at sun.reflect.GeneratedMethodAccessor2887.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Method.java:498) at weblogic.ejb.container.internal.RemoteBusinessIntfProxy.invoke(RemoteBusinessIntfProxy.java:84) at com.sun.proxy.$Proxy342.findAll(Unknown Source) at com.huiju.srm.e.ss.mro.inquiryquotation.action.MroPriceInquiryAction.getJson(MroPriceInquiryAction.java:140) at sun.reflect.GeneratedMethodAccessor3818.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Method.java:498) at ognl.OgnlRuntime.invokeMethod(OgnlRuntime.java:897) at ognl.OgnlRuntime.callAppropriateMethod(OgnlRuntime.java:1299) at ognl.ObjectMethodAccessor.callMethod(ObjectMethodAccessor.java:68) at com.opensymphony.xwork2.ognl.accessor.XWorkMethodAccessor.callMethodWithDebugInfo(XWorkMethodAccessor.java:117) at com.opensymphony.xwork2.ognl.accessor.XWorkMethodAccessor.callMethod(XWorkMethodAccessor.java:108) at ognl.OgnlRuntime.callMethod(OgnlRuntime.java:1375) at ognl.ASTMethod.getValueBody(ASTMethod.java:91) at ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212) at ognl.SimpleNode.getValue(SimpleNode.java:258) at ognl.Ognl.getValue(Ognl.java:470) at ognl.Ognl.getValue(Ognl.java:434) at com.opensymphony.xwork2.ognl.OgnlUtil$3.execute(OgnlUtil.java:362) at com.opensymphony.xwork2.ognl.OgnlUtil.compileAndExecuteMethod(OgnlUtil.java:414) at com.opensymphony.xwork2.ognl.OgnlUtil.callMethod(OgnlUtil.java:360) at com.opensymphony.xwork2.DefaultActionInvocation.invokeAction(DefaultActionInvocation.java:430) at com.opensymphony.xwork2.DefaultActionInvocation.invokeActionOnly(DefaultActionInvocation.java:290) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:251) at com.huiju.srm.license.interceptor.LicenseInterceptor$1.proceed(LicenseInterceptor.java:85) at com.huiju.module.license.interceptor.AbstractLicenseInterceptor.interceptor(AbstractLicenseInterceptor.java:48) at com.huiju.srm.license.interceptor.LicenseInterceptor.intercept(LicenseInterceptor.java:45) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.huiju.module.web.interceptor.InvocationContextAdapter.proceed(InvocationContextAdapter.java:75) at com.huiju.module.plugin.log.interceptor.AbstractLoggingInterceptor.aroundLogging(AbstractLoggingInterceptor.java:112) at com.huiju.module.web.interceptor.LoggingInterceptor.intercept(LoggingInterceptor.java:45) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.opensymphony.xwork2.interceptor.DefaultWorkflowInterceptor.doIntercept(DefaultWorkflowInterceptor.java:168) at com.opensymphony.xwork2.interceptor.MethodFilterInterceptor.intercept(MethodFilterInterceptor.java:98) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.opensymphony.xwork2.validator.ValidationInterceptor.doIntercept(ValidationInterceptor.java:265) at org.apache.struts2.interceptor.validation.AnnotationValidationInterceptor.doIntercept(AnnotationValidationInterceptor.java:76) at com.opensymphony.xwork2.interceptor.MethodFilterInterceptor.intercept(MethodFilterInterceptor.java:98) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.opensymphony.xwork2.interceptor.ConversionErrorInterceptor.intercept(ConversionErrorInterceptor.java:138) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.opensymphony.xwork2.interceptor.ParametersInterceptor.doIntercept(ParametersInterceptor.java:229) at com.opensymphony.xwork2.interceptor.MethodFilterInterceptor.intercept(MethodFilterInterceptor.java:98) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.opensymphony.xwork2.interceptor.ParametersInterceptor.doIntercept(ParametersInterceptor.java:229) at com.opensymphony.xwork2.interceptor.MethodFilterInterceptor.intercept(MethodFilterInterceptor.java:98) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.opensymphony.xwork2.interceptor.StaticParametersInterceptor.intercept(StaticParametersInterceptor.java:191) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at org.apache.struts2.interceptor.FileUploadInterceptor.intercept(FileUploadInterceptor.java:253) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.opensymphony.xwork2.interceptor.ModelDrivenInterceptor.intercept(ModelDrivenInterceptor.java:100) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.opensymphony.xwork2.interceptor.ChainingInterceptor.intercept(ChainingInterceptor.java:145) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.opensymphony.xwork2.interceptor.PrepareInterceptor.doIntercept(PrepareInterceptor.java:171) at com.opensymphony.xwork2.interceptor.MethodFilterInterceptor.intercept(MethodFilterInterceptor.java:98) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at org.apache.struts2.interceptor.ServletConfigInterceptor.intercept(ServletConfigInterceptor.java:164) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.opensymphony.xwork2.interceptor.ParametersInterceptor.doIntercept(ParametersInterceptor.java:229) at com.opensymphony.xwork2.interceptor.MethodFilterInterceptor.intercept(MethodFilterInterceptor.java:98) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at org.apache.struts2.interceptor.MultiselectInterceptor.intercept(MultiselectInterceptor.java:73) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at org.apache.struts2.interceptor.DateTextFieldInterceptor.intercept(DateTextFieldInterceptor.java:125) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at org.apache.struts2.interceptor.CheckboxInterceptor.intercept(CheckboxInterceptor.java:91) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.opensymphony.xwork2.interceptor.I18nInterceptor.intercept(I18nInterceptor.java:140) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.opensymphony.xwork2.interceptor.AliasInterceptor.intercept(AliasInterceptor.java:193) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.opensymphony.xwork2.interceptor.ExceptionMappingInterceptor.intercept(ExceptionMappingInterceptor.java:189) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at org.apache.struts2.interceptor.MessageStoreInterceptor.intercept(MessageStoreInterceptor.java:206) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at com.huiju.module.web.interceptor.AuthorizationInterceptor.intercept(AuthorizationInterceptor.java:111) at com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:245) at org.apache.struts2.impl.StrutsActionProxy.execute(StrutsActionProxy.java:54) at org.apache.struts2.dispatcher.Dispatcher.serviceAction(Dispatcher.java:575) at org.apache.struts2.dispatcher.ng.ExecuteOperations.executeAction(ExecuteOperations.java:81) at org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter.doFilter(StrutsPrepareAndExecuteFilter.java:99) at weblogic.servlet.internal.FilterChainImpl.doFilter(FilterChainImpl.java:79) at com.huiju.module.context.CurrentContextFilter.doFilter(CurrentContextFilter.java:49) at com.huiju.module.web.filter.WebCurrentContextFilter.doFilter(WebCurrentContextFilter.java:61) at weblogic.servlet.internal.FilterChainImpl.doFilter(FilterChainImpl.java:79) at com.huiju.module.web.filter.HttpContextWrapperFilter.doFilter(HttpContextWrapperFilter.java:37) at weblogic.servlet.internal.FilterChainImpl.doFilter(FilterChainImpl.java:79) at weblogic.servlet.internal.WebAppServletContext$ServletInvocationAction.wrapRun(WebAppServletContext.java:3436) at weblogic.servlet.internal.WebAppServletContext$ServletInvocationAction.__run(WebAppServletContext.java:3402) at weblogic.servlet.internal.WebAppServletContext$ServletInvocationAction.run(WebAppServletContext.java) at weblogic.security.acl.internal.AuthenticatedSubject.doAs(AuthenticatedSubject.java:321) at weblogic.security.service.SecurityManager.runAs(SecurityManager.java:120) at weblogic.servlet.provider.WlsSubjectHandle.run(WlsSubjectHandle.java:57) at weblogic.servlet.internal.WebAppServletContext.doSecuredExecute(WebAppServletContext.java:2285) at weblogic.servlet.internal.WebAppServletContext.securedExecute(WebAppServletContext.java:2201) at weblogic.servlet.internal.WebAppServletContext.execute(WebAppServletContext.java:2179) at weblogic.servlet.internal.ServletRequestImpl.run(ServletRequestImpl.java:1572) at weblogic.servlet.provider.ContainerSupportProviderImpl$WlsRequestExecutor.run(ContainerSupportProviderImpl.java:255) at weblogic.work.ExecuteThread.execute(ExecuteThread.java:311) at weblogic.work.ExecuteThread.run(ExecuteThread.java:263)Caused by: javax.persistence.PersistenceException: Exception [EclipseLink-4002] (Eclipse Persistence Services - 2.5.2.v20140319-9ad6abd): org.eclipse.persistence.exceptions.DatabaseExceptionInternal Exception: java.sql.SQLSyntaxErrorException: ORA-00932: 数据类型不一致: 应为 -, 但却获得 CLOBError Code: 932Call: SELECT * FROM (SELECT a.*, ROWNUM rnum FROM (SELECT DISTINCT t0.PRICEINQUIRYID AS a1, t0.CLIENTCODE AS a2, t0.COSTPRICEQUO AS a3, t0.CREATETIME AS a4, t0.CREATEUSERID AS a5, t0.CREATEUSERNAME AS a6, t0.ENDTIME AS a7, t0.INQUIRYREQUIRE AS a8, t0.MODIFYTIME AS a9, t0.MODIFYUSERID AS a10, t0.MODIFYUSERNAME AS a11, t0.MROPRICEINQUIRYSTATE AS a12, t0.PRICEINQUIRYNO AS a13, t0.PRICEINQUIRYTITLE AS a14, t0.PRICEQUOTETEMPLATE AS a15, t0.PRICEQUOTETYPE AS a16, t0.PURCHASINGGROUPCODE AS a17, t0.PURCHASINGGROUPNAME AS a18, t0.PURCHASINGORGCODE AS a19, t0.PURCHASINGORGNAME AS a20, t0.STARTTIME AS a21 FROM d_xbj_mro_priceInquiry t0, d_xbj_mro_priceinquiryvendor t1 WHERE ((t1.MROPRICEINQUIRYVENDORSTATE = ?) AND (t1.priceInquiryId = t0.PRICEINQUIRYID)) ORDER BY t0.PRICEINQUIRYID DESC) a WHERE ROWNUM &lt;= ?) WHERE rnum &gt; ? bind =&gt; [0, 20, 0]Query: ReadAllQuery(referenceClass=MroPriceInquiry sql=&quot;SELECT * FROM (SELECT a.*, ROWNUM rnum FROM (SELECT DISTINCT t0.PRICEINQUIRYID AS a1, t0.CLIENTCODE AS a2, t0.COSTPRICEQUO AS a3, t0.CREATETIME AS a4, t0.CREATEUSERID AS a5, t0.CREATEUSERNAME AS a6, t0.ENDTIME AS a7, t0.INQUIRYREQUIRE AS a8, t0.MODIFYTIME AS a9, t0.MODIFYUSERID AS a10, t0.MODIFYUSERNAME AS a11, t0.MROPRICEINQUIRYSTATE AS a12, t0.PRICEINQUIRYNO AS a13, t0.PRICEINQUIRYTITLE AS a14, t0.PRICEQUOTETEMPLATE AS a15, t0.PRICEQUOTETYPE AS a16, t0.PURCHASINGGROUPCODE AS a17, t0.PURCHASINGGROUPNAME AS a18, t0.PURCHASINGORGCODE AS a19, t0.PURCHASINGORGNAME AS a20, t0.STARTTIME AS a21 FROM d_xbj_mro_priceInquiry t0, d_xbj_mro_priceinquiryvendor t1 WHERE ((t1.MROPRICEINQUIRYVENDORSTATE = ?) AND (t1.priceInquiryId = t0.PRICEINQUIRYID)) ORDER BY t0.PRICEINQUIRYID DESC) a WHERE ROWNUM &lt;= ?) WHERE rnum &gt; ?&quot;) at org.eclipse.persistence.internal.jpa.QueryImpl.getDetailedException(QueryImpl.java:378) at org.eclipse.persistence.internal.jpa.QueryImpl.executeReadQuery(QueryImpl.java:260) at org.eclipse.persistence.internal.jpa.QueryImpl.getResultList(QueryImpl.java:469) at com.huiju.module.data.eao.GenericEaoImpl.findAll(GenericEaoImpl.java:232) at sun.reflect.GeneratedMethodAccessor2260.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Method.java:498) at com.bea.core.repackaged.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:310) at com.bea.core.repackaged.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:182) at com.bea.core.repackaged.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:149) at com.oracle.pitchfork.intercept.MethodInvocationInvocationContext.proceed(MethodInvocationInvocationContext.java:100) at com.oracle.pitchfork.intercept.JeeInterceptorInterceptor.invoke(JeeInterceptorInterceptor.java:117) at com.bea.core.repackaged.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171) at com.bea.core.repackaged.springframework.aop.support.DelegatingIntroductionInterceptor.doProceed(DelegatingIntroductionInterceptor.java:131) at com.bea.core.repackaged.springframework.aop.support.DelegatingIntroductionInterceptor.invoke(DelegatingIntroductionInterceptor.java:119) at com.bea.core.repackaged.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171) at com.bea.core.repackaged.springframework.aop.framework.JdkDynamicAopProxy.invoke(Unknown Source) at com.sun.proxy.$Proxy540.findAll(Unknown Source) at com.huiju.srm.e.ss.mro.inquiryquotation.eao.MroPriceInquiryEaoBean_jugebu_MroPriceInquiryEaoLocalImpl.__WL_invoke(Unknown Source) at weblogic.ejb.container.internal.SessionLocalMethodInvoker.invoke(SessionLocalMethodInvoker.java:33) ... 121 moreCaused by: Exception [EclipseLink-4002] (Eclipse Persistence Services - 2.5.2.v20140319-9ad6abd): org.eclipse.persistence.exceptions.DatabaseExceptionInternal Exception: java.sql.SQLSyntaxErrorException: ORA-00932: 数据类型不一致: 应为 -, 但却获得 CLOBError Code: 932Call: SELECT * FROM (SELECT a.*, ROWNUM rnum FROM (SELECT DISTINCT t0.PRICEINQUIRYID AS a1, t0.CLIENTCODE AS a2, t0.COSTPRICEQUO AS a3, t0.CREATETIME AS a4, t0.CREATEUSERID AS a5, t0.CREATEUSERNAME AS a6, t0.ENDTIME AS a7, t0.INQUIRYREQUIRE AS a8, t0.MODIFYTIME AS a9, t0.MODIFYUSERID AS a10, t0.MODIFYUSERNAME AS a11, t0.MROPRICEINQUIRYSTATE AS a12, t0.PRICEINQUIRYNO AS a13, t0.PRICEINQUIRYTITLE AS a14, t0.PRICEQUOTETEMPLATE AS a15, t0.PRICEQUOTETYPE AS a16, t0.PURCHASINGGROUPCODE AS a17, t0.PURCHASINGGROUPNAME AS a18, t0.PURCHASINGORGCODE AS a19, t0.PURCHASINGORGNAME AS a20, t0.STARTTIME AS a21 FROM d_xbj_mro_priceInquiry t0, d_xbj_mro_priceinquiryvendor t1 WHERE ((t1.MROPRICEINQUIRYVENDORSTATE = ?) AND (t1.priceInquiryId = t0.PRICEINQUIRYID)) ORDER BY t0.PRICEINQUIRYID DESC) a WHERE ROWNUM &lt;= ?) WHERE rnum &gt; ? bind =&gt; [0, 20, 0]Query: ReadAllQuery(referenceClass=MroPriceInquiry sql=&quot;SELECT * FROM (SELECT a.*, ROWNUM rnum FROM (SELECT DISTINCT t0.PRICEINQUIRYID AS a1, t0.CLIENTCODE AS a2, t0.COSTPRICEQUO AS a3, t0.CREATETIME AS a4, t0.CREATEUSERID AS a5, t0.CREATEUSERNAME AS a6, t0.ENDTIME AS a7, t0.INQUIRYREQUIRE AS a8, t0.MODIFYTIME AS a9, t0.MODIFYUSERID AS a10, t0.MODIFYUSERNAME AS a11, t0.MROPRICEINQUIRYSTATE AS a12, t0.PRICEINQUIRYNO AS a13, t0.PRICEINQUIRYTITLE AS a14, t0.PRICEQUOTETEMPLATE AS a15, t0.PRICEQUOTETYPE AS a16, t0.PURCHASINGGROUPCODE AS a17, t0.PURCHASINGGROUPNAME AS a18, t0.PURCHASINGORGCODE AS a19, t0.PURCHASINGORGNAME AS a20, t0.STARTTIME AS a21 FROM d_xbj_mro_priceInquiry t0, d_xbj_mro_priceinquiryvendor t1 WHERE ((t1.MROPRICEINQUIRYVENDORSTATE = ?) AND (t1.priceInquiryId = t0.PRICEINQUIRYID)) ORDER BY t0.PRICEINQUIRYID DESC) a WHERE ROWNUM &lt;= ?) WHERE rnum &gt; ?&quot;) at org.eclipse.persistence.exceptions.DatabaseException.sqlException(DatabaseException.java:340) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.basicExecuteCall(DatabaseAccessor.java:682) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.executeCall(DatabaseAccessor.java:558) at org.eclipse.persistence.internal.sessions.AbstractSession.basicExecuteCall(AbstractSession.java:2002) at org.eclipse.persistence.sessions.server.ServerSession.executeCall(ServerSession.java:570) at org.eclipse.persistence.sessions.server.ClientSession.executeCall(ClientSession.java:250) at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:242) at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:228) at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeSelectCall(DatasourceCallQueryMechanism.java:299) at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.selectAllRows(DatasourceCallQueryMechanism.java:694) at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectAllRowsFromTable(ExpressionQueryMechanism.java:2738) at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectAllRows(ExpressionQueryMechanism.java:2691) at org.eclipse.persistence.queries.ReadAllQuery.executeObjectLevelReadQuery(ReadAllQuery.java:495) at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeDatabaseQuery(ObjectLevelReadQuery.java:1168) at org.eclipse.persistence.queries.DatabaseQuery.execute(DatabaseQuery.java:899) at org.eclipse.persistence.queries.ObjectLevelReadQuery.execute(ObjectLevelReadQuery.java:1127) at org.eclipse.persistence.queries.ReadAllQuery.execute(ReadAllQuery.java:403) at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeInUnitOfWork(ObjectLevelReadQuery.java:1215) at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:2896) at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1804) at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1786) at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1751) at org.eclipse.persistence.internal.jpa.QueryImpl.executeReadQuery(QueryImpl.java:258) ... 138 moreCaused by: java.sql.SQLSyntaxErrorException: ORA-00932: 数据类型不一致: 应为 -, 但却获得 CLOB at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:450) at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:399) at oracle.jdbc.driver.T4C8Oall.processError(T4C8Oall.java:1059) at oracle.jdbc.driver.T4CTTIfun.receive(T4CTTIfun.java:522) at oracle.jdbc.driver.T4CTTIfun.doRPC(T4CTTIfun.java:257) at oracle.jdbc.driver.T4C8Oall.doOALL(T4C8Oall.java:587) at oracle.jdbc.driver.T4CPreparedStatement.doOall8(T4CPreparedStatement.java:225) at oracle.jdbc.driver.T4CPreparedStatement.doOall8(T4CPreparedStatement.java:53) at oracle.jdbc.driver.T4CPreparedStatement.executeForDescribe(T4CPreparedStatement.java:774) at oracle.jdbc.driver.OracleStatement.executeMaybeDescribe(OracleStatement.java:925) at oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1111) at oracle.jdbc.driver.OraclePreparedStatement.executeInternal(OraclePreparedStatement.java:4798) at oracle.jdbc.driver.OraclePreparedStatement.executeQuery(OraclePreparedStatement.java:4845) at oracle.jdbc.driver.OraclePreparedStatementWrapper.executeQuery(OraclePreparedStatementWrapper.java:1501) at weblogic.jdbc.wrapper.PreparedStatement.executeQuery(PreparedStatement.java:141) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.executeSelect(DatabaseAccessor.java:1007) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.basicExecuteCall(DatabaseAccessor.java:642) ... 159 more 总是报：ORA-00932: 数据类型不一致: 应为 -, 但却获得 CLOB 是由于这个t0.INQUIRYREQUIRE字段clob字段。 第一种解决方法： t0.INQUIRYREQUIRE 改成 to_char(t0.INQUIRYREQUIRE)。 第二种解决方法：去掉distinct 去重。","tags":[]},{"title":"JDK1.8源码解析——HashMap(二)","date":"2018-02-27T07:53:36.000Z","path":"2018/02/27/JDK1-8源码解析——HashMap-二/","text":"一：摘要HashMap是Java程序员使用频率最高的用于映射(键值对)处理的数据类型。随着JDK（Java Developmet Kit）版本的更新，JDK1.8对HashMap底层的实现进行了优化，例如引入红黑树的数据结构和扩容的优化等。本文结合JDK1.7和JDK1.8的区别，深入探讨HashMap的结构实现和功能原理。 二：简介Java为数据结构中的映射定义了一个接口java.util.Map，此接口主要有四个常用的实现类，分别是HashMap、Hashtable、LinkedHashMap和TreeMap，类继承关系如下图所示： 下面针对各个实现类的特点做一些说明： (1) HashMap：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。 (2) Hashtable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 (3) LinkedHashMap：LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。 (4) TreeMap：TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。 对于上述四种Map类型的类，要求映射中的key是不可变对象。不可变对象是该对象在创建后它的哈希值不会被改变。如果对象的哈希值发生变化，Map对象很可能就定位不到映射的位置了。 通过上面的比较，我们知道了HashMap是Java的Map家族中一个普通成员，鉴于它可以满足大多数场景的使用条件，所以是使用频度最高的一个。下文我们主要结合源码，从存储结构、常用方法分析、扩容以及安全性等方面深入讲解HashMap的工作原理。 三：内部实现搞清楚HashMap，首先需要知道HashMap是什么，即它的存储结构-字段；其次弄明白它能干什么，即它的功能实现-方法。下面我们针对这两个方面详细展开讲解。 3.1 存储结构-字段从结构实现来讲，HashMap是数组+链表+红黑树（JDK1.8增加了红黑树部分）实现的，如下如所示。 这里需要讲明白两个问题：数据底层具体存储的是什么？\b这样的存储方式有什么\b优点呢？ (1) 从源码可知，HashMap类中有一个非常重要的字段，就是 Node[] table，即哈希桶数组，明显它是一个Node的数组。我们来看Node[JDK1.8]是何物。 1234567891011121314static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个node Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; ... &#125; public final K getKey()&#123; ... &#125; public final V getValue() &#123; ... &#125; public final String toString() &#123; ... &#125; public final int hashCode() &#123; ... &#125; public final V setValue(V newValue) &#123; ... &#125; public final boolean equals(Object o) &#123; ... &#125;&#125; Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。上图中的每个黑色圆点就是一个Node对象。 (2) HashMap就是使用哈希表来存储的。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题，Java中HashMap采用了链地址法。链地址法，简单来说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。例如程序执行下面代码： 1map.put(&quot;美团&quot;,&quot;小美&quot;); 系统将调用”美团”这个key的hashCode()方法得到其hashCode 值（该方法适用于每个Java对象），然后再通过Hash算法的后两步运算（高位运算和取模运算，下文有介绍）来定位该键值对的存储位置，有时两个key会定位到相同的位置，表示发生了Hash碰撞。当然Hash算法计算结果越分散均匀，Hash碰撞的概率就越小，map的存取效率就会越高。 如果哈希桶数组很大，即使较差的Hash算法也会比较分散，如果哈希桶数组数组很小，即使好的Hash算法也会出现较多碰撞，所以就需要在空间成本和时间成本之间权衡，其实就是在根据实际情况确定哈希桶数组的大小，并在此基础上设计好的hash算法减少Hash碰撞。那么通过什么方式来控制map使得Hash碰撞的概率又小，哈希桶数组（Node[] table）占用空间又少呢？答案就是好的Hash算法和扩容机制。 在理解Hash和扩容流程之前，我们得先了解下HashMap的几个字段。从HashMap的默认构造函数源码可知，构造函数就是对下面几个字段进行初始化，源码如下： 1234int threshold; // 所能容纳的key-value对极限 final float loadFactor; // 负载因子int modCount; int size; 首先，Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。 结合负载因子的定义公式可知，threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，扩容后的HashMap容量是之前容量的两倍。默认的负载因子0.75是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。 size这个字段其实很好理解，就是HashMap中实际存在的键值对数量。注意和table的长度length、容纳最大键值对数量threshold的区别。而modCount字段主要用来记录HashMap内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如put新键值对，但是某个key对应的value值被覆盖不属于结构变化。 在HashMap中，哈希桶数组table的长度length大小必须为2的n次方(一定是合数)，这是一种非常规的设计，常规的设计是把桶的大小设计为素数。相对来说素数导致冲突的概率要小于合数，具体证明可以参考http://blog.csdn.net/liuqiyao_01/article/details/14475159，Hashtable初始化桶大小为11，就是桶大小设计为素数的应用（Hashtable扩容后不能保证还是素数）。HashMap采用这种非常规设计，主要是为了在取模和扩容时做优化，同时为了减少冲突，HashMap定位哈希桶索引位置时，也加入了高位参与运算的过程。 这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。本文不再对红黑树展开讨论，想了解更多红黑树数据结构的工作原理可以参考http://blog.csdn.net/v_july_v/article/details/6105630。 3.2 功能实现-方法HashMap的内部功能实现很多，本文主要从根据key获取哈希桶数组索引位置、put方法的详细执行、扩容过程三个具有代表性的点深入展开讲解。 3.2.1 确定哈希桶数组索引位置不管增加、删除、查找键值对，定位到哈希桶数组的位置都是很关键的第一步。前面说过HashMap的数据结构是数组和链表的结合，所以我们当然希望这个HashMap里面的元素位置尽量分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用hash算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，不用遍历链表，大大优化了查询的效率。HashMap定位数组索引位置，直接决定了hash方法的离散性能。先看看源码的实现(方法一+方法二): 1234567891011方法一：static final int hash(Object key) &#123; //jdk1.8 &amp; jdk1.7 int h; // h = key.hashCode() 为第一步 取hashCode值 // h ^ (h &gt;&gt;&gt; 16) 为第二步 高位参与运算 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;方法二：static int indexFor(int h, int length) &#123; //jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的 return h &amp; (length-1); //第三步 取模运算&#125; 这里的Hash算法本质上就是三步：取key的hashCode值、高位运算、取模运算。 对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，在HashMap中是这样做的：调用方法二来计算该对象应该保存在table数组的哪个索引处。 这个方法非常巧妙，它通过h &amp; (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h&amp; (length-1)运算等价于对length取模，也就是h%length，但是&amp;比%具有更高的效率。 在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在\b数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。 下面举例说明下，n为table的长度。 3.2.2 分析HashMap的put方法HashMap的put方法执行过程可以通过下图来理解，自己有兴趣\b可以去对比源码更清楚地研究学习。 ①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； ②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，\b转向③； ③.判断\btable[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals； ④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤； ⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；\b遍历过程中若发现key已经存在直接覆盖value即可； ⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。 JDK1.8HashMap的put方法源码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 public V put(K key, V value) &#123; // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true); &#125; final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 步骤①：tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 步骤②：计算index，并对null做处理 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 步骤③：节点key存在，直接覆盖value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 步骤④：判断该链为红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 步骤⑤：该链为链表 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key,value,null); //链表长度大于8转换为红黑树进行处理 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // key已经存在直接覆盖value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 步骤⑥：超过最大容量 就扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 3.2.3 扩容机制扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。 我们分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些，本质上区别不大，具体区别后文再说。 123456789101112131415161718//用新的容量来给table扩容 void resize(int newCapacity) &#123; Entry[] oldTable = table; //引用扩容前的Entry数组 int oldCapacity = oldTable.length; //保存old capacity // 如果旧的容量已经是系统默认最大容量了(扩容前的数组大小如果已经达到最大(2^30)了 )，那么将阈值设置成整形的最大值，退出 , if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; //初始化一个新的Entry数组 Entry[] newTable = new Entry[newCapacity]; //将数据转移到新的Entry数组里 transfer(newTable, initHashSeedAsNeeded(newCapacity)); //HashMap的table属性引用新的Entry数组 table = newTable; //设置阈值 threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); &#125; 这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。 1234567891011121314151617void transfer(Entry[] newTable) &#123; Entry[] src = table; //src引用了旧的Entry数组 int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; //遍历旧的Entry数组 Entry&lt;K,V&gt; e = src[j]; //取得旧Entry数组的每个元素 if (e != null) &#123; src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象） do &#123; Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置 e.next = newTable[i]; //标记[1] newTable[i] = e; //将元素放在数组上 e = next; //访问下一个Entry链上的元素 &#125; while (e != null); &#125; &#125;&#125; newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置；这样先放在一个索引上的元素终会被放到Entry链的尾部(如果发生了hash冲突的话），这一点和Jdk1.8有区别，下文详解。在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。 下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的\b哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。 下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。 元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。有兴趣的同学可以研究下JDK1.8的resize源码，写的很赞，如下: 代码中主要点在于判断高位新增的是1还是0，if ((e.hash &amp; oldCap) == 0) 就在原位置，否则在原索引+oldCap的位置。这个if即判断了新增的位是1还是0，一般我们用hash定址，都是hash &amp; length - 1，而这里是直接hash &amp; length，这样的做法是让低位全部为0，这样就可以判断高位是1还是0了！ 例如： 0000 0101 &amp; 0000 1111（15），解为5，而0000 0101 &amp; 0001 0000（16），解为0。 因此，假如现在在原table索引位置为5的地方有两个节点，分别为5和21，那么当16扩容成为32时，他们在新数组的位置是这样的： 0000 0101 &amp; 0001 0000 = 0 所以5在新数组的位置：原索引位置5 0001 0101 &amp; 0001 0000 = 1 所以21在新数组的位置：索引位置 + 16 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;，&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // 链表优化重hash的代码块 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 四：线程安全性在多线程使用场景中，应该尽量避免使用线程不安全的HashMap，而使用线程安全的ConcurrentHashMap。那么为什么说HashMap是线程不安全的，下面举例子说明在并发的多线程使用场景中使用HashMap可能造成死循环。代码例子如下(便于理解，仍然使用JDK1.7的环境)： 1234567891011121314151617181920public class HashMapInfiniteLoop &#123; private static HashMap&lt;Integer,String&gt; map = new HashMap&lt;Integer,String&gt;(2，0.75f); public static void main(String[] args) &#123; map.put(5， &quot;C&quot;); new Thread(&quot;Thread1&quot;) &#123; public void run() &#123; map.put(7, &quot;B&quot;); System.out.println(map); &#125;; &#125;.start(); new Thread(&quot;Thread2&quot;) &#123; public void run() &#123; map.put(3, &quot;A); System.out.println(map); &#125;; &#125;.start(); &#125; &#125; 其中，map初始化为一个长度为2的数组，loadFactor=0.75，threshold=2*0.75=1，也就是说当put第二个key的时候，map就需要进行resize。 通过设置断点让线程1和线程2同时debug到transfer方法(3.3小节代码块)的首行。注意此时两个线程已经成功添加数据。放开thread1的断点至transfer方法的“Entry next = e.next;” 这一行；然后放开线程2的的断点，让线程2进行resize。结果如下图。 注意，Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后的链表。 线程一被调度回来执行，先是执行 newTalbe[i] = e， 然后是e = next，导致了e指向了key(7)，而下一次循环的next = e.next导致了next指向了key(3)。 e.next = newTable[i] 导致 key(3).next 指向了 key(7)。注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现了。 于是，当我们用线程一调用map.get(11)时，悲剧就出现了——Infinite Loop。 五：JDK1.8与JDK1.7的性能对比HashMap中，如果key经过hash算法得出的数组索引位置全部不相同，即Hash算法非常好，那样的话，getKey方法的时间复杂度就是O(1)，如果Hash算法技术的结果碰撞非常多，假如Hash算极其差，所有的Hash算法结果得出的索引位置一样，那样所有的键值对都集中到一个桶中，或者在一个链表中，或者在一个红黑树中，时间复杂度分别为O(n)和O(lgn)。 鉴于JDK1.8做了多方面的优化，总体性能优于JDK1.7，下面我们从两个方面用例子证明这一点。 5.1 Hash较均匀的情况为了便于测试，我们先写一个类Key，如下： 123456789101112131415161718192021222324252627class Key implements Comparable&lt;Key&gt; &#123; private final int value; Key(int value) &#123; this.value = value; &#125; @Override public int compareTo(Key o) &#123; return Integer.compare(this.value, o.value); &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Key key = (Key) o; return value == key.value; &#125; @Override public int hashCode() &#123; return value; &#125;&#125; 这个类复写了equals方法，并且提供了相当好的hashCode函数，任何一个值的hashCode都不会相同，因为直接使用value当做hashcode。为了避免频繁的GC，我将不变的Key实例缓存了起来，而不是一遍一遍的创建它们。代码如下： 123456789101112131415public class Keys &#123; public static final int MAX_KEY = 10_000_000; private static final Key[] KEYS_CACHE = new Key[MAX_KEY]; static &#123; for (int i = 0; i &lt; MAX_KEY; ++i) &#123; KEYS_CACHE[i] = new Key(i); &#125; &#125; public static Key of(int value) &#123; return KEYS_CACHE[value]; &#125;&#125; 现在开始我们的试验，测试需要做的仅仅是，创建不同size的HashMap（1、10、100、……10000000），屏蔽了扩容的情况，代码如下： 1234567891011121314151617181920static void test(int mapSize) &#123; HashMap&lt;Key, Integer&gt; map = new HashMap&lt;Key,Integer&gt;(mapSize); for (int i = 0; i &lt; mapSize; ++i) &#123; map.put(Keys.of(i), i); &#125; long beginTime = System.nanoTime(); //获取纳秒 for (int i = 0; i &lt; mapSize; i++) &#123; map.get(Keys.of(i)); &#125; long endTime = System.nanoTime(); System.out.println(endTime - beginTime); &#125; public static void main(String[] args) &#123; for(int i=10;i&lt;= 1000 0000;i*= 10)&#123; test(i); &#125; &#125; 在测试中会查找不同的值，然后度量花费的时间，为了计算getKey的平均时间，我们遍历所有的get方法，计算总的时间，除以key的数量，计算一个平均值，主要用来比较，绝对值可能会受很多环境因素的影响。结果如下： 通过观测测试结果可知，JDK1.8的性能要高于JDK1.7 15%以上，在某些size的区域上，甚至高于100%。由于Hash算法较均匀，JDK1.8引入的红黑树效果不明显，下面我们看看Hash不均匀的的情况。 5.2 Hash极不均匀的情况假设我们又一个非常差的Key，它们所有的实例都返回相同的hashCode值。这是使用HashMap最坏的情况。代码修改如下： 123456789class Key implements Comparable&lt;Key&gt; &#123; //... @Override public int hashCode() &#123; return 1; &#125;&#125; 仍然执行main方法，得出的结果如下表所示： 从表中结果中可知，随着size的变大，JDK1.7的花费时间是增长的趋势，而JDK1.8是明显的降低趋势，并且呈现对数增长稳定。当一个\b链表太长的时候，HashMap会动态的将它替换成一个红黑树，这话\b的话会将时间复杂度从O(n)降为O(logn)。hash算法均匀和不均匀所花费的时间明显也不相同，这两种情况的相对比较，可以说明一个好的hash算法的重要性。 测试环境：处理器为2.2 GHz Intel Core i7，内存为16 GB 1600 MHz DDR3，SSD硬盘，使用默认的JVM参数，运行在64位的OS X 10.10.1上。 六：小结(1) 扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。 (2) 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。 (3) HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。 (4) JDK1.8引入红黑树大程度优化了HashMap的性能。 (5) 还没升级JDK1.8的，现在开始升级吧。HashMap的性能提升仅仅是JDK1.8的冰山一角。 七：参考JDK1.7&amp;JDK1.8 源码。CSDN博客频道，HashMap多线程死循环问题，2014。红黑联盟，Java类集框架之HashMap(JDK1.8)源码剖析，2015。CSDN博客频道， 教你初步了解红黑树，2010。Java Code Geeks，HashMap performance improvements in Java 8，2014。Importnew，危险！在HashMap中将可变对象用作Key，2014。CSDN博客频道，为什么一般hashtable的桶数会取一个素数，2013。转自：http://tech.meituan.com/java-hashmap.html","tags":[]},{"title":"JDK1.8源码解析——HashMap(一)","date":"2018-02-27T02:51:29.000Z","path":"2018/02/27/JDK1-8源码解析——HashMap/","text":"一：HashMap概述HashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 二：HashMap的数据结构在Java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，HashMap也不例外。HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结构，但是在jdk1.8里 加入了红黑树的实现，当链表的长度大于8时，转换为红黑树的结构。从上图中可以看出，java中HashMap采用了链地址法。链地址法，简单来说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。 123456789101112static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash;//用于定位数组索引的位置 final K key; V value; Node&lt;K,V&gt; next;//链表的下一个Node Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。 有时两个key会定位到相同的位置，表示发生了Hash碰撞。当然Hash算法计算结果越分散均匀，Hash碰撞的概率就越小，map的存取效率就会越高。 HashMap类中有一个非常重要的字段，就是 Node[] table，即哈希桶数组，明显它是一个Node的数组。 如果哈希桶数组很大，即使较差的Hash算法也会比较分散，如果哈希桶数组数组很小，即使好的Hash算法也会出现较多碰撞，所以就需要在空间成本和时间成本之间权衡，其实就是在根据实际情况确定哈希桶数组的大小，并在此基础上设计好的hash算法减少Hash碰撞。那么通过什么方式来控制map使得Hash碰撞的概率又小，哈希桶数组（Node[] table）占用空间又少呢？答案就是好的Hash算法和扩容机制。 在理解Hash和扩容流程之前，我们得先了解下HashMap的几个字段。从HashMap的默认构造函数源码可知，构造函数就是对下面几个字段进行初始化，源码如下： 1234int threshold; // 所能容纳的key-value对极限 final float loadFactor; // 负载因子int modCount; int size; 首先，Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。 结合负载因子的定义公式可知，threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，扩容后的HashMap容量是之前容量的两倍。默认的负载因子0.75是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。 size这个字段其实很好理解，就是HashMap中实际存在的键值对数量。注意和table的长度length、容纳最大键值对数量threshold的区别。而modCount字段主要用来记录HashMap内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如put新键值对，但是某个key对应的value值被覆盖不属于结构变化。 在HashMap中，哈希桶数组table的长度length大小必须为2的n次方(一定是合数)，这是一种非常规的设计，常规的设计是把桶的大小设计为素数。相对来说素数导致冲突的概率要小于合数，具体证明可以参考http://blog.csdn.net/liuqiyao_01/article/details/14475159，Hashtable初始化桶大小为11，就是桶大小设计为素数的应用（Hashtable扩容后不能保证还是素数）。HashMap采用这种非常规设计，主要是为了在取模和扩容时做优化，同时为了减少冲突，HashMap定位哈希桶索引位置时，也加入了高位参与运算的过程。 这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法 三：确定哈希桶数组索引位置代码实现： 1234567891011//方法一：static final int hash(Object key) &#123; //jdk1.8 &amp; jdk1.7 int h; // h = key.hashCode() 为第一步 取hashCode值 // h ^ (h &gt;&gt;&gt; 16) 为第二步 高位参与运算 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;//方法二：static int indexFor(int h, int length) &#123; //jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的 return h &amp; (length-1); //第三步 取模运算&#125; 这里的Hash算法本质上就是三步：取key的hashCode值、高位运算、取模运算。 对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，在HashMap中是这样做的：调用方法二来计算该对象应该保存在table数组的哪个索引处。 这个方法非常巧妙，它通过h &amp; (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h&amp; (length-1)运算等价于对length取模，也就是h%length，但是&amp;比%具有更高的效率。 在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在\b数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。 下面举例说明下，n为table的长度。 四：HashMap的put方法实现put函数大致的思路为： 对key的hashCode()做hash，然后再计算index; 如果没碰撞直接放到bucket里； 如果碰撞了，以链表的形式存在buckets后； 如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树； 如果节点已经存在就替换old value(保证key的唯一性) 如果bucket满了(超过load factor*current capacity)，就要resize。具体代码实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;/***生成hash的方法*/static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //判断table是否为空， if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length;//创建一个新的table数组，并且获取该数组的长度 //根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123;//如果对应的节点存在 Node&lt;K,V&gt; e; K k; //判断table[i]的首个元素是否和key一样，如果相同直接覆盖value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 该链为链表 else &#123; //遍历table[i]，判断链表长度是否大于TREEIFY_THRESHOLD(默认值为8)，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 写入 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 五：HashMap的get方法实现思路如下： bucket里的第一个节点，直接命中； 如果有冲突，则通过key.equals(k)去查找对应的entry ,若为树，则在树中通过key.equals(k)查找，O(logn)； 若为链表，则在链表中通过key.equals(k)查找，O(n)。 12345678910111213141516171819202122232425262728public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 直接命中 if (first.hash == hash &amp;&amp; // 每次都是校验第一个node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 未命中 if ((e = first.next) != null) &#123; // 在树中获取 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 在链表中获取 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; 六：扩容机制扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。 我们分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些，本质上区别不大，具体区别后文再说。 12345678910111213void resize(int newCapacity) &#123; //传入新的容量 Entry[] oldTable = table; //引用扩容前的Entry数组 int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; //扩容前的数组大小如果已经达到最大(2^30)了 threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了 return; &#125; Entry[] newTable = new Entry[newCapacity]; //初始化一个新的Entry数组 transfer(newTable); //！！将数据转移到新的Entry数组里 table = newTable; //HashMap的table属性引用新的Entry数组 threshold = (int)(newCapacity * loadFactor);//修改阈值&#125; 这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。 1234567891011121314151617 void transfer(Entry[] newTable) &#123; Entry[] src = table; //src引用了旧的Entry数组 int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; //遍历旧的Entry数组 Entry&lt;K,V&gt; e = src[j]; //取得旧Entry数组的每个元素 if (e != null) &#123; src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象） do &#123; Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置 e.next = newTable[i]; //标记[1] newTable[i] = e; //将元素放在数组上 e = next; //访问下一个Entry链上的元素 &#125; while (e != null); &#125; &#125;&#125; newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置；这样先放在一个索引上的元素终会被放到Entry链的尾部(如果发生了hash冲突的话），这一点和Jdk1.8有区别，下文详解。在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。 下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的\b哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。 下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。 元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。有兴趣的同学可以研究下JDK1.8的resize源码，写的很赞，如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 七：总结我们现在可以回答开始的几个问题，加深对HashMap的理解： 1.什么时候会使用HashMap？他有什么特点？ 是基于Map接口的实现，存储键值对时，它可以接收null的键值，是非同步的，HashMap存储着Entry(hash, key, value, next)对象。 2.你知道HashMap的工作原理吗？ 通过hash的方法，通过put和get存储和获取对象。存储对象时，我们将K/V传给put方法时，它调用hashCode计算hash从而得到bucket位置，进一步存储，HashMap会根据当前bucket的占用情况自动调整容量(超过Load Facotr则resize为原来的2倍)。获取对象时，我们将K传给get，它调用hashCode计算hash从而得到bucket位置，并进一步调用equals()方法确定键值对。如果发生碰撞的时候，Hashmap通过链表将产生碰撞冲突的元素组织起来，在Java 8中，如果一个bucket中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，从而提高速度。 3.你知道get和put的原理吗？equals()和hashCode()的都有什么作用？ 通过对key的hashCode()进行hashing，并计算下标( n-1 &amp; hash)，从而获得buckets的位置。如果产生碰撞，则利用key.equals()方法去链表或树中去查找对应的节点 4.你知道hash的实现吗？为什么要这样实现？ 在Java 1.8的实现中，是通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在bucket的n比较小的时候，也能保证考虑到高低bit都参与到hash的计算中，同时不会有太大的开销。 5.如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？ 如果超过了负载因子(默认0.75)，则会重新resize一个原来长度两倍的HashMap，并且重新调用hash方法。关于Java集合的小抄中是这样描述的：以Entry[]数组实现的哈希桶数组，用Key的哈希值取模桶数组的大小可得到数组下标。插入元素时，如果两条Key落在同一个桶(比如哈希值1和17取模16后都属于第一个哈希桶)，Entry用一个next属性实现多个Entry以单向链表存放，后入桶的Entry将next指向桶当前的Entry。查找哈希值为17的key时，先定位到第一个哈希桶，然后以链表遍历桶里所有元素，逐个比较其key值。当Entry数量达到桶数量的75%时(很多文章说使用的桶数量达到了75%，但看代码不是)，会成倍扩容桶数组，并重新分配所有原来的Entry，所以这里也最好有个预估值。取模用位运算(hash &amp; (arrayLength-1))会比较快，所以数组的大小永远是2的N次方， 你随便给一个初始值比如17会转为32。默认第一次放入元素时的初始值是16。iterator()时顺着哈希桶数组来遍历，看起来是个乱序。 6.当两个对象的hashcode相同会发生什么？ 因为hashcode相同，所以它们的bucket位置相同，‘碰撞’会发生。因为HashMap使用链表存储对象，这个Entry(包含有键值对的Map.Entry对象)会存储在链表中。 7.如果两个键的hashcode相同，你如何获取值对象？ 找到bucket位置之后，会调用keys.equals()方法去找到链表中正确的节点，最终找到要找的值对象。因此，设计HashMap的key类型时，如果使用不可变的、声明作final的对象，并且采用合适的equals()和hashCode()方法的话，将会减少碰撞的发生，提高效率。不可变性能够缓存不同键的hashcode，这将提高整个获取对象的速度，使用String，Interger这样的wrapper类作为键是非常好的选择 8.如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？ 默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置 9.你了解重新调整HashMap大小存在什么问题吗？ 当重新调整HashMap大小的时候，确实存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了。因此在并发环境下，我们使用CurrentHashMap来替代HashMap 10.为什么String, Interger这样的wrapper类适合作为键？ 因为String是不可变的，也是final的，而且已经重写了equals()和hashCode()方法了。其他的wrapper类也有这个特点。不可变性是必要的，因为为了要计算hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的hashcode的话，那么就不能从HashMap中找到你想要的对象。不可变性还有其他的优点如线程安全。如果你可以仅仅通过将某个field声明成final就能保证hashCode是不变的，那么请这么做吧。因为获取对象的时候要用到equals()和hashCode()方法，那么键对象正确的重写这两个方法是非常重要的。如果两个不相等的对象返回不同的hashcode的话，那么碰撞的几率就会小些，这样就能提高HashMap的性能 转载：http://blog.csdn.net/fjse51/article/details/53811465","tags":[]},{"title":"JDK1.7源码解析——HashMap","date":"2018-02-26T06:05:10.000Z","path":"2018/02/26/JDK1-7源码解析——HashMap/","text":"一：HashMap的定义和构造函数123public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable HashMap继承自AbstractMap，AbstractMap是Map接口的骨干实现，AbstractMap中实现了Map中最重要最常用和方法，这样HashMap继承AbstractMap就不需要实现Map的所有方法，让HashMap减少了大量的工作。而在这里仍然实现Map结构，没有什么作用，应该是为了让map的层次结构更加清晰HashMap有两个参数影响其性能：初始容量和加载因子。默认初始容量是16，加载因子是0.75。容量是哈希表中桶(Entry数组)的数量，初始容量只是哈希表在创建时的容量。加载因子是哈希表在其容量自动增加之前可以达到多满的一种尺度。当哈希表中的条目数超出了加载因子与当前容量的乘积时，通过调用 rehash 方法将容量翻倍。 HashMap中定义的成员变量如下：12345678910111213141516171819202122232425262728293031323334353637383940/** * The default initial capacity - MUST be a power of two. */ static final int DEFAULT_INITIAL_CAPACITY = 16;// 默认初始容量为16，必须为2的幂 /** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 最大容量为2的30次方 /** * The load factor used when none specified in constructor. */ static final float DEFAULT_LOAD_FACTOR = 0.75f;// 默认加载因子0.75 /** * The table, resized as necessary. Length MUST Always be a power of two. */ transient Entry&lt;K,V&gt;[] table;// Entry数组，哈希表，长度必须为2的幂 /** * The number of key-value mappings contained in this map. */ transient int size;// 已存元素的个数 /** * The next size value at which to resize (capacity * load factor). * @serial */ int threshold;// 下次扩容的临界值，size&gt;=threshold就会扩容，扩容临界点（容量和加载因子的乘积） /** * The load factor for the hash table. * * @serial */ final float loadFactor;// 加载因子 HashMap的四个构造函数public HashMap()：构造一个具有默认初始容量 (16) 和默认加载因子 (0.75) 的空 HashMappublic HashMap(int initialCapacity)：构造一个带指定初始容量和默认加载因子 (0.75) 的空 HashMappublic HashMap(int initialCapacity, float loadFactor)：构造一个带指定初始容量和加载因子的空 HashMappublic HashMap(Map&lt; ? extends K, ? extends V&gt; m)：构造一个映射关系与指定 Map 相同的新 HashMap 这里有两个很重要的参数：initialCapacity（初始容量）、loadFactor（加载因子），看看JDK中的解释：HashMap 的实例有两个参数影响其性能：初始容量 和加载因子。容量 ：是哈希表中桶的数量，初始容量只是哈希表在创建时的容量，实际上就是Entry&lt; K,V&gt;[] table的容量加载因子 ：是哈希表在其容量自动增加之前可以达到多满的一种尺度。它衡量的是一个散列表的空间的使用程度，负载因子越大表示散列表的装填程度越高，反之愈小。对于使用链表法的散列表来说，查找一个元素的平均时间是O(1+a)，因此如果负载因子越大，对空间的利用更充分，然而后果是查找效率的降低；如果负载因子太小，那么散列表的数据将过于稀疏，对空间造成严重浪费。系统默认负载因子为0.75，一般情况下我们是无需修改的。当哈希表中的条目数超出了加载因子与当前容量的乘积时，则要对该哈希表进行 rehash 操作（即重建内部数据结构），从而哈希表将具有大约两倍的桶数。 二：HashMap的数据结构我们知道在Java中最常用的两种结构是数组和模拟指针(引用)，几乎所有的数据结构都可以利用这两种来组合实现，HashMap也是如此。实际上HashMap是一个“链表散列”，如下是它数据结构： 从上图我们可以看出HashMap底层实现还是数组，只是数组的每一项都是一条链。其中参数initialCapacity就代表了该数组的长度。下面为HashMap构造函数的源码： 1234567891011121314151617181920212223242526public HashMap(int initialCapacity, float loadFactor) &#123; //容量不能小于0 if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); //容量不能超出最大容量 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //加载因子不能&lt;=0 或者 为非数字 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); //计算出大于初始容量的最小 2的n次方作为哈希表table的长度，下面会说明为什么要这样 int capacity = 1; while (capacity &lt; initialCapacity) capacity &lt;&lt;= 1; this.loadFactor = loadFactor; //设置HashMap的容量极限，当HashMap的容量达到该极限时就会进行扩容操作 threshold = (int)Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); //创建Entry数组 table = new Entry[capacity]; useAltHashing = sun.misc.VM.isBooted() &amp;&amp; (capacity &gt;= Holder.ALTERNATIVE_HASHING_THRESHOLD); init();&#125; 可以看到，这个构造函数主要做的事情就是： 对传入的 容量 和 加载因子进行判断处理 设置HashMap的容量极限 计算出大于初始容量的最小 2的n次方作为哈希表table的长度，然后用该长度创建Entry数组（table），这个是最核心的 可以发现，一个HashMap对应一个Entry数组，来看看Entry这个元素的内部结构： 123456789101112131415static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash; /** * Creates new entry. */ Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; Entry是HashMap的一个内部类，它也是维护着一个key-value映射关系，除了key和value，还有next引用（该引用指向当前table位置的链表），hash值（用来确定每一个Entry链表在table中位置） 三：HashMap的存储实现put（K,V）HashMap中我们最长用的就是put(K, V)和get(K)。我们都知道，HashMap的K值是唯一的，那如何保证唯一性呢？我们首先想到的是用equals比较，没错，这样可以实现，但随着内部元素的增多，put和get的效率将越来越低，这里的时间复杂度是O(n)，假如有1000个元素，put时最差情况需要比较1000次。实际上，HashMap很少会用到equals方法，因为其内通过一个哈希表管理所有元素，哈希是通过hash单词音译过来的，也可以称为散列表，哈希算法可以快速的存取元素，当我们调用put存值时，HashMap首先会调用K的hashCode方法，获取哈希码，通过哈希码快速找到某个存放位置，这个位置可以被称之为bucketIndex，但可能会存在多个元素找到了相同的bucketIndex，有个专业名词叫碰撞，当碰撞发生时，这时会取到bucketIndex位置已存储的元素，最终通过equals来比较，equals方法就是碰撞时才会执行的方法，所以前面说HashMap很少会用到equals。HashMap通过hashCode和equals最终判断出K是否已存在，如果已存在，则使用新V值替换旧V值，并返回旧V值，如果不存在 ，则存放新的键值对到bucketIndex位置。文字描述有些乱，通过下面的流程图来梳理一下整个put过程。现在我们知道，执行put方法后，最终HashMap的存储结构会有这三种情况，我们当然期望情形3是最少发生的（效率最低）。到目前为止，我们了解了两件事： HashMap通过键的hashCode来快速的存取元素。 当不同的对象发生碰撞时，HashMap通过单链表来解决，将新元素加入链表表头，通过next指向原有的元素。单链表在Java中的实现就是对象的引用(复合)。来鉴赏一下HashMap中put方法源码： 123456789101112131415161718192021222324252627public V put(K key, V value) &#123; //如果key为空的情况 if (key == null) return putForNullKey(value); //计算key的hash值 int hash = hash(key); //计算该hash值在table中的下标 int i = indexFor(hash, table.length); //对table[i]存放的链表进行遍历 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; //判断该条链上是否有hash值相同的(key相同) //若存在相同，则直接覆盖value，返回旧value if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; //修改次数+1 modCount++; //把当前key，value添加到table[i]的链表中 addEntry(hash, key, value, i); return null;&#125; 从上面的过程中，我们起码可以发现两点： 1.如果为null，则调用putForNullKey：这就是为什么HashMap可以用null作为键的原因，来看看HashMap是如何处理null键的： 123456789101112131415private V putForNullKey(V value) &#123; //查找链表中是否有null键 for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; //如果链中查找不到，则把该null键插入 addEntry(0, null, value, 0); return null;&#125; 12345678910void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); //这一步就是对null的处理，如果key为null，hash值为0，也就是会插入到哈希表的表头table[0]的位置 hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125; 2.如果链中存在该key，则用传入的value覆盖掉旧的value，同时把旧的value返回：这就是为什么HashMap不能有两个相同的key的原因 对于hash操作，最重要也是最困难的就是如何通过确定hash的位置，我们来看看HashMap的做法：首先求得key的hash值：hash(key) 12345678910111213final int hash(Object k) &#123; int h = 0; if (useAltHashing) &#123; if (k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h = hashSeed; &#125; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 这是一个数学计算，可以不用深入，关键是下面这里：计算该hash值在table中的下标 123static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; 对于HashMap的table而言，数据分布需要均匀（最好每项都只有一个元素，这样就可以直接找到），不能太紧也不能太松，太紧会导致查询速度慢，太松则浪费空间。计算hash值后，怎么才能保证table元素分布均与呢？我们会想到取模，但是由于取模的消耗较大，而HashMap是通过&amp;运算符（按位与操作）来实现的：h &amp; (length-1) 在构造函数中存在：capacity &lt;&lt;= 1，这样做总是能够保证HashMap的底层数组长度为2的n次方。当length为2的n次方时，h&amp;(length - 1)就相当于对length取模，而且速度比直接取模快得多，这是HashMap在速度上的一个优化。至于为什么是2的n次方下面解释。我们回到indexFor方法，该方法仅有一条语句：h&amp;(length - 1)，这句话除了上面的取模运算外还有一个非常重要的责任：均匀分布table数据和充分利用空间。这里我们假设length为16(2^n)和15，h为5、6、7。 当length-1 = 14时，6和7的结果一样，这样表示他们在table存储的位置是相同的，也就是产生了碰撞，6、7就会在一个位置形成链表，这样就会导致查询速度降低详细地看看当length-1 = 14 时的情况： 可以看到，这样发生发生的碰撞是非常多的，1,3,5,7,9,11,13都没有存放数据，空间减少，进一步增加碰撞几率，这样就会导致查询速度慢，分析一下：当length-1 = 14时，二进制的最后一位是0，在&amp;操作时，一个为0，无论另一个为1还是0，最终&amp;操作结果都是0，这就造成了结果的二进制的最后一位都是0，这就导致了所有数据都存储在2的倍数位上，所以说，所以说当length = 2^n时，不同的hash值发生碰撞的概率比较小，这样就会使得数据在table数组中分布较均匀，查询速度也较快。 然后我们来看看计算了hash值，并用该hash值来求得哈希表中的索引值之后，如何把该key-value插入到该索引的链表中：调用 addEntry(hash, key, value, i) 方法： 12345678910void addEntry(int hash, K key, V value, int bucketIndex) &#123; //如果size大于极限容量，将要进行重建内部数据结构操作，之后的容量是原来的两倍，并且重新设置hash值和hash值在table中的索引值 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; //真正创建Entry节点的操作 createEntry(hash, key, value, bucketIndex);&#125; 12345void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 首先取得bucketIndex位置的Entry头结点，并创建新节点，把该新节点插入到链表中的头部，该新节点的next指针指向原来的头结点 这里有两点需要注意：一、链的产生这是一个非常优雅的设计。系统总是将新的Entry对象添加到bucketIndex处。如果bucketIndex处已经有了对象，那么新添加的Entry对象将指向原有的Entry对象，形成一条Entry链，但是若bucketIndex处没有Entry对象，也就是e==null,那么新添加的Entry对象指向null，也就不会产生Entry链了。二、扩容问题还记得HashMap中的一个变量吗，threshold，这是容器的容量极限，还有一个变量size，这是指HashMap中键值对的数量，也就是node的数量 1threshold = (int)Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); 什么时候发生扩容？当不断添加key-value，size大于了容量极限threshold时，会发生扩容如何扩容？扩容发生在resize方法中，也就是扩大数组（桶）的数量，如何扩容参考：http://blog.csdn.net/jeffleo/article/details/63684953 我们重新来理一下存储的步骤： 传入key和value，判断key是否为null，如果为null，则调用putForNullKey，以null作为key存储到哈希表中； 然后计算key的hash值，根据hash值搜索在哈希表table中的索引位置，若当前索引位置不为null，则对该位置的Entry链表进行遍历，如果链中存在该key，则用传入的value覆盖掉旧的value，同时把旧的value返回，结束； 否则调用addEntry，用key-value创建一个新的节点，并把该节点插入到该索引对应的链表的头部 四：HashMap的读取实现get（key，value）123456789public V get(Object key) &#123; //如果key为null，求null键 if (key == null) return getForNullKey(); // 用该key求得entry Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue();&#125; 123456789101112final Entry&lt;K,V&gt; getEntry(Object key) &#123; int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; 读取的步骤比较简单，调用hash（key）求得key的hash值，然后调用indexFor（hash）求得hash值对应的table的索引位置，然后遍历索引位置的链表，如果存在key，则把key对应的Entry返回，否则返回null 五：HashMap键的遍历，keySet()HashMap遍历的核心代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private abstract class HashIterator&lt;E&gt; implements Iterator&lt;E&gt; &#123; Entry&lt;K,V&gt; next; // next entry to return int expectedModCount; // For fast-fail int index; // current slot Entry&lt;K,V&gt; current; // current entry //当调用keySet().iterator()时，调用此代码 HashIterator() &#123; expectedModCount = modCount; if (size &gt; 0) &#123; // advance to first entry Entry[] t = table; //从哈希表数组从上到下，查找第一个不为null的节点，并把next引用指向该节点 while (index &lt; t.length &amp;&amp; (next = t[index++]) == null) ; &#125; &#125; public final boolean hasNext() &#123; return next != null; &#125; //当调用next时，会调用此代码 final Entry&lt;K,V&gt; nextEntry() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); Entry&lt;K,V&gt; e = next; if (e == null) throw new NoSuchElementException(); //如果当前节点的下一个节点为null，从节点处罚往下查找哈希表，找到第一个不为null的节点 if ((next = e.next) == null) &#123; Entry[] t = table; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null) ; &#125; current = e; return e; &#125; public void remove() &#123; if (current == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); Object k = current.key; current = null; HashMap.this.removeEntryForKey(k); expectedModCount = modCount; &#125;&#125; 从这里可以看出，HashMap遍历时，按哈希表的每一个索引的链表从上往下遍历，由于HashMap的存储规则，最晚添加的节点都有可能在第一个索引的链表中，这就造成了HashMap的遍历时无序的。 参考：http://blog.csdn.net/jeffleo/article/details/54946424http://blog.csdn.net/ghsau/article/details/16843543http://blog.csdn.net/ghsau/article/details/16890151","tags":[]},{"title":"Docker容器部署Java web应用(定制镜像)","date":"2018-02-12T08:09:48.000Z","path":"2018/02/12/Docker容器部署Java-web应用方式二/","text":"概念简述 镜像 一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数。Docker镜像是一个只读的模板。比如一个镜像可以包含Ubuntu系统以及安装在Ubuntu上的Apache Web服务器和你自己的应用。镜像是用来创建容器的。Docker提供了一个简单的方式用以创建新的镜像或者更新现存的镜像，甚至你可以下载其他地方提供的镜像。镜像是Docker服务的组件之一。由于Docker使用一个统一文件系统，Docker镜像其实就是一堆文件的集合，并不是像VM那样的是一个操作系统。镜像可以简单到只有一个程序文件，比如如果你写了一个简单的hello world程序放到一个空的镜像中，那么整个镜像的大小，就是你编译后的二进制文件的大小。总结来说就是：镜像(image)是 Docker 的三大组件之一；镜像是用来启动容器的基石；镜像是只读的，也即是无状态的，一个镜像是永久不会变的；一个没有任何父镜像的镜像，称之为基础镜像;在Docker容器中所有的变更都发生顶层的镜像可写层;Docker 运行容器前需要本地存在对应的镜像，如果镜像不存在本地，Docker 会从镜像仓库下载（ 默认是 Docker Hub 公共注册服务器中的仓库）。 容器 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 仓库 镜像构建完成后，可以很容易的在当前宿主上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务 1)docker hub 2)私有仓库 Dockerfile 镜像的定制实际上就是定制每一层所添加的配置、文件。如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么之前提及的无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 数据卷 一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性: 数据卷可以在容器之间共享和重用 对数据卷的修改会立马生效 对数据卷的更新，不会影响镜像 数据卷默认会一直存在，即使容器被删除 创建docker镜像的两种方法 第一种:启动镜像后进入容器中操作,将需要的软件或者项目移动到容器中,安装或者部署,然后退出即可 第二种:编写dockerfile,将需要的镜像一层层叠加上去,比如我们要部署项目,可以先下载一个ubuntu基础镜像,然后叠加jdk,然后tomcat,然后项目 区别在于,第二种比较体现docker的镜像叠加特性,第一种到最终只有一层镜像.本文讲述第二种 环境准备（运行环境：Ubuntu 16.04） 安装jre：可参考1:http://blog.csdn.net/u010542873/article/details/516793732:http://www.linuxidc.com/Linux/2016-04/129731.htm 安装Tomcat：可参考：Tomcat9安装 在tomcat中部署webapp：可参考：http://www.linuxidc.com/Linux/2015-02/112887.htmIDEA集成样例可参考http://blog.csdn.net/yhao2014/article/details/45740111 Ubuntu 16.04安装docker：可参考 http://www.linuxidc.com/Linux/2016-12/138489.htm 利用DockerFile制定镜像通过编写Dockerfile的方式制作镜像。需要在Dockerfile中完成如下几项工作：（1）安装jre（2）安装tomcat，并完成在tomcat中部署web应用的基本配置（为实现此功能：在制作镜像之前直接先完成tomcat的基础配置，然后直接拷贝到镜像中即可）。（3）对外开发8080端口（具体的端口值可以根据实际Tomcat配置参数为准）。 $mkdir docker $cd docker 建立docker文件夹，并把之前下好的jre文件夹和tomcat文件夹（或者压缩包，均可）拖入其中，docker文件夹下目录如下： 编写Dockerfile文件补充：关于Dockerfile文件在容器中配置运行环境（此处是jre和tomcat）的任务主要是在容器中安装软件，并进行相应的配置，如果把这个过程所要执行的命令全都提取出来，写入一个文件中，若需要构建镜像则直接运行该文件，基于其中的命令生成一个镜像。这就是基于Dockerfile构建镜像的方式，这个文件就称为DockerfileDockerfile文件一共分为四个部分，分别是：注释信息、基础镜像、创建者信息、构建镜像所需的命令：详细介绍可参考：http://www.tuicool.com/articles/vqAVRrE或http://blog.csdn.net/wsscy2004/article/details/25878223Dockerfile文件内容如下：（以系统Ubuntu镜像为基础镜像） #Build java web app container image FROM ubuntu:16.04 MAINTAINER zhaokx3 &quot;zhaokx3@mail2.sysu.edu.cn&quot; #Make java and tomcat install directory RUN mkdir /usr/local/java RUN mkdir /usr/local/tomcat #Copy jre and tomcat into image ADD jre1.8.0_131 /usr/local/java/ ADD apache-tomcat-9.0.0.M21 /usr/local/tomcat/ ENV PATH $PATH:/usr/local/java/bin #Expose http port EXPOSE 8080 CMD [&quot;/usr/local/tomcat/bin/catalina.sh&quot;, &quot;run&quot;] 创建镜像sudo docker build -t=&quot;ubuntu/mine:tomcat&quot; . 启动容器sudo docker run -p 8090:8080 --name tomcat -v /home/zhaokx3/docker/webapps/:/webapps/ ubuntu/mine:tomcat 简要说明：参数-v指定挂载的卷，如没有可不使用，参数-p将8080端口映射成主机的8090端口，这样就可以访问主机的8090端口就到容器的8080端口。docker run 命令详解可参考：http://www.lupaworld.com/article-250439-1.html 最后成功通过http://localhost:8090/your_test 访问自己的web应用（端口8090）：可对比直接利用Tomcat部署web应用（端口8080）： 转载：http://blog.csdn.net/zhaokx3/article/details/72757527","tags":[{"name":"Docker","slug":"Docker","permalink":"http://wangyuanjun.cn/tags/Docker/"}]},{"title":"Docker容器部署Java web应用(容器基础上创建新镜像)","date":"2018-02-12T07:32:54.000Z","path":"2018/02/12/Docker容器部署Java-web应用/","text":"摘要：本文主要讲了如何在Ubuntu14.04 64位系统下来创建一个运行Java web应用程序的Docker容器。创建docker镜像的两种方法 第一种:启动镜像后进入容器中操作,将需要的软件或者项目移动到容器中,安装或者部署,然后退出即可 第二种:编写dockerfile,将需要的镜像一层层叠加上去,比如我们要部署项目,可以先下载一个ubuntu基础镜像,然后叠加jdk,然后tomcat,然后项目 区别在于,第二种比较体现docker的镜像叠加特性,第一种到最终只有一层镜像.本文讲述第一种 一：下载镜像、启动容器1、下载镜像先查看镜像 docker images 记住这个Image ID，下面我们启动容器需要用到它。如果看到以上输出，说明您可以使用“oursuer/ubuntu”这个镜像了，或将其称为仓库（Repository），该镜像有一个名为“14.04”的标签（Tag），此外还有一个名为1f879014f4d2 的镜像 ID（可能您所看到的镜像 ID 与此处的不一致，那是正常现象，因为这个数字是随机生成的）。此外，我们可以看到该镜像只有188.4 MB，非常小巧，而不像虚拟机的镜像文件那样庞大。现在镜像已经有了，我们下面就需要使用该镜像，来启动容器。 2、启动容器 容器是在镜像的基础上来运行的，一旦容器启动了，我们就可以登录到容器中，安装自己所需的软件或应用程序。既然镜像已经下载到本地，那么如何才能启动容器呢？只需使用以下命令即可启动容器： docker run -i -t -v /download/:/mnt/software/ 1f879014f4d2 /bin/bash 这条命令比较长，我们稍微分解一下，其实包含以下三个部分： docker run &lt;相关参数&gt; &lt;镜像 ID&gt; &lt;初始命令&gt; 如果看到以上输出，说明您可以使用“docker.cn/docker/centos”这个镜像了，或将其称为仓库（Repository），该镜像有一个名为“centos6”的标签（Tag），此外还有一个名为“25c5298b1a36 ”的镜像 ID（可能您所看到的镜像 ID 与此处的不一致，那是正常现象，因为这个数字是随机生成的）。此外，我们可以看到该镜像只有 215.8 MB，非常小巧，而不像虚拟机的镜像文件那样庞大。现在镜像已经有了，我们下面就需要使用该镜像，来启动容器。 其中，相关参数包括： -i：表示以“交互模式”运行容器 -t：表示容器启动后会进入其命令行 -v：表示需要将本地哪个目录挂载到容器中，格式：-v &lt;宿主机目录&gt;:&lt;容器目录&gt; 假设我们的所有安装程序都放在了宿主机的/download/目录下，现在需要将其挂载到容器的/mnt/software/目录下。需要说明的是，不一定要使用“镜像 ID”，也可以使用“仓库名:标签名”，例如：oursuer/ubuntu:14.04。初始命令表示一旦容器启动，需要运行的命令，此时使用“/bin/bash”，表示什么也不做，只需进入命令行即可。退出容器使用Ctrl+d或输入exit 如果退出容器后，可以再次使用命令（注意，得先运行docker run之后然后被stop掉的容器才可以使用如下命令） docker start 容器ID 其中容器ID。使用命令docker ps -a来看，如下： 然后再次启动已启动过但现在是关闭的容器 docker start sick_mestorf 如下： 二：安装相关软件首先先将JDK和tomcat的安装包.gz文件放在外面的/download文件夹下然后再次启动容器。进入容器然后看看是否有安装包。发现两个都在了，下面可以安装了 1、JDK安装 直接使用 cd /usr mkdir java cd java mkdir jdk cd /mnt/software/ tar zxvf jdk-8u65-linux-x64.gz -C /usr/java/jdk 这里直接接文件解压到/usr/java/jdk目录，如下 配置环境变量输入： vi /etc/profile 或添加如下内容： #set java environment export JAVA_HOME=/usr/java/jdk/jdk1.8.0_65 export JRE_HOME=/usr/java/jdk/jdk1.8.0_65/jre export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$JAVA_HOME:$PATH 注意此处改成对应的jdk的目录，并且要以root用户来做修改，否则无法保存保存后执行： source /etc/profile 验证安装：输入: java -version 如果出现如下内容，说明安装成功 2、tomcat安装 直接解压 cd /usr/java mkdir tomcat tar zxvf -C /usr/java/tomcat 配置环境进入到上面的tomcat的bin文件夹下：打开 vi setclasspath.sh 或 gedit setclasspath.sh 添加如下内容： export JAVA_HOME=/usr/java/jdk/jdk1.8.0_65 export JRE_HOME=/usr/java/jdk/jdk1.8.0_65/jre 保存即可。然后退回到bin目录下： 执行： ./startup.sh 说明tomcat启动成功或者使用如下命令查看： 三：配置容器启动环境变量（上面的JDK配置环境变量可以不要，但是这里的一定要写！！！！！！！！！！因为这里是设置容器启动时加载的环境变量） 1、设置环境变量 首先，编辑.bashrc文件 vi ~/.bashrc 然后，在该文件末尾添加如下配置： export JAVA_HOME=/usr/java/jdk/jdk1.8.0_65 export JRE_HOME=/usr/java/jdk/jdk1.8.0_65/jre export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$JAVA_HOME:$PATH 最后，需要使用source命令，让环境变量生效： source ~/.bashrc 2、编写运行脚本 我们需要编写一个运行脚本，当启动容器时，运行该脚本，启动 Tomcat，具体过程如下：首先，创建运行脚本： vi /root/run.sh 然后，编辑脚本内容如下： #!/bin/bash source ~/.bashrc sh /usr/java/tomcat/apache-tomcat-7.0.68/bin/catalina.sh run 注意：这里必须先加载环境变量，然后使用 Tomcat 的运行脚本来启动 Tomcat 服务。最后，为运行脚本添加执行权限： chmod u+x /root/run.sh 3、退出容器 当以上步骤全部完成后，可使用exit或ctrl+d命令，退出容器。随后，可使用如下命令查看正在运行的容器：docker ps此时，您应该看不到任何正在运行的程序，因为刚才已经使用exit命令退出的容器，此时容器处于停止状态，可使用如下命令查看所有容器：docker ps -a输出如下内容： 记住以上CONTAINER ID（容器 ID），随后我们将通过该容器，创建一个可运行 Java Web 的镜像。 四：创建 Java Web 镜像使用以下命令，根据某个“容器 ID”来创建一个新的“镜像”： docker commit 89a47b5b749e lin_javaweb:0.1 该容器的 ID 是“89a47b5b749e”，所创建的镜像名是“lin_javaweb:0.1”，随后可使用镜像来启动 Java Web 容器。这是创建成功后同样可以查看下镜像 五：启动 Java Web 容器有必要首先使用docker images命令，查看当前所有的镜像： 可见，此时已经看到了最新创建的镜像“lin_javaweb:0.1”，其镜像 ID 是“4487bd38df06”。正如上面所描述的那样，我们可以通过“镜像名”或“镜像 ID”来启动容器，与上次启动容器不同的是，我们现在不再进入容器的命令行，而是直接启动容器内部的 Tomcat 服务。此时，需要使用以下命令： docker run -d -p 58080:8080 --name javaweb lin_javaweb:0.1 /root/run.sh 稍作解释： -d：表示以“守护模式”执行/root/run.sh脚本，此时 Tomcat 控制台不会出现在输出终端上。 -p：表示宿主机与容器的端口映射，此时将容器内部的 8080 端口映射为宿主机的 58080 端口，这样就向外界暴露了 58080 端口，可通过 Docker 网桥来访问容器内部的 8080 端口了。 --name：表示容器名称，用一个有意义的名称命名即可。 关于 Docker 网桥的内容，需要补充说明一下。实际上 Docker 在宿主机与容器之间，搭建了一座网络通信的桥梁，我们可通过宿主机 IP 地址与端口号来映射容器内部的 IP 地址与端口号，在一系列参数后面的是“镜像名”或“镜像 ID”，怎么方便就怎么来。最后是“初始命令”，它是上面编写的运行脚本，里面封装了加载环境变量并启动 Tomcat 服务的命令。当运行以上命令后，会立即输出一长串“容器 ID”，我们可通过docker ps命令来查看当前正在运行的容器。 在浏览器中，输入以下地址，即可访问 Tomcat 首页：http://127.0.0.1:58080/ 或者 http://localhost:58080/注意：这里使用的是宿主机的 IP 地址，与对外暴露的端口号 58080，它映射容器内部的端口号 8080。 转载：http://blog.csdn.net/evankaka/article/details/50722788","tags":[{"name":"Docker","slug":"Docker","permalink":"http://wangyuanjun.cn/tags/Docker/"}]},{"title":"Shell脚本学习","date":"2018-02-11T03:40:37.000Z","path":"2018/02/11/Shell脚本学习/","text":"Shell脚本,就是利用Shell的命令解释的功能，对一个纯文本的文件进行解析，然后执行这些功能，也可以说Shell脚本就是一系列命令的集合。Shell可以直接使用在win/Unix/Linux上面，并且可以调用大量系统内部的功能来解释执行程序，如果熟练掌握Shell脚本，可以让我们操作计算机变得更加轻松，也会节省很多时间。 一：Shell应用场景Shell能做什么 将一些复杂的命令简单化(平时我们提交一次github代码可能需要很多步骤，但是可以用Shell简化成一步) 可以写一些脚本自动实现一个工程中自动更换最新的sdk(库) 自动打包、编译、发布等功能 清理磁盘中空文件夹 总之一切有规律的活脚本都可以尝试一下 Shell不能做什么 需要精密的运算的时候 需要语言效率很高的时候 需要一些网络操作的时候 总之Shell就是可以快速开发一个脚本简化开发流程，并不可以用来替代高级语言 Shell的工作原理Shell可以被称作是脚本语言，因为它本身是不需要编译的，而是通过解释器解释之后再编译执行，和传统语言相比多了解释的过程所以效率会略差于传统的直接编译的语言。 最简单的脚本:先来个简单的例子吧，也就是我们程序猿最长说的helloworld #!/bin/bash echo &quot;Hello World&quot; 只需要打开文本编辑工具，编辑成以上的样子,然后保存成test.sh 运行该脚本：1. cd 到该目录下 2. chmod +x ./test.sh #给脚本权限 3. ./test.sh #执行脚本 二：shell变量定义变量时，变量名不加美元符号（$，PHP语言中变量需要），如： your_name=”runoob.com” 注意，变量名和等号之间不能有空格，这可能和你熟悉的所有编程语言都不一样。同时，变量名的命名须遵循如下规则： 命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。中间不能有空格，可以使用下划线（_）。不能使用标点符号。不能使用bash里的关键字（可用help命令查看保留关键字）。 使用变量使用一个定义过的变量，只要在变量名前面加美元符号即可，如： your_name=&quot;qinjx&quot; echo $your_name echo ${your_name} 只读变量使用 readonly 命令可以将变量定义为只读变量，只读变量的值不能被改变。下面的例子尝试更改只读变量，结果报错： #!/bin/bash myUrl=&quot;http://www.w3cschool.cc&quot; readonly myUrl myUrl=&quot;http://www.runoob.com&quot; 运行脚本，结果如下： /bin/sh: NAME: This variable is read only. 删除变量变量被删除后不能再次使用。unset 命令不能删除只读变量。 unset variable_name 三：Shell 传递参数我们可以在执行 Shell 脚本时，向脚本传递参数，脚本内获取参数的格式为：$n。n 代表一个数字，1 为执行脚本的第一个参数，2 为执行脚本的第二个参数，以此类推…… 实例以下实例我们向脚本传递三个参数，并分别输出，其中 $0 为执行的文件名： #!/bin/bash # author:菜鸟教程 # url:www.runoob.com echo &quot;Shell 传递参数实例！&quot;; echo &quot;执行的文件名：$0&quot;; echo &quot;第一个参数为：$1&quot;; echo &quot;第二个参数为：$2&quot;; echo &quot;第三个参数为：$3&quot;; 为脚本设置可执行权限，并执行脚本，输出结果如下所示： $ chmod +x test.sh $ ./test.sh 1 2 3 Shell 传递参数实例！ 执行的文件名：./test.sh 第一个参数为：1 第二个参数为：2 第三个参数为：3 另外，还有几个特殊字符用来处理参数： 参数处理 说明 $# 传递到脚本的参数个数 $* 以一个单字符串显示所有向脚本传递的参数。如”$*”用「”」括起来的情况、以”$1 $2 … $n”的形式输出所有参数。 $$ 脚本运行的当前进程ID号 $! 后台运行的最后一个进程的ID号 $@ 与$*相同，但是使用时加引号，并在引号中返回每个参数。如”$@”用「”」括起来的情况、以”$1” “$2” … “$n” 的形式输出所有参数。 $- 显示Shell使用的当前选项，与set命令功能相同。 $? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。 #!/bin/bash # author:菜鸟教程 # url:www.runoob.com echo &quot;Shell 传递参数实例！&quot;; echo &quot;第一个参数为：$1&quot;; echo &quot;参数个数为：$#&quot;; echo &quot;传递的参数作为一个字符串显示：$*&quot;; 执行脚本，输出结果如下所示： $ chmod +x test.sh $ ./test.sh 1 2 3 Shell 传递参数实例！ 第一个参数为：1 参数个数为：3 传递的参数作为一个字符串显示：1 2 3 $* 与 $@ 区别： 相同点：都是引用所有参数。 不同点：只有在双引号中体现出来。假设在脚本运行时写了三个参数 1、2、3，，则 “ * “ 等价于 “1 2 3”（传递了一个参数），而 “@” 等价于 “1” “2” “3”（传递了三个参数）。 #!/bin/bash # author:菜鸟教程 # url:www.runoob.com echo &quot;-- \\$* 演示 ---&quot; for i in &quot;$*&quot;; do echo $i done echo &quot;-- \\$@ 演示 ---&quot; for i in &quot;$@&quot;; do echo $i done 执行脚本，输出结果如下所示： $ chmod +x test.sh $ ./test.sh 1 2 3 -- $* 演示 --- 1 2 3 -- $@ 演示 --- 1 2 3 四：shell数组定义数组在Shell中，用括号来表示数组，数组元素用”空格”符号分割开。定义数组的一般形式为：数组名=(值1 值2 … 值n)例如： 在Shell中，用括号来表示数组，数组元素用”空格”符号分割开。定义数组的一般形式为： 数组名=(值1 值2 ... 值n) 例如： array_name=(value0 value1 value2 value3) 或者 array_name=( value0 value1 value2 value3 ) 还可以单独定义数组的各个分量： array_name[0]=value0 array_name[1]=value1 array_name[n]=valuen 可以不使用连续的下标，而且下标的范围没有限制。 读取数组读取数组元素值的一般格式是： ${数组名[下标]} 例如： valuen=${array_name[n]} 使用@符号可以获取数组中的所有元素，例如： echo ${array_name[@]} 获取数组的长度获取数组长度的方法与获取字符串长度的方法相同，例如： # 取得数组元素的个数 length=${#array_name[@]} # 或者 length=${#array_name[*]} # 取得数组单个元素的长度 lengthn=${#array_name[n]} Shell 注释以”#”开头的行就是注释，会被解释器忽略。 sh里没有多行注释，只能每一行加一个#号。只能像这样： #-------------------------------------------- # 这是一个注释 # author：菜鸟教程 # site：www.runoob.com # slogan：学的不仅是技术，更是梦想！ #-------------------------------------------- ##### 用户配置区 开始 ##### # # # 这里可以添加脚本描述信息 # # ##### 用户配置区 结束 ##### 五：基本运算符Shell 和其他编程语言一样，支持多种运算符，包括： 算数运算符 关系运算符 布尔运算符 字符串运算符 文件测试运算符 原生bash不支持简单的数学运算，但是可以通过其他命令来实现，例如 awk 和 expr，expr 最常用。 expr 是一款表达式计算工具，使用它能完成表达式的求值操作。 例如，两个数相加(注意使用的是反引号 ` 而不是单引号 ‘)： #!/bin/bash val=`expr 2 + 2` echo &quot;两数之和为 : $val&quot; 执行脚本，输出结果如下所示： 两数之和为 : 4 两点注意： 表达式和运算符之间要有空格，例如 2+2 是不对的，必须写成 2 + 2，这与我们熟悉的大多数编程语言不一样。 完整的表达式要被 `` 包含，注意这个字符不是常用的单引号，在 Esc 键下边。 算术运算符下表列出了常用的算术运算符，假定变量 a 为 10，变量 b 为 20： 运算符 说明 举例 + 加法 expr $a + $b 结果为 30。 - 减法 expr $a - $b 结果为 -10。 * 乘法 expr $a \\* $b 结果为 200。 / 除法 expr $b / $a 结果为 2。 % 取余 expr $b % $a 结果为 0。 = 赋值 a=$b 将把变量 b 的值赋给 a。 == 相等。用于比较两个数字，相同则返回 true。 [ $a == $b ] 返回 false。 != 不相等。用于比较两个数字，不相同则返回 true。 [ $a != $b ] 返回 true。 注意：条件表达式要放在方括号之间，并且要有空格，例如: [$a==$b] 是错误的，必须写成 [ $a == $b ]。 实例算术运算符实例如下： #!/bin/bash # author:菜鸟教程 # url:www.runoob.com a=10 b=20 val=`expr $a + $b` echo &quot;a + b : $val&quot; val=`expr $a - $b` echo &quot;a - b : $val&quot; val=`expr $a \\* $b` echo &quot;a * b : $val&quot; val=`expr $b / $a` echo &quot;b / a : $val&quot; val=`expr $b % $a` echo &quot;b % a : $val&quot; if [ $a == $b ] then echo &quot;a 等于 b&quot; fi if [ $a != $b ] then echo &quot;a 不等于 b&quot; fi 执行脚本，输出结果如下所示： a + b : 30 a - b : -10 a * b : 200 b / a : 2 b % a : 0 a 不等于 b 注意： 乘号(*)前边必须加反斜杠()才能实现乘法运算； if…then…fi 是条件语句，后续将会讲解。 在 MAC 中 shell 的 expr 语法是：$((表达式))，此处表达式中的 “*” 不需要转义符号 “\\” 。 关系运算符关系运算符只支持数字，不支持字符串，除非字符串的值是数字。 下表列出了常用的关系运算符，假定变量 a 为 10，变量 b 为 20： 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 ###实例关系运算符实例如下： #!/bin/bash # author:菜鸟教程 # url:www.runoob.com a=10 b=20 if [ $a -eq $b ] then echo &quot;$a -eq $b : a 等于 b&quot; else echo &quot;$a -eq $b: a 不等于 b&quot; fi if [ $a -ne $b ] then echo &quot;$a -ne $b: a 不等于 b&quot; else echo &quot;$a -ne $b : a 等于 b&quot; fi if [ $a -gt $b ] then echo &quot;$a -gt $b: a 大于 b&quot; else echo &quot;$a -gt $b: a 不大于 b&quot; fi if [ $a -lt $b ] then echo &quot;$a -lt $b: a 小于 b&quot; else echo &quot;$a -lt $b: a 不小于 b&quot; fi if [ $a -ge $b ] then echo &quot;$a -ge $b: a 大于或等于 b&quot; else echo &quot;$a -ge $b: a 小于 b&quot; fi if [ $a -le $b ] then echo &quot;$a -le $b: a 小于或等于 b&quot; else echo &quot;$a -le $b: a 大于 b&quot; fi 执行脚本，输出结果如下所示： 10 -eq 20: a 不等于 b 10 -ne 20: a 不等于 b 10 -gt 20: a 不大于 b 10 -lt 20: a 小于 b 10 -ge 20: a 小于 b 10 -le 20: a 小于或等于 b 布尔运算符下表列出了常用的布尔运算符，假定变量 a 为 10，变量 b 为 20： 运算符 说明 举例 ! 非运算，表达式为 true 则返回 false，否则返回 true。 [ ! false ] 返回 true。 -o 或运算，有一个表达式为 true 则返回 true。 [ $a -lt 20 -o $b -gt 100 ] 返回 true。 -a 与运算，两个表达式都为 true 才返回 true。 [ $a -lt 20 -a $b -gt 100 ] 返回 false。 实例布尔运算符实例如下： #!/bin/bash # author:菜鸟教程 # url:www.runoob.com a=10 b=20 if [ $a != $b ] then echo &quot;$a != $b : a 不等于 b&quot; else echo &quot;$a != $b: a 等于 b&quot; fi if [ $a -lt 100 -a $b -gt 15 ] then echo &quot;$a 小于 100 且 $b 大于 15 : 返回 true&quot; else echo &quot;$a 小于 100 且 $b 大于 15 : 返回 false&quot; fi if [ $a -lt 100 -o $b -gt 100 ] then echo &quot;$a 小于 100 或 $b 大于 100 : 返回 true&quot; else echo &quot;$a 小于 100 或 $b 大于 100 : 返回 false&quot; fi if [ $a -lt 5 -o $b -gt 100 ] then echo &quot;$a 小于 5 或 $b 大于 100 : 返回 true&quot; else echo &quot;$a 小于 5 或 $b 大于 100 : 返回 false&quot; fi 执行脚本，输出结果如下所示： 10 != 20 : a 不等于 b 10 小于 100 且 20 大于 15 : 返回 true 10 小于 100 或 20 大于 100 : 返回 true 10 小于 5 或 20 大于 100 : 返回 false 逻辑运算符以下介绍 Shell 的逻辑运算符，假定变量 a 为 10，变量 b 为 20: 运算符 说明 举例 &amp;&amp; 逻辑的 AND [[ $a -lt 100 &amp;&amp; $b -gt 100 ]] 返回 false ll 逻辑的 OR [[ $a -lt 100 ll $b -gt 100 ]] 返回 true 实例逻辑运算符实例如下： #!/bin/bash # author:菜鸟教程 # url:www.runoob.com a=10 b=20 if [[ $a -lt 100 &amp;&amp; $b -gt 100 ]] then echo &quot;返回 true&quot; else echo &quot;返回 false&quot; fi if [[ $a -lt 100 || $b -gt 100 ]] then echo &quot;返回 true&quot; else echo &quot;返回 false&quot; fi 执行脚本，输出结果如下所示： 返回 false 返回 true 字符串运算符下表列出了常用的字符串运算符，假定变量 a 为 “abc”，变量 b 为 “efg”： 运算符 说明 举例 = 检测两个字符串是否相等，相等返回 true。 [ $a = $b ] 返回 false。 != 检测两个字符串是否相等，不相等返回 true。 [ $a != $b ] 返回 true。 -z 检测字符串长度是否为0，为0返回 true。 [ -z $a ] 返回 false。 -n 检测字符串长度是否为0，不为0返回 true。 [ -n $a ] 返回 true。 str 检测字符串是否为空，不为空返回 true。 [ $a ] 返回 true。 实例字符串运算符实例如下： #!/bin/bash # author:菜鸟教程 # url:www.runoob.com a=&quot;abc&quot; b=&quot;efg&quot; if [ $a = $b ] then echo &quot;$a = $b : a 等于 b&quot; else echo &quot;$a = $b: a 不等于 b&quot; fi if [ $a != $b ] then echo &quot;$a != $b : a 不等于 b&quot; else echo &quot;$a != $b: a 等于 b&quot; fi if [ -z $a ] then echo &quot;-z $a : 字符串长度为 0&quot; else echo &quot;-z $a : 字符串长度不为 0&quot; fi if [ -n $a ] then echo &quot;-n $a : 字符串长度不为 0&quot; else echo &quot;-n $a : 字符串长度为 0&quot; fi if [ $a ] then echo &quot;$a : 字符串不为空&quot; else echo &quot;$a : 字符串为空&quot; fi 执行脚本，输出结果如下所示： abc = efg: a 不等于 b abc != efg : a 不等于 b -z abc : 字符串长度不为 0 -n abc : 字符串长度不为 0 abc : 字符串不为空 文件测试运算符文件测试运算符用于检测 Unix 文件的各种属性。 属性检测描述如下： 操作符 说明 举例 -b file 检测文件是否是块设备文件，如果是，则返回 true。 [ -b $file ] 返回 false。 -c file 检测文件是否是字符设备文件，如果是，则返回 true。 [ -c $file ] 返回 false。 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -g file 检测文件是否设置了 SGID 位，如果是，则返回 true。 [ -g $file ] 返回 false。 -k file 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。 [ -k $file ] 返回 false。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -u file 检测文件是否设置了 SUID 位，如果是，则返回 true。 [ -u $file ] 返回 false。 -r file 检测文件是否可读，如果是，则返回 true。 [ -r $file ] 返回 true。 -w file 检测文件是否可写，如果是，则返回 true。 [ -w $file ] 返回 true。 -x file 检测文件是否可执行，如果是，则返回 true。 [ -x $file ] 返回 true。 -s file 检测文件是否为空（文件大小是否大于0），不为空返回 true。 [ -s $file ] 返回 true。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 实例变量 file 表示文件”/var/www/runoob/test.sh”，它的大小为100字节，具有 rwx 权限。下面的代码，将检测该文件的各种属性： #!/bin/bash # author:菜鸟教程 # url:www.runoob.com file=&quot;/var/www/runoob/test.sh&quot; if [ -r $file ] then echo &quot;文件可读&quot; else echo &quot;文件不可读&quot; fi if [ -w $file ] then echo &quot;文件可写&quot; else echo &quot;文件不可写&quot; fi if [ -x $file ] then echo &quot;文件可执行&quot; else echo &quot;文件不可执行&quot; fi if [ -f $file ] then echo &quot;文件为普通文件&quot; else echo &quot;文件为特殊文件&quot; fi if [ -d $file ] then echo &quot;文件是个目录&quot; else echo &quot;文件不是个目录&quot; fi if [ -s $file ] then echo &quot;文件不为空&quot; else echo &quot;文件为空&quot; fi if [ -e $file ] then echo &quot;文件存在&quot; else echo &quot;文件不存在&quot; fi 执行脚本，输出结果如下所示： 文件可读 文件可写 文件可执行 文件为普通文件 文件不是个目录 文件不为空 文件存在 六：Shell test 命令Shell中的 test 命令用于检查某个条件是否成立，它可以进行数值、字符和文件三个方面的测试。 数值测试 参数 说明 -eq 等于则为真 -ne 不等于则为真 -gt 大于则为真 -ge 大于等于则为真 -lt 小于则为真 -le 小于等于则为真 实例演示： num1=100 num2=100 if test $[num1] -eq $[num2] then echo &apos;两个数相等！&apos; else echo &apos;两个数不相等！&apos; fi 输出结果： 两个数相等！ 代码中的 [] 执行基本的算数运算，如： #!/bin/bash a=5 b=6 result=$[a+b] # 注意等号两边不能有空格 echo &quot;result 为： $result&quot; 结果为: result 为： 11 字符串测试 参数 说明 = 等于则为真 != 不相等则为真 -z 字符串 字符串的长度为零则为真 -n 字符串 字符串的长度不为零则为真 实例演示：num1=&quot;ru1noob&quot; num2=&quot;runoob&quot; if test $num1 = $num2 then echo &apos;两个字符串相等!&apos; else echo &apos;两个字符串不相等!&apos; fi 输出结果： 两个字符串不相等! 文件测试 参数 说明 -e 文件名 如果文件存在则为真 -r 文件名 如果文件存在且可读则为真 -w 文件名 如果文件存在且可写则为真 -x 文件名 如果文件存在且可执行则为真 -s 文件名 如果文件存在且至少有一个字符则为真 -d 文件名 如果文件存在且为目录则为真 -f 文件名 如果文件存在且为普通文件则为真 -c 文件名 如果文件存在且为字符型特殊文件则为真 -b 文件名 如果文件存在且为块特殊文件则为真 实例演示：cd /bin if test -e ./bash then echo &apos;文件已存在!&apos; else echo &apos;文件不存在!&apos; fi 输出结果： 文件已存在! 另外，Shell还提供了与( -a )、或( -o )、非( ! )三个逻辑操作符用于将测试条件连接起来，其优先级为：”!”最高，”-a”次之，”-o”最低。例如： cd /bin if test -e ./notFile -o -e ./bash then echo &apos;至少有一个文件存在!&apos; else echo &apos;两个文件都不存在&apos; fi 输出结果： 有一个文件存在! 七：Shell 流程控制和Java、PHP等语言不一样，sh的流程控制不可为空，如(以下为PHP流程控制写法)： &lt;?php if (isset($_GET[&quot;q&quot;])) { search(q); } else { // 不做任何事情 } 在sh/bash里可不能这么写，如果else分支没有语句执行，就不要写这个else。 if elseifif 语句语法格式： if condition then command1 command2 ... commandN fi 写成一行（适用于终端命令提示符）： if [ $(ps -ef | grep -c &quot;ssh&quot;) -gt 1 ]; then echo &quot;true&quot;; fi 末尾的fi就是if倒过来拼写，后面还会遇到类似的。 if elseif else 语法格式： if condition then command1 command2 ... commandN else command fi if else-if elseif else-if else 语法格式： if condition1 then command1 elif condition2 then command2 else commandN fi 以下实例判断两个变量是否相等： a=10 b=20 if [ $a == $b ] then echo &quot;a 等于 b&quot; elif [ $a -gt $b ] then echo &quot;a 大于 b&quot; elif [ $a -lt $b ] then echo &quot;a 小于 b&quot; else echo &quot;没有符合的条件&quot; fi 输出结果： a 小于 b if else语句经常与test命令结合使用，如下所示： num1=$[2*3] num2=$[1+5] if test $[num1] -eq $[num2] then echo &apos;两个数字相等!&apos; else echo &apos;两个数字不相等!&apos; fi 输出结果： 两个数字相等! for 循环与其他编程语言类似，Shell支持for循环。 for循环一般格式为： for var in item1 item2 ... itemN do command1 command2 ... commandN done 写成一行： for var in item1 item2 ... itemN; do command1; command2… done; 当变量值在列表里，for循环即执行一次所有命令，使用变量名获取列表中的当前取值。命令可为任何有效的shell命令和语句。in列表可以包含替换、字符串和文件名。 in列表是可选的，如果不用它，for循环使用命令行的位置参数。 例如，顺序输出当前列表中的数字： for loop in 1 2 3 4 5 do echo &quot;The value is: $loop&quot; done 输出结果： The value is: 1 The value is: 2 The value is: 3 The value is: 4 The value is: 5 顺序输出字符串中的字符： for str in &apos;This is a string&apos; do echo $str done 输出结果： This is a string while 语句while循环用于不断执行一系列命令，也用于从输入文件中读取数据；命令通常为测试条件。其格式为： while condition do command done 以下是一个基本的while循环，测试条件是：如果int小于等于5，那么条件返回真。int从0开始，每次循环处理时，int加1。运行上述脚本，返回数字1到5，然后终止。 #!/bin/sh int=1 while(( $int&lt;=5 )) do echo $int let &quot;int++&quot; done 运行脚本，输出： 1 2 3 4 5 使用中使用了 Bash let 命令，它用于执行一个或多个表达式，变量计算中不需要加上 $ 来表示变量，具体可查阅：Bash let 命令 。while循环可用于读取键盘信息。下面的例子中，输入信息被设置为变量FILM，按结束循环。 echo &apos;按下 &lt;CTRL-D&gt; 退出&apos; echo -n &apos;输入你最喜欢的网站名: &apos; while read FILM do echo &quot;是的！$FILM 是一个好网站&quot; done 运行脚本，输出类似下面： 按下 &lt;CTRL-D&gt; 退出 输入你最喜欢的网站名:菜鸟教程 是的！菜鸟教程 是一个好网站 无限循环无限循环语法格式： while : do command done 或者 while true do command done 或者 for (( ; ; )) until 循环until循环执行一系列命令直至条件为真时停止。 until循环与while循环在处理方式上刚好相反。 一般while循环优于until循环，但在某些时候—也只是极少数情况下，until循环更加有用。 until 语法格式: until condition do command done 条件可为任意测试条件，测试发生在循环末尾，因此循环至少执行一次—请注意这一点。 caseShell case语句为多选择语句。可以用case语句匹配一个值与一个模式，如果匹配成功，执行相匹配的命令。case语句格式如下： case 值 in 模式1) command1 command2 ... commandN ;; 模式2） command1 command2 ... commandN ;; esac case工作方式如上所示。取值后面必须为单词in，每一模式必须以右括号结束。取值可以为变量或常数。匹配发现取值符合某一模式后，其间所有命令开始执行直至 ;;。 取值将检测匹配的每一个模式。一旦模式匹配，则执行完匹配模式相应命令后不再继续其他模式。如果无一匹配模式，使用星号 * 捕获该值，再执行后面的命令。 下面的脚本提示输入1到4，与每一种模式进行匹配： echo &apos;输入 1 到 4 之间的数字:&apos; echo &apos;你输入的数字为:&apos; read aNum case $aNum in 1) echo &apos;你选择了 1&apos; ;; 2) echo &apos;你选择了 2&apos; ;; 3) echo &apos;你选择了 3&apos; ;; 4) echo &apos;你选择了 4&apos; ;; *) echo &apos;你没有输入 1 到 4 之间的数字&apos; ;; esac 输入不同的内容，会有不同的结果，例如： 输入 1 到 4 之间的数字: 你输入的数字为: 3 你选择了 3 跳出循环在循环过程中，有时候需要在未达到循环结束条件时强制跳出循环，Shell使用两个命令来实现该功能：break和continue。 break命令break命令允许跳出所有循环（终止执行后面的所有循环）。 下面的例子中，脚本进入死循环直至用户输入数字大于5。要跳出这个循环，返回到shell提示符下，需要使用break命令。 #!/bin/bash while : do echo -n &quot;输入 1 到 5 之间的数字:&quot; read aNum case $aNum in 1|2|3|4|5) echo &quot;你输入的数字为 $aNum!&quot; ;; *) echo &quot;你输入的数字不是 1 到 5 之间的! 游戏结束&quot; break ;; esac done 执行以上代码，输出结果为： 输入 1 到 5 之间的数字:3 你输入的数字为 3! 输入 1 到 5 之间的数字:7 你输入的数字不是 1 到 5 之间的! 游戏结束 continuecontinue命令与break命令类似，只有一点差别，它不会跳出所有循环，仅仅跳出当前循环。 对上面的例子进行修改： #!/bin/bash while : do echo -n &quot;输入 1 到 5 之间的数字: &quot; read aNum case $aNum in 1|2|3|4|5) echo &quot;你输入的数字为 $aNum!&quot; ;; *) echo &quot;你输入的数字不是 1 到 5 之间的!&quot; continue echo &quot;游戏结束&quot; ;; esac done 运行代码发现，当输入大于5的数字时，该例中的循环不会结束，语句 echo “Game is over!” 永远不会被执行。 esaccase的语法和C family语言差别很大，它需要一个esac（就是case反过来）作为结束标记，每个case分支用右圆括号，用两个分号表示break。 八：Shell 函数linux shell 可以用户定义函数，然后在shell脚本中可以随便调用。 shell中函数的定义格式如下： [ function ] funname [()] { action; [return int;] } 说明： 1、可以带function fun() 定义，也可以直接fun() 定义,不带任何参数。2、参数返回，可以显示加：return 返回，如果不加，将以最后一条命令运行结果，作为返回值。 return后跟数值n(0-255下面的例子定义了一个函数并进行调用： #!/bin/bash # author:菜鸟教程 # url:www.runoob.com demoFun(){ echo &quot;这是我的第一个 shell 函数!&quot; } echo &quot;-----函数开始执行-----&quot; demoFun echo &quot;-----函数执行完毕-----&quot; 输出结果： -----函数开始执行----- 这是我的第一个 shell 函数! -----函数执行完毕----- 下面定义一个带有return语句的函数： #!/bin/bash # author:菜鸟教程 # url:www.runoob.com funWithReturn(){ echo &quot;这个函数会对输入的两个数字进行相加运算...&quot; echo &quot;输入第一个数字: &quot; read aNum echo &quot;输入第二个数字: &quot; read anotherNum echo &quot;两个数字分别为 $aNum 和 $anotherNum !&quot; return $(($aNum+$anotherNum)) } funWithReturn echo &quot;输入的两个数字之和为 $? !&quot; 输出类似下面： 这个函数会对输入的两个数字进行相加运算... 输入第一个数字: 1 输入第二个数字: 2 两个数字分别为 1 和 2 ! 输入的两个数字之和为 3 ! 函数返回值在调用该函数后通过 $? 来获得。 注意：所有函数在使用前必须定义。这意味着必须将函数放在脚本开始部分，直至shell解释器首次发现它时，才可以使用。调用函数仅使用其函数名即可。 函数参数在Shell中，调用函数时可以向其传递参数。在函数体内部，通过 $n 的形式来获取参数的值，例如，$1表示第一个参数，$2表示第二个参数… 带参数的函数示例： #!/bin/bash # author:菜鸟教程 # url:www.runoob.com funWithParam(){ echo &quot;第一个参数为 $1 !&quot; echo &quot;第二个参数为 $2 !&quot; echo &quot;第十个参数为 $10 !&quot; echo &quot;第十个参数为 ${10} !&quot; echo &quot;第十一个参数为 ${11} !&quot; echo &quot;参数总数有 $# 个!&quot; echo &quot;作为一个字符串输出所有参数 $* !&quot; } funWithParam 1 2 3 4 5 6 7 8 9 34 73 输出结果： 第一个参数为 1 ! 第二个参数为 2 ! 第十个参数为 10 ! 第十个参数为 34 ! 第十一个参数为 73 ! 参数总数有 11 个! 作为一个字符串输出所有参数 1 2 3 4 5 6 7 8 9 34 73 ! 注意，$10 不能获取第十个参数，获取第十个参数需要${10}。当n&gt;=10时，需要使用${n}来获取参数。 另外，还有几个特殊字符用来处理参数： 参数处理 说明 $# 传递到脚本的参数个数 $* 以一个单字符串显示所有向脚本传递的参数 $$ 脚本运行的当前进程ID号 $! 后台运行的最后一个进程的ID号 $@ 与$*相同，但是使用时加引号，并在引号中返回每个参数。 $- 显示Shell使用的当前选项，与set命令功能相同。 $? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。 九：Shell 输入/输出重定向大多数 UNIX 系统命令从你的终端接受输入并将所产生的输出发送回​​到您的终端。一个命令通常从一个叫标准输入的地方读取输入，默认情况下，这恰好是你的终端。同样，一个命令通常将其输出写入到标准输出，默认情况下，这也是你的终端。 重定向命令列表如下： 命令 说明 command &gt; file 将输出重定向到 file。 command &lt; file 将输入重定向到 file。 command &gt;&gt; file 将输出以追加的方式重定向到 file。 n &gt; file 将文件描述符为 n 的文件重定向到 file。 n &gt;&gt; file 将文件描述符为 n 的文件以追加的方式重定向到 file。 n &gt;&amp; m 将输出文件 m 和 n 合并。 n &lt;&amp; m 将输入文件 m 和 n 合并。 &lt;&lt; tag 将开始标记 tag 和结束标记 tag 之间的内容作为输入。 需要注意的是文件描述符 0 通常是标准输入（STDIN），1 是标准输出（STDOUT），2 是标准错误输出（STDERR）。 输出重定向重定向一般通过在命令间插入特定的符号来实现。特别的，这些符号的语法如下所示: command1 &gt; file1 上面这个命令执行command1然后将输出的内容存入file1。 注意任何file1内的已经存在的内容将被新内容替代。如果要将新内容添加在文件末尾，请使用&gt;&gt;操作符。 实例执行下面的 who 命令，它将命令的完整的输出重定向在用户文件中(users): $ who &gt; users 执行后，并没有在终端输出信息，这是因为输出已被从默认的标准输出设备（终端）重定向到指定的文件。 你可以使用 cat 命令查看文件内容： $ cat users _mbsetupuser console Oct 31 17:35 tianqixin console Oct 31 17:35 tianqixin ttys000 Dec 1 11:33 输出重定向会覆盖文件内容，请看下面的例子： $ echo &quot;菜鸟教程：www.runoob.com&quot; &gt; users $ cat users 菜鸟教程：www.runoob.com $ 如果不希望文件内容被覆盖，可以使用 &gt;&gt; 追加到文件末尾，例如： $ echo &quot;菜鸟教程：www.runoob.com&quot; &gt;&gt; users $ cat users 菜鸟教程：www.runoob.com 菜鸟教程：www.runoob.com $ 输入重定向和输出重定向一样，Unix 命令也可以从文件获取输入，语法为： command1 &lt; file1 这样，本来需要从键盘获取输入的命令会转移到文件读取内容。 注意：输出重定向是大于号(&gt;)，输入重定向是小于号(&lt;)。 实例接着以上实例，我们需要统计 users 文件的行数,执行以下命令： $ wc -l users 2 users 也可以将输入重定向到 users 文件： $ wc -l &lt; users 2 注意：上面两个例子的结果不同：第一个例子，会输出文件名；第二个不会，因为它仅仅知道从标准输入读取内容。 command1 &lt; infile &gt; outfile 同时替换输入和输出，执行command1，从文件infile读取内容，然后将输出写入到outfile中。 重定向深入讲解一般情况下，每个 Unix/Linux 命令运行时都会打开三个文件： 标准输入文件(stdin)：stdin的文件描述符为0，Unix程序默认从stdin读取数据。 标准输出文件(stdout)：stdout 的文件描述符为1，Unix程序默认向stdout输出数据。 标准错误文件(stderr)：stderr的文件描述符为2，Unix程序会向stderr流中写入错误信息。 默认情况下，command &gt; file 将 stdout 重定向到 file，command &lt; file 将stdin 重定向到 file。 如果希望 stderr 重定向到 file，可以这样写： $ command 2 &gt; file 如果希望 stderr 追加到 file 文件末尾，可以这样写： $ command 2 &gt;&gt; file 2 表示标准错误文件(stderr)。 如果希望将 stdout 和 stderr 合并后重定向到 file，可以这样写： $ command &gt; file 2&gt;&amp;1 或者 $ command &gt;&gt; file 2&gt;&amp;1 如果希望对 stdin 和 stdout 都重定向，可以这样写： $ command &lt; file1 &gt;file2 command 命令将 stdin 重定向到 file1，将 stdout 重定向到 file2。 Here DocumentHere Document 是 Shell 中的一种特殊的重定向方式，用来将输入重定向到一个交互式 Shell 脚本或程序。 它的基本的形式如下： command &lt;&lt; delimiter document delimiter 它的作用是将两个 delimiter 之间的内容(document) 作为输入传递给 command。 注意： 结尾的delimiter 一定要顶格写，前面不能有任何字符，后面也不能有任何字符，包括空格和 tab 缩进。 开始的delimiter前后的空格会被忽略掉。 实例在命令行中通过 wc -l 命令计算 Here Document 的行数： $ wc -l &lt;&lt; EOF 欢迎来到 菜鸟教程 www.runoob.com EOF 3 # 输出结果为 3 行 $ 我们也可以将 Here Document 用在脚本中，例如： #!/bin/bash # author:菜鸟教程 # url:www.runoob.com cat &lt;&lt; EOF 欢迎来到 菜鸟教程 www.runoob.com EOF 执行以上脚本，输出结果： 欢迎来到 菜鸟教程 www.runoob.com /dev/null 文件如果希望执行某个命令，但又不希望在屏幕上显示输出结果，那么可以将输出重定向到 /dev/null： $ command &gt; /dev/null /dev/null 是一个特殊的文件，写入到它的内容都会被丢弃；如果尝试从该文件读取内容，那么什么也读不到。但是 /dev/null 文件非常有用，将命令的输出重定向到它，会起到”禁止输出”的效果。 如果希望屏蔽 stdout 和 stderr，可以这样写： $ command &gt; /dev/null 2&gt;&amp;1 注意：0 是标准输入（STDIN），1 是标准输出（STDOUT），2 是标准错误输出（STDERR）。","tags":[{"name":"shell","slug":"shell","permalink":"http://wangyuanjun.cn/tags/shell/"}]},{"title":"MySQL读写分离详解与实践","date":"2018-02-11T03:38:51.000Z","path":"2018/02/11/MySQL读写分离详解与实践/","text":"一：mysql读写分离原理MySQL的主从复制和MySQL的读写分离两者有着紧密联系，首先部署主从复制，只有主从复制完了，才能在此基础上进行数据的读写分离。简单来说，读写分离就是只在主服务器上写，只在从服务器上读，基本的原理是让主数据库处理事务性操作，而从数据库处理非事务性操作，然后再采用主从复制来把master上的事务性操作同步到slave数据库中。 1.基于程序代码内部实现在代码中根据select,insert进行路由分类，这类方法也是目前生产环境应用最广泛的，优点是性能好，因为在程序代码中实现，不需要曾加额外的设备作为硬件开支，缺点是需要开发人员来实现，运维人员无从下手。2.基于中间代理层实现代理一般位于客户端和服务器之间，代理服务器接到客户端请求后通过判断后转发到后端数据库，有两个代表性程序。 （1）mysql-proxy 为mysql开源项目，通过其自带的lua脚本进行SQL判断，虽然是mysql的官方产品，但是mysql官方不建议将其应用到生产环境 （2）Amoeba （变形虫）由陈思儒开发，曾就职与阿里巴巴，该程序由java语言进行开发，阿里巴巴将其应用于生成环境，它不支持事物和存储过程 通过程序代码实现mysql读写分离自然是一个不错的选择，但是并不是所有的应用都适合在程序代码中实现读写分离，像一些大型复杂的java应用，如果在程序代码中实现读写分离对代码改动就较大，像这种应用一般会考虑使用代理层来实现。 二：基于 Amoeba 实现读写分离 2.1 环境搭建amoeba:192.168.2.203 masterDB：192.168.2.204 slaveDB：192.168.2.205以上系统全为centos6.8 Amoeba框架是居于JDK1.5开发的，采用了JDK1.5的特性，所以还需要安装java环境，建议使用javaSE1.5以上的JDK版本 2.2 安装java环境先去官网下载：http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html 2.2.1 安装[root@bogon src]# rpm -ivh jdk-8u111-linux-x64.rpm Preparing... ########################################### [100%] 1:jdk1.8.0_111 ########################################### [100%] Unpacking JAR files... tools.jar... plugin.jar... javaws.jar... deploy.jar... rt.jar... jsse.jar... charsets.jar... localedata.jar... 2.2.2 设置java环境变量[root@bogon src]# vim /etc/profile #set java environment JAVA_HOME=/usr/java/jdk1.8.0_111 JRE_HOME=/usr/java/jdk1.8.0_111/jre CLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin export JAVA_HOME JRE_HOME CLASS_PATH PATH [root@bogon amoeba]# source /etc/profile 2.2.3 测试是否安装成功[root@bogon src]# java -version java version &quot;1.8.0_111&quot; Java(TM) SE Runtime Environment (build 1.8.0_111-b14) Java HotSpot(TM) 64-Bit Server VM (build 25.111-b14, mixed mode) 2.3 安装Amoeba可以从https://sourceforge.net/projects/amoeba/下载最新版本的Amoeba，我这里下载的是amoeba-mysql-3.0.5-RC-distribution.zip。Amoeba安装非常简单，直接解压即可使用，这里将Amoeba解压到/usr/local/amoeba目录下，这样就安装完成了 [root@bogon amoeba]# pwd /usr/local/amoeba [root@bogon amoeba]# ll 总用量 20 drwxrwxrwx. 2 root root 4096 7月 5 2013 benchmark drwxrwxrwx. 2 root root 4096 7月 5 2013 bin drwxrwxrwx. 2 root root 4096 7月 5 2013 conf -rwxrwxrwx. 1 root root 728 7月 5 2013 jvm.properties drwxrwxrwx. 2 root root 4096 7月 5 2013 lib 2.4 配置AmoebaAmoeba的配置文件在本环境下位于/usr/local/amoeba/conf目录下。配置文件比较多，但是仅仅使用读写分离功能，只需配置两个文件即可，分别是dbServers.xml和amoeba.xml，如果需要配置ip访问控制，还需要修改access_list.conf文件，下面首先介绍dbServers.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768[root@bogon amoeba]# cat conf/dbServers.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;gbk&quot;?&gt;&lt;!DOCTYPE amoeba:dbServers SYSTEM &quot;dbserver.dtd&quot;&gt;&lt;amoeba:dbServers xmlns:amoeba=&quot;http://amoeba.meidusa.com/&quot;&gt; &lt;!-- Each dbServer needs to be configured into a Pool, If you need to configure multiple dbServer with load balancing that can be simplified by the following configuration: add attribute with name virtual = &quot;true&quot; in dbServer, but the configuration does not allow the element with name factoryConfig such as &apos;multiPool&apos; dbServer --&gt; &lt;dbServer name=&quot;abstractServer&quot; abstractive=&quot;true&quot;&gt; &lt;factoryConfig class=&quot;com.meidusa.amoeba.mysql.net.MysqlServerConnectionFactory&quot;&gt; &lt;property name=&quot;connectionManager&quot;&gt;$&#123;defaultManager&#125;&lt;/property&gt; &lt;property name=&quot;sendBufferSize&quot;&gt;64&lt;/property&gt; &lt;property name=&quot;receiveBufferSize&quot;&gt;128&lt;/property&gt; &lt;!-- mysql port --&gt; &lt;property name=&quot;port&quot;&gt;3306&lt;/property&gt; #设置Amoeba要连接的mysql数据库的端口，默认是3306 &lt;!-- mysql schema --&gt; &lt;property name=&quot;schema&quot;&gt;testdb&lt;/property&gt; #设置缺省的数据库，当连接amoeba时，操作表必须显式的指定数据库名，即采用dbname.tablename的方式，不支持 use dbname指定缺省库，因为操作会调度到各个后端dbserver &lt;!-- mysql user --&gt; &lt;property name=&quot;user&quot;&gt;test1&lt;/property&gt; #设置amoeba连接后端数据库服务器的账号和密码，因此需要在所有后端数据库上创建该用户，并授权amoeba服务器可连接 &lt;property name=&quot;password&quot;&gt;111111&lt;/property&gt; &lt;/factoryConfig&gt; &lt;poolConfig class=&quot;com.meidusa.toolkit.common.poolable.PoolableObjectPool&quot;&gt; &lt;property name=&quot;maxActive&quot;&gt;500&lt;/property&gt; #最大连接数，默认500 &lt;property name=&quot;maxIdle&quot;&gt;500&lt;/property&gt; #最大空闲连接数 &lt;property name=&quot;minIdle&quot;&gt;1&lt;/property&gt; #最新空闲连接数 &lt;property name=&quot;minEvictableIdleTimeMillis&quot;&gt;600000&lt;/property&gt; &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot;&gt;600000&lt;/property&gt; &lt;property name=&quot;testOnBorrow&quot;&gt;true&lt;/property&gt; &lt;property name=&quot;testOnReturn&quot;&gt;true&lt;/property&gt; &lt;property name=&quot;testWhileIdle&quot;&gt;true&lt;/property&gt; &lt;/poolConfig&gt; &lt;/dbServer&gt; &lt;dbServer name=&quot;writedb&quot; parent=&quot;abstractServer&quot;&gt; #设置一个后端可写的dbServer，这里定义为writedb，这个名字可以任意命名，后面还会用到 &lt;factoryConfig&gt; &lt;!-- mysql ip --&gt; &lt;property name=&quot;ipAddress&quot;&gt;192.168.2.204&lt;/property&gt; #设置后端可写dbserver &lt;/factoryConfig&gt; &lt;/dbServer&gt; &lt;dbServer name=&quot;slave&quot; parent=&quot;abstractServer&quot;&gt; #设置后端可读dbserver &lt;factoryConfig&gt; &lt;!-- mysql ip --&gt; &lt;property name=&quot;ipAddress&quot;&gt;192.168.2.205&lt;/property&gt; &lt;/factoryConfig&gt; &lt;/dbServer&gt; &lt;dbServer name=&quot;myslave&quot; virtual=&quot;true&quot;&gt; #设置定义一个虚拟的dbserver，实际上相当于一个dbserver组，这里将可读的数据库ip统一放到一个组中，将这个组的名字命名为myslave &lt;poolConfig class=&quot;com.meidusa.amoeba.server.MultipleServerPool&quot;&gt; &lt;!-- Load balancing strategy: 1=ROUNDROBIN , 2=WEIGHTBASED , 3=HA--&gt; &lt;property name=&quot;loadbalance&quot;&gt;1&lt;/property&gt; #选择调度算法，1表示复制均衡，2表示权重，3表示HA， 这里选择1 &lt;!-- Separated by commas,such as: server1,server2,server1 --&gt; &lt;property name=&quot;poolNames&quot;&gt;slave&lt;/property&gt; #myslave组成员 &lt;/poolConfig&gt; &lt;/dbServer&gt; &lt;/amoeba:dbServers&gt; 另一个配置文件amoeba.xml [root@bogon amoeba]# cat conf/amoeba.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;gbk&quot;?&gt; &lt;!DOCTYPE amoeba:configuration SYSTEM &quot;amoeba.dtd&quot;&gt; &lt;amoeba:configuration xmlns:amoeba=&quot;http://amoeba.meidusa.com/&quot;&gt; &lt;proxy&gt; &lt;!-- service class must implements com.meidusa.amoeba.service.Service --&gt; &lt;service name=&quot;Amoeba for Mysql&quot; class=&quot;com.meidusa.amoeba.mysql.server.MySQLService&quot;&gt; &lt;!-- port --&gt; &lt;property name=&quot;port&quot;&gt;8066&lt;/property&gt; #设置amoeba监听的端口，默认是8066 &lt;!-- bind ipAddress --&gt; #下面配置监听的接口，如果不设置，默认监听所以的IP &lt;!-- &lt;property name=&quot;ipAddress&quot;&gt;127.0.0.1&lt;/property&gt; --&gt; &lt;property name=&quot;connectionFactory&quot;&gt; &lt;bean class=&quot;com.meidusa.amoeba.mysql.net.MysqlClientConnectionFactory&quot;&gt; &lt;property name=&quot;sendBufferSize&quot;&gt;128&lt;/property&gt; &lt;property name=&quot;receiveBufferSize&quot;&gt;64&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=&quot;authenticateProvider&quot;&gt; &lt;bean class=&quot;com.meidusa.amoeba.mysql.server.MysqlClientAuthenticator&quot;&gt; # 提供客户端连接amoeba时需要使用这里设定的账号 (这里的账号密码和amoeba连接后端数据库服务器的密码无关) &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;filter&quot;&gt; &lt;bean class=&quot;com.meidusa.toolkit.net.authenticate.server.IPAccessController&quot;&gt; &lt;property name=&quot;ipFile&quot;&gt;${amoeba.home}/conf/access_list.conf&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/service&gt; &lt;runtime class=&quot;com.meidusa.amoeba.mysql.context.MysqlRuntimeContext&quot;&gt; &lt;!-- proxy server client process thread size --&gt; &lt;property name=&quot;executeThreadSize&quot;&gt;128&lt;/property&gt; &lt;!-- per connection cache prepared statement size --&gt; &lt;property name=&quot;statementCacheSize&quot;&gt;500&lt;/property&gt; &lt;!-- default charset --&gt; &lt;property name=&quot;serverCharset&quot;&gt;utf8&lt;/property&gt; &lt;!-- query timeout( default: 60 second , TimeUnit:second) --&gt; &lt;property name=&quot;queryTimeout&quot;&gt;60&lt;/property&gt; &lt;/runtime&gt; &lt;/proxy&gt; &lt;!-- Each ConnectionManager will start as thread manager responsible for the Connection IO read , Death Detection --&gt; &lt;connectionManagerList&gt; &lt;connectionManager name=&quot;defaultManager&quot; class=&quot;com.meidusa.toolkit.net.MultiConnectionManagerWrapper&quot;&gt; &lt;property name=&quot;subManagerClassName&quot;&gt;com.meidusa.toolkit.net.AuthingableConnectionManager&lt;/property&gt; &lt;/connectionManager&gt; &lt;/connectionManagerList&gt; &lt;!-- default using file loader --&gt; &lt;dbServerLoader class=&quot;com.meidusa.amoeba.context.DBServerConfigFileLoader&quot;&gt; &lt;property name=&quot;configFile&quot;&gt;${amoeba.home}/conf/dbServers.xml&lt;/property&gt; &lt;/dbServerLoader&gt; &lt;queryRouter class=&quot;com.meidusa.amoeba.mysql.parser.MysqlQueryRouter&quot;&gt; &lt;property name=&quot;ruleLoader&quot;&gt; &lt;bean class=&quot;com.meidusa.amoeba.route.TableRuleFileLoader&quot;&gt; &lt;property name=&quot;ruleFile&quot;&gt;${amoeba.home}/conf/rule.xml&lt;/property&gt; &lt;property name=&quot;functionFile&quot;&gt;${amoeba.home}/conf/ruleFunctionMap.xml&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=&quot;sqlFunctionFile&quot;&gt;${amoeba.home}/conf/functionMap.xml&lt;/property&gt; &lt;property name=&quot;LRUMapSize&quot;&gt;1500&lt;/property&gt; &lt;property name=&quot;defaultPool&quot;&gt;writedb&lt;/property&gt; #设置amoeba默认的池，这里设置为writedb &lt;property name=&quot;writePool&quot;&gt;writedb&lt;/property&gt; #这两个选项默认是注销掉的，需要取消注释，这里用来指定前面定义好的俩个读写池 &lt;property name=&quot;readPool&quot;&gt;myslave&lt;/property&gt; # &lt;property name=&quot;needParse&quot;&gt;true&lt;/property&gt; &lt;/queryRouter&gt; &lt;/amoeba:configuration&gt; 2.5 在masterdb上创建数据库testdbmysql&gt; create database testdb; Query OK, 1 row affected (0.08 sec) mysql&gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mydb | | mysql | | performance_schema | | test | | testdb | +--------------------+ 6 rows in set (0.00 sec) 查看slavedb是否复制成功 mysql&gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mydb | | mysql | | performance_schema | | test | | testdb | +--------------------+ 6 rows in set (0.00 sec) 分别在masterdb和slavedb上为amoedb授权 mysql&gt; GRANT ALL ON testdb.* TO &apos;test1&apos;@&apos;192.168.2.203&apos; IDENTIFIED BY &apos;111111&apos;; Query OK, 0 rows affected (0.05 sec) mysql&gt; flush privileges; Query OK, 0 rows affected (0.02 sec) 启动amoeba [root@bogon amoeba]# /usr/local/amoeba/bin/launcher Error: JAVA_HOME environment variable is not set. [root@bogon amoeba]# vim /etc/profile^C [root@bogon amoeba]# source /etc/profile [root@bogon amoeba]# /usr/local/amoeba/bin/launcher Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=16m; support was removed in 8.0 Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=96m; support was removed in 8.0 The stack size specified is too small, Specify at least 228k Error: Could not create the Java Virtual Machine. Error: A fatal exception has occurred. Program will exit. 报错: Error: Could not create the Java Virtual Machine.Error: A fatal exception has occurred. Program will exit.从错误文字上看，应该是由于stack size太小，导致JVM启动失败，要如何修改呢？其实Amoeba已经考虑到这个问题，并将JVM参数配置写在属性文件里。现在，让我们通过该属性文件修改JVM参数。修改jvm.properties文件JVM_OPTIONS参数。 [root@bogon amoeba]# vim /usr/local/amoeba/jvm.properties 改成：JVM_OPTIONS=&quot;-server -Xms1024m -Xmx1024m -Xss256k -XX:PermSize=16m -XX:MaxPermSize=96m&quot; 原为：JVM_OPTIONS=&quot;-server -Xms256m -Xmx1024m -Xss196k -XX:PermSize=16m -XX:MaxPermSize=96m&quot; 再次启动 [root@bogon ~]# /usr/local/amoeba/bin/launcher at org.codehaus.plexus.classworlds.launcher.Launcher.launchStandard(Launcher.java:329) at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:239) at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:409) at org.codehaus.classworlds.Launcher.mainWithExitCode(Launcher.java:127) at org.codehaus.classworlds.Launcher.main(Launcher.java:110) Caused by: com.meidusa.toolkit.common.bean.util.InitialisationException: default pool required!,defaultPool=writedb invalid at com.meidusa.amoeba.route.AbstractQueryRouter.init(AbstractQueryRouter.java:469) at com.meidusa.amoeba.context.ProxyRuntimeContext.initAllInitialisableBeans(ProxyRuntimeContext.java:337) ... 11 more 2016-10-24 18:46:37 [INFO] Project Name=Amoeba-MySQL, PID=1577 , System shutdown .... Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=16m; support was removed in 8.0 Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=96m; support was removed in 8.0 2016-10-24 18:50:19 [INFO] Project Name=Amoeba-MySQL, PID=1602 , starting... log4j:WARN log4j config load completed from file:/usr/local/amoeba/conf/log4j.xml 2016-10-24 18:50:21,668 INFO context.MysqlRuntimeContext - Amoeba for Mysql current versoin=5.1.45-mysql-amoeba-proxy-3.0.4-BETA log4j:WARN ip access config load completed from file:/usr/local/amoeba/conf/access_list.conf 2016-10-24 18:50:22,852 INFO net.ServerableConnectionManager - Server listening on 0.0.0.0/0.0.0.0:8066. 查看端口 [root@bogon ~]# netstat -unlpt | grep java tcp 0 0 :::8066 :::* LISTEN 1602/java 由此可知Amoeba启动正常 2.6 测试远程登陆mysql客户端通过指定amoeba配置文件中指定的用户名、密码、和端口以及amoeba服务器ip地址链接mysql数据库 [root@lys2 ~]# mysql -h192.168.2.203 -uroot -p -P8066 Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 1364055863 Server version: 5.1.45-mysql-amoeba-proxy-3.0.4-BETA Source distribution Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement. mysql&gt; 在testdb中创建表test并插入数据 mysql&gt; use testdb; Database changed mysql&gt; create table test_table(id int,password varchar(40) not null); Query OK, 0 rows affected (0.19 sec) mysql&gt; show tables; +------------------+ | Tables_in_testdb | +------------------+ | test_table | +------------------+ 1 row in set (0.02 sec) mysql&gt; insert into test_table(id,password) values(&apos;1&apos;,&apos;test1&apos;); Query OK, 1 row affected (0.04 sec) mysql&gt; select * from test_table; +------+----------+ | id | password | +------+----------+ | 1 | test1 | +------+----------+ 1 row in set (0.02 sec) 分别登陆masterdb和slavedb查看数据 masterdb： mysql&gt; use testdb; Database changed mysql&gt; show tables; +------------------+ | Tables_in_testdb | +------------------+ | test_table | +------------------+ 1 row in set (0.00 sec) mysql&gt; select * from test_table; +------+----------+ | id | password | +------+----------+ | 1 | test1 | +------+----------+ 1 row in set (0.03 sec) slavedb： mysql&gt; use testdb; Database changed mysql&gt; show tables; +------------------+ | Tables_in_testdb | +------------------+ | test_table | +------------------+ 1 row in set (0.00 sec) mysql&gt; select * from test_table; +------+----------+ | id | password | +------+----------+ | 1 | test1 | +------+----------+ 1 row in set (0.00 sec) 停掉masterdb，然后在客户端分别执行插入和查询功能 masterdb： [root@bogon ~]# service mysqld stop Shutting down MySQL. SUCCESS! 客户端： mysql&gt; insert into test_table(id,password) values(&apos;2&apos;,&apos;test2&apos;); ERROR 1044 (42000): Amoeba could not connect to MySQL server[192.168.2.204:3306],拒绝连接 mysql&gt; select * from test_table; +------+----------+ | id | password | +------+----------+ | 1 | test1 | +------+----------+ 1 row in set (0.01 sec) 可以看到，关掉masterdb和写入报错，读正常 开启masterdb上的msyql 关闭slave上的mysql masterdb： [root@bogon ~]# service mysqld start Starting MySQL.. SUCCESS! slavedb： [root@localhost ~]# service mysqld stop Shutting down MySQL. SUCCESS! 客户端再次尝试 mysql&gt; insert into test_table(id,password) values(&apos;2&apos;,&apos;test2&apos;); Query OK, 1 row affected (0.19 sec) mysql&gt; select * from test_table; ERROR 1044 (42000): poolName=myslave, no valid pools 可以看到插入成功，读取失败 开启slavedb上的mysql，查看数据是否自动同步 slavedb: [root@localhost ~]# service mysqld start Starting MySQL... SUCCESS! 客户端： mysql&gt; select * from test_table; +------+----------+ | id | password | +------+----------+ | 1 | test1 | | 2 | test2 | +------+----------+ 2 rows in set (0.01 sec) 接着客户端： mysql&gt; insert into test_table(id,password) values(&apos;3&apos;,&apos;test3&apos;); Query OK, 1 row affected (0.03 sec) mysql&gt; select * from test_table; +------+----------+ | id | password | +------+----------+ | 1 | test1 | | 2 | test2 | | 3 | test3 | +------+----------+ 3 rows in set (0.02 sec) OK 一切正常，到此全部结束 注：关于mysql主从同步自行查看博主之前的主从同步笔记！ Amoeba主配置文件($AMOEBA_HOME/conf/amoeba.xml)，用来配置Amoeba服务的基本参数，如Amoeba主机地址、端口、认证方式、用于连接的用户名、密码、线程数、超时时间、其他配置文件的位置等。 数据库服务器配置文件($AMOEBA_HOME/conf/dbServers.xml)，用来存储和配置Amoeba所代理的数据库服务器的信息，如:主机IP、端口、用户名、密码等。 切分规则配置文件($AMOEBA_HOME/conf/rule.xml)，用来配置切分规则。 数据库函数配置文件($AMOEBA_HOME/conf/functionMap.xml)，用来配置数据库函数的处理方法，Amoeba将使用该配置文件中的方法解析数据库函数。 切分规则函数配置文件($AMOEBA_HOME/conf/ruleFunctionMap.xml)，用来配置切分规则中使用的用户自定义函数的处理方法。 访问规则配置文件($AMOEBA_HOME/conf/access_list.conf)，用来授权或禁止某些服务器IP访问Amoeba。 日志规格配置文件($AMOEBA_HOME/conf/log4j.xml)，用来配置Amoeba输出日志的级别和方式。 转载：Amoeba+Mysql实现数据库读写分离","tags":[{"name":"mysql","slug":"mysql","permalink":"http://wangyuanjun.cn/tags/mysql/"}]},{"title":"MySQL主从复制详解与实践","date":"2018-02-09T14:25:14.000Z","path":"2018/02/09/MySQL主从复制详解与实践/","text":"一：mysql主从原理1.1 基本介绍MySQL 内建的复制功能是构建大型，高性能应用程序的基础。将 MySQL 的 数亿分布到到多个系统上去，这种分步的机制，是通过将 MySQL 的某一台主机的数据复制到其它主机( Slave )上，并重新执行一遍来实现的。复制过程中一个服务器充当服务器，而一个或多个其它服务器充当从服务器。主服务器将更新写入二进制日志，并维护文件的一个索引以跟踪日志循环。这些日志可以记录发送到从服务器的更新。当一个从服务器连接主服务器时，它通知主服务器从服务器在日志中读取的最后一次成功更新的位置，从服务器接收从那时起发生的任何更新，然后封锁等等主服务器通知新的更新。请注意当你进行复制时，所有对复制中的表的更新必须在主服务器上进行。否则，你必须要小心，以避免用户对主服务器上的表进行的更新与对服务器上的表所进行的更新之间的冲突 1.2 MySQL支持的复制类型 基于语句的复制。 在主服务器上执行的 SQL 语句，在从服务器上执行同样的语句。否则，你必须要小心，以避免用户对主服务器上的表进行的更新与对服务器上的表所进行的更新之间的冲突，配置：binlog_format = ‘STATEMENT’ 基于行的复制。把改变的内容复制过去，而不是把命令在从服务器上执行一遍，从 MySQL 5.0开始支持，配置：binlog_format = ‘ROW’ 混合类型的复制。默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制,配置：binlog_format = ‘MIXED’ 1.3 mysql复制解决的问题 数据分布 负载平衡 备份 高可用性和容错行 1.4 复制是如何工作的MySQL之间数据复制的基础是二进制日志文件（binary log file）。一台MySQL数据库一旦启用二进制日志后，其作为master，它的数据库中所有操作都会以“事件”的方式记录在二进制日志中，其他数据库作为slave通过一个I/O线程与主服务器保持通信，并监控master的二进制日志文件的变化，如果发现master二进制日志文件发生变化，则会把变化复制到自己的中继日志中，然后slave的一个SQL线程会把相关的“事件”执行到自己的数据库中，以此实现从数据库和主数据库的一致性，也就实现了主从复制。可以简化为三个步骤(如下图)： Master 将改变记录到二进制日志中。 Slave 将 Master 的二进制日志拷贝到它的中继日志( Relay_log ) Slave 重做中继日志中的事件，将改变反映它自己的数据 说明: Master 记录二进制的日志。在每个事务更新数据之前，Master 在二进制日志记录这些改变。 MySQL 将事务日志的写入二进制日志，及时事务中的语句都市交叉执行的。在事件写入二进制日志完成后，Master 通知存储引擎提交事务。 Slave 将 Master 的 Binary log 拷贝到它自己的中继日志。首先 Slave 开始一个工作线程–I/O线程。I/O 线程在 Master 上打开一个连接，然后开始从二进制日志中读取事件，如果已经连上 Master，它会并等待master产生新的事件。I/O线程就这些事件写入中继日志。 SQL Slave Thread ( SQL从线程)处理该过程的最后一步。SQL纯种从中继日志读取事件，并重放其中的事件而更新 Slave 的数据。使其它与 Master 中的数据保持一致。只要该线程与 I/O 线程保持一致，中继日志通常会位于 OS 的缓存中，所以中继日志的开销很小。 此处，在 Master 中也有一个工作线程，和其他 MySQL 的连接一样，Slave 在 Master 中打开一个连接也会使得 Master 开始一个线程。复制过程有一个很重要的限制—复制在 Slave 上是串行化的，也就是说 Master 上的并行更新操作不能在 Slave 上并行操作。 1.5 复制实现细节分析MySQL主从复制功能使用三个线程实现，一个在主服务器上，两个在从服务器上 1.5.1 Binlog转储线程。当从服务器与主服务器连接时，主服务器会创建一个线程将二进制日志内容发送到从服务器。该线程可以使用 语句 SHOW PROCESSLIST(下面有示例介绍) 在服务器 sql 控制台输出中标识为Binlog Dump线程。 二进制日志转储线程获取服务器上二进制日志上的锁，用于读取要发送到从服务器的每个事件。一旦事件被读取，即使在将事件发送到从服务器之前，锁会被释放。 1.5.2 从服务器I/O线程。当在从服务器sql 控制台发出 START SLAVE语句时，从服务器将创建一个I/O线程，该线程连接到主服务器，并要求它发送记录在主服务器上的二进制更新日志。 从机I/O线程读取主服务器Binlog Dump线程发送的更新 （参考上面 Binlog转储线程 介绍），并将它们复制到自己的本地文件二进制日志中。 该线程的状态显示详情 Slave_IO_running 在输出端 使用 命令SHOW SLAVE STATUS 使用\\G语句终结符,而不是分号,是为了，易读的垂直布局 这个命令在上面 查看从服务器状态 用到过 1mysql&gt; SHOW SLAVE STATUS\\G 1.5.3 从服务器SQL线程。从服务器创建一条SQL线程来读取由主服务器I/O线程写入的二级制日志，并执行其中包含的事件。 在前面的描述中，每个主/从连接有三个线程。主服务器为每个当前连接的从服务器创建一个二进制日志转储线程，每个从服务器都有自己的I/O和SQL线程。从服务器使用两个线程将读取更新与主服务器更新事件，并将其执行为独立任务。因此，如果语句执行缓慢，则读取语句的任务不会减慢。 例如，如果从服务器开始几分钟没有运行，或者即使SQL线程远远落后，它的I/O线程也可以从主服务器建立连接时，快速获取所有二进制日志内容。 如果从服务器在SQL线程执行所有获取的语句之前停止，则I/O线程至少获取已经读取到的内容，以便将语句的安全副本存储在自己的二级制日志文件中，准备下次执行主从服务器建立连接，继续同步。 使用命令 SHOW PROCESSLIST\\G 可以查看有关复制的信息 命令 SHOW FULL PROCESSLISTG 12345678910mysql&gt; SHOW FULL PROCESSLIST\\G*************************** 1. row *************************** Id: 22 User: repl Host: node2:39114 db: NULLCommand: Binlog Dump Time: 4435 State: Master has sent all binlog to slave; waiting for more updates Info: NULL Id: 22是Binlog Dump服务连接的从站的复制线程Host: node2:39114 是从服务，主机名 级及端口State: 信息表示所有更新都已同步发送到从服务器，并且主服务器正在等待更多更新发生。如果Binlog Dump在主服务器上看不到 线程，意味着主从复制没有配置成功; 也就是说，没有从服务器连接主服务器。 命令 SHOW PROCESSLISTG 在 Slave 从服务器 ，查看两个线程的更新状态 12345678910111213141516171819mysql&gt; SHOW PROCESSLIST\\G*************************** 1. row *************************** Id: 6 User: system user Host: db: NULLCommand: Connect Time: 6810 State: Waiting for master to send event Info: NULL*************************** 2. row *************************** Id: 7 User: system user Host: db: NULLCommand: Connect Time: 3069 State: Slave has read all relay log; waiting for more updates Info: NULL Id: 6是与主服务器通信的I/O线程Id: 7是正在处理存储在中继日志中的更新的SQL线程 在 运行 SHOW PROCESSLIST 命令时，两个线程都空闲，等待进一步更新 如果在主服务器上在设置的超时，时间内 Binlog Dump线程没有活动，则主服务器会和从服务器断开连接。超时取决于的 服务器系统变量 值 net_write_timeout(在中止写入之前等待块写入连接的秒数，默认10秒)和 net_retry_count;(如果通信端口上的读取或写入中断，请在重试次数，默认10次) 设置 服务器系统变量 该SHOW SLAVE STATUS语句提供了有关从服务器上复制处理的附加信息。 1.6 复制常用类型1.6.1 复制的常用体系结构基本原则 每个 Slave 只能有一个 Master； 每个 Slave 只能有一个唯一的服务器ID； 每个 Master 可以有很多 Slave; 如果你设置了 log_slave_updates，Slave 可以是其他 Slave 的 Master，从而扩散 Master 的更新 MySQL 不支持多主服务器复制—即一个 Slave 可以有多个 Master，但是，通过一些简单的组合，我们却可以建立灵活而强大的复制体系结构。 1.6.2 一主多从复制架构 场景：在主库读取请求压力非常大的场景下，可以通过配置一主多从复制架构实现读写分离，把大量对实时性要求不是特别高的读请求通过负载均衡到多个从库上，降低主库的读取压力。在主库出现异常宕机的情况下，可以把一个从库切换为主库继续提供服务； 建议： 当 Slave 增加到一定数量时，Slave 对 Master 的负载以及网络带宽都会成为一个严重的问题。 不同的 Slave 扮演不同的作用(例如使用不同的索引，或者不同的存储引擎) 用一个 Slave 作为备用 Master，只进行复制 用一个远程的 Slave，用于灾难恢复。 1.6.3 多级复制架构 场景：一主多从的架构能够解决大部分读请求压力特别大的场景需求，但主库的I/O压力和网络压力会随着从库的增加而增长，而使用多级复制架构就可以解决一主多从场景下，主库额外的I/O和网络压力。 但要注意的是，多级复制场景下主库的数据是经历两次才到达读取的从库，期间的延时比一主多从复制场景下只经历一次复制的要大。 建议： 可能存在延时较长的风险 这种方案可以与第三方软件结合使用，例如Slave+LVS+Keepalived 实现高可用。 1.6.4 双主复制/Dual Master架构 场景：双主/Dual Master架构适用于写压力比较大的场景，或者DBA做维护需要主从切换的场景，通过双主/Dual master架构避免了重复搭建从库的麻烦。 建议： 最大问题就是更新冲突。 可以采用MySQL Cluster，以及将Cluster和Replication结合起来，可以建立强大的高性能的数据库平台。 二：mysql主从配置实践2.1 实现MySQL主从复制需要进行的配置：主服务器： 开启二进制日志 配置唯一的server-id 获得master二进制日志文件名及位置 创建一个用于slave和master通信的用户账号 从服务器： 配置唯一的server-id 使用master分配的用户账号读取master二进制日志 启用slave服务 具体实现过程如下： 2.2 基础环境配置 数据库版本： mysql 5.1.73 ( Slave 版本可以大于或者等于 Maste r版本) 操作系统： CentOS 6.7 x86_64 IP地址：192.168.124.10 ( Master ) 192.168.124.20 ( Slave ) 2.3 Master-Server配置2.3.1 修改mysql配置找到主数据库的配置文件my.cnf(或者my.ini)，我的在/etc/mysql/my.cnf,在[mysqld]部分插入如下两行：123[mysqld]log-bin=mysql-bin #开启二进制日志server-id=1 #设置server-id 重启MySQL服务 1# service mysqld restart 2.3.2 创建用于同步的用户账号(复制帐号)在主服务器上为从服务器分配一个账号，就像一把钥匙，从服务器拿着这个钥匙，才能到主服务器上来共享主服务器的日志文件。 在 Master 的数据库中建立一个复制账户，每个 Slave 使用该账户连接 Master 进行复制，需要 replication slave 和 replication client 权限，Master 的连接信息会存储在文本文件 master.info 文件中。(master.info文件在 Slave 的数据目录中) mysql&gt;grant replication slave on *.* to &apos;replication&apos;@&apos;192.168.124.20&apos; identified by &apos;123456&apos;;#创建用户和分配权限 mysql&gt;flush privileges;#刷新权限 说明：创建了一个用户名为 replication 的用户，密码为 123456 ,只允许在 192.168.124.20 这个 Slave 上登录。 2.3.3 查询master的状态查看 File(日志文件名) 和 Postition(日志地址)，下面配置 Slave 的时候需要用。执行完之后记录下这两值，然后在配置完从服务器之前不要对主服务器进行任何操作，因为每次操作数据库时这两值会发生改变 1mysql&gt;show master status; 注：执行完这个步骤后不要再操作主数据库了，防止主数据库状态值变化 2.4 Slave-Server 配置2.4.1 修改mysql配置关闭slave（如果你以前配置过主从的话，一定要先关闭）命令：stop slave; 找到从数据库的配置文件my.cnf(或者my.ini)，我的在/etc/mysql/my.cnf,在[mysqld]部分插入如下两行：Master-Server和Slave-Server 的server-id必须不一样 123[mysqld]log-bin=mysql-bin #开启二进制日志server-id=2 #设置server-id 重启MySQL服务 1# service mysqld restart 2.4.2 执行同步命令执行同步命令，设置主数据库ip，同步帐号密码，同步位置 123456mysql&gt; CHANGE MASTER TO -&gt; MASTER_HOST=&apos;192.168.124.10&apos;, -&gt; MASTER_USER=&apos;replication&apos;, -&gt; MASTER_PASSWORD=&apos;123456&apos;, -&gt; MASTER_LOG_FILE=&apos;mysql-bin.000060&apos;, -&gt; MASTER_LOG_POS=248; 选项： master_host：Master 服务器IP master_user：Master 服务器授权用户，也就是 Master 前面创建的那个用户 master_password：Master 服务器授权用户对应的密码 master_log_file：Master binlog 文件名 master_log_pos：Master binlog 文件中的 Postion 值更多的选项可以看:http://dev.mysql.com/doc/refman/5.7/en/change-master-to.html说明：使用刚刚在 Master 创建的用户连接，log_file 和 log_pos 就是使用刚刚在 Master 上执行 show master status; 执行出来的结果 2.4.3 启动slave同步进程：1mysql&gt;start slave; 2.4.4 查看slave状态：mysql&gt; show slave status\\G; *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.124.10 Master_User: replication Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000013 Read_Master_Log_Pos: 11662 Relay_Log_File: mysqld-relay-bin.000022 Relay_Log_Pos: 11765 Relay_Master_Log_File: mysql-bin.000013 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: ... 当Slave_IO_Running和Slave_SQL_Running都为YES的时候就表示主从同步设置成功了。接下来就可以进行一些验证了，比如在主master数据库的test数据库的一张表中插入一条数据，在slave的test库的相同数据表中查看是否有新增的数据即可验证主从复制功能是否有效，还可以关闭slave（mysql&gt;stop slave;）,然后再修改master，看slave是否也相应修改（停止slave后，master的修改不会同步到slave），就可以完成主从复制功能的验证了。 还可以用到的其他相关参数： master开启二进制日志后默认记录所有库所有表的操作，可以通过配置来指定只记录指定的数据库甚至指定的表的操作，具体请看2.5 2.5 其他可能用到的相关参数 master端： 1234567891011121314151617181920# 不同步哪些数据库 binlog-ignore-db = mysql binlog-ignore-db = test binlog-ignore-db = information_schema # 只同步哪些数据库，除此之外，其他不同步 binlog-do-db = game # 日志保留时间 expire_logs_days = 10 # 控制binlog的写入频率。每执行多少次事务写入一次 # 这个参数性能消耗很大，但可减小MySQL崩溃造成的损失 sync_binlog = 5 # 日志格式，建议mixed # statement 保存SQL语句 # row 保存影响记录数据 # mixed 前面两种的结合 binlog_format = mixed slave端： 12345678# 停止主从同步 mysql&gt; stop slave; # 连接断开时，重新连接超时时间 mysql&gt; change master to master_connect_retry=50; # 开启主从同步 mysql&gt; start slave; 2.6 测试在 Master 数据库中执行sql语句操作，观察 Slave 是否同步，如果同步则说明配置成功。 2.7 注意事项 主库和从库的数据库名必须相同； 主库和从库的复制可以精确到表，但是在需要更改主库或从库的数据结构时需要立刻重启slave； 不能在mysql配置文件里直接写入master的配置信息，需要用change master命令来完成； 指定replicate_do_db必须在my.cnf里配置，不能用change master命令来完成； 如果不及时清理，日积月累二进制日志文件可能会把磁盘空间占满，可以在配置文件里加上expire_logs_days=7，只保留最近7天的日志，建议当slave不再使用时，通过reset slave来取消relaylog； 写一个监控脚本，用来监控 Slave 中的两个”yes”，如果只有一个”yes”或者零个，就表明主从有问题。 三：MySQL 主从错误处理解决和处理主从错误这个是最重要的，比配置更更要。提高处理问题的能力，要熟悉原理，多处理积累，多学习其他网友的处理方式。出现错误都会在 Last_SQL_Error 中显示错误，一般根据错误提示进行处理，如果不太清楚，可以谷歌查询一下，不过操作完之后，同步正常后，一定要核对一下数据是否一致。以下是收集的几个处理主从问题的链接： http://hzcsky.blog.51cto.com/1560073/479476/ http://storysky.blog.51cto.com/628458/259280 http://outofmemory.cn/code-snippet/3177/mysql-zhucong-library-clock-error-%EF%BC%9A-1062-Error-Duplicate-entry-1438019-for-key-PRIMARY-on-query https://dev.mysql.com/doc/refman/5.7/en/faqs-replication.html 参考：MySQL数据库设置主从同步MySQL主从复制（Master-Slave）与读写分离（MySQL-Proxy）实践MySQL 主从复制详解（详细）","tags":[{"name":"mysql","slug":"mysql","permalink":"http://wangyuanjun.cn/tags/mysql/"}]},{"title":"Java虚拟机学习——垃圾收集器与内存分配策略","date":"2018-02-08T07:24:49.000Z","path":"2018/02/08/Java虚拟机学习——垃圾收集器与内存分配策略/","text":"一：Java中是如何管理对象的垃圾收集（Garbage Collection，GC），要设计一个GC，需要考虑解决下面三件事情：（1）哪些内存需要回收？（2）什么时候回收？（3）如何回收？ 1.1 哪些内存需要回收？根据《Java虚拟机学习——Java内存区域与内存溢出异常》中介绍的java内存模型，其中，程序计数器、虚拟机栈、本地方法栈3个区域随线程而生，随线程而灭；栈中的栈帧随着方法的进入和退出有条不紊地执行着出栈和入栈操作。每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的，因此这几个区域的内存分配和回收都具备确定性，故这几个区域就不需要过多考虑回收的问题，因为方法结束或者线程结束时，内存自然就跟着回收了。对于java堆和方法区则不一样，java堆是存放实例对象的地方，我们只有在程序运行期间才能知道会创建哪些对象，这部分内存的分配和回收是动态的，因此，垃圾收集器所关注的就是这一部分。对于方法区（或者说HotSpot虚拟机中的永久代），垃圾回收主要是回收这两部分内容：废弃常量和无用的类。对于废弃常量，主要是判断当前系统中有没有对象引用这个常量；对于无用类则比较严格，需要满足下面三个条件：（1）该类的所有实例都已经被回收，即堆中不存在该类任何势力；（2）加载该类的ClassLoader已经被回收；（3）对类对应的java.lang.Class对象没有在任何地方被引用，无法再任何地方通过反射访问该类的方法；满足了上面三个条件也仅仅是“可以”进行回收了，还要根据HotSpot的一些配置参数综合考虑。 1.2 什么时候回收？垃圾收集器在对堆进行回收前，第一件事就是要确定这些对象之中哪些还“存活”着，哪些已经“死去”，对于这些已经“死去”的对象我们需要进行回收。判断对象是否存活的算法： 1.2.1 引用计数算法算法过程如下：【给对象添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的】。引用计数算法实现简单，判定效率也很高，大部分情况下是一个不错的算法。但有一个比较重要的缺点：很难解决对象之间相互循环引用的问题。比如：j假设变量objA、objB为某个类的对象实例，objA中持有一个指向objB的成员，此时objB的引用计数为1；在objB中持有一个指向objA的成员，此时objA的引用计数值也为1；此时，即使把objA、objB都置为null，此时两个对象都不能被回收，因为这两个对象虽然为null了，但是它们的引用计数值都还为1。123456789101112131415161718public class ReferenceCountingGC &#123; public Object instance = null; private static final int_1MB=1024*1024； private byte[]bigSize=new byte[2*_1MB]；//这个成员属性的唯一意义就是占点内存，以便能在GC日志中看清楚是否被回收过 public static void testGC()&#123; ReferenceCountingGC objA = new ReferenceCountingGC(); ReferenceCountingGC objB = new ReferenceCountingGC(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; //假设在这行发生GC,objA和objB是否能被回收？ System.gc(); &#125;&#125; 运行结果： 1234567891011[F u l l G C（S y s t e m）[T e n u r e d：0 K-＞2 1 0 K（1 0 2 4 0 K），0.0 1 4 9 1 4 2 s e c s]4603K-＞210K（19456K），[Perm：2999K-＞2999K（21248K）]，0.0150007 secs][Times：user=0.01 sys=0.00，real=0.02 secs]Heapdef new generation total 9216K,used 82K[0x00000000055e0000，0x0000000005fe0000，0x0000000005fe0000）Eden space 8192K，1%used[0x00000000055e00000x00000000055f4850，0x0000000005de0000）from space 1024K，0%used[0x0000000005de0000，0x0000000005de0000，0x0000000005ee0000）to space 1024K，0%used[0x0000000005ee0000，0x0000000005ee0000，0x0000000005fe0000）tenured generation total 10240K,used 210K[0x0000000005fe0000，0x00000000069e0000，0x00000000069e0000）the space 10240K，2%used[0x0000000005fe0000，0x0000000006014a18，0x0000000006014c00，0x00000000069e0000）compacting perm gen total 21248K,used 3016K[0x00000000069e0000，0x0000000007ea0000，0x000000000bde0000）the space 21248K，14%used[0x00000000069e0000，0x0000000006cd2398，0x0000000006cd2400，0x0000000007ea0000）No shared spaces configured. 从运行结果中可以清楚看到，GC日志中包含“4603K-＞210K”，意味着虚拟机并没有因为这两个对象互相引用就不回收它们，这也从侧面说明虚拟机并不是通过引用计数算法来判断对象是否存活的 1.2.2 可达性分析算法目前主流的虚拟机，如java默认虚拟机HotSpot就是用的这种方式。算法基本思路为：【通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时（或者说从GC Roots到这个对象不可达），则证明此对象是不可用的】。如下图所示：对象Object5、Object6、Object7相互虽然有关联，但是它们到GC Roots是不可达的，所以它们将会被判定为是可回收的对象。在Java语言中，可作为GC Roots的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象； 方法区中类静态static属性引用的对象； 方法区中常量final引用的对象； 本地方法栈中JNI（即一般说的Native方法）引用的对象； 1.3 再谈引用无论是引用计数法还是可达性分析算法，都用到了引用的概念，从JDK1.2开始，Java对引用的概念进行了扩充，讲引用分为强引用（Strong Reference）、软引用（Softe Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）四种，增强引用的适用性。 强引用就是指在程序代码之中普遍存在的，类似“Object obj = new Object()”这类的引用，只有强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用也是用来描述一些有用但并非必要的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。 弱引用也是用来描述非必要对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。但垃圾收集工作时，无论当前内存是否足够，都会回收掉只内弱引用关联的对象。 虚引用也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。因为finalize函数（后续会讲）被调用的不确定性，所以无法预知对象是否被回收，所在这里虚引用就起作用了。 1.4 生存还是死亡需要注意的是，即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过（也就是说对象的finalize()方法只能被调用一次），虚拟机将这两种情况都视为“没有必要执行”。如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，这样做的原因是，如果一个对象在finalize()方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能会导致F-Queue队列中其他对象永久处于等待，甚至导致整个内存回收系统崩溃。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize()中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它将被移除出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的被回收了。从以下代码中我们可以看到一个对象的finalize()被执行，但是它仍然可以存活。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/***此代码演示了两点：*1.对象可以在被GC时自我拯救。*2.这种自救的机会只有一次，因为一个对象的finalize（）方法最多只会被系统自动调用一次*/public class FinalizeEscapeGC&#123; public static FinalizeEscapeGC SAVE_HOOK=null； public void isAlive()&#123; System.out.println(&quot;yes,i am still alive：)&quot;)； &#125; @Override protected void finalize()throws Throwable&#123; super.finalize()； System.out.println(&quot;finalize mehtod executed！&quot;)； FinalizeEscapeGC.SAVE_HOOK=this； &#125; public static void main(String[]args)throws Throwable&#123; SAVE_HOOK=new FinalizeEscapeGC()； //对象第一次成功拯救自己 SAVE_HOOK=null； System.gc()； //因为finalize方法优先级很低，所以暂停0.5秒以等待它 Thread.sleep(500）； if(SAVE_HOOK！=null）&#123; SAVE_HOOK.isAlive()； &#125;else&#123; System.out.println(&quot;no,i am dead：(&quot;)； &#125; //下面这段代码与上面的完全相同，但是这次自救却失败了 SAVE_HOOK=null； System.gc()； //因为finalize方法优先级很低，所以暂停0.5秒以等待它 Thread.sleep(500）； if（SAVE_HOOK！=null）&#123; SAVE_HOOK.isAlive()； &#125;else&#123; System.out.println(&quot;no,i am dead：(&quot;)； &#125; &#125;&#125; 运行结果： 123finalize mehtod executed！yes,i am still alive：)no,i am dead：( 因此对于不可达对象判定真正死亡的过程小结如下：（1）GC进行第一次标记并进行一次筛选（筛选那些覆盖了finalize方法并且finalize方法是第一次调用的对象）；（2）另一个低优先级的线程去调用那些被筛选出来的对象的finalize方法；（3）GC进行第二次标记，如果在前一步中那些筛选出来的对象没有在finalize拯救自己，此时，那些未被筛选到的和这些这些筛选到的但是没有拯救自己的对象都将会回收。 1.5 方法区收回很多人认为方法区（或者HotSpot虚拟机中的永久代）是没有垃圾收集的，Java虚拟机规范中确实说过可以不要求虚拟机在方法区实现垃圾收集，而且在方法区中进行垃圾收集的“性价比”一般比较低：在堆中，尤其是在新生代中，常规应用进行一次垃圾收集一般可以回收70%～95%的空间，而永久代的垃圾收集效率远低于此。 永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类。回收废弃常量与回收Java堆中的对象非常类似。以常量池中字面量的回收为例，假如一个字符串“abc”已经进入了常量池中，但是当前系统没有任何一个String对象是叫做“abc”的，换句话说，就是没有任何String对象引用常量池中的“abc”常量，也没有其他地方引用了这个字面量，如果这时发生内存回收，而且必要的话，这个“abc”常量就会被系统清理出常量池。常量池中的其他类（接口）、方法、字段的符号引用也与此类似。 判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面3个条件才能算是“无用的类”： 该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样，不使用了就必然会回收。是否对类进行回收，HotSpot虚拟机提供了-Xnoclassgc参数进行控制，还可以使用-verbose：class以及-XX：+TraceClassLoading、-XX：+TraceClassUnLoading查看类加载和卸载信息，其中-verbose：class和-XX：+TraceClassLoading可以在Product版的虚拟机中使用，-XX：+TraceClassUnLoading参数需要FastDebug版的虚拟机支持。可能永久代的效果不理想，在JDK8中，已经没有永久代的概念了，原先这块区域被放置到本地内存了。 二：垃圾收集算法2.1 标记-清除算法最基础的收集算法是“标记-清除”（Mark-Sweep）算法，如同它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象，标记过程就是上面可达性分析算法中所讲的二次标记过程。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。标记-清除算法的执行过程如下图所示： 缺点：（1）效率问题：标记和清除的两个过程效率都不高；（2）空间问题：标记清除后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后需要分配较大对象时，无法找到足够的连续内存而不得不提前出发另一次垃圾收集动作； 2.2 复制算法为了解决效率问题，一种称为“复制”（Copying）的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为原来的一半，未免太高了一点。复制算法的执行过程如图复制算法的优点：（1）每次都是对整个半区进行内存回收，实现简单、运行也高效；（2）在那块使用内存上进行内存分配时，不用考虑内存碎片的问题，只要移动堆顶指针，按顺序分配内存即可；缺点：使用内存比原来缩小了一半。 按照新生代的特点，新生代中的对象98%是“朝生夕死”的，因此，可以改进上面的复制算法，目前商业虚拟机正是用这种改进的收集算法来回收新生代。改进的收集算法：根据新生代的特点，我们并不需要按照1:1的比例来划分内存空间，而是将内存划分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活的对象一次性地复制到另外一块Survivor空间。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间最后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的内存会被“浪费”。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（Handle Promotion）。 这种改进的收集算法也有一个问题，就是在回收时，那块空的Survivor空间能否放得下Eden和使用的Survivor空间中还存活的对象，如果Survivor空间不够存放上一次新生代收集下来的存活对象，此时就需要向老年代“借”内存，那些剩余未放下的对象就通过分配担保机制进入老年代。 2.4 标记-整理算法复制收集算法在对象存活率较高时就要执行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存，“标记-整理”算法的示意图如图 2.5 分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”（Generational Collection）算法，这种算法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。 三：垃圾收集器如果说上面介绍的收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现，按照上面的介绍，目前垃圾收集器基本都采用分代收集，因此一个垃圾收集器中一般都存在多种垃圾回收算法。不同的虚拟机提供的垃圾收集器也有很大差异，如下是HotSpot虚拟机基于JDK1.7版本所包含的所有垃圾收集器：HotSpot中共有7中不同的垃圾收集器，如果两个收集器之间存在连线，说明它们之间可以搭配使用，其中，Serial、ParNew、Parallel Scavenge属于新生代收集器，CMS、Serial Old、Parallel Old属于老年代收集器，G1是最新的一种收集器，在新生代和老年代中都可使用。 3.1 Serial（串行）收集器最基本、发展历史最悠久的一种收集器。看名字就知道，这个收集器是一个单线程的收集器，只使用一个CPU或一条收集线程去完成垃圾收集工作，最重要的是，在它进行垃圾收集的时候，必须暂停其他所有的工作线程，知道它收集结束。虽然有这个缺点，但是依然是虚拟机运行在Client模式下的默认新生代收集器。优点是：简单而高效，没有线程交互的开销。运行过程如图：新生代采用的是“复制算法”，老年代采用的是“标记-整理”算法。 3.2 ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其他行为和Serial收集器一样。ParNew是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关的重要原因，除了Serial收集器外，目前只有ParNew能与老年代的CMS收集器配合使用。ParNew是一种并行的收集器。在垃圾回收中，并行是指：多条垃圾收集线程并行工作，用户线程处于等待状态；并发是指：用户线程和垃圾收集线程同时执行（不一定并行，可能交替执行）。 3.3 Parallel Scavenge收集器Parallel Scavenge收集器使用的是复制算法，也是一个并行的多线程收集器。和ParNew相似，但是Parallel Scavenge的关注点不同，CMS收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量，吞吐量 = 运行用户代码时间 / (运行用户代码时间 + 垃圾收集时间)。 上面三种都是新生代收集器，下面介绍老年代收集器。 3.4 Serial Old收集器Serial Old收集器是新生代Serial收集器的老年代版本，同样是一个单线程收集器，使用“标记-整理”算法，Serial Old的主要意义也是在于给Client模式下的虚拟机使用。 3.5 Parallel Old收集器Parallel Old是新生代收集器Prarllel Scavenge的老年代版本，使用多线程和“标记-整理”算法。运行流程如下： 3.6 CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。对于互联网站或者B/S系统的这种注重响应速度的服务端来说，CMS是很好的选择。从名字Mark Sweep可以看出，CMS是基于“标记-清除”算法实现的，分为四个步骤：（1）初始标记（CMS initial mark）：仅仅标记一GC Roots能直接关联到的对象，这个步骤需要“stop the world”；（2）并发标记（CMS concurrent mark）：就是GC Roots进行可达性分析阶段，可并发执行；（3）重新标记（CMS remark）：修正并发标记期间发生变动的那一部分对象，这个步骤需要“stop the world”；（4）并发清除（CMS concurrent sweep）：执行清除阶段。执行过程如下：可以看到，初始标记和重新标记阶段都是并行的，需要暂停用户线程（过程比较短）；在并发标记和并发清除阶段是并发的，可以和用户线程一起工作。 CMS的优点：并发收集、低停顿。CMS的缺点：（1）对CPU资源非常敏感，面向并发设计程序的通病，虽然不至于导致用户线程停顿，但是会降低吞吐率；（2）无法清理“浮动垃圾”，由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断出现，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次的GC；（3）会产生大量空间碎片，因为CMS是基于“标记-清除”算法，这种算法的最大缺点就是会产生大量空间碎片，给分配大对象带来麻烦，不得不提前触发Full GC。为了解决这个问题，CMS提供了一个“-XX:+UseCMSCompaceAtFullCollection”的开关参数（默认开启），用于在CMS收集器顶不住要进行Full GC时开启内存碎片的合并整理过程。 3.7 G1收集器G1收集器是最新的一款收集器，JDK1.7才发布，是一种面向服务端应用的垃圾收集器，有如下特点：（1）并行与并发：G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿的时间；（2）分代收集：分代概念在G1中依然得以保留。虽然G1可以不需其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果；（3）空间整合：与CMS的“标记-清理”算法不同，G1从整体看来是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上看是基于“复制”算法实现，无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存；（4）可预测的停顿时间； 使用G1收集器时，Java堆的内存布局与就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。 G1的收集过程分为以下几个步骤：（1）初始标记（Initial Marking）（2）并发标记（Concurrent Marking）（3）最终标记（Final Marking）（4）筛选回收（Live Data Counting and Evacuation）前几个步骤和CMS有很多相似之处。运行示意图如下： 四：总结JVM内存模型中分两大块，一块是New Generation, 另一块是Old Generation. 在New Generation中，有一个叫Eden的空间，主要是用来存放新生的对象，还有两个Survivor Spaces（from,to）, 它们用来存放每次垃圾回收后存活下来的对象。在Old Generation中，主要存放应用程序中生命周期长的内存对象，还有个Permanent Generation，主要用来放JVM自己的反射对象，比如类对象和方法对象等。1) 在New Generation块中，垃圾回收一般用复制算法，速度快。每次GC的时候，存活下来的对象首先由Eden拷贝到某个Survivor Space, 当Survivor Space空间满了后, 剩下的live对象就被直接拷贝到Old Generation中去。因此，每次GC后，Eden内存块会被清空 2) 在Old Generation块中，垃圾回收一般用标记整理的算法，速度慢些，但减少内存要求. 垃圾回收分多级，0级为全部(Full)的垃圾回收，会回收Old段中的垃圾；1级或以上为部分垃圾回收，只会回收New中的垃圾，内存溢出通常发生于Old段或Perm段垃圾回收后，仍然无内存空间容纳新的Java对象的情况。 Out Of Memory 只发生在jvm对old和perm generation 回收后还不能获足够内存的情况.当生成一个新对象时，内存申请过程如下：A. JVM会试图为相关Java对象在Eden中初始化一块内存区域B. 当Eden空间足够时，内存申请结束。否则到下一步C. JVM试图释放在Eden中所有不活跃的对象（这属于1或更高级的垃圾回收）, 释放后若Eden空间仍然不足以放入新对象，则试图将部分Eden中活跃对象放入Survivor区D. Survivor区被用来作为Eden及Old的中间交换区域，当Old区空间足够时，Survivor区的对象会被移到Old区，否则会被保留在Survivor区E. 当Old区空间不够时，JVM会在Old区进行完全的垃圾收集（0级）F. 完全垃圾收集后，若Survivor及Old区仍然无法存放从Eden复制过来的部分对象，导致JVM无法在Eden区为新对象创建内存区域，则出现”out of memory错误” 造成full gc的原因new了很多对象,没有即时在主动释放掉-&gt;Eden内存不够用-&gt;不断把对象往old迁移-&gt;old满了-&gt;full gc 总结：上面的内容就介绍了Java虚拟机如何管理对象的，我们也看到了上面主要就是收集算法和堆空间的从新划分，这样做的目的都是在于垃圾回收的高效执行，但是总归看来，如果对象交给系统来管理，在系统运行的过程效率肯定会有影响的，但是这有一点比较好，就是不需要手动管理，给程序猿带来方便。","tags":[{"name":"JVM","slug":"JVM","permalink":"http://wangyuanjun.cn/tags/JVM/"}]},{"title":"Java虚拟机学习——Java内存区域与内存溢出异常","date":"2018-02-01T02:50:54.000Z","path":"2018/02/01/Java虚拟机学习——Java内存区域与内存溢出异常/","text":"一：运行时数据区域 1.1 程序计数器（Program Counter Register）程序计数器（Program Counter Register），也有称作为PC寄存器。在汇编语言中，程序计数器是指CPU中的寄存器，它保存的是程序当前执行的指令的地址（也可以说保存下一条指令的所在存储单元的地址），当CPU需要执行指令时，需要从程序计数器中得到当前需要执行的指令所在存储单元的地址，然后根据得到的地址获取到指令，在得到指令之后，程序计数器便自动加1或者根据转移指针得到下一条指令的地址，如此循环，直至执行完所有的指令。虽然JVM中的程序计数器并不像汇编语言中的程序计数器一样是物理概念上的CPU寄存器，但是JVM中的程序计数器的功能跟汇编语言中的程序计数器的功能在逻辑上是等同的，也就是说是用来指示 执行哪条指令的。程序计数器（ Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于在JVM中，多线程是通过线程轮流切换来获得CPU执行时间的，因此，在任一具体时刻，一个CPU的内核只会执行一条线程中的指令，因此，为了能够使得每个线程都在线程切换后能够恢复在切换之前的程序执行位置，每个线程都需要有自己独立的程序计数器，并且不能互相被干扰，否则就会影响到程序的正常执行次序,此时程序计数器需要记录当前线程执行到哪一步了，以便下一次CPU可以在这个记录点上继续执行。因此，可以这么说，程序计数器是每个线程所私有的。 在JVM规范中规定，如果线程执行的是非native方法，则程序计数器中保存的是当前需要执行的指令的地址,如果线程执行的是native方法，则程序计数器中的值是undefined。 由于程序计数器中存储的数据所占空间的大小不会随程序的执行而发生改变，因此，对于程序计数器是不会发生内存溢出现象(OutOfMemory)的。 1.2 java虚拟机栈与程序计时器一样,虚拟机栈也是线程私有的，它的生命周期与线程相同，虚拟机中描述的是Java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧（Stack Frame）(Java栈中存放的是一个个的栈帧，每个栈帧对应一个被调用的方法)，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直到执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈道出栈的过程。当线程执行一个方法时，就会随之创建一个对应的栈帧，并将建立的栈帧压栈。当方法执行完毕之后，便会将栈帧出栈。因此可知，线程当前执行的方法所对应的栈帧必定位于Java栈的顶部。其中局部变量表中存放了编译器可知的各种基本数据类型、对象引用类型（不是对象本身）。 局部变量表，就是用来存储方法中的局部变量（包括在方法中声明的非静态变量以及函数形参）。局部变量表中存放了编译器可知的各种基本数据类型(boolean、byte、char、short、int、float、long、double)、对象引用（ reference 类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和 returnAddress 类型（指向了一条字节码指令的地址）。对于基本数据类型的变量，则直接存储它的值，对于引用类型的变量，则存的是指向对象的引用。局部变量表所需的内存空间在编译期完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期不会改变局部变量大小。 操作数栈，栈最典型的一个应用就是用来对表达式求值。想想一个线程执行方法的过程中，实际上就是不断执行语句的过程，而归根到底就是进行计算的过程。因此可以这么说，程序中的所有计算过程都是在借助于操作数栈来完成的以及参数的传递。 指向运行时常量池的引用，因为在方法执行的过程中有可能需要用到类中的常量，所以必须要有一个引用指向运行时常量。 方法返回地址，当一个方法执行完毕之后，要返回之前调用它的地方，因此在栈帧中必须保存一个方法返回地址。由于每个线程正在执行的方法可能不同，因此每个线程都会有一个自己的Java栈，互不干扰。 对于java虚拟机栈，有两种异常情况：1)如果线程请求的栈深度大于虚拟机所允许的深度，将抛出 StackOverflowError 异常 。2)如果虚拟机栈扩展时无法申请到足够的内存时会抛出 OutOfMemoryError 异常。 1.3 本地方法栈（Native Method Stack）线程私有。本地方法栈与Java栈的作用和原理非常相似。区别只不过是虚拟机栈为虚拟机执行 Java 方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的 Native方法服务。有的虚拟机（譬如 Sun HotSpot 虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈也会抛出StackOverflowError和OutMemoryError错误。 1.4 java堆(Java Heap)对于大多数应用来说，Java堆是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java 堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC 堆”（Garbage Collected Heap）。如果从内存回收的角度看，由于现在收集器基本采用分代回收算法，所以Java堆还可细分为：新生代（Young Generation）与老生代(Old Generation)；再细致一点的有Eden空间,From Survivor空间,To Survivor空间等。值得注意的是，从JKD1.7开始，永久代Perm逐渐被移除，最新的JDK1.8中已经使用元空间（MetaSpace）代替永久代。如果从内存分配的角度看，线程共享的Java堆中可能划分出多个线程私有的分配缓冲区。但无论怎么去划分，无论那个区域，java堆中存储的依然是对象的实例。进一步划分的目的是为了更好地回收内存，或者更快地分配内存。当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。如果堆中没有内存完成实例分配，并且对也无法再扩展时，将会抛出OutOfMemoryError异常。如图，新生代还可以分为Eden空间、From Survivor空间、To Survivor空间。永久代(Permanent Generation)用于存储静态类型数据，与垃圾收集器关系不大。注意：本图展示的是JVM堆的内存模型，JVM堆内存包括Java堆区域 和 永久代区域。因此，永久代不属于Java堆。 1.5 方法区（Method Area）方法区是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据 。 方法区与堆一样，是各个线程共享的内存区域。在方法区中，存储了每个类的信息（包括类的名称、方法信息、字段信息）、静态变量、常量以及编译器编译后的代码等。在JVM规范中，没有强制要求方法区必须实现垃圾回收。很多人习惯将方法区称为“永久代”，是因为HotSpot虚拟机以永久代来实现方法区，从而JVM的垃圾收集器可以像管理堆区一样管理这部分区域，从而不需要专门为这部分设计垃圾回收机制。不过自从JDK7之后，Hotspot虚拟机便将运行时常量池从永久代移除了。相对而言，垃圾收集行为在这个区域比较少出现，但并非数据进了方法区就永久的存在了，这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载。JDK1.7中，已经把放在永久代的字符串常量池移到堆中。JDK1.8撤销永久代，引入元空间。 根据java虚拟机规范的规定：当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 1.6 运行时常量池运行时常量池是方法区的一部分，在Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用。这部分内容将在类加载后进入方法区的运行时常量池中存放。 同时运行时常量池具备动态性，并非预置入Class文件中常量池的内存才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，例如String类的intern()方法(方法返回s1在常量池中的引用，没有则创建)。既然运行时常量池是方法区的一部分，自然受到方法区内存限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 1.7 直接内存（Direct Memory）直接内存（Direct memory）并不是JVM运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。但这部分内存也被频繁使用，而且它也可能导致OutOfMemoryError异常出现。 直接内存不是虚拟机运行时数据区的一部分，在NIO类中引入一种基于通道与缓冲区的IO方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因此避免了在java堆和Native堆中来回复制数据。 本机直接内存的分配不会受到Java堆大小的限制，但是，还是会受到本机总内存（包括RAM及SWAP区或者分页文件）的大小及处理器寻址空间的限制，从而导致动态扩展时出现OutOfMemoryError异常。 二：hotspot虚拟机对象奥秘2.1 对象的创建过程Java在语言层面，通过一个关键字new来创建对象。在虚拟机中，当遇到一条new指令后，将开始如下创建过程： 2.1.1 判断类是否加载、解析、初始化虚拟机遇到一条new指令时，先去检查这个指定的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那先执行相应的类加载过程。 2.1.2 为新对象分配内存前面说到，对象的内存分配是在Java堆中的，对象所需内存的大小在类加载完便可确实。为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来，此时Java堆中的情况有两种可能，一种是Java堆中内存是绝对规整的，一种是Java堆中的内存并不是规整的。因此有两种分配方式： Java堆内存是规整的，即所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，此时，分配内存仅需要把这个指针向空闲空间那边挪动一段与对象大小相等的距离，这种方式也称为“指针碰撞”（Bump the Pointer）； Java堆内存不是规整的，即已使用的内存和空闲的内存相互交错，就没有办法简单地进行指针的移动，此时的分配方案是，虚拟机必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的控件划分给对象实例，并更新列表上的记录，这种方式也称为“空闲列表”（Free List）； 选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。因此，对于Serial、ParNew等带Compact过程的垃圾收集器，系统采用的是指针碰撞算法；对于CMS这种基于Mark-Sweep算法的收集器，通常采用空闲列表算法。 2.1.3 解决并发安全问题确定了如何划分内存空间之后，还有一个问题就是，对象的创建在虚拟机中是非常频繁的行为，比如，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况，解决这种并发问题，一般有两种方案： 对分配内存空间的动作进行同步处理，比如，虚拟机采用CAS配上失败重试的方式保证更新操作的原子性； 另一种方式是，把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer，TLAB），哪个线程要分配内存，就在哪个线程的TLAB上分配。只有TLAB用完并分配新的TLAB时，才需要同步锁定，虚拟机是否使用TLAB，可以通过-XX:+/-UserTLAB参数来设定。 2.1.4 初始化分配到的内存空间内存分配完成后，虚拟机将分配到的内存空间都初始化为零值（不包括对象头），如果使用TLAB，这一工作也可以提前至TLAB分配时进行。也正是这一步操作，才保证了我们对象的实例字段在Java代码中可以不赋初值就直接使用。注意，此时对象的实例字段全部为零值，并没有按照程序中的初值进行初始化。 2.1.5 设置对象实例的对象头上面工作完成后，虚拟机对对象进行必要的设置，主要是设置对象的对象头信息，比如，这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等… 2.1.6 初始化对象方法其实，上面工作完成后，从虚拟机角度来看，一个新的对象已经产生了，但从Java程序的角度来看，对象创建才刚刚开始，对象实例中的字段仅仅都为零值，还需要通过方法进行初始化，把对象按照程序员的意愿进行初始化。此时，一个真正可用的对象才算完全产生出来。 2.2 对象的内存布局经过前面的创建工作，一个对象已经成功产生，也已经在Java堆中分配好了内存。那这个对象在Java堆内存中到底是什么形态呢？又包括哪些部分呢？这就涉及到了对象的内存布局了。不同的虚拟机实现中，对象的内存布局有差别，以最常用的HotSpot虚拟机为例，对象在内存中存储的布局分为3块区域：对象头（Header）、实例数据（Instance Data）、对齐填充（Padding）。 对象头：包含两部分信息，一部分是用于存储对象自身的运行时数据，如哈希码、GC分代年龄、锁状态标志等；另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。如果对象是一个Java数组，对象头中还有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中却无法确定数组大小。 实例数据：真正存储对象有效信息的部分。也就是在程序中定义的各种类型的字段内容，包括从父类继承下来的，以及子类中定义的，都会在实例数据中记录。 对齐填充：不是必然存在的，仅起着占位符的作用，对于HotSpot来说，虚拟机的自动内存管理系统要求对象其实地址必须是8字节的整数倍，因此，如果对象实例数据部分没有对齐时，就需要通过对齐填充的方式来补全。 2.3 对象的访问定位建立了对象是为了使用对象，我们对数据的使用是通过栈上的reference数据来操作堆上的具体对象，对于不同的虚拟机实现，reference数据类型有不同的定义，主要是如下两种访问方式： 2.3.1 使用句柄访问此时，Java堆中将会划出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息，如下图： 2.3.2 使用直接指针访问此时reference中存储的就是对象的地址。如下图： 上面所说的，所谓对象类型，其实就是指，对象所属的哪个类。 上面两种对象访问方式各有优势，使用句柄访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时，只会改变句柄中的实例数据指针，而reference本身不需要修改；使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销（根据上图，节省的是对象实例数据的指针定位），由于对象的访问在Java中非常频繁，因此，这类开销积少成多后也是一项非常可观的执行成本。对于HotSpot而言，选择的是第二种方式。 三：内存溢出OOM分为两种情况：内存溢出（Memory Overflow）和内存泄漏（Memory Leak）。 3.1 OutOfMemoryError是指程序在申请内存时，没有足够的空间供其使用，出现了Out Of Memory，也就是要求分配的内存超出了系统能给你的，系统不能满足需求，于是产生溢出。内存溢出分为上溢和下溢，比方说栈，栈满时再做进栈必定产生空间溢出，叫上溢，栈空时再做退栈也产生空间溢出，称为下溢。 3.1.1 java堆溢出(OutOfMemoryError：Java heap space)是被所有线程共享的一块内存区域，该内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都是在这里分配创建。由于他是虚拟机中管理的最大一块内存，所以是主要的收集区域。如果还需要再堆上分配实例，但是无法扩展出足够的内存空间，将会抛出OutOfMemoryError异常。Java堆用于存储对象实例，我们只要不断的创建对象，而又没有及时回收这些对象（即内存泄漏），就会在对象数量达到最大堆容量限制后产生内存溢出异常。如下代码限制java堆的大小为1m，不可扩展（就堆的最小值-Xms参数与最大值-Xmx参数设置为一样的即可避免堆自动扩展），通过参数-XX:+HeapDumpOnOutOfMemoryError可以让虚拟机在出现内存溢出时Dump出当前的转储快照以便事后进行分析。 /** * VM Args: -Xms1m -Xmx1m -XX:+HeapDumpOnOutOfMemoryError * java堆溢出 * * @author：WangYuanJun * @date：2018年2月7日 下午2:22:42 */ public class HeapOOM { static class OOMObejct { } public static void main(String[] args) { List&lt;OOMObejct&gt; list = new ArrayList&lt;&gt;(); while (true) { list.add(new OOMObejct()); } } } java.lang.OutOfMemoryError: Java heap space Dumping heap to java_pid4008.hprof ... Heap dump file created [2760158 bytes in 0.013 secs] Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at com.example.demo.test3.HeapOOM.main(HeapOOM.java:21) 3.1.2 虚拟机栈和本地方法栈溢出(OutOfMemoryError：Java heap space)虚拟机栈：每个线程有一个私有的栈，随着线程的创建而创建。栈里面存着的是一种叫“栈帧”的东西，每个方法会创建一个栈帧，栈帧中存放了局部变量表（基本数据类型和对象引用）、操作数栈、方法出口等信息。栈的大小可以固定也可以动态扩展。当栈调用深度大于JVM所允许的范围，会抛出StackOverflowError的错误，不过这个深度范围不是一个恒定的值，我们通过下面这段程序可以测试一下这个结果当应用程序递归太深而发生堆栈溢出时，抛出该错误。因为栈一般默认为1-2m，一旦出现死循环或者是大量的递归调用，在不断的压栈过程中，造成栈容量超过1m而导致溢出。栈溢出的原因：（1）递归调用（2）大量循环或死循环（3）全局变量是否过多（4）数组、List、Map数据过大1)如果线程请求的栈深度大于虚拟机所允许的深度，将抛出 StackOverflowError 异常 。 /** * VM Args: -Xss160k * * * @author：WangYuanJun * @date：2018年2月7日 下午2:45:03 */ public class JavaVMStackSOF { private int stackLen = 1; public void stackLeak() { stackLen++; stackLeak(); } public static void main(String[] args) throws Throwable { JavaVMStackSOF oom = new JavaVMStackSOF(); try { oom.stackLeak(); } catch (Throwable e) { System.out.println(&quot;stack length:&quot; + oom.stackLen); throw e; } } } stack length:771Exception in thread &quot;main&quot; java.lang.StackOverflowError at com.wdm.mem.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11) at com.wdm.mem.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:12) at com.wdm.mem.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:12) at com.wdm.mem.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:12) 2)如果虚拟机栈扩展时无法申请到足够的内存时会抛出 OutOfMemoryError 异常。 /** * VM Args: -Xss2m * * * @author：WangYuanJun * @date：2018年2月7日 下午3:04:59 */ public class JavaVMStackOOM { private void dontStop() { while (true) { } } public void stackLeakByThread() { while (true) { Thread thread = new Thread(new Runnable() { @Override public void run() { dontStop(); } }); thread.start(); } } public static void main(String[] args) { JavaVMStackOOM javaVMStackOOM = new JavaVMStackOOM(); javaVMStackOOM.stackLeakByThread(); } } Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: unable to create new native thread 3.1.3 方法区和运行常量池溢出1.方法区溢出绝大部分 Java 程序员应该都见过 “java.lang.OutOfMemoryError: PermGen space “这个异常。这里的 “PermGen space”其实指的就是方法区。不过方法区和“PermGen space”又有着本质的区别。前者是 JVM 的规范，而后者则是 JVM 规范的一种实现，并且只有 HotSpot 才有 “PermGen space”，而对于其他类型的虚拟机，如 JRockit（Oracle）、J9（IBM） 并没有“PermGen space”。由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。最典型的场景就是，在 jsp 页面比较多的情况，容易出现永久代内存溢出。我们现在通过动态生成类来模拟 “PermGen space”的内存溢出：1234567891011121314151617181920212223242526 /** * jdk1.7 * VM Args: -XX:PermSize=8M -XX:MaxPermSize=8M * * @author：WangYuanJun * @date：2018年2月2日 下午1:42:48 */public class PermGenOomMock&#123; public static void main(String[] args) &#123; URL url = null; List&lt;ClassLoader&gt; classLoaderList = new ArrayList&lt;ClassLoader&gt;(); try &#123; url = new File(&quot;/tmp&quot;).toURI().toURL(); URL[] urls = &#123;url&#125;; while (true)&#123; ClassLoader loader = new URLClassLoader(urls); classLoaderList.add(loader); loader.loadClass(&quot;com.example.demo.test2.test&quot;); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: PermGen space 本例中使用的 JDK 版本是 1.7，指定的 PermGen 区的大小为 8M。通过每次生成不同URLClassLoader对象来加载Test类，从而生成不同的类对象，这样就能看到我们熟悉的 “java.lang.OutOfMemoryError: PermGen space “ 异常了。这里之所以采用 JDK 1.7，是因为在 JDK 1.8 中， HotSpot 已经没有 “PermGen space”这个区间了，取而代之是一个叫做 Metaspace（元空间） 的东西。下面我们就来看看 Metaspace 与 PermGen space 的区别。可参考Java8内存模型—永久代(PermGen)和元空间(Metaspace) 2.运行常量池溢出 其实，移除永久代的工作从JDK1.7就开始了。JDK1.7中，存储在永久代的部分数据就已经转移到了Java Heap或者是 Native Heap。但永久代仍存在于JDK1.7中，并没完全移除，譬如符号引用(Symbols)转移到了native heap；字面量(interned strings)转移到了java heap；类的静态变量(class statics)转移到了java heap。我们可以通过一段程序来比较 JDK 1.6 与 JDK 1.7及 JDK 1.8 的区别，以字符串常量为例： 1234567891011121314151617181920运行常量池溢出(jdk1.6及jdk1.6之前)/** * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M -Xmx16m * 使用jdk1.6及jdk1.6之前 * * @author：WangYuanJun * @date：2018年2月2日 下午2:10:12 */public class RuntimeConsPoolOOM &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); int i = 0; while (true) &#123; list.add(String.valueOf(i++).intern()); &#125; &#125;&#125;Exception in thread &quot;main&quot; java.lang.OutOfMemoryError： PermGen space 12345678910111213141516171819/** * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M -Xmx16m * 使用jdk1.7 * * @author：WangYuanJun * @date：2018年2月2日 下午2:10:12 */public class RuntimeConsPoolOOM &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); int i = 0; while (true) &#123; list.add(String.valueOf(i++).intern()); &#125; &#125;&#125;Exception in thread &quot;main&quot; java.lang.OutOfMemoryError： Java heap space 12345678910111213141516171819/** * VM Args: -Xmx16m * 使用jdk1.8 * * @author：WangYuanJun * @date：2018年2月2日 下午2:10:12 */public class RuntimeConsPoolOOM &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); int i = 0; while (true) &#123; list.add(String.valueOf(i++).intern()); &#125; &#125;&#125;Exception in thread &quot;main&quot; java.lang.OutOfMemoryError： Java heap space 从上述结果可以看出，JDK 1.6下，会出现“PermGen Space”的内存溢出，而在 JDK 1.7和 JDK 1.8 中，会出现堆内存溢出，并且 JDK 1.8中 PermSize 和 MaxPermGen 已经无效。因此，可以大致验证 JDK 1.7 和 1.8 将字符串常量由永久代转移到堆中，并且 JDK 1.8 中已经不存在永久代的结论。现在我们看看元空间到底是一个什么东西？ 元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制，但可以通过以下参数来指定元空间的大小： -XX:MetaspaceSize，初始空间大小，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize时，适当提高该值。 -XX:MaxMetaspaceSize，最大空间，默认是没有限制的。 除了上面两个指定大小的选项以外，还有两个与 GC 相关的属性： -XX:MinMetaspaceFreeRatio，在GC之后，最小的Metaspace剩余空间容量的百分比，减少为分配空间所导致的垃圾收集 -XX:MaxMetaspaceFreeRatio，在GC之后，最大的Metaspace剩余空间容量的百分比，减少为释放空间所导致的垃圾收集 现在我们在 JDK 8下重新运行一下代码段 ，不过这次不再指定 PermSize 和 MaxPermSize。而是指定 MetaSpaceSize 和 MaxMetaSpaceSize的大小。输出结果如下：12345678910111213141516171819202122232425262728 /** * jdk1.8 * -XX:MetaspaceSize=8m -XX:MaxMetaspaceSize=8m * 1.8无PermGen space，取而代之是一个叫做 Metaspace（元空间） * Metaspace（元空间）内存溢出 * 解决：增大perm区，允许class回收 * * @author：WangYuanJun * @date：2018年2月2日 下午1:42:48 */public class PermGenOomMock&#123; public static void main(String[] args) &#123; URL url = null; List&lt;ClassLoader&gt; classLoaderList = new ArrayList&lt;ClassLoader&gt;(); try &#123; url = new File(&quot;/tmp&quot;).toURI().toURL(); URL[] urls = &#123;url&#125;; while (true)&#123; ClassLoader loader = new URLClassLoader(urls); classLoaderList.add(loader); loader.loadClass(&quot;com.example.demo.test2.test&quot;); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;Exception in thread &quot;main&quot; java.lang.OutOfMemoryError： Metaspace 3.1.4 本机直接内存溢出通过参数-XX:MaxDirectMemorySize指定DirectMemory容量，若不指定则与Java堆最大值一样。可以直接通过反射获取Unsafe实例并进行内存分配，使用unsafe.allocateMemory()申请分配内存。不足时会出现OutOfMemoryError。 3.2 内存泄露（memory leak）是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存,迟早会被占光，举个例子，就是说系统的篮子（内存）是有限的，而你申请了一个篮子，拿到之后没有归还（忘记还了或是丢了），于是造成一次内存泄漏。在你需要用篮子的时候，又去申请，如此反复，最终系统的篮子无法满足你的需求，最终会由内存泄漏造成内存溢出。 四：总结4.1 内存区域模型小结：（1）线程私有的区域：程序计数器、虚拟机栈、本地方法栈； （2）所有线程共享的区域：Java堆、方法区；（注：直接内存不属于虚拟机内存模型的部分） （3）没有异常的区域：程序计数器； （4）StackOverflowError异常：Java虚拟机栈、本地方法栈； （5）OutOfMemoryError异常：除程序计数器外的其他四个区域，Java虚拟机栈、本地方法栈、Java堆、方法区；直接内存也会出现OutOfMemoryError。 4.2 类和对象在运行时的内存里是怎么样的？以及各类型变量、方法在运行时是怎么交互的？- 在程序运行时类是在方法区，实例对象本身在堆里面。 - 方法字节码在方法区。 - 线程调用方法执行时创建栈帧并压栈，方法的参数和局部变量在栈帧的局部变量表。 - 对象的实例变量和对象一起在堆里，所以各个线程都可以共享访问对象的实例变量。 - 静态变量在方法区，所有对象共享。字符串常量等常量在运行时常量池。 - 各线程调用的方法，通过堆内的对象，方法区的静态数据，可以共享交互信息。 对于JVM的内存管理， 最重要的还是与OS内存管理知识进行类比以及结合实践来学习。理解JVM内存区域的目的也是为了在工程中出现内存相关异常时能够准确的定位所在区域，及时处理。 参考:周志明:《深入理解Java虚拟机：JVM高级特性与最佳实践》","tags":[{"name":"JVM","slug":"JVM","permalink":"http://wangyuanjun.cn/tags/JVM/"}]},{"title":"IntelliJ IDEA 2017.3激活","date":"2018-01-31T15:42:34.000Z","path":"2018/01/31/IntelliJ-IDEA-2017-3激活/","text":"最新的IDEA激活方式，博主使用的是3.4的版本 方法一：使用激活服务器激活方法(博主使用此方法)由于JetBrains封杀，大部分激活服务器已经不能使用，目前可用的网址有： 1http://idea.java.sx 步骤1、打开注册/激活窗口； 2、选择 License server； 3、填入上述其中一个网址； 4、点击Activate即可完美激活! 方法二：注册码激活方法1、进入hosts文件中：C:\\Windows\\System32\\drivers\\etc\\hosts2、将“0.0.0.0 account.jetbrains.com”添加到hosts文件中注意：添加只有重新打开hosts文件进行确认之后在进行下一步操作。修改成功后如图所示：注：将这条数据加入之后会提示保存，然后确认之后，重新打开hosts文件确认是否添加成功，有时候会提示确认两次。3、点击获得注册码，点我，然后将注册码复制，粘贴到IDEA中4、点击获得注册码即可获得IDEA激活码。 方法三：本地搭建激活服务器激活方法1、下载IDEA本地服务器，点我下载(密码jx0m) 2、解压到本地硬盘任意位置，运行相应程序，32位操作系统请双击运行32位程序，64位操作系统请双击运行64位程序，如下图：3、运行结果如图：4、打开IDEA，在激活框内输入上图标示的网址即可。 注：在新版本IDEA2017.3中可能会出现无法激活的情况，此时将网址改为http://0.0.0.0:1017即可。 方法四：破解补丁激活方法（1）破解补丁下载点我下载(密码jilt)将下载的破解补丁放在你的安装IDEA下面的bin的目录下面（如图），本文示例为E:\\develop-tools\\toolsInstall\\idea\\IntelliJ IDEA 2017.3.4\\bin（2）修改配置文件 在安装的IDEA下面的bin目录下面有2个文件 ： idea.exe.vmoptions和idea64.exe.vmoptions。用记事本打开，在上述两个文件的最后一行均加上下面这段代码（红色字体部分为你的IDEA安装目录）： -javaagent:E:\\develop-tools\\toolsInstall\\idea\\IntelliJ IDEA 2017.3.4\\bin\\JetbrainsCrack-2.6.10-release-enc.jar （3）输入激活码 启动IDEA，第一次进入会提示激活，选择Activation Code，并输入如下激活码： BIG3CLIK6F-eyJsaWNlbnNlSWQiOiJCSUczQ0xJSzZGIiwibGljZW5zZWVOYW1lIjoibGFuIHl1IiwiYXNzaWduZWVOYW1lIjoiIiwiYXNzaWduZWVFbWFpbCI6IiIsImxpY2Vuc2VSZXN0cmljdGlvbiI6IkZvciBlZHVjYXRpb25hbCB1c2Ugb25seSIsImNoZWNrQ29uY3VycmVudFVzZSI6ZmFsc2UsInByb2R1Y3RzIjpbeyJjb2RlIjoiQUMiLCJwYWlkVXBUbyI6IjIwMTctMTEtMjMifSx7ImNvZGUiOiJETSIsInBhaWRVcFRvIjoiMjAxNy0xMS0yMyJ9LHsiY29kZSI6IklJIiwicGFpZFVwVG8iOiIyMDE3LTExLTIzIn0seyJjb2RlIjoiUlMwIiwicGFpZFVwVG8iOiIyMDE3LTExLTIzIn0seyJjb2RlIjoiV1MiLCJwYWlkVXBUbyI6IjIwMTctMTEtMjMifSx7ImNvZGUiOiJEUE4iLCJwYWlkVXBUbyI6IjIwMTctMTEtMjMifSx7ImNvZGUiOiJSQyIsInBhaWRVcFRvIjoiMjAxNy0xMS0yMyJ9LHsiY29kZSI6IlBTIiwicGFpZFVwVG8iOiIyMDE3LTExLTIzIn0seyJjb2RlIjoiREMiLCJwYWlkVXBUbyI6IjIwMTctMTEtMjMifSx7ImNvZGUiOiJEQiIsInBhaWRVcFRvIjoiMjAxNy0xMS0yMyJ9LHsiY29kZSI6IlJNIiwicGFpZFVwVG8iOiIyMDE3LTExLTIzIn0seyJjb2RlIjoiUEMiLCJwYWlkVXBUbyI6IjIwMTctMTEtMjMifSx7ImNvZGUiOiJDTCIsInBhaWRVcFRvIjoiMjAxNy0xMS0yMyJ9XSwiaGFzaCI6IjQ3NzU1MTcvMCIsImdyYWNlUGVyaW9kRGF5cyI6MCwiYXV0b1Byb2xvbmdhdGVkIjpmYWxzZSwiaXNBdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlfQ==-iygsIMXTVeSyYkUxAqpHmymrgwN5InkOfeRhhPIPa88FO9FRuZosIBTY18tflChACznk3qferT7iMGKm7pumDTR4FbVVlK/3n1ER0eMKu2NcaXb7m10xT6kLW1Xb3LtuZEnuis5pYuEwT1zR7GskeNWdYZ0dAJpNDLFrqPyAPo5s1KLDHKpw+VfVd4uf7RMjOIzuJhAAYAG+amyivQt61I9aYiwpHQvUphvTwi0X0qL/oDJHAQbIv4Qwscyo4aYZJBKutYioZH9rgOP6Yw/sCltpoPWlJtDOcw/iEWYiCVG1pH9AWjCYXZ9AbbEBOWV71IQr5VWrsqFZ7cg7hLEJ3A==-MIIEPjCCAiagAwIBAgIBBTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE1MTEwMjA4MjE0OFoXDTE4MTEwMTA4MjE0OFowETEPMA0GA1UEAwwGcHJvZDN5MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxcQkq+zdxlR2mmRYBPzGbUNdMN6OaXiXzxIWtMEkrJMO/5oUfQJbLLuMSMK0QHFmaI37WShyxZcfRCidwXjot4zmNBKnlyHodDij/78TmVqFl8nOeD5+07B8VEaIu7c3E1N+e1doC6wht4I4+IEmtsPAdoaj5WCQVQbrI8KeT8M9VcBIWX7fD0fhexfg3ZRt0xqwMcXGNp3DdJHiO0rCdU+Itv7EmtnSVq9jBG1usMSFvMowR25mju2JcPFp1+I4ZI+FqgR8gyG8oiNDyNEoAbsR3lOpI7grUYSvkB/xVy/VoklPCK2h0f0GJxFjnye8NT1PAywoyl7RmiAVRE/EKwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQC9WZuYgQedSuOc5TOUSrRigMw4/+wuC5EtZBfvdl4HT/8vzMW/oUlIP4YCvA0XKyBaCJ2iX+ZCDKoPfiYXiaSiH+HxAPV6J79vvouxKrWg2XV6ShFtPLP+0gPdGq3x9R3+kJbmAm8w+FOdlWqAfJrLvpzMGNeDU14YGXiZ9bVzmIQbwrBA+c/F4tlK/DV07dsNExihqFoibnqDiVNTGombaU2dDup2gwKdL81ua8EIcGNExHe82kjF4zwfadHk3bQVvbfdAwxcDy4xBjs3L4raPLU3yenSzr/OEur1+jfOxnQSmEcMXKXgrAQ9U55gwjcOFKrgOxEdek/Sk1VfOjvS+nuM4eyEruFMfaZHzoQiuw4IqgGc45ohFH0UUyjYcuFxxDSU9lMCv8qdHKm+wnPRb0l9l5vXsCBDuhAGYD6ss+Ga+aDY6f/qXZuUCEUOH3QUNbbCUlviSz6+GiRnt1kA9N2Qachl+2yBfaqUqr8h7Z2gsx5LcIf5kYNsqJ0GavXTVyWh7PYiKX4bs354ZQLUwwa/cG++2+wNWP+HtBhVxMRNTdVhSm38AknZlD+PTAsWGu9GyLmhti2EnVwGybSD2Dxmhxk3IPCkhKAK+pl0eWYGZWG3tJ9mZ7SowcXLWDFAk0lRJnKGFMTggrWjV8GYpw5bq23VmIqqDLgkNzuoog== （4）软件启动，进入Help，选择About，页面显示December 31，2099到期，完成激活。如下图：","tags":[{"name":"工具","slug":"工具","permalink":"http://wangyuanjun.cn/tags/工具/"},{"name":"IDEA","slug":"IDEA","permalink":"http://wangyuanjun.cn/tags/IDEA/"}]},{"title":"Java虚拟机学习——类加载机制","date":"2018-01-31T09:28:16.000Z","path":"2018/01/31/Java虚拟机学习——类加载机制/","text":"一：类加载机制概述虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。在java中，类型的加载、连接和初始化过程都是在程序运行期间完成的，这种策略虽然会带来一些性能开销，但是却为java应用程序提供了高度的灵活性，java动态扩展的语言特性就是依赖运行期动态加载和动态链接这个特点形成的，所谓java动态扩展，比如，如果编写了一个面向接口的应用程序，可以等到运行时再指定其实际的实现类。 二：类加载时机类从被加载到虚拟机内存中开始，到卸载出内存为止，整个生命周期包括：加载、验证、准备、解析、初始化、使用、卸载，共七个阶段。其中，验证、准备、解析3个阶段称为连接（Linking），7个过程发生顺序如下：上面这七个过程，除了解析这个过程外，其余过程必须按部就班地执行，即顺序是确定的，而解析过程不一定，在某些情况下可以在初始化阶段之后再执行，这是为了支持java语言的运行时绑定（也称为动态绑定或晚期绑定）。 java虚拟机规范中，并没有规定类加载过程中的第一个阶段（即加载阶段）的执行时机，但是对于初始化阶段，虚拟机规范中严格规定了“有且只有”下面5种情况下必须立即对类进行初始化（而这时，加载、验证、准备自然需要在此之前开始）：（1）遇到new、getstatic、putstatic、invokestatic这四条指令时，必须触发其初始化。这四条指令最常见的场景是：使用new关键字实例化对象、读取或设置一个类的静态字段（被final修饰、已经在编译期把结果放入常量池的静态字段除外，即常量除外）、调用一个类的静态方法的时候；（2）进行反射调用的时候；（3）初始化一个类的时候，如果其父类还没有初始化，则需要先触发其父类的初始化；（4）当虚拟机启动时，需要先初始化那个包含main方法的要执行的主类；（5）当使用JDK1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果为REF_getStatic 、REF_putStatic、REF_invokeStatic的方法句柄，句柄对应的类会被初始化； 上面五种场景触发类进行初始化的行为称为对一个类进行“主动引用”，除此之外，所有其他引用类的方式都不会触发初始化步骤（注意，此时已经是引用了，只不过不会触发初始化，其他阶段是否触发要看具体虚拟机的实现），这些引用称为“被动引用”。被动引用的几个例子：（1）对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。至于是否要出发子类的加载、验证需要看具体虚拟机实现；如下： 123456789101112131415161718class SuperClass&#123; static&#123; System.out.println(&quot;SuperClass init!&quot;); &#125; public static int value = 123; &#125; class SubClass extends SuperClass&#123; static&#123; System.out.println(&quot;SubClass init!&quot;);//子类中引用父类的静态字段，不会导致类初始化 &#125; &#125; public class Test &#123; public static void main(String[] args) &#123; System.out.println(SubClass.value); &#125; &#125; 运行结果：12SuperClass init!123 可以看到，只会打印出父类的初始化语句。 （2）通过数组定义来引用类，不会触发此类的初始化。如 A[] ints = new A[10] ， 不会触发A 类的初始化。而是会触发名为 LA的类初始化。它是一个由虚拟机自动生成的、直接继承于Object 的子类，创建动作由字节码指令 newarray 触发。这个类代表了一个元素类型为 A 的一位数组，数组中的属性和方法都实现在这个类中。Java 语言中数组的访问比C/C++ 安全是因为这个类封装了数组元素的访问方法。如下：12345public class Test &#123; public static void main(String[] args) &#123; SuperClass[] sca = new SuperClass[10]; &#125;&#125; SuperClass类为上面的那个，运行后发现并没有打印出SuperClass init!，说明没有触发SuperClass类的初始化阶段。 （3）常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化，如下： 123456789101112class ConstClass&#123; static&#123; System.out.println(&quot;ConstClass init!&quot;); &#125; public static final String HELLOWORLD = &quot;hello world&quot;; &#125; public class Test &#123; public static void main(String[] args) &#123; System.out.println(ConstClass.HELLOWORLD); &#125; &#125; 运行结果：1hello world 只是输出了hello world，并没有输出ConstClass init!，可见ConstClass类并没有被初始化。 注意：上面讲的三个例子是被动引用的情况，很多情况下我们会通过new来初始化一个类，这个情形它属于上面提到的5种主动引用的场景，因此会触发这个类的初始化，如果这个类有父类的话，会先触发父类的初始化。注意不要和上面的被动引用搞混了。 接口的初始化上面代码中用static语句块进行初始化，而结构中不能使用static语句块，但是编译器仍然回味接口生成&lt;clinit&gt;()类构造器来初始化接口中的成员变量（常量）；接口与类初始化的区别主要是在上面五种主动引用中的第三种：当一个类在初始化时，要求其父类全部已经初始化过了，但是对于接口的初始化来说，并不要求其父接口全部都完成了初始化，只有在真正使用到付接口的时候（如引用接口中定义的常量）才会初始化。 三：类加载过程3.1 加载在加载阶段，需要完成三件事情：（1）通过一个类的全限定名来获取其定义的二进制字节流。(获取.class文件的二进制流) （2）将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。(将类信息、静态变量、字节码、常量这些.class文件中的内容放入方法区中) （3）在内存中生成一个代表这个类的java.lang.Class对象（并没有明确规定是在java堆中，对于HotSpot虚拟机来说，Class对象比较特殊，它虽然是对象，但是存放在方法区里面），作为对方法区中这些数据的访问入口。(在内存中生成一个代表这个.class文件的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。一般这个Class是在堆里的，不过HotSpot虚拟机比较特殊，这个Class对象是放在方法区中的) 对于（1），并没有指明二进制字节流的获取途径，也即不一定都是从一个Class文件中获取，还可以从如下方式获取： 1）从压缩包中获取，比如 JAR包、EAR、WAR包等2）从网络中获取，比如红极一时的Applet技术3）从运行过程中动态生成，最出名的便是动态代理技术，在java.lang.reflect.Proxy 中，就是用了 ProxyGenerator.generateProxyClass 来为特定接口生成形式为“$Proxy”的代理类的二进制流4）从其它文件生成，如JSP文件生成Class 类5）从数据库中读取，比如说有些中间件服务器，通过数据库完成程序代码在集群之间的分发 相对于类加载过程的其他阶段，加载这一步骤是开发人员可控的，即可以通过自定义类加载器来控制加载过程。 对于数组来说，数组类本身不通过类加载器创建，它是由Java虚拟机直接创建的，但是数组的元素类型，最终是要靠类加载器去创建。 3.2 验证验证阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。Java语言本身是相对安全的，因为使用纯粹的java代码无法做到诸如访问数组边界意外的数据、讲一个对象转型为它并未实现的类型、跳转到不存在的代码行之类的事情，如果我们这样做了，那编译器将拒绝编译，也就保证了安全。但是前面说过，Class文件并不一定要用Java源码编译而来，它还可以从很多途径产生，在字节码层面，其他方式可能能做到java代码无法做到的事情，因此虚拟机需要对加载尽量的字节流进行验证。验证过程分为四步：（1）文件格式验证这一阶段是要验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理。包括以下这些验证点： 是否以魔数0xCAFEBABE开头 主、次版本号是否在当前虚拟机处理范围之内 常量池的常量中是否有不被支持的常量类型（检查常量tag标志） 指向常量的各种索引值中是否有指向不存在的常量或不符合类型的常量 CONSTANT_Utf8_info 型的常量中是否有不符合UTF8 编码的数据 Class 文件中各个部分以及文件本身是否有被删除的或被附加的其它信息… 这一阶段验证的目的是保证输入的字节流能正确的解析并存储到方法区中，这阶段是基于二进制字节流进行的，通过验证后，字节流才会进入到内存的方法区中进行存储。因此，后面的3个验证阶段是基于方法区的存储结构进行分析的，不会再直接操作字节流了。 （2）元数据验证对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范的要求，主要是验证类的继承关系、数据类型是否符合，验证点包括： 这个类是否有父类（除Object类外，其他所有类都应当有父类） 这个类的父类是否继承了不允许被继承的类（final 修饰的类） 这个类如果不是抽象类，是否实现了其父类或接口之中要求实现的所有方法 类中的字段、方法是否和父类产生矛盾（如覆盖了父类final 字段，出现了非法的方法重载，如方法参数一致，但返回类型却不同） （3）字节码验证最复杂的一个阶段，主要目的是通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。在元数据验证阶段对数据类型做完校验后，这个阶段将对类的方法体进行校验分析，以保证被校验类的方法在运行时不会做出危害虚拟机安全的事件，有如下一些验证点： 保证任何时候，操作数栈的数据类型与指令代码序列都能配合工作，例如不会出现类似这样的情况：在操作栈放入了一个int类型数据，使用时却按 long 类型加载到本地变量表中 保证跳转指令不会跳转到方法体外的字节码指令上 保证方法体中类型转换是有效的 （4）符号引用验证这一阶段发生在虚拟机将符号引用转化为直接引用的时候，而这个转化动作发生在解析阶段，符号引用可以看做是对类自身以外（常量池中的各种符号引用）的信息进行匹配性校验，验证点如下： 符号引用中通过字符串描述的全限定名是否能找到相应的类 在指定类中对否存在符合方法的字段描述符以及简单名称所描述的方法和字段 符号引用中的类、字段、方法的访问性（private、protected、public、default）是否可被当前类访问这一阶段验证的目的是确保解析动作能正常执行。 对于虚拟机来说，验证阶段是一个非常重要的，但不是一定必要（因为对程序运行期没有影响）的的阶段。 3.3 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。有两点需要注意：（1）这阶段进行内存分配的仅包括类变量（即被static修饰的变量），不包括实例变量，实例变量会在对象实例化时随着对象一起分配在Java堆中；（2）这里所说的初始值“通常情况”下是数据类型的零值，假设一个类变量的定义如下： public static int value = 123;那变量value在准备阶段过后的零值为0而不是123，因为这时候并未执行任何Java方法，把value赋值为123的动作是在初始化阶段才会进行。对于“非通常情况”，是指定义为常量的那些变量（即final修饰的），会在这一阶段就被赋值，如： public static final int value = 123;此时在准备阶段过后，value的值将会被赋值为123。 3.4 解析解析阶段是虚拟机将常量池中的符号引用转化为直接引用的过程。 符号引用（Symbolic References）：即用一组符号来描述所引用的目标。它与虚拟机的内存布局无关，引用的目标不一定已经加载到内存中。 直接引用（Direct References）：直接引用可以是指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。它是和虚拟机内存布局相关的，如果有了直接引用，那引用的目标必定已经在内存中存在了。解析动作主要针对 类或接口、字段、类方法、接口方法、方法类型、方法句柄 和 调用限定符 7类符号引用进行。（1）类或接口的解析判断所要转化成的直接引用是对数组类型，还是普通的对象类型的引用，从而进行不同的解析。（2）字段解析在对字段进行解析前，会先查看该字段所属的类或接口的符号引用是否已经解析过，没有就先对字段所属的接口或类进行解析。在对字段进行解析的时候，先查找本类或接口中是否有该字段，有就直接返回；否则，再对实现的接口进行遍历，会按照继承关系从下往上递归（也就是说，每个父接口都会走一遍）搜索各个接口和它的父接口，返回最近一个接口的直接引用；再对继承的父类进行遍历，会按照继承关系从下往上递归（也就是说，每个父类都会走一遍）搜索各个父类，返回最近一个父类的直接引用。（3）类方法解析和字段解析搜索步骤差不多，只不过是先搜索父类，再搜索接口。（4）接口方法解析和类方法解析差不多，只不过接口中不会有父类，因此只需要对父接口进行搜索即可。 3.5 初始化初始化是类加载过程的最后一步，此阶段才开始真正执行类中定义的Java程序代码（或者说字节码，也仅限与执行&lt;clinit&gt;()方法）。在准备阶段，我们已经给变量付过一次系统要求的初始值（零值），而在初始化阶段，则会根据程序员的意愿给类变量和其他资源赋值。主要是通过&lt;clinit&gt;()方法来执行的： （1）&lt;clinit&gt;()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句中可以赋值，但是不能访问。如下： 1234567public class Test &#123; static&#123; i = 0;//可以给变量赋值，编译通过 System.out.println(i);//编译不通过！！不能进行访问后面的静态变量 &#125; static int i =1; &#125; 有点与我们平常的认知相反，这里是可以下赋值，却不能访问… （2）&lt;clinit&gt;()方法与实例构造器&lt;init&gt;()方法（类的构造函数）不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的&lt;clinit&gt;()方法执行之前，父类的&lt;clinit&gt;()方法已经执行完毕。因此，在虚拟机中第一个被执行的&lt;clinit&gt;()方法的类肯定是java.lang.Object。 （3）&lt;clinit&gt;()方法对于类或接口来说并不是必须的，如果一个类中没有静态语句块，也没有对类变量的赋值操作，那么编译器可以不为这个类生成&lt;clinit&gt;()方法。 （4）接口中不能使用静态语句块，但仍然有类变量（final static）初始化的赋值操作，因此接口与类一样会生成&lt;clinit&gt;()方法。但是接口与类不同的是：执行接口的&lt;clinit&gt;()方法不需要先执行父接口的&lt;clinit&gt;()方法，只有当父接口中定义的变量被使用时，父接口才会被初始化。另外，接口的实现类在初始化时也一样不会执行接口的&lt;clinit&gt;()方法。 （5）虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确地加锁和同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的&lt;clinit&gt;()方法，其他线程都需要阻塞等待，直到活动线程执行&lt;clinit&gt;()方法完毕。如果在一个类的&lt;clinit&gt;()方法中有耗时很长的操作，那就可能造成多个线程阻塞，在实际应用中这种阻塞往往是很隐蔽的。 四：类加载器前面说过，在类加载过程的第一个阶段：加载阶段，除了可以使用系统提供的引导类加载器外，还可以使用用户自定义的类加载器，以便让用户决定如何去获取所需要的类（是从Class文件中？还是从jar、或者其他方式…可以自由决定）。 4.1 类和类加载器任意一个类，都需要由加载它的类加载器和这个类本身共同确定其在Java 虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。这句话可以表达的更通俗一些：比较两个类是否相等，只有在这两个类是同一个类加载器加载的前提下才意义。否则，即使这两个类来自同一个Class文件，被同一个虚拟机加载，但只要加载他们的类加载器不同，那这两个类就必定不相等。 这里的“相等”，包括代表类的 Class 对象的equals() 方法、isAssignableFrom() 方法、isInstance() 方法的返回结果，也包括 instanceof 关键字对对象所属关系判定等情况。下面代码演示了不同类加载器对 instanceof 关键字运算的结果的影响。 123456789101112131415161718192021222324252627282930public class ClassLoaderTest &#123; public static void main(String[] args) throws Exception &#123; ClassLoader myLoader = new ClassLoader() &#123; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(&quot;.&quot;) + 1) + &quot;.class&quot;; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) &#123; return super.loadClass(name); &#125; byte[] b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); &#125; catch (IOException e) &#123; throw new ClassNotFoundException(name); &#125; &#125; &#125;; Class c = myLoader.loadClass(&quot;org.bupt.xiaoye.blog.ClassLoaderTest&quot;); Object obj = c.newInstance(); System.out.println(obj.getClass()); System.out.println(ClassLoaderTest.class); System.out.println(obj instanceof ClassLoaderTest); &#125; &#125; 运行结果如下：123class org.bupt.xiaoye.blog.ClassLoaderTest class org.bupt.xiaoye.blog.ClassLoaderTest false 我们使用了一个自定义的类加载器去加载ClassLoaderTest，由第一句也可以看出这个对象也的确是ClassLoaderTest实例化出来的对象，但是这个对象在与类class org.bupt.xiaoye.blog.ClassLoaderTest 做属性检查的时候却反悔了false，这就是因为虚拟机中存在了两个ClassLoaderTest类，一个由系统应用程序类加载器加载，一个由我们自定义的类加载器加载，虽然是 来自同一个Class文件，但依然是两个独立的类。 因此，类是否相等，取决于类本身和加载该类的类加载器是否是同一个类加载器。 4.2 双亲委派模型从虚拟机的角度来讲，只存在两种不同的类加载器： 一种是启动类加载器（Bootstrap ClassLoader），这个类加载器用 C++ 语言实现， 是虚拟机自身的一部分：另一种就是所有其它的类加载器， 这些类加载器用Java 语言实现，独立于虚拟机外部，并且全都继承与抽象类 java.lang.ClassLoader。 从Java 开发人员的角度来看，类加载器还可以划分的更细致一些，绝大多数Java 程序都会用到以下3种系统提供的类加载器： （1）启动类加载器（Bootstrap ClassLoader） ： 这个类加载器负责将存放在 &lt;JAVA_HOME&gt;\\lib 目录中的，或者被 -Xbootclasspath 参数指定的路径中的，并且是虚拟机识别的(仅按照文件名识别,如rt.jar ，名字不符合类库不会加载) 类库加载到虚拟机内存中。启动类加载器无法被 java 程序直接引用，如需要，直接使用 null 代替即可。（2）扩展类加载器（Extension ClassLoader）：这个加载器由sun.misc.Launcher$ExtClassLoader 实现，它负责加载&lt;JAVA_HOME&gt;\\lib\\ext 目录中的，或者被 java.ext.dirs 系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。（3）应用程序类加载器(Application ClassLoader)：这个类加载器由 sun.misc.Launcher$AppClassLoader 实现。这个这个类加载器是 ClassLoader 中的getSystemClassLoader() 方法的返回值，所以一般称它为系统类加载器。它负责加载用户路径(ClassPath)上所指定的类库，开发者可以使用这个类加载器，如果应用程序没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 我们的应用程序都是由这3中类加载器互相配合进行加载的，如果有必要，还可以加入自己定义的类加载器。这些类加载器之间的关系一般如下图所示： !双亲委派](Java虚拟机学习——类加载机制/双亲委派.png) 图中的类加载器之间的这种层次关系，称为类加载器的双亲委派模型。双亲委派模型要求除了顶层的启动类加载器，其余的类加载器都应该有自己的父类加载器。这里类加载器之间的父子关系一般不会以继承关系来实现，而是使用组合关系来复用父加载器的代码。双亲委派模型的工作过程是：如果一个类加载器收到了类加载器的请求，它首先不会自己尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父类加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类时），子加载类才会尝试自己去加载。 使用双亲委派模型的好处：就是Java类随着它的类加载器一起具备了一种带有优先级的层次关系。比如对于类Object来说，它存放在rt.jar中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的启动类加载器去加载，因此Object类在程序中的各种类加载器环境中都是同一个类。相反，如果没有使用双亲委派模型，由各个类自己去加载的话，按照我们前面说的，如果用户自己编写了一个Object类，并放在程序的ClassPath中，那系统中将会出现多个不同的Object类，此时Java类型提醒中最基础的行为也就无法保证了，应用程序也将变得混乱。 因此，双亲委派模型对于保证Java程序的稳定运作很重要，但是他的实现其实很简单，实现双亲委派模型的代码几种在java.lang.ClassLoader的loadClass()方法之中，逻辑清晰易懂：先检查类是否被加载过，若没有则调用父加载器的loadClass() 方法，若父加载器为空则默认使用启动类加载器作为父加载器。如果父加载器失败，抛出 ClassNotFoundException 异常后，再调用自己的 finClass() 方法进行加载，如下： 12345678910111213141516171819202122232425262728293031323334353637383940protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // 首先检查类是否已经被加载过 Class c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; // 调用父类加载器加载 c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. //父类加载器无法完成加载，调用本身的加载器加载 long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime( t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom( t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 参考:周志明:《深入理解Java虚拟机：JVM高级特性与最佳实践》","tags":[{"name":"JVM","slug":"JVM","permalink":"http://wangyuanjun.cn/tags/JVM/"}]},{"title":"JDK1.8源码解析——String","date":"2018-01-30T14:32:49.000Z","path":"2018/01/30/JDK1.8源码解析——String/","text":"String源码分析 一：类的声明在java.lang包中，此类被final修饰，表示String的对象是不可变量，不可继承。String类实现了Serizlizable，Comparable, CharSequence接口。Serizlizable接口没有任何方法和域，仅用于标识序列化的语意，实现此接口的类是可序列化的，是java提供的通用数据保存和读取的接口。Comparable接口只有一个compareTo(To)方法。CharSequence接口如下图 类的成员变量/** The value is used for character storage. */ private final char value[]; //使用字符数组存放字符串 /** Cache the hash code for the string */ private int hash; // Default to 0 存放哈希值 类的构造方法无参构造器// 无参构造方法 因为String对象内容不可变，所以没有必要调用此方法。 public String() { this.value = &quot;&quot;.value; } String 参数//初始化一个新创建的 String 对象，使其表示一个与参数相同的字符序列；换句话说，新创建的字符串是该参数字符串的副本。 public String(String original) { this.value = original.value; this.hash = original.hash; } 可以看到只是将value引用指向original中的value数组，因为两者都是final的，所以这个看来也没那么必要。因为String s1=new String(“s1s1”); String s2=new String(s1);这种用法完全没有必要，而不如直接引用，s2=s1; char[]参数// 分配一个新的 String，使其表示字符数组参数中当前包含的字符序列。 public String(char value[]) { this.value = Arrays.copyOf(value, value.length); } //可以发现当通过char数组构建时，只是将char数组复制到value中，而且是复制，而不是简单的引用相等。 // 分配一个新的 String，它包含取自字符数组参数一个子数组的字符。 // offset是起始位置，count是字符数量 public String(char value[], int offset, int count) { if (offset &lt; 0) { // 如果起始位置小于0 throw new StringIndexOutOfBoundsException(offset); } if (count &lt;= 0) { // 如果字符数量小于1 if (count &lt; 0) { // 如果字符数量小于0 throw new StringIndexOutOfBoundsException(count); } if (offset &lt;= value.length) { // 如果起始位置不超过参数中字符数组长度 this.value = &quot;&quot;.value; // 设置为空字符串 return; } } // Note: offset or count might be near -1&gt;&gt;&gt;1. if (offset &gt; value.length - count) { // 如果起始位置与字符数量不符合逻辑 throw new StringIndexOutOfBoundsException(offset + count); } // 创建字符数组副本 this.value = Arrays.copyOfRange(value, offset, offset+count); } 与上面的区别是，这里只是利用char数组中的一部分来构建String，其中offset代表起始下标，count是所有构建的长度。 int[]参数//分配一个新的 String，它包含 Unicode 代码点数组参数一个子数组的字符。 public String(int[] codePoints, int offset, int count) { if (offset &lt; 0) { throw new StringIndexOutOfBoundsException(offset); } if (count &lt;= 0) { if (count &lt; 0) { throw new StringIndexOutOfBoundsException(count); } if (offset &lt;= codePoints.length) { this.value = &quot;&quot;.value; return; } } // Note: offset or count might be near -1&gt;&gt;&gt;1. if (offset &gt; codePoints.length - count) { throw new StringIndexOutOfBoundsException(offset + count); } final int end = offset + count; // Pass 1: Compute precise size of char[] int n = count; for (int i = offset; i &lt; end; i++) { int c = codePoints[i]; if (Character.isBmpCodePoint(c)) continue; else if (Character.isValidCodePoint(c)) n++; else throw new IllegalArgumentException(Integer.toString(c)); } // Pass 2: Allocate and fill in char[] final char[] v = new char[n]; for (int i = offset, j = 0; i &lt; end; i++, j++) { int c = codePoints[i]; if (Character.isBmpCodePoint(c)) v[j] = (char)c; else Character.toSurrogates(c, v, j++); } this.value = v; } byte[]参数所谓好的适用性模块，一定是能有一坨坨的各种适应代码的。下面是一系列的利用byte[]数组来构建String对象的构造器，主要差别是可能需要指定特殊的字符集来解码，但是这一点其实在web编程，网络编程中还是很重要的 //通过使用指定的字符集解码指定的 byte 子数组，构造一个新的 String。 public String(byte bytes[], int offset, int length, String charsetName) throws UnsupportedEncodingException { if (charsetName == null) throw new NullPointerException(&quot;charsetName&quot;); checkBounds(bytes, offset, length); this.value = StringCoding.decode(charsetName, bytes, offset, length); } //通过使用指定的 charset 解码指定的 byte 子数组，构造一个新的 String。 public String(byte bytes[], int offset, int length, Charset charset) { if (charset == null) throw new NullPointerException(&quot;charset&quot;); checkBounds(bytes, offset, length); this.value = StringCoding.decode(charset, bytes, offset, length); } // 通过使用指定的 charset 解码指定的 byte 数组，构造一个新的 String。 public String(byte bytes[], String charsetName) throws UnsupportedEncodingException { this(bytes, 0, bytes.length, charsetName); } //通过使用指定的 charset 解码指定的 byte 数组，构造一个新的 String。 public String(byte bytes[], Charset charset) { this(bytes, 0, bytes.length, charset); } //通过使用平台的默认字符集解码指定的 byte 子数组，构造一个新的 String。 public String(byte bytes[], int offset, int length) { checkBounds(bytes, offset, length); this.value = StringCoding.decode(bytes, offset, length); } //通过使用平台的默认字符集解码指定的 byte 数组，构造一个新的 String。 public String(byte bytes[]) { this(bytes, 0, bytes.length); } 基于StringBuilder,StringBuffer参数//分配一个新的字符串，它包含字符串缓冲区参数中当前包含的字符序列。 public String(StringBuffer buffer) { synchronized(buffer) { this.value = Arrays.copyOf(buffer.getValue(), buffer.length()); } } //分配一个新的字符串，它包含字符串生成器参数中当前包含的字符序列。 public String(StringBuilder builder) { this.value = Arrays.copyOf(builder.getValue(), builder.length()); } String(char[] value, boolean share) { // assert share : &quot;unshared not supported&quot;; this.value = value; } 重要方法length//获取字符串长度 //返回字符串中所包含的字符数目，即value数组的长度 public int length() { return value.length; } isEmpty// 判断字符串是否为空 // 判断字符串是否为空，即判断value数组的长度为0即可 public boolean isEmpty() { return value.length == 0; } charAt//按下标获取单个字符 //返回指定索引处的 char 值。索引范围为从 0 到 length() - 1。序列的第一个 char 值位于索引 0 处，第二个位于索引 1 处，依此类推，这类似于数组索引。 public char charAt(int index) { if ((index &lt; 0) || (index &gt;= value.length)) { throw new StringIndexOutOfBoundsException(index); } return value[index]; } getChars//将字符串拷贝到目标字符数组 void getChars(char dst[], int dstBegin) { System.arraycopy(value, 0, dst, dstBegin, value.length); } // 获取子串，把它拷贝到目标字符数组 public void getChars(int srcBegin, int srcEnd, char dst[], int dstBegin) { if (srcBegin &lt; 0) { // 如果源数组开始位置&lt;0 throw new StringIndexOutOfBoundsException(srcBegin); } if (srcEnd &gt; value.length) { // 如果源数组结束位置&gt;字符数组长度 throw new StringIndexOutOfBoundsException(srcEnd); } if (srcBegin &gt; srcEnd) { // 如果源数组开始位置&gt;源数组结束位置 throw new StringIndexOutOfBoundsException(srcEnd - srcBegin); } System.arraycopy(value, srcBegin, dst, dstBegin, srcEnd - srcBegin); } getBytes//使用指定的字符集将此 String 编码为 byte 序列，并将结果存储到一个新的 byte 数组中。 public byte[] getBytes(String charsetName) throws UnsupportedEncodingException { if (charsetName == null) throw new NullPointerException(); return StringCoding.encode(charsetName, value, 0, value.length); } //使用给定的 charset 将此 String 编码到 byte 序列，并将结果存储到新的 byte 数组。 public byte[] getBytes(Charset charset) { if (charset == null) throw new NullPointerException(); return StringCoding.encode(charset, value, 0, value.length); } //使用平台的默认字符集将此 String 编码为 byte 序列，并将结果存储到一个新的 byte 数组中。 public byte[] getBytes() { return StringCoding.encode(value, 0, value.length); } equals//将此字符串与指定的对象比较。当且仅当该参数不为 null，并且是与此对象表示相同字符序列的 String 对象时，结果才为 true。 //比较两个引用指向的String对象内容是否相同 public boolean equals(Object anObject) { if (this == anObject) { // 如果两个引用指向的是同一个String对象 return true; } if (anObject instanceof String) { // 如果第2个引用指向的对象是String实例 String anotherString = (String)anObject; // 强制类型转换 int n = value.length; // 获取第1个引用指向的String对象的字符串长度 if (n == anotherString.value.length) { // 如果两个字符串长度相等 // 定义字符数组指针 char v1[] = value; char v2[] = anotherString.value; // 字符依次比较 int i = 0; while (n-- != 0) { if (v1[i] != v2[i]) return false; i++; } return true; } } return false; } 可以看到equals方法重写了，会判断两个字符串的每一个字符是否相等。 equalsIgnoreCase//将此 String 与另一个 String 比较，不考虑大小写。如果两个字符串的长度相同，并且其中的相应字符都相等（忽略大小写），则认为这两个字符串是相等的。 public boolean equalsIgnoreCase(String anotherString) { return (this == anotherString) ? true : (anotherString != null) &amp;&amp; (anotherString.value.length == value.length) &amp;&amp; regionMatches(true, 0, anotherString, 0, value.length); } 判断两个字符串在忽略大小写的情况下是否相等，主要调用regionMatches方法 public boolean regionMatches(boolean ignoreCase, int toffset, String other, int ooffset, int len) { char ta[] = value; int to = toffset; char pa[] = other.value; int po = ooffset; // Note: toffset, ooffset, or len might be near -1&gt;&gt;&gt;1. if ((ooffset &lt; 0) || (toffset &lt; 0) || (toffset &gt; (long)value.length - len) || (ooffset &gt; (long)other.value.length - len)) { return false; } while (len-- &gt; 0) { char c1 = ta[to++]; char c2 = pa[po++]; //在这里先行判断，如果相等就直接跳过后面即可，可以提高效率 if (c1 == c2) { continue; } if (ignoreCase) { // If characters don&apos;t match but case may be ignored, // try converting both characters to uppercase. // If the results match, then the comparison scan should // continue. char u1 = Character.toUpperCase(c1); char u2 = Character.toUpperCase(c2); //都转换成大写的形式，如果相等，则跳过 if (u1 == u2) { continue; } // Unfortunately, conversion to uppercase does not work properly // for the Georgian alphabet, which has strange rules about case // conversion. So we need to make one last check before // exiting. if (Character.toLowerCase(u1) == Character.toLowerCase(u2)) { continue; } } return false; } return true; } compareTo// 比较两个String对象的大小 public int compareTo(String anotherString) { // 获取字符数组长度 int len1 = value.length; int len2 = anotherString.value.length; // 获取最小长度 int lim = Math.min(len1, len2); // 定义字符数组指针 char v1[] = value; char v2[] = anotherString.value; int k = 0; while (k &lt; lim) { char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) { // 如果两个字符不相等 return c1 - c2; } k++; } // 根据长度比较大小 return len1 - len2; } 比较两个字符串的大小。如果两个字符串的字符序列相等，则返回0；不相等时，从两个字符串第0个字符开始比较，返回第一个不相等的字符差。另一种情况，较长的字符串的前面部分恰好是较短的字符串，则返回他们的长度差。 startsWith//测试此字符串从指定索引开始的子字符串是否以指定前缀开始。 public boolean startsWith(String prefix, int toffset) { char ta[] = value; int to = toffset; char pa[] = prefix.value; int po = 0; int pc = prefix.value.length; // Note: toffset might be near -1&gt;&gt;&gt;1. if ((toffset &lt; 0) || (toffset &gt; value.length - pc)) { return false; } while (--pc &gt;= 0) { if (ta[to++] != pa[po++]) { return false; } } return true; } //测试此字符串是否以指定的前缀开始。 public boolean startsWith(String prefix) { return startsWith(prefix, 0); } endsWith//测试此字符串是否以指定的后缀结束。 public boolean endsWith(String suffix) { return startsWith(suffix, value.length - suffix.value.length); } hashCode//返回此字符串的哈希码。String 对象的哈希码根据以下公式计算： s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1] 使用 int 算法，这里 s[i] 是字符串的第 i 个字符，n 是字符串的长度，^ 表示求幂。（空字符串的哈希值为 0。） // 获取散列码方法 public int hashCode() { // 获取字符串缓存散列码 int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) { // 如果字符串缓存散列码为0并且字符串数组长度大于0 // 定义字符数组指针 char val[] = value; // 遍历每个字符 for (int i = 0; i &lt; value.length; i++) { h = 31 * h + val[i]; // 31 * h会被JVM优化成(h &lt;&lt; 5) - h } hash = h; // 修改字符串缓存散列码 } return h; } indexOf// 获取指定字符在此字符串中第一次出现处的索引 public int indexOf(int ch) { return indexOf(ch, 0); // 从0开始查找 } // 获取在此字符串中第一次出现指定字符处的索引，从指定的索引开始搜索。 // Unicode指统一码（采用双字节对字符进行编码） public int indexOf(int ch, int fromIndex) { // 获取字符数组长度 final int max = value.length; if (fromIndex &lt; 0) { // 如果起始位置&lt;0 fromIndex = 0; // 起始位置置0 } else if (fromIndex &gt;= max) { // 如果起始位置&gt;=字符数组长度 // Note: fromIndex might be near -1&gt;&gt;&gt;1. return -1; } // Character.MIN_SUPPLEMENTARY_CODE_POINT是BmpCode代码点 // 值是2的16次方，是2个字节最大值+1 // 如果ch是非辅助代码点或者负值（无效代码点） if (ch &lt; Character.MIN_SUPPLEMENTARY_CODE_POINT) { // handle most cases here (ch is a BMP code point or a // negative value (invalid code point)) final char[] value = this.value; // 创建字符数组的指针 for (int i = fromIndex; i &lt; max; i++) { // 从fromIndex开始遍历每个字符 if (value[i] == ch) { // 如果找到ch字符 return i; } } return -1; } else { // 寻找ch在辅助部分中的索引 return indexOfSupplementary(ch, fromIndex); } } //返回指定字符在此字符串中最后一次出现处的索引。 public int lastIndexOf(int ch) { return lastIndexOf(ch, value.length - 1); } //返回指定字符在此字符串中最后一次出现处的索引，从指定的索引处开始进行反向搜索。 public int lastIndexOf(int ch, int fromIndex) { if (ch &lt; Character.MIN_SUPPLEMENTARY_CODE_POINT) { // handle most cases here (ch is a BMP code point or a // negative value (invalid code point)) final char[] value = this.value; int i = Math.min(fromIndex, value.length - 1); for (; i &gt;= 0; i--) { if (value[i] == ch) { return i; } } return -1; } else { return lastIndexOfSupplementary(ch, fromIndex); } } //返回指定子字符串在此字符串中第一次出现处的索引。 public int indexOf(String str) { return indexOf(str, 0); } //返回指定子字符串在此字符串中第一次出现处的索引，从指定的索引开始。 public int indexOf(String str, int fromIndex) { return indexOf(value, 0, value.length, str.value, 0, str.value.length, fromIndex); } // 获取参数子串在该字符串中从起始位置开始第一次出现的位置 static int indexOf(char[] source, int sourceOffset, int sourceCount, String target, int fromIndex) { return indexOf(source, sourceOffset, sourceCount, target.value, 0, target.value.length, fromIndex); } /* @param source the characters being searched.//这里就是value数组 * @param sourceOffset offset of the source string./ //源字符串的偏移量 * @param sourceCount count of the source string. //这里是value数组的长度 * @param target the characters being searched for. //待搜索目标字符串 * @param targetOffset offset of the target string. //待搜索目标字符串的偏移量 * @param targetCount count of the target string. //待搜索目标字符串的长度 * @param fromIndex the index to begin searching from. //起始位置 */ // 获取参数子串在该字符串中从起始位置开始第一次出现的位置 // source是目标串（该字符串），target是模式串（子串） static int indexOf(char[] source, int sourceOffset, int sourceCount, char[] target, int targetOffset, int targetCount, int fromIndex) { if (fromIndex &gt;= sourceCount) {//越界了 return (targetCount == 0 ? sourceCount : -1); } if (fromIndex &lt; 0) { fromIndex = 0; } if (targetCount == 0) { return fromIndex; } char first = target[targetOffset];//待搜索字符串第一个字符 int max = sourceOffset + (sourceCount - targetCount);//搜索第一个匹配的字符时所能达到的最大值，因为要保证后面的长度&gt;=targetCount // 朴素匹配算法 //下面这里就是核心搜索算法了，会先匹配第一个字符，然后依次向后移，直到完全匹配 //或者是匹配到max仍然没有匹配成功 for (int i = sourceOffset + fromIndex; i &lt;= max; i++) { /* Look for first character. */ if (source[i] != first) {// 如果第一个字符不匹配 while (++i &lt;= max &amp;&amp; source[i] != first);// 寻找第一个匹配上的字符 } /* Found first character, now look at the rest of v2 */ //可以注意这里i下标只是用来匹配第一个字符，因为有可能部分匹配时，需要从先在匹配 //所以这里重新应用下标j if (i &lt;= max) {// 匹配除了第一个字符的其他部分 int j = i + 1; int end = j + targetCount - 1; for (int k = targetOffset + 1; j &lt; end &amp;&amp; source[j] == target[k]; j++, k++); if (j == end) { /* Found whole string. */ return i - sourceOffset; } } } return -1; }//当匹配失败时，返回-1 //返回指定子字符串在此字符串中最右边出现处的索引。 public int lastIndexOf(String str) { return lastIndexOf(str, value.length); } public int lastIndexOf(String str, int fromIndex) { return lastIndexOf(value, 0, value.length, str.value, 0, str.value.length, fromIndex); } static int lastIndexOf(char[] source, int sourceOffset, int sourceCount, char[] target, int targetOffset, int targetCount, int fromIndex) { /* * Check arguments; return immediately where possible. For * consistency, don&apos;t check for null str. */ //第一个字符所能匹配的最大位置，类似于上面的max int rightIndex = sourceCount - targetCount; if (fromIndex &lt; 0) { return -1; } if (fromIndex &gt; rightIndex) { fromIndex = rightIndex; } /* Empty string always matches. */ if (targetCount == 0) { return fromIndex; } int strLastIndex = targetOffset + targetCount - 1;//目标字符串最后一个字符下标 char strLastChar = target[strLastIndex];//最后一个字符 int min = sourceOffset + targetCount - 1;//目标字符串最后一个字符所能匹配的源字符串最小下标 int i = min + fromIndex;//这里i下标永远是最后一个字符匹配的下标索引 startSearchForLastChar: while (true) { while (i &gt;= min &amp;&amp; source[i] != strLastChar) { i--; } //小于min则不可能在搜索到了 if (i &lt; min) { return -1; } int j = i - 1; int start = j - (targetCount - 1); int k = strLastIndex - 1; while (j &gt; start) { if (source[j--] != target[k--]) { //当存在部分匹配，而前半部分不匹配时，跳出当前查找，整体向前窗移 i--; continue startSearchForLastChar;//直接跳到顶层while循环 } } return start - sourceOffset + 1; } } 可以看到与indexOf方法是对应的，只不过是反向搜索。 substring//返回一个新的字符串，它是此字符串的一个子字符串。该子字符串从指定索引处的字符开始，直到此字符串末尾。 public String substring(int beginIndex) { if (beginIndex &lt; 0) { // 如果起始下标&lt;0 throw new StringIndexOutOfBoundsException(beginIndex); } int subLen = value.length - beginIndex; // 获取截取长度 if (subLen &lt; 0) { // 如果截取长度&lt;0 throw new StringIndexOutOfBoundsException(subLen); } return (beginIndex == 0) ? this : new String(value, beginIndex, subLen); } //返回一个新字符串，它是此字符串的一个子字符串。该子字符串从指定的 beginIndex 处开始，直到索引 endIndex - 1 处的字符。因此，该子字符串的长度为 endIndex-beginIndex。 public String substring(int beginIndex, int endIndex) { if (beginIndex &lt; 0) { // 如果起始下标&lt;0 throw new StringIndexOutOfBoundsException(beginIndex); } if (endIndex &gt; value.length) { // 如果末尾下标&gt;字符数组长度 throw new StringIndexOutOfBoundsException(endIndex); } int subLen = endIndex - beginIndex; // 获取截取长度 if (subLen &lt; 0) { // 如果截取长度&lt;0 throw new StringIndexOutOfBoundsException(subLen); } return ((beginIndex == 0) &amp;&amp; (endIndex == value.length)) ? this : new String(value, beginIndex, subLen); } concat//将指定字符串连接到此字符串的结尾。 //如果参数字符串的长度为 0，则返回此 String 对象。否则，创建一个新的 String 对象，用来表示由此 String 对象表示的字符序列和参数字符串表示的字符序列连接而成的字符序列。 public String concat(String str) { int otherLen = str.length(); if (otherLen == 0) { return this; } int len = value.length; char buf[] = Arrays.copyOf(value, len + otherLen); str.getChars(buf, len); return new String(buf, true); } void getChars(char dst[], int dstBegin) { System.arraycopy(value, 0, dst, dstBegin, value.length); } replacepublic String replace(char oldChar, char newChar) { if (oldChar != newChar) { int len = value.length; int i = -1; char[] val = value; /* avoid getfield opcode */ while (++i &lt; len) { if (val[i] == oldChar) { break; } } if (i &lt; len) { char buf[] = new char[len]; for (int j = 0; j &lt; i; j++) { buf[j] = val[j]; } while (i &lt; len) { char c = val[i]; buf[i] = (c == oldChar) ? newChar : c; i++; } return new String(buf, true); } } return this; } matches//告知此字符串是否匹配给定的正则表达式。 public boolean matches(String regex) { return Pattern.matches(regex, this); } split//根据给定正则表达式的匹配拆分此字符串。 public String[] split(String regex, int limit) { /* fastpath if the regex is a (1)one-char String and this character is not one of the RegEx&apos;s meta characters &quot;.$|()[{^?*+\\\\&quot;, or (2)two-char String and the first char is the backslash and the second is not the ascii digit or ascii letter. */ char ch = 0; if (((regex.value.length == 1 &amp;&amp; &quot;.$|()[{^?*+\\\\&quot;.indexOf(ch = regex.charAt(0)) == -1) || (regex.length() == 2 &amp;&amp; regex.charAt(0) == &apos;\\\\&apos; &amp;&amp; (((ch = regex.charAt(1))-&apos;0&apos;)|(&apos;9&apos;-ch)) &lt; 0 &amp;&amp; ((ch-&apos;a&apos;)|(&apos;z&apos;-ch)) &lt; 0 &amp;&amp; ((ch-&apos;A&apos;)|(&apos;Z&apos;-ch)) &lt; 0)) &amp;&amp; (ch &lt; Character.MIN_HIGH_SURROGATE || ch &gt; Character.MAX_LOW_SURROGATE)) { int off = 0; int next = 0; boolean limited = limit &gt; 0; ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); while ((next = indexOf(ch, off)) != -1) { if (!limited || list.size() &lt; limit - 1) { list.add(substring(off, next)); off = next + 1; } else { // last one //assert (list.size() == limit - 1); list.add(substring(off, value.length)); off = value.length; break; } } // If no match was found, return this if (off == 0) return new String[]{this}; // Add remaining segment if (!limited || list.size() &lt; limit) list.add(substring(off, value.length)); // Construct result int resultSize = list.size(); if (limit == 0) { while (resultSize &gt; 0 &amp;&amp; list.get(resultSize - 1).length() == 0) { resultSize--; } } String[] result = new String[resultSize]; return list.subList(0, resultSize).toArray(result); } return Pattern.compile(regex).split(this, limit); } public String[] split(String regex) { return split(regex, 0); } trim//返回字符串的副本，忽略前导空白和尾部空白。 public String trim() { int len = value.length; int st = 0; char[] val = value; /* avoid getfield opcode */ while ((st &lt; len) &amp;&amp; (val[st] &lt;= &apos; &apos;)) { st++; } while ((st &lt; len) &amp;&amp; (val[len - 1] &lt;= &apos; &apos;)) { len--; } return ((st &gt; 0) || (len &lt; value.length)) ? substring(st, len) : this; } 这个trim()是去掉首尾的空格，而实现方式也非常简单，分别找到第一个非空格字符的下标，与最后一个非空格字符的下标然后返回之间的子字符串。注意这里由于应用了substring方法，所以len变量的控制要小心 toString//获取当前String对象 public String toString() { return this; } toCharArray//将此字符串转换为一个新的字符数组。 public char[] toCharArray() { // Cannot use Arrays.copyOf because of class initialization order issues char result[] = new char[value.length]; System.arraycopy(value, 0, result, 0, value.length); return result; } format//使用指定的格式字符串和参数返回一个格式化字符串。 public static String format(String format, Object... args) { return new Formatter().format(format, args).toString(); } //使用指定的语言环境、格式字符串和参数返回一个格式化字符串。 public static String format(Locale l, String format, Object... args) { return new Formatter(l).format(format, args).toString(); } valueOf//返回 Object 参数的字符串表示形式。 public static String valueOf(Object obj) { return (obj == null) ? &quot;null&quot; : obj.toString(); } //返回 char 数组参数的字符串表示形式。字符数组的内容已被复制，后续修改不会影响新创建的字符串。 public static String valueOf(char data[]) { return new String(data); } //返回 char 数组参数的特定子数组的字符串表示形式。 //offset 参数是子数组的第一个字符的索引。count 参数指定子数组的长度。字符数组的内容已被复制，后续修改不会影响新创建的字符串。 public static String valueOf(char data[], int offset, int count) { return new String(data, offset, count); } //返回指定数组中表示该字符序列的 String。 public static String copyValueOf(char data[], int offset, int count) { return new String(data, offset, count); } //返回指定数组中表示该字符序列的 String。 public static String copyValueOf(char data[]) { return new String(data); } //返回 boolean 参数的字符串表示形式。 public static String valueOf(boolean b) { return b ? &quot;true&quot; : &quot;false&quot;; } //返回 char 参数的字符串表示形式。 public static String valueOf(char c) { char data[] = {c}; return new String(data, true); } //返回 int 参数的字符串表示形式。 public static String valueOf(int i) { return Integer.toString(i); } //返回 long 参数的字符串表示形式。 public static String valueOf(long l) { return Long.toString(l); } //返回 float 参数的字符串表示形式。 public static String valueOf(float f) { return Float.toString(f); } //返回 double 参数的字符串表示形式。 public static String valueOf(double d) { return Double.toString(d); } //本地方法，把该字符串存入常量池，返回此字符串的引用 public native String intern();","tags":[{"name":"JDK1.8源码","slug":"JDK1-8源码","permalink":"http://wangyuanjun.cn/tags/JDK1-8源码/"}]},{"title":"成为Java顶尖程序员 ，看这11本书就够了","date":"2018-01-30T09:40:17.000Z","path":"2018/01/30/成为Java顶尖程序员-，看这11本书就够了/","text":"“学习的最好途径就是看书”，这是我自己学习并且小有了一定的积累之后的第一体会。个人认为看书有两点好处：1.能出版出来的书一定是经过反复的思考、雕琢和审核的，因此从专业性的角度来说，一本好书的价值远超其他资料 2.对着书上的代码自己敲的时候方便 “看完书之后再次提升自我的最好途径是看一些相关的好博文”，我个人认为这是学习的第二步，因为一本书往往有好几百页，好的博文是自己看书学习之后的一些总结和提炼，对于梳理学习的内容很有好处，当然这里不是说自己的学习方法，就不再扯下去了。 很多程序员们往往有看书的冲动，但不知道看哪些书，下面我就给各位Java程序猿们推荐一些好书（每本书的作者会加粗标红），其中绝大多数都是我自己平时在看的书，也算是我对于平时读的书做一个小总结和读后感吧。 首先推荐的不是一本书，而是一个博客，也是我们博客园另外一位博友java_my_life。 目前市面上讲解设计模式的书很多，虽然我前面讲了看书是最好的，但是对设计模式感兴趣的朋友们，我推荐的是这个博客。这位博友的设计模式讲得非常非常好，我认为90%的内容都是没有问题且很值得学习的，其讲解设计模式的大体路线是： 1、随便开篇点明该设计模式的定义 2、图文并茂讲解该设计模式中的结构 3、以详细的代码形式写一下该种设计模式的实现 4、补充内容 5、讲解该设计模式的优缺点 对于一个设计模式我们关注、学习的知识点，不就是上面这些吗？ 不 过我要重点提醒一下网友们，同一种设计模式的写法有多种，并不是说只有按某种写法来写才是这种设计模式。比方说适配器模式，我们关注适配器模式一定要关注 的是什么是适配器模式不是怎么写适配器模式，不要认为某段代码不是按照适配器模式的写法写下来的它就不是适配器模式了，记住这一点，你在学习设计模式的时 候一定会对代码中用到的设计模式有更深入的理解。 《深入理解Java虚拟机：JVM高级特性与最佳实践》 如果你不满足于做一个只会写if…else…的Java程序员，而是希望更进一步，我随便举几个例子吧： 1、了解Java代码的底层运行机制 2、定位性能问题 3、对整个系统进行性能调优 4、解决各种奇奇怪怪的线上线下问题 5、更加高级别的，为自己的项目量身定做一款适合自己项目的虚拟机 那 么Java虚拟机是你必学的一门技术。《深入理解Java虚拟机：JVM高级特性与最佳实践》作者是周志明，这本书可以说是国内写得最好的有关Java虚 拟机的书籍，近半年，前前后后这本书我起码看了有5遍。国内写虚拟机的书除了这本，其实还有一些其他的，我也买过，不过粗略看下来，很多内容也是《深入理 解Java虚拟机：JVM高级特性与最佳实践》此书里面的。 另外值得一提的是，《深入理解Java虚拟机：JVM高级特性与最佳实践》这本 书，有电子版的，网上搜一下就能下载到了。不过建议有兴趣的朋友还是去买书看，电子版本下载到的一般是比较老的版本，相比最新修订版的《深入理解Java 虚拟机：JVM高级特性与最佳实践》，有很多作者新补充的知识点是没有的。 《HotSpot实战》所有的Java虚拟机都是遵循着Java虚拟机规范来的，市面上的Java虚拟机几十款，《深入理解Java虚拟机：JVM高级特性与最佳实践》一书里面讲的虚拟机并不针对某种特定的虚拟机，而是从Java虚拟机规范的角度来讲解Java虚拟机。 我们平时使用的乃至商用的大多数Java虚拟机都是Sun公司的HotSpot，大家cmd进入命令行，使用”java -version”命令就可以看到了。如果希望在Java虚拟机规范的基础上更加深入地去理解虚拟机的一些细节是怎么实现的，就可以看一下《HotSpot实战》一书，作者是陈涛。不过由于HotSpot的源码都是C/C++写的，所以要求读者有非常好的C/C++基础，如果对这两门语言不是很熟悉的朋友，看这本书可能对你帮助不是很大。 最后提一句，如果有兴趣的朋友，不妨先去网上下载一个openJDK，HotSpot的源码就在里面。 《Java并发编程实战》这本书常常被列入Java程序员必读十大书籍排行榜前几位，不过个人不是很推荐这本书。 《Java并发编程实战》作者是Brian Goetz，怎么说呢，这本书前前后后我也看了两遍左右，个人感受是： 1、文字多代码少 2、讲解多实践少 我 觉得这可能就是老外写书的特点吧，因为Java是北美国家（加拿大、美国）开发和维护的，所以老外对Java方方面面的理论知识体系都掌握得是非常清楚和 透彻的。翻开这本书看，多线程什么用、什么是死锁、什么是竞争、什么是线程安全等等，方方面面的知识点都用大量的文字篇幅讲解，不免让人感觉十分枯燥，也 难让读者有实质性的进步。我这本书看了两遍也属于一目十行意思，有兴趣的地方就重点看一下。 无论如何，作为一本常常位于Jva程序员必读十大书籍排行榜前几名的书，还是一定要推荐给大家的。 《java多线程编程核心技术》《Java多线程编程核心技术》作者高洪岩。想要学习多线程的朋友，这本书是我大力推荐的，我的个人博客里面二十多篇的多线程博文都是基于此书，并且在这本书的基础上进行提炼和总结而写出来的。 此书和《Java并发编程实战》 相反，这本书的特点是大篇幅的代码+小篇幅的精讲解，可能这和中国人写的书比较偏向实用主义的风格有关。本书关于线程安全、synchronized、 Reentrant、Timer等等都用详细的代码进行了讲解，而且每个大知识点下的多个小知识点都会详细讲解到，非常有实践价值。 有兴趣的朋友们，我相信只要你们跟着这本书里面的代码敲、运行、思考，三步走，对于多线程的使用与理解一定会进几大步。 不 过这本书的缺点就是对于Java并发包下的一些类像CountDownLatch、Semphore、CyclicBarrier、Future、 Callable等都没有讲到，重点的CAS和AQS也没有触及，重点类的实现原理也没有提。当然，这很深入了，在学习了这本书之后如果能再去对这些知识 进行一些学习、研究的话，你一定会慢慢成长为一个很厉害的多线程高手。 《Effective Java中文版》这是唯一一本我没有买的书。初识这本书，是在我的博文Java代码优化（长期更新）里面，底下评论的时候有朋友提到了这本书，当时我说要去买，不过这两个月一直都没时间去逛书店，甚是遗憾，之后肯定会找时间去买这本书的。 《Effective Java中文版》的作者是Joshua Bloch，这个人就很厉害了，他是谷歌的首席架构师，属于超级技术大牛级别了吧，呵呵。由于没有看过这本书，所以我不好发表评论，但是从这本书的知名度 以及其作者的来头来看（多提一句，这本书也是Java之父James Gosling博士推崇的一本书），我相信这一定是一本值得一看的好书。 好 的代码是每个Java程序员都应该去追求的，不是说我今天写一段好代码相比写一段烂代码对性能会有多大的提升，更多的应该是提升了代码的可读性以及可以规 避许多潜在的、未知的问题，避免代码上线之后出问题而花时间去维护—-无论从时间成本、人力成本还是风险成本来说，这都是非常高的。 《深入分析Java Web技术内幕》《深入分析Java Web技术内幕》，作者许令波，淘宝工程师。 这本书我用一个字概括就是：全。真的非常全，HTTP、DNS、CDN、静态化、Jetty、Tomcat、Servlet、Spring、MyBatis等等，什么都有，涉及知识面非常广，但又不像专门精讲某个知识点的书籍一样讲得非常深入，感觉这本书就是尽量去用短的篇幅讲清楚一些Java Web使用到的技术的内幕，让读者对这些知识点的技术内幕有一个理性的认识。 不过，尽管每个知识点的篇幅都不多，但是重点都基本讲到了，是一本让人真正有收获的书。如果想进一步了解这些技术的技术内幕，就要自己去买相关书籍或者自己上网查资料了，有种抛砖引玉，或者说师傅领进门、修行在个人的感觉。 《大型网站技术架构 核心原理与案例分析》 一个字评价这本书，屌；两个字评价这本书，很屌；三个字评价这本书，非常屌。呵呵，好了，再说下去可能别人以为我是水军了。 《大型网站技术架构 核心原理与案例分析》的作者是李智慧，原阿里巴巴技术专家。 Java 的大多数应用都是用在Web上的，现在只要稍微大型一点的Web应用，都一定是一个分布式系统，那么一个分布式系统用到了哪些技术？一个大型网站是如何从 一个小型网站成长起来的？如何保证你的网站安全？分布式系统使用到了缓存，有哪些缓存？缓存的使用有哪些值得注意的事项？ 关 于分布式的知识点，都在这本书里面有体现，只有你想不到，没有他写不到，而且写得非常易懂，基本属于看一两遍，再记一些笔记就知道是怎么一回事儿了。多看 几遍，对分布式的理解一定会加深不少。而且里面不仅仅是分布式的知识，还非常接地气地写了如何做一个好的架构师，其实我认为这不仅仅是写给想做架构师的读 者看的，就是给读者一些建议，如何更好地提出意见、如何更让别人关注你的声音、如何看到他人的优点，入木三分，让人获益匪浅。 《大型网站系统与Java中间件实践》《大型网站系统与Java中间件实践》作者曾宪杰，是淘宝的技术总监，算起来应该在阿里有至少P8的级别了吧。 这本书的部分内容和上面一本李智慧的《大型网站技术架构 核心原理与案例分析》有所重合，像分布式系统的演化、CDN、CAP理论和BASE理论等等，这也更说明这些都是分布式系统或者说是一个大型网站重点关注的内容，当作一次再学习也不错。 本书要突出的重点是中间件三个字，中间件是分布式系统中一个非常重要的东西，其最重要的作用应该就是解耦，降低模块与模块之间的强依赖，不同的模块之间的依赖度降低，便可以各自独立地开发自己的功能，这也可以说是软件工程发展的目标和驱动力。 因此，本书有一部分的内容就是基于中间件，详细讲解了中间件与JMS的各种知识，适合对分布式系统比较熟悉并且想要往中间件方面有一定研究的读者。 《从Paxos到ZooKeeper 分布式一致性原理与实践》 《从Paxos到ZooKeeper 分布式一致性原理与实践》，作者倪超，阿里巴巴工程师。 这本书是我最近在研读的一本书，和上面的《大型网站系统与Java中间件实践》一样，属于分布式组件的范畴，属于有些深入的内容，当然也是我自己的个人兴趣。当然，如果有志向做一个出色的大型网站架构师、公司的技术总监之类，这些知识当然是必须掌握的。 本书从分布式系统基本理论开始讲起，讲到Paxos算法，最后慢慢引入到Zookeeper，循序渐进。当然，更多的我目前还不方便发表什么看法，因为这本书的第二张Paxos算法我都还没有弄懂（Paxos算法确实有些难以理解和不太易懂），接下来的章节还没有看下去。 如果网友们所在的公司在使用Zookeeper，并且你又对Zookeeper感兴趣想要研究一下它的原理的，这本书将是不二之选。 《MySQL5.6从零开始学》《MySQL5.6从零开始学》，作者刘增杰和李坤。 作为一名Java程序员，我认为我们千万不要觉得数据库是DBA的事情，数据库对一个Java程序员来说也是必须掌握的一门知识，丰富的数据库性能优化经验是一个顶尖程序员必备技能。 目前主流的数据库有Oracle和MySQL，当然推荐大家的是MySQL，主要原因我认为有两点： 1、MySQL相比Oracle更轻量级、更小、安装和卸载更方便，SQL其实都是差不多的，如果想学数据库，学MySQL就可以了，在家里面可以自己方便地研究，如果你的公司使用Oracle，只要再用对比学习法，关注一下Oracle和MySQL的差别即可 2、随着2009年阿里巴巴去IOE的运动的进行，目前国内的很多互联网公司都会选择MySQL作为它们使用的数据库，因为MySQL免费，所以既省钱又不需要出了问题就依赖甲骨文公司 MySQL学习我推荐的是这本我自己学习看的《MySQL5.6从零开始学》，我是觉得挺好的这本书，书里面的知识点很细致、很全面，读者选择书籍的标准大多不就是这两点吗？ 《Spring源码深度解析》《Spring源码深度解析》，作者郝佳。 Spring 这个框架做得太好了，功能太强大了，以至于很多开发者都只知Spring，不知什么是工厂、什么是单例、什么是代理（我面试别人的真实体会）。这种功能强 大的框架内部一定是很复杂的实现，这就导致一旦你的程序使用Spring，出了问题，可能是Error、可能是Exception、可能是程序运行结果不 是你的预期的，出现诸如此类问题的时候，将会让你感到困惑，除了上网查资料或者问别人似乎没有更好的解决办法。 研读Spring的源代码不失为一种很好的学习方法，我个人认为这有很多好处： 1、理解框架内部的实现之后，可以主动去解决问题，而不需要依赖别人 2、Spring框架内部实现用到了很多设计模式，很好的代码设计思路，这将会对你写代码、对你理解设计模式有很大的提高 3、研究Spring框架将会大大增强你读代码的能力，我相信只要你能研究清楚Spring内部是如何实现的，其他任何一个框架的源代码都难不倒你 总而言之，我认为读代码的能力是一个普通的程序员和一个好的程序员之间最大的差别之一，前者只会把别人写好的东西拿来用，后者不仅能用好，还清楚知道别人写好的东西底层是如何实现的，在出现问题的时候可以轻松解决。 Spring源代码，个人推荐《Spring源码深度解析》一书，真要研究透并且写清楚Spring源代码，恐怕三四本书都不够，作者在近400页的篇幅中尽量去讲解Spring源代码是如何实现的，殊为不易，尽管无法讲得完全，但是相信作者的讲解配合上读者自己的研究，一定可以对Spring的实现有更深度的理解。 后记 以 上就是我推荐给Java开发者们的一些值得一看的好书。但是这些书里面并没有Java基础、Java教程之类的书，不是我不推荐，而是离我自己学习 Java基础技术也过去好几年了，我学习的时候看的什么也忘了，所以我不能不负责任地推荐一些我自己都没有看过的书给大家。对于Java基础知识的学习， 我提两点建议吧： 1、多写多敲代码，好的代码与扎实的基础知识一定是实践出来的 2、可以去尚学堂下载一下马士兵的视频来学习一下Java基础，还挺不错的，如果尚学堂官网上下载不了可以底下回复，我的电脑里有 最后，每一位读到这里的网友，感谢你们能耐心地看完。希望在成为一名更优秀的Java程序员的道路上，我们可以一起学习、一起进步。 转载：http://developer.51cto.com/art/201512/503095.htm","tags":[{"name":"学习","slug":"学习","permalink":"http://wangyuanjun.cn/tags/学习/"}]},{"title":"解决微信公共号开发出现 redirect_uri域名与后台配置不一致，错误码10003 错误","date":"2018-01-27T15:27:54.000Z","path":"2018/01/27/解决微信公共号开发出现-redirect-uri域名与后台配置不一致，错误码10003-错误/","text":"做微信网页OAuth2.0 授权开发，进入授权页面是报错，redirect_uri域名与后台配置不一致，错误码10003 问题原因：可能OAuth2.0网页授权页面没有填写授权回调页面域名，或者域名前面加了 http:// 解决方法： 到 微信公共平台-&gt;测试号管理-&gt;体验接口权限表-&gt;网页服务-&gt;网页帐号-&gt;修改 ，填写域名","tags":[{"name":"微信公共号","slug":"微信公共号","permalink":"http://wangyuanjun.cn/tags/微信公共号/"}]},{"title":"微信公共号开发教程java版——微信网页授权(八)","date":"2018-01-27T08:17:17.000Z","path":"2018/01/27/微信公共号开发教程java版——微信网页授权-八/","text":"一：微信网页授权介绍官网详细介绍:https://mp.weixin.qq.com/wiki?t=resource/res_main&amp;id=mp1421140839如果用户在微信客户端中访问第三方网页，公众号可以通过微信网页授权机制，来获取用户基本信息，进而实现业务逻辑。 关于网页授权回调域名的说明1、在微信公众号请求用户网页授权之前，开发者需要先到公众平台官网中的“开发 - 接口权限 - 网页服务 - 网页帐号 - 网页授权获取用户基本信息”的配置选项中，修改授权回调域名。请注意，这里填写的是域名（是一个字符串），而不是URL，因此请勿加 http:// 等协议头； 2、授权回调域名配置规范为全域名，比如需要网页授权的域名为：www.qq.com，配置以后此域名下面的页面http://www.qq.com/music.html 、 http://www.qq.com/login.html 都可以进行OAuth2.0鉴权。但http://pay.qq.com 、 http://music.qq.com 、 http://qq.com无法进行OAuth2.0鉴权 3、如果公众号登录授权给了第三方开发者来进行管理，则不必做任何设置，由第三方代替公众号实现网页授权即可 关于网页授权的两种scope的区别说明1、以snsapi_base为scope发起的网页授权，是用来获取进入页面的用户的openid的，并且是静默授权并自动跳转到回调页的。用户感知的就是直接进入了回调页（往往是业务页面） 2、以snsapi_userinfo为scope发起的网页授权，是用来获取用户的基本信息的。但这种授权需要用户手动同意，并且由于用户同意过，所以无须关注，就可在授权后获取该用户的基本信息。 3、用户管理类接口中的“获取用户基本信息接口”，是在用户和公众号产生消息交互或关注后事件推送后，才能根据用户OpenID来获取用户基本信息。这个接口，包括其他微信接口，都是需要该用户（即openid）关注了公众号后，才能调用成功的。 关于网页授权access_token和普通access_token的区别1、微信网页授权是通过OAuth2.0机制实现的，在用户授权给公众号后，公众号可以获取到一个网页授权特有的接口调用凭证（网页授权access_token），通过网页授权access_token可以进行授权后接口调用，如获取用户基本信息； 2、其他微信接口，需要通过基础支持中的“获取access_token”接口来获取到的普通access_token调用。 关于UnionID机制1、请注意，网页授权获取用户基本信息也遵循UnionID机制。即如果开发者有在多个公众号，或在公众号、移动应用之间统一用户帐号的需求，需要前往微信开放平台（open.weixin.qq.com）绑定公众号后，才可利用UnionID机制来满足上述需求。 2、UnionID机制的作用说明：如果开发者拥有多个移动应用、网站应用和公众帐号，可通过获取用户基本信息中的unionid来区分用户的唯一性，因为同一用户，对同一个微信开放平台下的不同应用（移动应用、网站应用和公众帐号），unionid是相同的。 关于特殊场景下的静默授权1、上面已经提到，对于以snsapi_base为scope的网页授权，就静默授权的，用户无感知； 2、对于已关注公众号的用户，如果用户从公众号的会话或者自定义菜单进入本公众号的网页授权页，即使是scope为snsapi_userinfo，也是静默授权，用户无感知。 具体而言，网页授权流程分为四步： 1、引导用户进入授权页面同意授权，获取code 2、通过code换取网页授权access_token（与基础支持中的access_token不同） 3、如果需要，开发者可以刷新网页授权access_token，避免过期 4、通过网页授权access_token和openid获取用户基本信息（支持UnionID机制） 二：网页授权的实现1.用户同意授权，获取code在确保微信公众账号拥有授权作用域（scope参数）的权限的前提下（服务号获得高级接口后，默认拥有scope参数中的snsapi_base和snsapi_userinfo），引导关注者打开如下页面： 1https://open.weixin.qq.com/connect/oauth2/authorize?appid=APPID&amp;redirect_uri=REDIRECT_URI&amp;response_type=code&amp;scope=SCOPE&amp;state=STATE#wechat_redirect 若提示“该链接无法访问”，请检查参数是否填写错误，是否拥有scope参数对应的授权作用域权限。 尤其注意：由于授权操作安全等级较高，所以在发起授权请求时，微信会对授权链接做正则强匹配校验，如果链接的参数顺序不对，授权页面将无法正常访问 12345参考链接(请在微信客户端中打开此链接体验):scope为snsapi_basehttps://open.weixin.qq.com/connect/oauth2/authorize?appid=wx520c15f417810387&amp;redirect_uri=https%3A%2F%2Fchong.qq.com%2Fphp%2Findex.php%3Fd%3D%26c%3DwxAdapter%26m%3DmobileDeal%26showwxpaytitle%3D1%26vb2ctag%3D4_2030_5_1194_60&amp;response_type=code&amp;scope=snsapi_base&amp;state=123#wechat_redirectscope为snsapi_userinfohttps://open.weixin.qq.com/connect/oauth2/authorize?appid=wxf0e81c3bee622d60&amp;redirect_uri=http%3A%2F%2Fnba.bluewebgame.com%2Foauth_response.php&amp;response_type=code&amp;scope=snsapi_userinfo&amp;state=STATE#wechat_redirect 尤其注意：跳转回调redirect_uri，应当使用https链接来确保授权code的安全性。 参数说明 参数 是否必须 说明 appid 是 公众号的唯一标识 redirect_uri 是 授权后重定向的回调链接地址， 请使用 urlEncode 对链接进行处理 response_type 是 返回类型，请填写code scope 是 应用授权作用域，snsapi_base （不弹出授权页面，直接跳转，只能获取用户openid），snsapi_userinfo （弹出授权页面，可通过openid拿到昵称、性别、所在地。并且， 即使在未关注的情况下，只要用户授权，也能获取其信息 ） state 否 重定向后会带上state参数，开发者可以填写a-zA-Z0-9的参数值，最多128字节 #wechat_redirect 是 无论直接打开还是做页面302重定向时候，必须带此参数 下图为scope等于snsapi_userinfo时的授权页面： 用户同意授权后如果用户同意授权，页面将跳转至 redirect_uri/?code=CODE&amp;state=STATE。 1code说明 ： code作为换取access_token的票据，每次用户授权带上的code将不一样，code只能使用一次，5分钟未被使用自动过期。 错误返回码说明如下： 返回码 说明 10003 redirect_uri域名与后台配置不一致 10004 此公众号被封禁 10005 此公众号并没有这些scope的权限 10006 必须关注此测试号 10009 操作太频繁了，请稍后重试 10010 scope不能为空 10011 redirect_uri不能为空 10012 appid不能为空 10013 state不能为空 10015 公众号未授权第三方平台，请检查授权状态 10016 不支持微信开放平台的Appid，请使用公众号Appid 2. 通过网页授权获取的用户信息用户信息类：SNSUserInfo类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102package com.wyj.wechart.pojo;import java.util.List;/** * 通过网页授权获取的用户信息 * * * @author：WangYuanJun * @date：2018年1月24日 下午3:09:02 */public class SNSUserInfo &#123; // 用户标识 private String openId; // 用户昵称 private String nickname; // 性别（1是男性，2是女性，0是未知） private int sex; // 国家 private String country; // 省份 private String province; // 城市 private String city; // 用户头像链接 private String headImgUrl; // 用户特权信息 private List&lt;String&gt; privilegeList; public String getOpenId() &#123; return openId; &#125; public void setOpenId(String openId) &#123; this.openId = openId; &#125; public String getNickname() &#123; return nickname; &#125; public void setNickname(String nickname) &#123; this.nickname = nickname; &#125; public int getSex() &#123; return sex; &#125; public void setSex(int sex) &#123; this.sex = sex; &#125; public String getCountry() &#123; return country; &#125; public void setCountry(String country) &#123; this.country = country; &#125; public String getProvince() &#123; return province; &#125; public void setProvince(String province) &#123; this.province = province; &#125; public String getCity() &#123; return city; &#125; public void setCity(String city) &#123; this.city = city; &#125; public String getHeadImgUrl() &#123; return headImgUrl; &#125; public void setHeadImgUrl(String headImgUrl) &#123; this.headImgUrl = headImgUrl; &#125; public List&lt;String&gt; getPrivilegeList() &#123; return privilegeList; &#125; public void setPrivilegeList(List&lt;String&gt; privilegeList) &#123; this.privilegeList = privilegeList; &#125;&#125; 3.凭证实体类123456789101112131415161718192021222324252627282930313233package com.wyj.wechart.pojo;/** * * 凭证 * * @author：WangYuanJun * @date：2018年1月23日 下午3:19:14 */public class Token &#123; // 接口访问凭证 private String accessToken; // 凭证有效期，单位：秒 private int expiresIn; public String getAccessToken() &#123; return accessToken; &#125; public void setAccessToken(String accessToken) &#123; this.accessToken = accessToken; &#125; public int getExpiresIn() &#123; return expiresIn; &#125; public void setExpiresIn(int expiresIn) &#123; this.expiresIn = expiresIn; &#125;&#125; 4.网页授权信息 WeixinOauth2Token类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.wyj.wechart.pojo;/** * 网页授权信息 * * * @author：WangYuanJun * @date：2018年1月24日 下午3:10:03 */public class WeixinOauth2Token &#123; // 网页授权接口调用凭证 private String accessToken; // 凭证有效时长 private int expiresIn; // 用于刷新凭证 private String refreshToken; // 用户标识 private String openId; // 用户授权作用域 private String scope; public String getAccessToken() &#123; return accessToken; &#125; public void setAccessToken(String accessToken) &#123; this.accessToken = accessToken; &#125; public int getExpiresIn() &#123; return expiresIn; &#125; public void setExpiresIn(int expiresIn) &#123; this.expiresIn = expiresIn; &#125; public String getRefreshToken() &#123; return refreshToken; &#125; public void setRefreshToken(String refreshToken) &#123; this.refreshToken = refreshToken; &#125; public String getOpenId() &#123; return openId; &#125; public void setOpenId(String openId) &#123; this.openId = openId; &#125; public String getScope() &#123; return scope; &#125; public void setScope(String scope) &#123; this.scope = scope; &#125;&#125; 5.微信用户的基本信息WeixinUserInfo类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121package com.wyj.wechart.pojo;/** * 微信用户的基本信息 * * * @author：WangYuanJun * @date：2018年1月24日 上午10:05:42 */public class WeixinUserInfo &#123; // 用户的标识 private String openId; // 关注状态（1是关注，0是未关注），未关注时获取不到其余信息 private int subscribe; // 用户关注时间，为时间戳。如果用户曾多次关注，则取最后关注时间 private String subscribeTime; // 昵称 private String nickname; // 用户的性别（1是男性，2是女性，0是未知） private int sex; // 用户所在国家 private String country; // 用户所在省份 private String province; // 用户所在城市 private String city; // 用户的语言，简体中文为zh_CN private String language; // 用户头像 private String headImgUrl; public String getOpenId() &#123; return openId; &#125; public void setOpenId(String openId) &#123; this.openId = openId; &#125; public int getSubscribe() &#123; return subscribe; &#125; public void setSubscribe(int subscribe) &#123; this.subscribe = subscribe; &#125; public String getSubscribeTime() &#123; return subscribeTime; &#125; public void setSubscribeTime(String subscribeTime) &#123; this.subscribeTime = subscribeTime; &#125; public String getNickname() &#123; return nickname; &#125; public void setNickname(String nickname) &#123; this.nickname = nickname; &#125; public int getSex() &#123; return sex; &#125; public void setSex(int sex) &#123; this.sex = sex; &#125; public String getCountry() &#123; return country; &#125; public void setCountry(String country) &#123; this.country = country; &#125; public String getProvince() &#123; return province; &#125; public void setProvince(String province) &#123; this.province = province; &#125; public String getCity() &#123; return city; &#125; public void setCity(String city) &#123; this.city = city; &#125; public String getLanguage() &#123; return language; &#125; public void setLanguage(String language) &#123; this.language = language; &#125; public String getHeadImgUrl() &#123; return headImgUrl; &#125; public void setHeadImgUrl(String headImgUrl) &#123; this.headImgUrl = headImgUrl; &#125;&#125; 6.获取网页授权凭证及获取用户信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108package com.wyj.wechart.utils;import java.util.List;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import com.wyj.wechart.pojo.SNSUserInfo;import com.wyj.wechart.pojo.WeixinOauth2Token;import net.sf.json.JSONArray;import net.sf.json.JSONObject;/** * * * * @author：WangYuanJun * @date：2018年1月24日 下午3:19:44 */public class AdvancedUtil &#123; private static Logger log = LoggerFactory.getLogger(AdvancedUtil.class); /** * 获取网页授权凭证 * * @param appId * 公众账号的唯一标识 * @param appSecret * 公众账号的密钥 * @param code * @return WeixinAouth2Token */ public static WeixinOauth2Token getOauth2AccessToken(String appId, String appSecret, String code) &#123; WeixinOauth2Token wat = null; // 拼接请求地址 String requestUrl = &quot;https://api.weixin.qq.com/sns/oauth2/access_token?appid=APPID&amp;secret=SECRET&amp;code=CODE&amp;grant_type=authorization_code&quot;; requestUrl = requestUrl.replace(&quot;APPID&quot;, appId); requestUrl = requestUrl.replace(&quot;SECRET&quot;, appSecret); requestUrl = requestUrl.replace(&quot;CODE&quot;, code); // 获取网页授权凭证 JSONObject jsonObject = CommonUtil.httpsRequest(requestUrl, &quot;GET&quot;, null); if (null != jsonObject) &#123; try &#123; wat = new WeixinOauth2Token(); wat.setAccessToken(jsonObject.getString(&quot;access_token&quot;)); wat.setExpiresIn(jsonObject.getInt(&quot;expires_in&quot;)); wat.setRefreshToken(jsonObject.getString(&quot;refresh_token&quot;)); wat.setOpenId(jsonObject.getString(&quot;openid&quot;)); wat.setScope(jsonObject.getString(&quot;scope&quot;)); &#125; catch (Exception e) &#123; wat = null; int errorCode = jsonObject.getInt(&quot;errcode&quot;); String errorMsg = jsonObject.getString(&quot;errmsg&quot;); log.error(&quot;获取网页授权凭证失败 errcode:&#123;&#125; errmsg:&#123;&#125;&quot;, errorCode, errorMsg); &#125; &#125; return wat; &#125; /** * 通过网页授权获取用户信息 * * @param accessToken * 网页授权接口调用凭证 * @param openId * 用户标识 * @return SNSUserInfo */ @SuppressWarnings(&#123; &quot;deprecation&quot;, &quot;unchecked&quot; &#125;) public static SNSUserInfo getSNSUserInfo(String accessToken, String openId) &#123; SNSUserInfo snsUserInfo = null; // 拼接请求地址 String requestUrl = &quot;https://api.weixin.qq.com/sns/userinfo?access_token=ACCESS_TOKEN&amp;openid=OPENID&quot;; requestUrl = requestUrl.replace(&quot;ACCESS_TOKEN&quot;, accessToken).replace(&quot;OPENID&quot;, openId); // 通过网页授权获取用户信息 JSONObject jsonObject = CommonUtil.httpsRequest(requestUrl, &quot;GET&quot;, null); if (null != jsonObject) &#123; try &#123; snsUserInfo = new SNSUserInfo(); // 用户的标识 snsUserInfo.setOpenId(jsonObject.getString(&quot;openid&quot;)); // 昵称 snsUserInfo.setNickname(jsonObject.getString(&quot;nickname&quot;)); // 性别（1是男性，2是女性，0是未知） snsUserInfo.setSex(jsonObject.getInt(&quot;sex&quot;)); // 用户所在国家 snsUserInfo.setCountry(jsonObject.getString(&quot;country&quot;)); // 用户所在省份 snsUserInfo.setProvince(jsonObject.getString(&quot;province&quot;)); // 用户所在城市 snsUserInfo.setCity(jsonObject.getString(&quot;city&quot;)); // 用户头像 snsUserInfo.setHeadImgUrl(jsonObject.getString(&quot;headimgurl&quot;)); // 用户特权信息 snsUserInfo.setPrivilegeList(JSONArray.toList(jsonObject.getJSONArray(&quot;privilege&quot;), List.class)); &#125; catch (Exception e) &#123; snsUserInfo = null; int errorCode = jsonObject.getInt(&quot;errcode&quot;); String errorMsg = jsonObject.getString(&quot;errmsg&quot;); log.error(&quot;获取用户信息失败 errcode:&#123;&#125; errmsg:&#123;&#125;&quot;, errorCode, errorMsg); &#125; &#125; return snsUserInfo; &#125;&#125; 7.封装https请求类 CommonUtil 类https请求的工具 1234567891011121314151617181920212223242526272829package com.wyj.wechart.utils;import java.security.cert.CertificateException;import java.security.cert.X509Certificate;import javax.net.ssl.X509TrustManager;/** * 证书信任管理器（用于https请求） * 这个证书管理器的作用就是让它信任我们指定的证书，下面的代码意味着信任所有证书，不管是否权威机构颁发。 * * @author：WangYuanJun * @date：2018年1月23日 下午3:22:19 */public class MyX509TrustManager implements X509TrustManager &#123; // 检查客户端证书 public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; // 检查服务器端证书 public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; // 返回受信任的X509证书数组 public X509Certificate[] getAcceptedIssuers() &#123; return null; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * 发送https请求 * * @param requestUrl * 请求地址 * @param requestMethod * 请求方式（GET、POST） * @param outputStr * 提交的数据 * @return JSONObject(通过JSONObject.get(key)的方式获取json对象的属性值) */public static JSONObject httpsRequest(String requestUrl, String requestMethod, String outputStr) &#123; JSONObject jsonObject = null; try &#123; // 创建SSLContext对象，并使用我们指定的信任管理器初始化 TrustManager[] tm = &#123; new MyX509TrustManager() &#125;; SSLContext sslContext = SSLContext.getInstance(&quot;SSL&quot;, &quot;SunJSSE&quot;); sslContext.init(null, tm, new java.security.SecureRandom()); // 从上述SSLContext对象中得到SSLSocketFactory对象 SSLSocketFactory ssf = sslContext.getSocketFactory(); URL url = new URL(requestUrl); HttpsURLConnection conn = (HttpsURLConnection) url.openConnection(); conn.setSSLSocketFactory(ssf); conn.setDoOutput(true); conn.setDoInput(true); conn.setUseCaches(false); // 设置请求方式（GET/POST） conn.setRequestMethod(requestMethod); // 当outputStr不为null时向输出流写数据 if (null != outputStr) &#123; OutputStream outputStream = conn.getOutputStream(); // 注意编码格式 outputStream.write(outputStr.getBytes(&quot;UTF-8&quot;)); outputStream.close(); &#125; // 从输入流读取返回内容 InputStream inputStream = conn.getInputStream(); InputStreamReader inputStreamReader = new InputStreamReader(inputStream, &quot;utf-8&quot;); BufferedReader bufferedReader = new BufferedReader(inputStreamReader); String str = null; StringBuffer buffer = new StringBuffer(); while ((str = bufferedReader.readLine()) != null) &#123; buffer.append(str); &#125; // 释放资源 bufferedReader.close(); inputStreamReader.close(); inputStream.close(); inputStream = null; conn.disconnect(); jsonObject = JSONObject.fromObject(buffer.toString()); &#125; catch (ConnectException ce) &#123; log.error(&quot;连接超时：&#123;&#125;&quot;, ce); &#125; catch (Exception e) &#123; log.error(&quot;https请求异常：&#123;&#125;&quot;, e); &#125; return jsonObject;&#125; 8.写授权类：替换成自己的appid 和 密钥 123456789101112131415161718192021222324252627282930313233343536373839404142package com.wyj.wechart.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.servlet.ModelAndView;import com.wyj.wechart.pojo.SNSUserInfo;import com.wyj.wechart.pojo.WeixinOauth2Token;import com.wyj.wechart.utils.AdvancedUtil;/** * 授权后的回调请求处理 * * * @author：WangYuanJun * @date：2018年1月27日 下午5:31:09 */@Controller@RequestMapping(&quot;/oauth&quot;)public class OAuthController &#123; @RequestMapping public ModelAndView index(String code,String state)&#123; ModelAndView mv = new ModelAndView(&quot;/index&quot;); // 用户同意授权 if (!&quot;authdeny&quot;.equals(code)) &#123; // 获取网页授权access_token WeixinOauth2Token weixinOauth2Token = AdvancedUtil.getOauth2AccessToken(&quot;wx17fdedc3d6d0b68e&quot;, &quot;c3b3d919d65a781ba7db58d9d8dfb515&quot;, code); // 网页授权接口访问凭证 String accessToken = weixinOauth2Token.getAccessToken(); // 用户标识 String openId = weixinOauth2Token.getOpenId(); // 获取用户信息 SNSUserInfo snsUserInfo = AdvancedUtil.getSNSUserInfo(accessToken, openId); // 设置要传递的参数 mv.addObject(&quot;snsUserInfo&quot;, snsUserInfo); mv.addObject(&quot;state&quot;, state); &#125; return mv; &#125; &#125; 9.授权后，显示信息的页面123456789101112131415161718192021222324252627282930&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;OAuth2.0网页授权&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;#if snsUserInfo??&gt; &lt;table width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt; &lt;tr&gt;&lt;td width=&quot;20%&quot;&gt;属性&lt;/td&gt;&lt;td width=&quot;80%&quot;&gt;值&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;OpenID&lt;/td&gt;&lt;td&gt;$&#123;snsUserInfo.openId&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;昵称&lt;/td&gt;&lt;td&gt;$&#123;snsUserInfo.nickname&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;性别&lt;/td&gt;&lt;td&gt;$&#123;snsUserInfo.sex&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;国家&lt;/td&gt;&lt;td&gt;$&#123;snsUserInfo.country&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;省份&lt;/td&gt;&lt;td&gt;$&#123;snsUserInfo.province&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;城市&lt;/td&gt;&lt;td&gt;$&#123;snsUserInfo.city&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;头像&lt;/td&gt;&lt;td&gt;$&#123;snsUserInfo.headImgUrl&#125;&lt;/td&gt;&lt;/tr&gt;&lt;!-- &lt;tr&gt;&lt;td&gt;特权&lt;/td&gt;&lt;td&gt;$&#123;snsUserInfo.privilegeList&#125;&lt;/td&gt;&lt;/tr&gt; --&gt; &lt;tr&gt;&lt;td&gt;state:&lt;/td&gt;&lt;td&gt;$&#123;state&#125;&lt;/td&gt;&lt;/tr&gt; &lt;/table&gt; &lt;#else&gt; &lt;p&gt;用户不同意授权,未获取到用户信息！&lt;/p&gt;&lt;/#if&gt;&lt;/body&gt;&lt;/html&gt; 10.application.properties配置123456789101112server.port=80spring.freemarker.cache=falsespring.freemarker.charset=UTF-8spring.freemarker.check-template-location=truespring.freemarker.content-type=text/htmlspring.freemarker.expose-request-attributes=truespring.freemarker.expose-session-attributes=truespring.freemarker.request-context-attribute=requestspring.freemarker.template-loader-path=classpath:/templatesspring.freemarker.suffix=.htmlspring.mvc.static-path-pattern=/static/** 11.替换官方的链接成我们的方法路径：官方的请求链接： 1https://open.weixin.qq.com/connect/oauth2/authorize?appid=APPID&amp;redirect_uri=REDIRECT_URI&amp;response_type=code&amp;scope=SCOPE&amp;state=STATE#wechat_redirect 需要修改的地方： （1）替换自己的AppID （2）将redirect_url换成自己的授权请求链接URL。注意这个连接需要经过UTF-8编码。 （3）需要修改scope。需要弹出页面则要修改为snsapi_userinfo 。 scope参数的解释： 1、以snsapi_base为scope发起的网页授权，是用来获取进入页面的用户的openid的，并且是静默授权并自动跳转到回调页的。用户感知的就是直接进入了回调页（往往是业务页面） 2、以snsapi_userinfo为scope发起的网页授权，是用来获取用户的基本信息的。但这种授权需要用户手动同意，并且由于用户同意过，所以无须关注，就可在授权后获取该用户的基本信息。 URL转码 123456789101112131415/** * URL编码（utf-8） * * @param source * @return */public static String urlEncodeUTF8(String source) &#123; String result = source; try &#123; result = java.net.URLEncoder.encode(source, &quot;utf-8&quot;); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; return result;&#125; 123456789101112131415161718192021package com.wyj.wechart.test;import com.wyj.wechart.utils.CommonUtil;/** * URL转码 * * * @author：WangYuanJun * @date：2018年1月27日 下午5:35:02 */public class TransCodeUrlTest &#123; /** * 生成URL编码 * * @param args */ public static void main(String[] args) &#123; String source = &quot;http://6400cc45.ngrok.io/oauth&quot;; System.out.println(CommonUtil.urlEncodeUTF8(source)); &#125;&#125; 也可以直接在线url编码： http://tool.chinaz.com/Tools/URLEncode.aspx 12.修改网页授权获取用户基本信息微信公共平台-&gt;测试号管理-&gt;体验接口权限表-&gt;网页服务-&gt;网页帐号-&gt;修改修改完成后需要重新关注 13.测试效果：复制上面替换好的链接，然后丢进浏览器，然后用微信来扫一扫。 注：github项目地址：微信公共号开发用例","tags":[{"name":"微信公共号","slug":"微信公共号","permalink":"http://wangyuanjun.cn/tags/微信公共号/"}]},{"title":"微信公共号开发教程java版——获取用户基本信息(UnionID机制)(七)","date":"2018-01-27T07:14:32.000Z","path":"2018/01/27/微信公共号开发教程java版——获取用户基本信息-UnionID机制-七/","text":"一：UnionID机制说明官网详细介绍:https://mp.weixin.qq.com/wiki?t=resource/res_main&amp;id=mp1421140839 获取用户基本信息(UnionID机制)在关注者与公众号产生消息交互后，公众号可获得关注者的OpenID（加密后的微信号，每个用户对每个公众号的OpenID是唯一的。对于不同公众号，同一用户的openid不同）。公众号可通过本接口来根据OpenID获取用户基本信息，包括昵称、头像、性别、所在城市、语言和关注时间。 请注意，如果开发者有在多个公众号，或在公众号、移动应用之间统一用户帐号的需求，需要前往微信开放平台（open.weixin.qq.com）绑定公众号后，才可利用UnionID机制来满足上述需求。 UnionID机制说明：开发者可通过OpenID来获取用户基本信息。特别需要注意的是，如果开发者拥有多个移动应用、网站应用和公众帐号，可通过获取用户基本信息中的unionid来区分用户的唯一性，因为只要是同一个微信开放平台帐号下的移动应用、网站应用和公众帐号，用户的unionid是唯一的。换句话说，同一用户，对同一个微信开放平台下的不同应用，unionid是相同的。 获取用户基本信息（包括UnionID机制）开发者可通过OpenID来获取用户基本信息。请使用https协议。 123接口调用请求说明http请求方式: GEThttps://api.weixin.qq.com/cgi-bin/user/info?access_token=ACCESS_TOKEN&amp;openid=OPENID&amp;lang=zh_CN 参数说明 参数 是否必须 说明 access_token 是 调用接口凭证 openid 是 普通用户的标识，对当前公众号唯一 lang 否 返回国家地区语言版本，zh_CN 简体，zh_TW 繁体，en 英语 返回说明 正常情况下，微信会返回下述JSON数据包给公众号： 1234567891011121314151617&#123; &quot;subscribe&quot;: 1, &quot;openid&quot;: &quot;o6_bmjrPTlm6_2sgVt7hMZOPfL2M&quot;, &quot;nickname&quot;: &quot;Band&quot;, &quot;sex&quot;: 1, &quot;language&quot;: &quot;zh_CN&quot;, &quot;city&quot;: &quot;广州&quot;, &quot;province&quot;: &quot;广东&quot;, &quot;country&quot;: &quot;中国&quot;, &quot;headimgurl&quot;:&quot;http://wx.qlogo.cn/mmopen/g3MonUZtNHkdmzicIlibx6iaFqAc56vxLSUfpb6n5WKSYVY0ChQKkiaJSgQ1dZuTOgvLLrhJbERQQ4eMsv84eavHiaiceqxibJxCfHe/0&quot;, &quot;subscribe_time&quot;: 1382694957, &quot;unionid&quot;: &quot; o6_bmasdasdsad6_2sgVt7hMZOPfL&quot; &quot;remark&quot;: &quot;&quot;, &quot;groupid&quot;: 0, &quot;tagid_list&quot;:[128,2]&#125; 参数说明 参数 说明 subscribe 用户是否订阅该公众号标识，值为0时，代表此用户没有关注该公众号，拉取不到其余信息。 openid 用户的标识，对当前公众号唯一 nickname 用户的昵称 sex 用户的性别，值为1时是男性，值为2时是女性，值为0时是未知 city 用户所在城市 country 用户所在国家 province 用户所在省份 language 用户的语言，简体中文为zh_CN headimgurl 用户头像，最后一个数值代表正方形头像大小（有0、46、64、96、132数值可选，0代表640*640正方形头像），用户没有头像时该项为空。若用户更换头像，原有头像URL将失效。 subscribe_time 用户关注时间，为时间戳。如果用户曾多次关注，则取最后关注时间 unionid 只有在用户将公众号绑定到微信开放平台帐号后，才会出现该字段。 remark 公众号运营者对粉丝的备注，公众号运营者可在微信公众平台用户管理界面对粉丝添加备注 groupid 用户所在的分组ID（兼容旧的用户分组接口） tagid_list 用户被打上的标签ID列表 错误时微信会返回错误码等信息，JSON数据包示例如下（该示例为AppID无效错误）: 1&#123;&quot;errcode&quot;:40013,&quot;errmsg&quot;:&quot;invalid appid&quot;&#125; 二：封装用户信息1.用户的基本信息类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121package com.wyj.wechart.pojo;/** * 微信用户的基本信息 * * * @author：WangYuanJun * @date：2018年1月24日 上午10:05:42 */public class WeixinUserInfo &#123; // 用户的标识 private String openId; // 关注状态（1是关注，0是未关注），未关注时获取不到其余信息 private int subscribe; // 用户关注时间，为时间戳。如果用户曾多次关注，则取最后关注时间 private String subscribeTime; // 昵称 private String nickname; // 用户的性别（1是男性，2是女性，0是未知） private int sex; // 用户所在国家 private String country; // 用户所在省份 private String province; // 用户所在城市 private String city; // 用户的语言，简体中文为zh_CN private String language; // 用户头像 private String headImgUrl; public String getOpenId() &#123; return openId; &#125; public void setOpenId(String openId) &#123; this.openId = openId; &#125; public int getSubscribe() &#123; return subscribe; &#125; public void setSubscribe(int subscribe) &#123; this.subscribe = subscribe; &#125; public String getSubscribeTime() &#123; return subscribeTime; &#125; public void setSubscribeTime(String subscribeTime) &#123; this.subscribeTime = subscribeTime; &#125; public String getNickname() &#123; return nickname; &#125; public void setNickname(String nickname) &#123; this.nickname = nickname; &#125; public int getSex() &#123; return sex; &#125; public void setSex(int sex) &#123; this.sex = sex; &#125; public String getCountry() &#123; return country; &#125; public void setCountry(String country) &#123; this.country = country; &#125; public String getProvince() &#123; return province; &#125; public void setProvince(String province) &#123; this.province = province; &#125; public String getCity() &#123; return city; &#125; public void setCity(String city) &#123; this.city = city; &#125; public String getLanguage() &#123; return language; &#125; public void setLanguage(String language) &#123; this.language = language; &#125; public String getHeadImgUrl() &#123; return headImgUrl; &#125; public void setHeadImgUrl(String headImgUrl) &#123; this.headImgUrl = headImgUrl; &#125;&#125; 我们先来看看获取用户信息的接口：https://api.weixin.qq.com/cgi-bin/user/info?access_token=ACCESS_TOKEN&amp;openid=OPENID&amp;lang=zh_CN根据分析，获取用户的基本信息需要一个token。 创建token类123456789101112131415161718192021222324252627282930313233package com.wyj.wechart.pojo;/** * * 凭证 * * @author：WangYuanJun * @date：2018年1月23日 下午3:19:14 */public class Token &#123; // 接口访问凭证 private String accessToken; // 凭证有效期，单位：秒 private int expiresIn; public String getAccessToken() &#123; return accessToken; &#125; public void setAccessToken(String accessToken) &#123; this.accessToken = accessToken; &#125; public int getExpiresIn() &#123; return expiresIn; &#125; public void setExpiresIn(int expiresIn) &#123; this.expiresIn = expiresIn; &#125;&#125; 创建信任管理器1234567891011121314151617181920212223242526272829package com.wyj.wechart.utils;import java.security.cert.CertificateException;import java.security.cert.X509Certificate;import javax.net.ssl.X509TrustManager;/** * 证书信任管理器（用于https请求） * 这个证书管理器的作用就是让它信任我们指定的证书，下面的代码意味着信任所有证书，不管是否权威机构颁发。 * * @author：WangYuanJun * @date：2018年1月23日 下午3:22:19 */public class MyX509TrustManager implements X509TrustManager &#123; // 检查客户端证书 public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; // 检查服务器端证书 public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; // 返回受信任的X509证书数组 public X509Certificate[] getAcceptedIssuers() &#123; return null; &#125;&#125; 封装了一个公共类：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220package com.wyj.wechart.utils;import java.io.BufferedReader;import java.io.InputStream;import java.io.InputStreamReader;import java.io.OutputStream;import java.io.UnsupportedEncodingException;import java.net.ConnectException;import java.net.URL;import javax.net.ssl.HttpsURLConnection;import javax.net.ssl.SSLContext;import javax.net.ssl.SSLSocketFactory;import javax.net.ssl.TrustManager;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import com.wyj.wechart.pojo.Token;import com.wyj.wechart.pojo.WeixinUserInfo;import net.sf.json.JSONException;import net.sf.json.JSONObject;/** * 通用工具类 * * * @author：WangYuanJun * @date：2018年1月23日 下午3:36:50 */public class CommonUtil &#123; private static Logger log = LoggerFactory.getLogger(CommonUtil.class); // 凭证获取（GET） public final static String token_url = &quot;https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&amp;appid=APPID&amp;secret=APPSECRET&quot;; /** * 发送https请求 * * @param requestUrl * 请求地址 * @param requestMethod * 请求方式（GET、POST） * @param outputStr * 提交的数据 * @return JSONObject(通过JSONObject.get(key)的方式获取json对象的属性值) */ public static JSONObject httpsRequest(String requestUrl, String requestMethod, String outputStr) &#123; JSONObject jsonObject = null; try &#123; // 创建SSLContext对象，并使用我们指定的信任管理器初始化 TrustManager[] tm = &#123; new MyX509TrustManager() &#125;; SSLContext sslContext = SSLContext.getInstance(&quot;SSL&quot;, &quot;SunJSSE&quot;); sslContext.init(null, tm, new java.security.SecureRandom()); // 从上述SSLContext对象中得到SSLSocketFactory对象 SSLSocketFactory ssf = sslContext.getSocketFactory(); URL url = new URL(requestUrl); HttpsURLConnection conn = (HttpsURLConnection) url.openConnection(); conn.setSSLSocketFactory(ssf); conn.setDoOutput(true); conn.setDoInput(true); conn.setUseCaches(false); // 设置请求方式（GET/POST） conn.setRequestMethod(requestMethod); // 当outputStr不为null时向输出流写数据 if (null != outputStr) &#123; OutputStream outputStream = conn.getOutputStream(); // 注意编码格式 outputStream.write(outputStr.getBytes(&quot;UTF-8&quot;)); outputStream.close(); &#125; // 从输入流读取返回内容 InputStream inputStream = conn.getInputStream(); InputStreamReader inputStreamReader = new InputStreamReader(inputStream, &quot;utf-8&quot;); BufferedReader bufferedReader = new BufferedReader(inputStreamReader); String str = null; StringBuffer buffer = new StringBuffer(); while ((str = bufferedReader.readLine()) != null) &#123; buffer.append(str); &#125; // 释放资源 bufferedReader.close(); inputStreamReader.close(); inputStream.close(); inputStream = null; conn.disconnect(); jsonObject = JSONObject.fromObject(buffer.toString()); &#125; catch (ConnectException ce) &#123; log.error(&quot;连接超时：&#123;&#125;&quot;, ce); &#125; catch (Exception e) &#123; log.error(&quot;https请求异常：&#123;&#125;&quot;, e); &#125; return jsonObject; &#125; /** * 获取接口访问凭证 * * @param appid * 凭证 * @param appsecret * 密钥 * @return */ public static Token getToken(String appid, String appsecret) &#123; Token token = null; String requestUrl = token_url.replace(&quot;APPID&quot;, appid).replace(&quot;APPSECRET&quot;, appsecret); // 发起GET请求获取凭证 JSONObject jsonObject = httpsRequest(requestUrl, &quot;GET&quot;, null); if (null != jsonObject) &#123; try &#123; token = new Token(); token.setAccessToken(jsonObject.getString(&quot;access_token&quot;)); token.setExpiresIn(jsonObject.getInt(&quot;expires_in&quot;)); &#125; catch (JSONException e) &#123; token = null; // 获取token失败 log.error(&quot;获取token失败 errcode:&#123;&#125; errmsg:&#123;&#125;&quot;, jsonObject.getInt(&quot;errcode&quot;), jsonObject.getString(&quot;errmsg&quot;)); &#125; &#125; return token; &#125; /** * URL编码（utf-8） * * @param source * @return */ public static String urlEncodeUTF8(String source) &#123; String result = source; try &#123; result = java.net.URLEncoder.encode(source, &quot;utf-8&quot;); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; return result; &#125; /** * 根据内容类型判断文件扩展名 * * @param contentType * 内容类型 * @return */ public static String getFileExt(String contentType) &#123; String fileExt = &quot;&quot;; if (&quot;image/jpeg&quot;.equals(contentType)) fileExt = &quot;.jpg&quot;; else if (&quot;audio/mpeg&quot;.equals(contentType)) fileExt = &quot;.mp3&quot;; else if (&quot;audio/amr&quot;.equals(contentType)) fileExt = &quot;.amr&quot;; else if (&quot;video/mp4&quot;.equals(contentType)) fileExt = &quot;.mp4&quot;; else if (&quot;video/mpeg4&quot;.equals(contentType)) fileExt = &quot;.mp4&quot;; return fileExt; &#125; /** * 获取用户信息 * * @param accessToken 接口访问凭证 * @param openId 用户标识 * @return WeixinUserInfo */ public static WeixinUserInfo getUserInfo(String accessToken, String openId) &#123; WeixinUserInfo weixinUserInfo = null; // 拼接请求地址 String requestUrl = &quot;https://api.weixin.qq.com/cgi-bin/user/info?access_token=ACCESS_TOKEN&amp;openid=OPENID&quot;; requestUrl = requestUrl.replace(&quot;ACCESS_TOKEN&quot;, accessToken).replace(&quot;OPENID&quot;, openId); // 获取用户信息 JSONObject jsonObject = CommonUtil.httpsRequest(requestUrl, &quot;GET&quot;, null); if (null != jsonObject) &#123; try &#123; weixinUserInfo = new WeixinUserInfo(); // 用户的标识 weixinUserInfo.setOpenId(jsonObject.getString(&quot;openid&quot;)); // 关注状态（1是关注，0是未关注），未关注时获取不到其余信息 weixinUserInfo.setSubscribe(jsonObject.getInt(&quot;subscribe&quot;)); // 用户关注时间 weixinUserInfo.setSubscribeTime(jsonObject.getString(&quot;subscribe_time&quot;)); // 昵称 weixinUserInfo.setNickname(jsonObject.getString(&quot;nickname&quot;)); // 用户的性别（1是男性，2是女性，0是未知） weixinUserInfo.setSex(jsonObject.getInt(&quot;sex&quot;)); // 用户所在国家 weixinUserInfo.setCountry(jsonObject.getString(&quot;country&quot;)); // 用户所在省份 weixinUserInfo.setProvince(jsonObject.getString(&quot;province&quot;)); // 用户所在城市 weixinUserInfo.setCity(jsonObject.getString(&quot;city&quot;)); // 用户的语言，简体中文为zh_CN weixinUserInfo.setLanguage(jsonObject.getString(&quot;language&quot;)); // 用户头像 weixinUserInfo.setHeadImgUrl(jsonObject.getString(&quot;headimgurl&quot;)); &#125; catch (Exception e) &#123; if (0 == weixinUserInfo.getSubscribe()) &#123; log.error(&quot;用户&#123;&#125;已取消关注&quot;, weixinUserInfo.getOpenId()); &#125; else &#123; int errorCode = jsonObject.getInt(&quot;errcode&quot;); String errorMsg = jsonObject.getString(&quot;errmsg&quot;); log.error(&quot;获取用户信息失败 errcode:&#123;&#125; errmsg:&#123;&#125;&quot;, errorCode, errorMsg); &#125; &#125; &#125; return weixinUserInfo; &#125; &#125; 测试：替换为自己的appid和秘钥。 12345678910111213141516171819202122232425262728293031package com.wyj.wechart.test;import org.junit.Test;import com.wyj.wechart.pojo.WeixinUserInfo;import com.wyj.wechart.utils.CommonUtil;public class WeixinUserInfoTest &#123; @Test public void testWeixinUserInfo() &#123; // 获取接口访问凭证(替换为自己的appid和秘钥。) String accessToken = CommonUtil.getToken(&quot;xxxx&quot;, &quot;xxxx&quot;).getAccessToken(); /** * 获取用户信息 */ WeixinUserInfo user = CommonUtil.getUserInfo(accessToken, &quot;OpenID&quot;); System.out.println(&quot;OpenID：&quot; + user.getOpenId()); System.out.println(&quot;关注状态：&quot; + user.getSubscribe()); System.out.println(&quot;关注时间：&quot; + user.getSubscribeTime()); System.out.println(&quot;昵称：&quot; + user.getNickname()); System.out.println(&quot;性别：&quot; + user.getSex()); System.out.println(&quot;国家：&quot; + user.getCountry()); System.out.println(&quot;省份：&quot; + user.getProvince()); System.out.println(&quot;城市：&quot; + user.getCity()); System.out.println(&quot;语言：&quot; + user.getLanguage()); System.out.println(&quot;头像：&quot; + user.getHeadImgUrl()); &#125;&#125; 效果如下： 注：github项目地址：微信公共号开发用例","tags":[{"name":"微信公共号","slug":"微信公共号","permalink":"http://wangyuanjun.cn/tags/微信公共号/"}]},{"title":"微信公共号开发教程java版——实现自定义菜单(六)","date":"2018-01-26T09:22:56.000Z","path":"2018/01/26/微信公共号开发教程java版——实现自定义菜单-六/","text":"一：自定义菜单文档说明自定义菜单能够帮助公众号丰富界面，让用户更好更快地理解公众号的功能。开启自定义菜单后，公众号界面如图所示：官网详细介绍:https://mp.weixin.qq.com/wiki?t=resource/res_main&amp;id=mp1421141013请注意： 1231、自定义菜单最多包括3个一级菜单，每个一级菜单最多包含5个二级菜单。2、一级菜单最多4个汉字，二级菜单最多7个汉字，多出来的部分将会以“...”代替。3、创建自定义菜单后，菜单的刷新策略是，在用户进入公众号会话页或公众号profile页时，如果发现上一次拉取菜单的请求在5分钟以前，就会拉取一下菜单，如果菜单有更新，就会刷新客户端的菜单。测试时可以尝试取消关注公众账号后再次关注，则可以看到创建后的效果。 自定义菜单接口可实现多种类型按钮，如下： 123456789101、click：点击推事件用户点击click类型按钮后，微信服务器会通过消息接口推送消息类型为event的结构给开发者（参考消息接口指南），并且带上按钮中开发者填写的key值，开发者可以通过自定义的key值与用户进行交互；2、view：跳转URL用户点击view类型按钮后，微信客户端将会打开开发者在按钮中填写的网页URL，可与网页授权获取用户基本信息接口结合，获得用户基本信息。3、scancode_push：扫码推事件用户点击按钮后，微信客户端将调起扫一扫工具，完成扫码操作后显示扫描结果（如果是URL，将进入URL），且会将扫码的结果传给开发者，开发者可以下发消息。4、scancode_waitmsg：扫码推事件且弹出“消息接收中”提示框用户点击按钮后，微信客户端将调起扫一扫工具，完成扫码操作后，将扫码的结果传给开发者，同时收起扫一扫工具，然后弹出“消息接收中”提示框，随后可能会收到开发者下发的消息。5、pic_sysphoto：弹出系统拍照发图用户点击按钮后，微信客户端将调起系统相机，完成拍照操作后，会将拍摄的相片发送给开发者，并推送事件给开发者，同时收起系统相机，随后可能会收到开发者下发的消息。6、pic_photo_or_album：弹出拍照或者相册发图用户点击按钮后，微信客户端将弹出选择器供用户选择“拍照”或者“从手机相册选择”。用户选择后即走其他两种流程。7、pic_weixin：弹出微信相册发图器用户点击按钮后，微信客户端将调起微信相册，完成选择操作后，将选择的相片发送给开发者的服务器，并推送事件给开发者，同时收起相册，随后可能会收到开发者下发的消息。8、location_select：弹出地理位置选择器用户点击按钮后，微信客户端将调起地理位置选择工具，完成选择操作后，将选择的地理位置发送给开发者的服务器，同时收起位置选择工具，随后可能会收到开发者下发的消息。9、media_id：下发消息（除文本消息）用户点击media_id类型按钮后，微信服务器会将开发者填写的永久素材id对应的素材下发给用户，永久素材类型可以是图片、音频、视频、图文消息。请注意：永久素材id必须是在“素材管理/新增永久素材”接口上传后获得的合法id。10、view_limited：跳转图文消息URL用户点击view_limited类型按钮后，微信客户端将打开开发者在按钮中填写的永久素材id对应的图文消息URL，永久素材类型只支持图文消息。请注意：永久素材id必须是在“素材管理/新增永久素材”接口上传后获得的合法id。 请注意，3到8的所有事件，仅支持微信iPhone5.4.1以上版本，和Android5.4以上版本的微信用户，旧版本微信用户点击后将没有回应，开发者也不能正常接收到事件推送。9和10，是专门给第三方平台旗下未微信认证（具体而言，是资质认证未通过）的订阅号准备的事件类型，它们是没有事件推送的，能力相对受限，其他类型的公众号不必使用。 接口调用请求说明1http请求方式：POST（请使用https协议） https://api.weixin.qq.com/cgi-bin/menu/create?access_token=ACCESS_TOKEN click和view的请求示例1234567891011121314151617181920212223242526272829&#123; &quot;button&quot;:[ &#123; &quot;type&quot;:&quot;click&quot;, &quot;name&quot;:&quot;今日歌曲&quot;, &quot;key&quot;:&quot;V1001_TODAY_MUSIC&quot; &#125;, &#123; &quot;name&quot;:&quot;菜单&quot;, &quot;sub_button&quot;:[ &#123; &quot;type&quot;:&quot;view&quot;, &quot;name&quot;:&quot;搜索&quot;, &quot;url&quot;:&quot;http://www.soso.com/&quot; &#125;, &#123; &quot;type&quot;:&quot;miniprogram&quot;, &quot;name&quot;:&quot;wxa&quot;, &quot;url&quot;:&quot;http://mp.weixin.qq.com&quot;, &quot;appid&quot;:&quot;wx286b93c14bbf93aa&quot;, &quot;pagepath&quot;:&quot;pages/lunar/index&quot; &#125;, &#123; &quot;type&quot;:&quot;click&quot;, &quot;name&quot;:&quot;赞一下我们&quot;, &quot;key&quot;:&quot;V1001_GOOD&quot; &#125;] &#125;]&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&#123; &quot;button&quot;: [ &#123; &quot;name&quot;: &quot;扫码&quot;, &quot;sub_button&quot;: [ &#123; &quot;type&quot;: &quot;scancode_waitmsg&quot;, &quot;name&quot;: &quot;扫码带提示&quot;, &quot;key&quot;: &quot;rselfmenu_0_0&quot;, &quot;sub_button&quot;: [ ] &#125;, &#123; &quot;type&quot;: &quot;scancode_push&quot;, &quot;name&quot;: &quot;扫码推事件&quot;, &quot;key&quot;: &quot;rselfmenu_0_1&quot;, &quot;sub_button&quot;: [ ] &#125; ] &#125;, &#123; &quot;name&quot;: &quot;发图&quot;, &quot;sub_button&quot;: [ &#123; &quot;type&quot;: &quot;pic_sysphoto&quot;, &quot;name&quot;: &quot;系统拍照发图&quot;, &quot;key&quot;: &quot;rselfmenu_1_0&quot;, &quot;sub_button&quot;: [ ] &#125;, &#123; &quot;type&quot;: &quot;pic_photo_or_album&quot;, &quot;name&quot;: &quot;拍照或者相册发图&quot;, &quot;key&quot;: &quot;rselfmenu_1_1&quot;, &quot;sub_button&quot;: [ ] &#125;, &#123; &quot;type&quot;: &quot;pic_weixin&quot;, &quot;name&quot;: &quot;微信相册发图&quot;, &quot;key&quot;: &quot;rselfmenu_1_2&quot;, &quot;sub_button&quot;: [ ] &#125; ] &#125;, &#123; &quot;name&quot;: &quot;发送位置&quot;, &quot;type&quot;: &quot;location_select&quot;, &quot;key&quot;: &quot;rselfmenu_2_0&quot; &#125;, &#123; &quot;type&quot;: &quot;media_id&quot;, &quot;name&quot;: &quot;图片&quot;, &quot;media_id&quot;: &quot;MEDIA_ID1&quot; &#125;, &#123; &quot;type&quot;: &quot;view_limited&quot;, &quot;name&quot;: &quot;图文消息&quot;, &quot;media_id&quot;: &quot;MEDIA_ID2&quot; &#125; ]&#125; 参数说明 参数 是否必须 说明 button 是 一级菜单数组，个数应为1~3个 sub_button 否 二级菜单数组，个数应为1~5个 type 是 菜单的响应动作类型，view表示网页类型，click表示点击类型，miniprogram表示小程序类型 name 是 菜单标题，不超过16个字节，子菜单不超过60个字节 key click等点击类型必须 菜单KEY值，用于消息接口推送，不超过128字节 url view、miniprogram类型必须 网页 链接，用户点击菜单可打开链接，不超过1024字节。 type为miniprogram时，不支持小程序的老版本客户端将打开本url media_id media_id类型和view_limited类型必须 调用新增永久素材接口返回的合法media_id appid miniprogram类型必须 小程序的appid（仅认证公众号可配置） pagepath miniprogram类型必须 小程序的页面路径 返回结果 正确时的返回JSON数据包如下： 1&#123;&quot;errcode&quot;:0,&quot;errmsg&quot;:&quot;ok&quot;&#125; 错误时的返回JSON数据包如下（示例为无效菜单名长度）： 1&#123;&quot;errcode&quot;:40018,&quot;errmsg&quot;:&quot;invalid button name size&quot;&#125; 使用网页调试工具调试该接口：网页调试工具 二：菜单的封装接下来是对菜单结构的封装。因为我们是采用面向对象的编程方式，最终提交的json格式菜单数据就应该是由对象直接转换得到，而不是在程序代码中拼一大堆json数据。菜单结构封装的依据是公众平台API文档中给出的那一段json格式的菜单结构，如下所示： 1.菜单项的基类首先是 菜单项的基类，所有一级菜单、二级菜单都共有一个相同的属性，那就是name。菜单项基类的封装代码如下： 12345678910111213141516171819202122package com.wyj.wechart.menu;/** * 菜单项的基类 * * * @author：WangYuanJun * @date：2018年1月23日 下午3:52:28 */public class Button &#123; private String name;// 所有一级菜单、二级菜单都共有一个相同的属性，那就是name public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 2.子菜单项的封装接着是子菜单项的封装。这里对子菜单是这样定义的：没有子菜单的菜单项，有可能是二级菜单项，也有可能是不含二级菜单的一级菜单。这类子菜单项一定会包含三个属性：type、name和key，封装的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.wyj.wechart.menu;/** * 子菜单项 :没有子菜单的菜单项，有可能是二级菜单项，也有可能是不含二级菜单的一级菜单。 * * * @author：WangYuanJun * @date：2018年1月23日 下午3:54:53 */public class CommonButton extends Button &#123; // 菜单的响应动作类型，view表示网页类型，click表示点击类型，miniprogram表示小程序类型 private String type; // 菜单KEY值，用于消息接口推送，不超过128字节 private String key; private String url; public String getType() &#123; return type; &#125; public void setType(String type) &#123; this.type = type; &#125; public String getKey() &#123; return key; &#125; public void setKey(String key) &#123; this.key = key; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; this.url = url; &#125;&#125; 3.父菜单项的封装 再往下是父菜单项的封装。对父菜单项的定义：包含有二级菜单项的一级菜单。这类菜单项包含有二个属性：name和sub_button，而sub_button以是一个子菜单项数组。父菜单项的封装代码如下： 1234567891011121314151617181920package com.wyj.wechart.menu;/** * 父菜单项 :包含有二级菜单项的一级菜单。这类菜单项包含有二个属性：name和sub_button，而sub_button以是一个子菜单项数组 * * * @author：WangYuanJun * @date：2018年1月23日 下午3:59:04 */public class ComplexButton extends Button &#123; private Button[] sub_button; public Button[] getSub_button() &#123; return sub_button; &#125; public void setSub_button(Button[] sub_button) &#123; this.sub_button = sub_button; &#125;&#125; 4.菜单对象的封装最后是整个菜单对象的封装，菜单对象包含多个菜单项（最多只能有3个），这些菜单项即可以是子菜单项（不含二级菜单的一级菜单），也可以是父菜单项（包含二级菜单的菜单项），如果能明白上面所讲的，再来看封装后的代码就很容易理解了： 123456789101112131415161718192021package com.wyj.wechart.menu;/** * 整个菜单对象的封装 * * * @author：WangYuanJun * @date：2018年1月23日 下午3:59:46 */public class Menu &#123; private Button[] button; public Button[] getButton() &#123; return button; &#125; public void setButton(Button[] button) &#123; this.button = button; &#125;&#125; 关于菜单的POJO类的封装就介绍完了。 5.接口凭证的封装AccessToken 的POJO的封装 123456789101112131415161718192021222324252627282930313233package com.wyj.wechart.pojo;/** * 微信通用接口凭证 * * * @author：WangYuanJun * @date：2018年1月23日 下午4:01:12 */public class AccessToken &#123; // 获取到的凭证 private String token; // 凭证有效时间，单位：秒 private int expiresIn; public String getToken() &#123; return token; &#125; public void setToken(String token) &#123; this.token = token; &#125; public int getExpiresIn() &#123; return expiresIn; &#125; public void setExpiresIn(int expiresIn) &#123; this.expiresIn = expiresIn; &#125;&#125; 封装通用的请求方法 读到这里，就默认大家已经掌握了上面讲到的所有关于自定义菜单的理论知识，下面就进入代码实战讲解的部分。 先前我们了解到，创建菜单需要调用二个接口，并且都是https请求，而非http。如果要封装一个通用的请求方法，该方法至少需要具备以下能力： 1）支持HTTPS请求； 2）支持GET、POST两种方式； 3）支持参数提交，也支持无参数的情况； 6.创建证书信任管理器对于https请求，我们需要一个证书信任管理器，这个管理器类需要自己定义，但需要实现X509TrustManager接口，代码如下 1234567891011121314151617181920212223242526272829package com.wyj.wechart.utils;import java.security.cert.CertificateException;import java.security.cert.X509Certificate;import javax.net.ssl.X509TrustManager;/** * 证书信任管理器（用于https请求） * 这个证书管理器的作用就是让它信任我们指定的证书，下面的代码意味着信任所有证书，不管是否权威机构颁发。 * * @author：WangYuanJun * @date：2018年1月23日 下午3:22:19 */public class MyX509TrustManager implements X509TrustManager &#123; // 检查客户端证书 public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; // 检查服务器端证书 public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; // 返回受信任的X509证书数组 public X509Certificate[] getAcceptedIssuers() &#123; return null; &#125;&#125; 这个证书管理器的作用就是让它信任我们指定的证书，上面的代码意味着信任所有证书，不管是否权威机构颁发。 7.https请求方法实现证书有了，通用的https请求方法就不难实现了，实现代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164package com.wyj.wechart.utils;import java.io.BufferedReader;import java.io.InputStream;import java.io.InputStreamReader;import java.io.OutputStream;import java.net.ConnectException;import java.net.URL;import javax.net.ssl.HttpsURLConnection;import javax.net.ssl.SSLContext;import javax.net.ssl.SSLSocketFactory;import javax.net.ssl.TrustManager;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import com.wyj.wechart.menu.Menu;import com.wyj.wechart.pojo.AccessToken;import net.sf.json.JSONException;import net.sf.json.JSONObject;/** * 公众平台通用接口工具类 * * * @author：WangYuanJun * @date：2018年1月23日 下午4:06:13 */public class WeixinUtil &#123; private static Logger log = LoggerFactory.getLogger(WeixinUtil.class); // 获取access_token的接口地址（GET） 限200（次/天） public final static String access_token_url = &quot;https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&amp;appid=APPID&amp;secret=APPSECRET&quot;; // 菜单创建（POST） 限100（次/天） public static String menu_create_url = &quot;https://api.weixin.qq.com/cgi-bin/menu/create?access_token=ACCESS_TOKEN&quot;; /** * 创建菜单 * * @param menu * 菜单实例 * @param accessToken * 有效的access_token * @return 0表示成功，其他值表示失败 */ public static int createMenu(Menu menu, String accessToken) &#123; int result = 0; // 拼装创建菜单的url String url = menu_create_url.replace(&quot;ACCESS_TOKEN&quot;, accessToken); // 将菜单对象转换成json字符串 String jsonMenu = JSONObject.fromObject(menu).toString(); // 调用接口创建菜单 JSONObject jsonObject = httpRequest(url, &quot;POST&quot;, jsonMenu); if (null != jsonObject) &#123; if (0 != jsonObject.getInt(&quot;errcode&quot;)) &#123; result = jsonObject.getInt(&quot;errcode&quot;); log.error(&quot;创建菜单失败 errcode:&#123;&#125; errmsg:&#123;&#125;&quot;, jsonObject.getInt(&quot;errcode&quot;), jsonObject.getString(&quot;errmsg&quot;)); &#125; &#125; return result; &#125; /** * 获取access_token * * @param appid * 凭证 * @param appsecret * 密钥 * @return */ public static AccessToken getAccessToken(String appid, String appsecret) &#123; AccessToken accessToken = null; String requestUrl = access_token_url.replace(&quot;APPID&quot;, appid).replace(&quot;APPSECRET&quot;, appsecret); JSONObject jsonObject = httpRequest(requestUrl, &quot;GET&quot;, null); // 如果请求成功 if (null != jsonObject) &#123; try &#123; accessToken = new AccessToken(); accessToken.setToken(jsonObject.getString(&quot;access_token&quot;)); accessToken.setExpiresIn(jsonObject.getInt(&quot;expires_in&quot;)); &#125; catch (JSONException e) &#123; accessToken = null; // 获取token失败 log.error(&quot;获取token失败 errcode:&#123;&#125; errmsg:&#123;&#125;&quot;, jsonObject.getInt(&quot;errcode&quot;), jsonObject.getString(&quot;errmsg&quot;)); &#125; &#125; return accessToken; &#125; /** * 描述: 发起https请求并获取结果 * * @param requestUrl * 请求地址 * @param requestMethod * 请求方式（GET、POST） * @param outputStr * 提交的数据 * @return JSONObject(通过JSONObject.get(key)的方式获取json对象的属性值) */ public static JSONObject httpRequest(String requestUrl, String requestMethod, String outputStr) &#123; JSONObject jsonObject = null; StringBuffer buffer = new StringBuffer(); try &#123; // 创建SSLContext对象，并使用我们指定的信任管理器初始化 TrustManager[] tm = &#123; new MyX509TrustManager() &#125;; SSLContext sslContext = SSLContext.getInstance(&quot;SSL&quot;, &quot;SunJSSE&quot;); sslContext.init(null, tm, new java.security.SecureRandom()); // 从上述SSLContext对象中得到SSLSocketFactory对象 SSLSocketFactory ssf = sslContext.getSocketFactory(); URL url = new URL(requestUrl); HttpsURLConnection httpUrlConn = (HttpsURLConnection) url.openConnection(); httpUrlConn.setSSLSocketFactory(ssf); httpUrlConn.setDoOutput(true); httpUrlConn.setDoInput(true); httpUrlConn.setUseCaches(false); // 设置请求方式（GET/POST） httpUrlConn.setRequestMethod(requestMethod); if (&quot;GET&quot;.equalsIgnoreCase(requestMethod)) httpUrlConn.connect(); // 当有数据需要提交时 if (null != outputStr) &#123; OutputStream outputStream = httpUrlConn.getOutputStream(); // 注意编码格式，防止中文乱码 outputStream.write(outputStr.getBytes(&quot;UTF-8&quot;)); outputStream.close(); &#125; // 将返回的输入流转换成字符串 InputStream inputStream = httpUrlConn.getInputStream(); InputStreamReader inputStreamReader = new InputStreamReader(inputStream, &quot;utf-8&quot;); BufferedReader bufferedReader = new BufferedReader(inputStreamReader); String str = null; while ((str = bufferedReader.readLine()) != null) &#123; buffer.append(str); &#125; bufferedReader.close(); inputStreamReader.close(); // 释放资源 inputStream.close(); inputStream = null; httpUrlConn.disconnect(); jsonObject = JSONObject.fromObject(buffer.toString()); &#125; catch (ConnectException ce) &#123; log.error(&quot;Weixin server connection timed out.&quot;); &#125; catch (Exception e) &#123; log.error(&quot;https request error:&#123;&#125;&quot;, e); &#125; return jsonObject; &#125;&#125; 8.添加菜单管理器：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139package com.wyj.wechart.main;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import com.wyj.wechart.menu.Button;import com.wyj.wechart.menu.CommonButton;import com.wyj.wechart.menu.ComplexButton;import com.wyj.wechart.menu.Menu;import com.wyj.wechart.pojo.AccessToken;import com.wyj.wechart.utils.WeixinUtil;/** * 菜单管理器类 * * * @author：WangYuanJun * @date：2018年1月23日 下午4:12:08 */public class MenuManager &#123; private static Logger log = LoggerFactory.getLogger(MenuManager.class); public static void main(String[] args) &#123; // 第三方用户唯一凭证 String appId = &quot;wx17fdedc3d6d0b68e&quot;; // 第三方用户唯一凭证密钥 String appSecret = &quot;c3b3d919d65a781ba7db58d9d8dfb515&quot;; // 调用接口获取access_token AccessToken at = WeixinUtil.getAccessToken(appId, appSecret); if (null != at) &#123; // 调用接口创建菜单 int result = WeixinUtil.createMenu(getMenu(), at.getToken()); // 判断菜单创建结果 if (0 == result) log.info(&quot;菜单创建成功！&quot;); else log.info(&quot;菜单创建失败，错误码：&quot; + result); &#125; &#125; /** * 组装菜单数据 * * @return */ private static Menu getMenu() &#123; CommonButton btn11 = new CommonButton(); btn11.setName(&quot;天气预报&quot;); btn11.setType(&quot;view&quot;); btn11.setKey(&quot;11&quot;); btn11.setUrl(&quot;http://www.weather.com.cn/weather/101190101.shtml&quot;); CommonButton btn12 = new CommonButton(); btn12.setName(&quot;公交查询&quot;); btn12.setType(&quot;view&quot;); btn12.setKey(&quot;12&quot;); btn12.setUrl(&quot;http://www.gongjiao.com/&quot;); CommonButton btn13 = new CommonButton(); btn13.setName(&quot;百度地图&quot;); btn13.setType(&quot;view&quot;); btn13.setKey(&quot;13&quot;); btn13.setUrl(&quot;https://map.baidu.com/&quot;); CommonButton btn14 = new CommonButton(); btn14.setName(&quot;滴滴出行&quot;); btn14.setType(&quot;click&quot;); btn14.setKey(&quot;14&quot;); CommonButton btn21 = new CommonButton(); btn21.setName(&quot;csdn&quot;); btn21.setType(&quot;click&quot;); btn21.setKey(&quot;21&quot;); CommonButton btn22 = new CommonButton(); btn22.setName(&quot;博客园&quot;); btn22.setType(&quot;click&quot;); btn22.setKey(&quot;22&quot;); CommonButton btn23 = new CommonButton(); btn23.setName(&quot;开发头条&quot;); btn23.setType(&quot;click&quot;); btn23.setKey(&quot;23&quot;); CommonButton btn24 = new CommonButton(); btn24.setName(&quot;云栖社区&quot;); btn24.setType(&quot;click&quot;); btn24.setKey(&quot;24&quot;); CommonButton btn25 = new CommonButton(); btn25.setName(&quot;github&quot;); btn25.setType(&quot;click&quot;); btn25.setKey(&quot;25&quot;); CommonButton btn31 = new CommonButton(); btn31.setName(&quot;淘宝网&quot;); btn31.setType(&quot;click&quot;); btn31.setKey(&quot;31&quot;); CommonButton btn32 = new CommonButton(); btn32.setName(&quot;电影天堂&quot;); btn32.setType(&quot;click&quot;); btn32.setKey(&quot;32&quot;); CommonButton btn33 = new CommonButton(); btn33.setName(&quot;小游戏&quot;); btn33.setType(&quot;click&quot;); btn33.setKey(&quot;33&quot;); /** * 微信： mainBtn1,mainBtn2,mainBtn3底部的三个一级菜单。 */ ComplexButton mainBtn1 = new ComplexButton(); mainBtn1.setName(&quot;生活便利&quot;); //一级下有4个子菜单 mainBtn1.setSub_button(new CommonButton[] &#123; btn11, btn12, btn13, btn14 &#125;); ComplexButton mainBtn2 = new ComplexButton(); mainBtn2.setName(&quot;学习社区&quot;); mainBtn2.setSub_button(new CommonButton[] &#123; btn21, btn22, btn23, btn24, btn25 &#125;); ComplexButton mainBtn3 = new ComplexButton(); mainBtn3.setName(&quot;娱乐一下&quot;); mainBtn3.setSub_button(new CommonButton[] &#123; btn31, btn32, btn33 &#125;); /** * 封装整个菜单 */ Menu menu = new Menu(); menu.setButton(new Button[] &#123; mainBtn1, mainBtn2, mainBtn3 &#125;); return menu; &#125;&#125; 注意替换称自己的appId和appSecret。 直接执行MenuManager 的main 方法即可。 效果如下： 注：github项目地址：微信公共号开发用例","tags":[{"name":"微信公共号","slug":"微信公共号","permalink":"http://wangyuanjun.cn/tags/微信公共号/"}]},{"title":"微信公共号开发教程java版——公共号access_token的获取(五)","date":"2018-01-26T08:13:15.000Z","path":"2018/01/26/微信公共号开发教程java版——公共号access-token的获取-五/","text":"一：access_token简介为了使第三方开发者能够为用户提供更多更有价值的个性化服务，微信公众平台 开放了许多接口，包括自定义菜单接口、客服接口、获取用户信息接口、用户分组接口、群发接口等， access_token是公众号的全局唯一接口调用凭据，公众号调用各接口时都需使用access_token。开发者需要进行妥善保存。access_token的存储至少要保留512个字符空间。access_token的有效期目前为2个小时，需定时刷新，重复获取将导致上次获取的access_token失效。 公众平台的API调用所需的access_token的使用及生成方式说明： 1、建议公众号开发者使用中控服务器统一获取和刷新Access_token，其他业务逻辑服务器所使用的access_token均来自于该中控服务器，不应该各自去刷新，否则容易造成冲突，导致access_token覆盖而影响业务； 2、目前Access_token的有效期通过返回的expire_in来传达，目前是7200秒之内的值。中控服务器需要根据这个有效时间提前去刷新新access_token。在刷新过程中，中控服务器可对外继续输出的老access_token，此时公众平台后台会保证在5分钟内，新老access_token都可用，这保证了第三方业务的平滑过渡； 3、Access_token的有效时间可能会在未来有调整，所以中控服务器不仅需要内部定时主动刷新，还需要提供被动刷新access_token的接口，这样便于业务服务器在API调用获知access_token已超时的情况下，可以触发access_token的刷新流程。 公众号可以使用AppID和AppSecret调用本接口来获取access_token。AppID和AppSecret可在“微信公众平台-开发-基本配置”页中获得（需要已经成为开发者，且帐号没有异常状态）。调用接口时，请登录“微信公众平台-开发-基本配置”提前将服务器IP地址添加到IP白名单中，点击查看设置方法，否则将无法调用成功。 目前，获取access_token接口的调用频率限制为2000次/天，如果每次发送客服消息、获取用户信息、群发消息之前都要先调用获取 access_token接口得到接口访问凭证，这显然是不合理的，一方面会更耗时（多了一次接口调用操作），另一方面2000次/天的调用限制恐怕也不 够用。因此，在实际应用中，我们需要将获取到的access_token存储起来，然后定期调用access_token接口更新它，以保证随时取出的 access_token都是有效的。 官网详细介绍：https://mp.weixin.qq.com/wiki?t=resource/res_main&amp;id=mp1421140183 接口调用请求说明1https请求方式: GEThttps://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&amp;appid=APPID&amp;secret=APPSECRET 参数说明 参数 是否必须 说明 grant_type 是 获取access_token填写client_credential appid 是 第三方用户唯一凭证 secret 是 第三方用户唯一凭证密钥，即appsecret 返回说明正常情况下，微信会返回下述JSON数据包给公众号： 1&#123;&quot;access_token&quot;:&quot;ACCESS_TOKEN&quot;,&quot;expires_in&quot;:7200&#125; 参数说明 参数 说明 access_token 获取到的凭证 expires_in 凭证有效时间，单位：秒 错误时微信会返回错误码等信息，JSON数据包示例如下（该示例为AppID无效错误）: 1&#123;&quot;errcode&quot;:40013,&quot;errmsg&quot;:&quot;invalid appid&quot;&#125; 返回码说明 返回码 说明 -1 系统繁忙，此时请开发者稍候再试 0 请求成功 40001 AppSecret错误或者AppSecret不属于这个公众号，请开发者确认AppSecret的正确性 40002 请确保grant_type字段值为client_credential 40164 调用接口的IP地址不在白名单中，请在接口IP白名单中进行设置 二：封装基本类封装一下token类： 123456789101112131415161718192021222324252627282930313233package com.wyj.wechart.pojo;/** * * 凭证 * * @author：WangYuanJun * @date：2018年1月23日 下午3:19:14 */public class Token &#123; // 接口访问凭证 private String accessToken; // 凭证有效期，单位：秒 private int expiresIn; public String getAccessToken() &#123; return accessToken; &#125; public void setAccessToken(String accessToken) &#123; this.accessToken = accessToken; &#125; public int getExpiresIn() &#123; return expiresIn; &#125; public void setExpiresIn(int expiresIn) &#123; this.expiresIn = expiresIn; &#125;&#125; 三：获取token 使用网页调试工具调试该接口：网页调试工具 直接通过浏览器访问：https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&amp;appid=APPID&amp;secret=APPSECRET ，然后把APPID和APPSECRET替换成自己的appID和appsecret，在浏览器即可获得token。 编写程序，模拟https连接，获得token：对于https请求，我们需要一个证书信任管理器，这个管理器类需要自己定义，但需要实现X509TrustManager接口， 首先定义一个MyX509TrustManager 类。 1234567891011121314151617181920212223242526272829package com.wyj.wechart.utils;import java.security.cert.CertificateException;import java.security.cert.X509Certificate;import javax.net.ssl.X509TrustManager;/** * 证书信任管理器（用于https请求） * 这个证书管理器的作用就是让它信任我们指定的证书，下面的代码意味着信任所有证书，不管是否权威机构颁发。 * * @author：WangYuanJun * @date：2018年1月23日 下午3:22:19 */public class MyX509TrustManager implements X509TrustManager &#123; // 检查客户端证书 public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; // 检查服务器端证书 public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; // 返回受信任的X509证书数组 public X509Certificate[] getAcceptedIssuers() &#123; return null; &#125;&#125; 建立一个token测试类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.wyj.wechart.test;import java.io.BufferedReader;import java.io.InputStream;import java.io.InputStreamReader;import java.net.URL;import javax.net.ssl.HttpsURLConnection;import javax.net.ssl.SSLContext;import javax.net.ssl.SSLSocketFactory;import javax.net.ssl.TrustManager;import org.junit.Test;import com.wyj.wechart.pojo.Token;import com.wyj.wechart.utils.CommonUtil;import com.wyj.wechart.utils.MyX509TrustManager;public class TokenTest &#123; @Test public void testGetToken1() throws Exception &#123; String tokenUrl = &quot;https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&amp;appid=appID&amp;secret=appsecret&quot;; // 建立连接 URL url = new URL(tokenUrl); HttpsURLConnection httpUrlConn = (HttpsURLConnection) url.openConnection(); // 创建SSLContext对象，并使用我们指定的信任管理器初始化 TrustManager[] tm = &#123; new MyX509TrustManager() &#125;; SSLContext sslContext = SSLContext.getInstance(&quot;SSL&quot;, &quot;SunJSSE&quot;); sslContext.init(null, tm, new java.security.SecureRandom()); // 从上述SSLContext对象中得到SSLSocketFactory对象 SSLSocketFactory ssf = sslContext.getSocketFactory(); httpUrlConn.setSSLSocketFactory(ssf); httpUrlConn.setDoOutput(true); httpUrlConn.setDoInput(true); // 设置请求方式（GET/POST） httpUrlConn.setRequestMethod(&quot;GET&quot;); // 取得输入流 InputStream inputStream = httpUrlConn.getInputStream(); InputStreamReader inputStreamReader = new InputStreamReader( inputStream, &quot;utf-8&quot;); BufferedReader bufferedReader = new BufferedReader(inputStreamReader); // 读取响应内容 StringBuffer buffer = new StringBuffer(); String str = null; while ((str = bufferedReader.readLine()) != null) &#123; buffer.append(str); &#125; bufferedReader.close(); inputStreamReader.close(); // 释放资源 inputStream.close(); httpUrlConn.disconnect(); // 输出返回结果 System.out.println(buffer); &#125;&#125; 微信服务器返回的结果： 1&#123;&quot;access_token&quot;:&quot;E3kRcQTati3QBPz97ou7zG0NXFrZFbA5No_hs5FNUZ62ROT0jr0txWr-gG1w-t06kk0zBW0kFmJiicJAydFyHNZhIh2uqIw4B5t85huRLs4&quot;,&quot;expires_in&quot;:7200&#125; 代码优化：微信服务器返回的是json数据，如何从json里面解析出来的值 通过一款开源的json开发工具包json-lib，将他转换为java对象 123456&lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;classifier&gt;jdk15&lt;/classifier&gt;&lt;!--指定jdk版本 --&gt;&lt;/dependency&gt; 封装一个通用的工具类 CommonUtil ，用于专门获取token： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130package com.wyj.wechart.utils;import java.io.BufferedReader;import java.io.InputStream;import java.io.InputStreamReader;import java.io.OutputStream;import java.io.UnsupportedEncodingException;import java.net.ConnectException;import java.net.URL;import javax.net.ssl.HttpsURLConnection;import javax.net.ssl.SSLContext;import javax.net.ssl.SSLSocketFactory;import javax.net.ssl.TrustManager;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import com.wyj.wechart.pojo.Token;import com.wyj.wechart.pojo.WeixinUserInfo;import net.sf.json.JSONException;import net.sf.json.JSONObject;/** * 通用工具类 * * * @author：WangYuanJun * @date：2018年1月23日 下午3:36:50 */public class CommonUtil &#123; private static Logger log = LoggerFactory.getLogger(CommonUtil.class); // 凭证获取（GET） public final static String token_url = &quot;https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&amp;appid=APPID&amp;secret=APPSECRET&quot;; /** * 发送https请求 * * @param requestUrl * 请求地址 * @param requestMethod * 请求方式（GET、POST） * @param outputStr * 提交的数据 * @return JSONObject(通过JSONObject.get(key)的方式获取json对象的属性值) */ public static JSONObject httpsRequest(String requestUrl, String requestMethod, String outputStr) &#123; JSONObject jsonObject = null; try &#123; // 创建SSLContext对象，并使用我们指定的信任管理器初始化 TrustManager[] tm = &#123; new MyX509TrustManager() &#125;; SSLContext sslContext = SSLContext.getInstance(&quot;SSL&quot;, &quot;SunJSSE&quot;); sslContext.init(null, tm, new java.security.SecureRandom()); // 从上述SSLContext对象中得到SSLSocketFactory对象 SSLSocketFactory ssf = sslContext.getSocketFactory(); URL url = new URL(requestUrl); HttpsURLConnection conn = (HttpsURLConnection) url.openConnection(); conn.setSSLSocketFactory(ssf); conn.setDoOutput(true); conn.setDoInput(true); conn.setUseCaches(false); // 设置请求方式（GET/POST） conn.setRequestMethod(requestMethod); // 当outputStr不为null时向输出流写数据 if (null != outputStr) &#123; OutputStream outputStream = conn.getOutputStream(); // 注意编码格式 outputStream.write(outputStr.getBytes(&quot;UTF-8&quot;)); outputStream.close(); &#125; // 从输入流读取返回内容 InputStream inputStream = conn.getInputStream(); InputStreamReader inputStreamReader = new InputStreamReader(inputStream, &quot;utf-8&quot;); BufferedReader bufferedReader = new BufferedReader(inputStreamReader); String str = null; StringBuffer buffer = new StringBuffer(); while ((str = bufferedReader.readLine()) != null) &#123; buffer.append(str); &#125; // 释放资源 bufferedReader.close(); inputStreamReader.close(); inputStream.close(); inputStream = null; conn.disconnect(); jsonObject = JSONObject.fromObject(buffer.toString()); &#125; catch (ConnectException ce) &#123; log.error(&quot;连接超时：&#123;&#125;&quot;, ce); &#125; catch (Exception e) &#123; log.error(&quot;https请求异常：&#123;&#125;&quot;, e); &#125; return jsonObject; &#125; /** * 获取接口访问凭证 * * @param appid * 凭证 * @param appsecret * 密钥 * @return */ public static Token getToken(String appid, String appsecret) &#123; Token token = null; String requestUrl = token_url.replace(&quot;APPID&quot;, appid).replace(&quot;APPSECRET&quot;, appsecret); // 发起GET请求获取凭证 JSONObject jsonObject = httpsRequest(requestUrl, &quot;GET&quot;, null); if (null != jsonObject) &#123; try &#123; token = new Token(); token.setAccessToken(jsonObject.getString(&quot;access_token&quot;)); token.setExpiresIn(jsonObject.getInt(&quot;expires_in&quot;)); &#125; catch (JSONException e) &#123; token = null; // 获取token失败 log.error(&quot;获取token失败 errcode:&#123;&#125; errmsg:&#123;&#125;&quot;, jsonObject.getInt(&quot;errcode&quot;), jsonObject.getString(&quot;errmsg&quot;)); &#125; &#125; return token; &#125;&#125; 修改Token测试类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package com.wyj.wechart.test;import java.io.BufferedReader;import java.io.InputStream;import java.io.InputStreamReader;import java.net.URL;import javax.net.ssl.HttpsURLConnection;import javax.net.ssl.SSLContext;import javax.net.ssl.SSLSocketFactory;import javax.net.ssl.TrustManager;import org.junit.Test;import com.wyj.wechart.pojo.Token;import com.wyj.wechart.utils.CommonUtil;import com.wyj.wechart.utils.MyX509TrustManager;public class TokenTest &#123; @Test public void testGetToken1() throws Exception &#123; String tokenUrl = &quot;https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&amp;appid=appID&amp;secret=appsecret&quot;; // 建立连接 URL url = new URL(tokenUrl); HttpsURLConnection httpUrlConn = (HttpsURLConnection) url.openConnection(); // 创建SSLContext对象，并使用我们指定的信任管理器初始化 TrustManager[] tm = &#123; new MyX509TrustManager() &#125;; SSLContext sslContext = SSLContext.getInstance(&quot;SSL&quot;, &quot;SunJSSE&quot;); sslContext.init(null, tm, new java.security.SecureRandom()); // 从上述SSLContext对象中得到SSLSocketFactory对象 SSLSocketFactory ssf = sslContext.getSocketFactory(); httpUrlConn.setSSLSocketFactory(ssf); httpUrlConn.setDoOutput(true); httpUrlConn.setDoInput(true); // 设置请求方式（GET/POST） httpUrlConn.setRequestMethod(&quot;GET&quot;); // 取得输入流 InputStream inputStream = httpUrlConn.getInputStream(); InputStreamReader inputStreamReader = new InputStreamReader( inputStream, &quot;utf-8&quot;); BufferedReader bufferedReader = new BufferedReader(inputStreamReader); // 读取响应内容 StringBuffer buffer = new StringBuffer(); String str = null; while ((str = bufferedReader.readLine()) != null) &#123; buffer.append(str); &#125; bufferedReader.close(); inputStreamReader.close(); // 释放资源 inputStream.close(); httpUrlConn.disconnect(); // 输出返回结果 System.out.println(buffer); &#125; @Test public void testGetToken2() &#123; Token token = CommonUtil.getToken(&quot;appID&quot;,&quot;appsecret&quot;); System.out.println(&quot;access_token:&quot;+token.getAccessToken()); System.out.println(&quot;expires_in:&quot;+token.getExpiresIn()); &#125;&#125; 控制台输出效果如下，说明我们获取到了access_token和expires_in： 12access_token:2amR6pr1eN-BuSBgho-nzo5tofxJ6BdEnRJQ87Zs5bj4ny4CGB8w-1D3YtjG2PzmEvVm1INrsVg-5BjyHCkWmBKsLPDSF3r_bdaPxMpKtbwexpires_in:7200 注：github项目地址：微信公共号开发用例","tags":[{"name":"微信公共号","slug":"微信公共号","permalink":"http://wangyuanjun.cn/tags/微信公共号/"}]},{"title":"微信公共号开发教程java版——发送消息和处理消息(四)","date":"2018-01-26T06:13:13.000Z","path":"2018/01/26/微信公共号开发教程java版——发送消息和处理消息-四/","text":"消息的发送和处理是在doPost方法中完成的 一：微信公众平台的通讯过程当微信用户向你的公众平台发送一条消息，实际上这条消息首先发送到微信服务器，由微信服务器向网站服务器发起另外一个请求，网站服务器返回这个请求的结果，再由微信服务器发送到微信客户端。 整个消息通讯流程如下图： 上述5个步骤中，作为开发者我们主要精力都集中在步骤3上，这个步骤主实际上要有3项任务： 接收来自2的XML信息服务器内部逻辑执行组织并返回用于4的XML信息 上述三项任务我会在后面做详细说明，并提供一整套简单、高效的处理方法。 二：解析微信服务器传来的消息因为微信服务器发送过来的是xml格式的消息，所以我们可以采用 开源框架dom4j去解析xml 。 12345&lt;dependency&gt; &lt;groupId&gt;dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt;&lt;/dependency&gt; 三：将响应消息转换成xml返回给微信服务器如何将响应消息转换成xml返回的问题，这里我们将 采用开源框架xstream来实现Java类到xml的转换 123456&lt;!-- 采用开源框架xstream来实现Java类到xml的转换 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.thoughtworks.xstream&lt;/groupId&gt; &lt;artifactId&gt;xstream&lt;/artifactId&gt; &lt;version&gt;1.4.10&lt;/version&gt;&lt;/dependency&gt; 1.封装消息处理工具：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226package com.wyj.wechart.utils;import java.io.InputStream;import java.io.Writer;import java.util.HashMap;import java.util.List;import java.util.Map;import javax.servlet.http.HttpServletRequest;import org.dom4j.Document;import org.dom4j.Element;import org.dom4j.io.SAXReader;import com.thoughtworks.xstream.XStream;import com.thoughtworks.xstream.core.util.QuickWriter;import com.thoughtworks.xstream.io.HierarchicalStreamWriter;import com.thoughtworks.xstream.io.xml.PrettyPrintWriter;import com.thoughtworks.xstream.io.xml.XppDriver;import com.wyj.wechart.message.resp.Article;import com.wyj.wechart.message.resp.ImageMessage;import com.wyj.wechart.message.resp.MusicMessage;import com.wyj.wechart.message.resp.NewsMessage;import com.wyj.wechart.message.resp.TextMessage;import com.wyj.wechart.message.resp.VideoMessage;import com.wyj.wechart.message.resp.VoiceMessage;/** * 消息处理工具类 * * * @author：WangYuanJun * @date：2018年1月23日 下午2:09:54 */public class MessageUtil &#123; // 请求消息类型：文本 public static final String REQ_MESSAGE_TYPE_TEXT = &quot;text&quot;; // 请求消息类型：图片 public static final String REQ_MESSAGE_TYPE_IMAGE = &quot;image&quot;; // 请求消息类型：语音 public static final String REQ_MESSAGE_TYPE_VOICE = &quot;voice&quot;; // 请求消息类型：视频 public static final String REQ_MESSAGE_TYPE_VIDEO = &quot;video&quot;; // 请求消息类型：小视频 public static final String REQ_MESSAGE_TYPE_SHORTVIDEO = &quot;shortvideo&quot;; // 请求消息类型：地理位置 public static final String REQ_MESSAGE_TYPE_LOCATION = &quot;location&quot;; // 请求消息类型：链接 public static final String REQ_MESSAGE_TYPE_LINK = &quot;link&quot;; // 请求消息类型：事件推送 public static final String REQ_MESSAGE_TYPE_EVENT = &quot;event&quot;; // 事件类型：subscribe(订阅) public static final String EVENT_TYPE_SUBSCRIBE = &quot;subscribe&quot;; // 事件类型：unsubscribe(取消订阅) public static final String EVENT_TYPE_UNSUBSCRIBE = &quot;unsubscribe&quot;; // 事件类型：scan(用户已关注时的扫描带参数二维码) public static final String EVENT_TYPE_SCAN = &quot;scan&quot;; // 事件类型：LOCATION(上报地理位置) public static final String EVENT_TYPE_LOCATION = &quot;LOCATION&quot;; // 事件类型：CLICK(自定义菜单) public static final String EVENT_TYPE_CLICK = &quot;CLICK&quot;; // 响应消息类型：文本 public static final String RESP_MESSAGE_TYPE_TEXT = &quot;text&quot;; // 响应消息类型：图片 public static final String RESP_MESSAGE_TYPE_IMAGE = &quot;image&quot;; // 响应消息类型：语音 public static final String RESP_MESSAGE_TYPE_VOICE = &quot;voice&quot;; // 响应消息类型：视频 public static final String RESP_MESSAGE_TYPE_VIDEO = &quot;video&quot;; // 响应消息类型：音乐 public static final String RESP_MESSAGE_TYPE_MUSIC = &quot;music&quot;; // 响应消息类型：图文 public static final String RESP_MESSAGE_TYPE_NEWS = &quot;news&quot;; /** * 解析微信发来的请求（XML） * * @param request * @return Map&lt;String, String&gt; * @throws Exception */ @SuppressWarnings(&quot;unchecked&quot;) public static Map&lt;String, String&gt; parseXml(HttpServletRequest request) throws Exception &#123; // 将解析结果存储在HashMap中 Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); // 从request中取得输入流 InputStream inputStream = request.getInputStream(); // 读取输入流 SAXReader reader = new SAXReader(); Document document = reader.read(inputStream); // 得到xml根元素 Element root = document.getRootElement(); // 得到根元素的所有子节点 List&lt;Element&gt; elementList = root.elements(); // 遍历所有子节点 for (Element e : elementList) map.put(e.getName(), e.getText()); // 释放资源 inputStream.close(); inputStream = null; return map; &#125; /** * 扩展xstream使其支持CDATA */ private static XStream xstream = new XStream(new XppDriver() &#123; public HierarchicalStreamWriter createWriter(Writer out) &#123; return new PrettyPrintWriter(out) &#123; // 对所有xml节点的转换都增加CDATA标记 boolean cdata = true; @SuppressWarnings(&quot;unchecked&quot;) public void startNode(String name, Class clazz) &#123; super.startNode(name, clazz); &#125; protected void writeText(QuickWriter writer, String text) &#123; if (cdata) &#123; writer.write(&quot;&lt;![CDATA[&quot;); writer.write(text); writer.write(&quot;]]&gt;&quot;); &#125; else &#123; writer.write(text); &#125; &#125; &#125;; &#125; &#125;); /** * 文本消息对象转换成xml * * @param textMessage * 文本消息对象 * @return xml */ public static String messageToXml(TextMessage textMessage) &#123; xstream.alias(&quot;xml&quot;, textMessage.getClass()); return xstream.toXML(textMessage); &#125; /** * 图片消息对象转换成xml * * @param imageMessage * 图片消息对象 * @return xml */ public static String messageToXml(ImageMessage imageMessage) &#123; xstream.alias(&quot;xml&quot;, imageMessage.getClass()); return xstream.toXML(imageMessage); &#125; /** * 语音消息对象转换成xml * * @param voiceMessage * 语音消息对象 * @return xml */ public static String messageToXml(VoiceMessage voiceMessage) &#123; xstream.alias(&quot;xml&quot;, voiceMessage.getClass()); return xstream.toXML(voiceMessage); &#125; /** * 视频消息对象转换成xml * * @param videoMessage * 视频消息对象 * @return xml */ public static String messageToXml(VideoMessage videoMessage) &#123; xstream.alias(&quot;xml&quot;, videoMessage.getClass()); return xstream.toXML(videoMessage); &#125; /** * 音乐消息对象转换成xml * * @param musicMessage * 音乐消息对象 * @return xml */ public static String messageToXml(MusicMessage musicMessage) &#123; xstream.alias(&quot;xml&quot;, musicMessage.getClass()); return xstream.toXML(musicMessage); &#125; /** * 图文消息对象转换成xml * * @param newsMessage * 图文消息对象 * @return xml */ public static String messageToXml(NewsMessage newsMessage) &#123; xstream.alias(&quot;xml&quot;, newsMessage.getClass()); xstream.alias(&quot;item&quot;, new Article().getClass()); return xstream.toXML(newsMessage); &#125;&#125; 2.使用CoreServlet 类完成消息的接受与响应：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package com.wyj.wechart.servlet;import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import com.wyj.wechart.service.CoreService;import com.wyj.wechart.utils.SignUtil;/** * 来接收微信服务器传来信息 * * * @author：WangYuanJun * @date：2018年1月23日 下午2:17:39 */@WebServlet(urlPatterns = &quot;/wechat&quot;, description = &quot;wechat&quot;)public class CoreServlet extends HttpServlet &#123; private static final long serialVersionUID = -8685285401859800066L; /** * 确认请求来自微信服务器 */ @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; System.out.println(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;doGet()&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;); // 微信加密签名 String signature = req.getParameter(&quot;signature&quot;); // 时间戳 String timestamp = req.getParameter(&quot;timestamp&quot;); // 随机数 String nonce = req.getParameter(&quot;nonce&quot;); // 随机字符串 String echostr = req.getParameter(&quot;echostr&quot;); PrintWriter out = resp.getWriter(); // 通过检验signature对请求进行校验，若校验成功则原样返回echostr，表示接入成功，否则接入失败 if (SignUtil.checkSignature(signature, timestamp, nonce)) &#123; out.print(echostr); &#125; out.close(); out = null; &#125; /** * 处理微信服务器发来的消息 */ @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; System.out.println(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;doPost()&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;); // 消息的接收、处理、响应 // 将请求、响应的编码均设置为UTF-8（防止中文乱码） req.setCharacterEncoding(&quot;UTF-8&quot;); resp.setCharacterEncoding(&quot;UTF-8&quot;); // 调用核心业务类接收消息、处理消息 String respXml = CoreService.processRequest(req); // 响应消息 PrintWriter out = resp.getWriter(); out.print(respXml); out.close(); &#125;&#125; 3.使用CoreService类完成消息的处理：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108package com.wyj.wechart.service;import java.util.Date;import java.util.Map;import javax.servlet.http.HttpServletRequest;import com.wyj.wechart.message.resp.TextMessage;import com.wyj.wechart.utils.MessageUtil;/** * * 核心服务类 * * @author：WangYuanJun * @date：2018年1月23日 下午2:21:24 */public class CoreService &#123; /** * 处理微信发来的请求 * @param request * @return xml */ public static String processRequest(HttpServletRequest request) &#123; // xml格式的消息数据 String respXml = null; // 默认返回的文本消息内容 String respContent = &quot;未知的消息类型！&quot;; try &#123; // 调用parseXml方法解析请求消息 Map&lt;String, String&gt; requestMap = MessageUtil.parseXml(request); // 发送方帐号 String fromUserName = requestMap.get(&quot;FromUserName&quot;); // 开发者微信号 String toUserName = requestMap.get(&quot;ToUserName&quot;); // 消息类型 String msgType = requestMap.get(&quot;MsgType&quot;); // 回复文本消息 TextMessage textMessage = new TextMessage(); textMessage.setToUserName(fromUserName); textMessage.setFromUserName(toUserName); textMessage.setCreateTime(new Date().getTime()); textMessage.setMsgType(MessageUtil.RESP_MESSAGE_TYPE_TEXT); // 文本消息 if (msgType.equals(MessageUtil.REQ_MESSAGE_TYPE_TEXT)) &#123; respContent = &quot;您发送的是文本消息！&quot;; &#125; // 图片消息 else if (msgType.equals(MessageUtil.REQ_MESSAGE_TYPE_IMAGE)) &#123; respContent = &quot;您发送的是图片消息！&quot;; &#125; // 语音消息 else if (msgType.equals(MessageUtil.REQ_MESSAGE_TYPE_VOICE)) &#123; respContent = &quot;您发送的是语音消息！&quot;; &#125; // 视频消息 else if (msgType.equals(MessageUtil.REQ_MESSAGE_TYPE_VIDEO)) &#123; respContent = &quot;您发送的是视频消息！&quot;; &#125; // 视频消息 else if (msgType.equals(MessageUtil.REQ_MESSAGE_TYPE_SHORTVIDEO)) &#123; respContent = &quot;您发送的是小视频消息！&quot;; &#125; // 地理位置消息 else if (msgType.equals(MessageUtil.REQ_MESSAGE_TYPE_LOCATION)) &#123; respContent = &quot;您发送的是地理位置消息！&quot;; &#125; // 链接消息 else if (msgType.equals(MessageUtil.REQ_MESSAGE_TYPE_LINK)) &#123; respContent = &quot;您发送的是链接消息！&quot;; &#125; // 事件推送 else if (msgType.equals(MessageUtil.REQ_MESSAGE_TYPE_EVENT)) &#123; // 事件类型 String eventType = requestMap.get(&quot;Event&quot;); // 关注 if (eventType.equals(MessageUtil.EVENT_TYPE_SUBSCRIBE)) &#123; respContent = &quot;谢谢您的关注！&quot;; &#125; // 取消关注 else if (eventType.equals(MessageUtil.EVENT_TYPE_UNSUBSCRIBE)) &#123; // TODO 取消订阅后用户不会再收到公众账号发送的消息，因此不需要回复 &#125; // 扫描带参数二维码 else if (eventType.equals(MessageUtil.EVENT_TYPE_SCAN)) &#123; // TODO 处理扫描带参数二维码事件 &#125; // 上报地理位置 else if (eventType.equals(MessageUtil.EVENT_TYPE_LOCATION)) &#123; // TODO 处理上报地理位置事件 &#125; // 自定义菜单 else if (eventType.equals(MessageUtil.EVENT_TYPE_CLICK)) &#123; // TODO 处理菜单点击事件 &#125; &#125; // 设置文本消息的内容 textMessage.setContent(respContent); // 将文本消息对象转换成xml respXml = MessageUtil.messageToXml(textMessage); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return respXml; &#125;&#125; 本地测试效果如下 注：github项目地址：微信公共号开发用例","tags":[{"name":"微信公共号","slug":"微信公共号","permalink":"http://wangyuanjun.cn/tags/微信公共号/"}]},{"title":"微信公共号开发教程java版——请求消息，响应消息及事件消息类的封装(三)","date":"2018-01-25T14:55:20.000Z","path":"2018/01/25/微信公共号开发教程java版——请求消息，响应消息及事件消息类的封装-三/","text":"一：封装请求信息 当普通微信用户向公众账号发消息时，微信服务器将POST消息的XML数据包到开发者填写的URL上。各消息类型的推送XML数据包结构如下：查看官网详细介绍123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171文本消息 &lt;xml&gt; &lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt; &lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;1348831860&lt;/CreateTime&gt; &lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt; &lt;Content&gt;&lt;![CDATA[this is a test]]&gt;&lt;/Content&gt; &lt;MsgId&gt;1234567890123456&lt;/MsgId&gt; &lt;/xml&gt;参数 描述ToUserName 开发者微信号FromUserName 发送方帐号（一个OpenID）CreateTime 消息创建时间 （整型）MsgType textContent 文本消息内容MsgId 消息id，64位整型 图片消息 &lt;xml&gt; &lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt; &lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;1348831860&lt;/CreateTime&gt; &lt;MsgType&gt;&lt;![CDATA[image]]&gt;&lt;/MsgType&gt; &lt;PicUrl&gt;&lt;![CDATA[this is a url]]&gt;&lt;/PicUrl&gt; &lt;MediaId&gt;&lt;![CDATA[media_id]]&gt;&lt;/MediaId&gt; &lt;MsgId&gt;1234567890123456&lt;/MsgId&gt; &lt;/xml&gt;参数 描述ToUserName 开发者微信号FromUserName 发送方帐号（一个OpenID）CreateTime 消息创建时间 （整型）MsgType imagePicUrl 图片链接MediaId 图片消息媒体id，可以调用多媒体文件下载接口拉取数据。MsgId 消息id，64位整型 语音消息&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;1357290913&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[voice]]&gt;&lt;/MsgType&gt;&lt;MediaId&gt;&lt;![CDATA[media_id]]&gt;&lt;/MediaId&gt;&lt;Format&gt;&lt;![CDATA[Format]]&gt;&lt;/Format&gt;&lt;MsgId&gt;1234567890123456&lt;/MsgId&gt;&lt;/xml&gt;参数 描述ToUserName 开发者微信号FromUserName 发送方帐号（一个OpenID）CreateTime 消息创建时间 （整型）MsgType 语音为voiceMediaId 语音消息媒体id，可以调用多媒体文件下载接口拉取数据。Format 语音格式，如amr，speex等MsgID 消息id，64位整型 请注意，开通语音识别后，用户每次发送语音给公众号时，微信会在推送的语音消息XML数据包中，增加一个Recongnition字段 （注：由于客户端缓存，开发者开启或者关闭语音识别功能，对新关注者立刻生效，对已关注用户需要24小时生效。开发者可以重新关注此帐号进行测试）。开启 语音识别后的语音XML数据包如下：&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;1357290913&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[voice]]&gt;&lt;/MsgType&gt;&lt;MediaId&gt;&lt;![CDATA[media_id]]&gt;&lt;/MediaId&gt;&lt;Format&gt;&lt;![CDATA[Format]]&gt;&lt;/Format&gt;&lt;Recognition&gt;&lt;![CDATA[腾讯微信团队]]&gt;&lt;/Recognition&gt;&lt;MsgId&gt;1234567890123456&lt;/MsgId&gt;&lt;/xml&gt;多出的字段中，Format为语音格式，一般为amr，Recognition为语音识别结果，使用UTF8编码。视频消息&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;1357290913&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[video]]&gt;&lt;/MsgType&gt;&lt;MediaId&gt;&lt;![CDATA[media_id]]&gt;&lt;/MediaId&gt;&lt;ThumbMediaId&gt;&lt;![CDATA[thumb_media_id]]&gt;&lt;/ThumbMediaId&gt;&lt;MsgId&gt;1234567890123456&lt;/MsgId&gt;&lt;/xml&gt;参数 描述ToUserName 开发者微信号FromUserName 发送方帐号（一个OpenID）CreateTime 消息创建时间 （整型）MsgType 视频为videoMediaId 视频消息媒体id，可以调用多媒体文件下载接口拉取数据。ThumbMediaId 视频消息缩略图的媒体id，可以调用多媒体文件下载接口拉取数据。MsgId 消息id，64位整型 小视频消息&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;1357290913&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[shortvideo]]&gt;&lt;/MsgType&gt;&lt;MediaId&gt;&lt;![CDATA[media_id]]&gt;&lt;/MediaId&gt;&lt;ThumbMediaId&gt;&lt;![CDATA[thumb_media_id]]&gt;&lt;/ThumbMediaId&gt;&lt;MsgId&gt;1234567890123456&lt;/MsgId&gt;&lt;/xml&gt;参数 描述ToUserName 开发者微信号FromUserName 发送方帐号（一个OpenID）CreateTime 消息创建时间 （整型）MsgType 小视频为shortvideoMediaId 视频消息媒体id，可以调用多媒体文件下载接口拉取数据。ThumbMediaId 视频消息缩略图的媒体id，可以调用多媒体文件下载接口拉取数据。MsgId 消息id，64位整型 地理位置消息&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;1351776360&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[location]]&gt;&lt;/MsgType&gt;&lt;Location_X&gt;23.134521&lt;/Location_X&gt;&lt;Location_Y&gt;113.358803&lt;/Location_Y&gt;&lt;Scale&gt;20&lt;/Scale&gt;&lt;Label&gt;&lt;![CDATA[位置信息]]&gt;&lt;/Label&gt;&lt;MsgId&gt;1234567890123456&lt;/MsgId&gt;&lt;/xml&gt; 参数 描述ToUserName 开发者微信号FromUserName 发送方帐号（一个OpenID）CreateTime 消息创建时间 （整型）MsgType locationLocation_X 地理位置维度Location_Y 地理位置经度Scale 地图缩放大小Label 地理位置信息MsgId 消息id，64位整型 链接消息&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;1351776360&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[link]]&gt;&lt;/MsgType&gt;&lt;Title&gt;&lt;![CDATA[公众平台官网链接]]&gt;&lt;/Title&gt;&lt;Description&gt;&lt;![CDATA[公众平台官网链接]]&gt;&lt;/Description&gt;&lt;Url&gt;&lt;![CDATA[url]]&gt;&lt;/Url&gt;&lt;MsgId&gt;1234567890123456&lt;/MsgId&gt;&lt;/xml&gt; 参数 描述ToUserName 接收方微信号FromUserName 发送方微信号，若为普通用户，则是一个OpenIDCreateTime 消息创建时间MsgType 消息类型，linkTitle 消息标题Description 消息描述Url 消息链接MsgId 消息id，64位整型 其中用户可以向微信服务器发送的消息类型大概可以分为：文本消息，图片消息，语音消息，视频消息，小视频消息，地理位置消息，链接消息。 根据观察可以知道这些消息中，都会传回来这些公共的字段如：123456789ToUserName（开发者微信号）;FromUserName（发送方帐 号，OPEN_ID）;CreateTime（消息的创建时间）;MsgType（消息类型）;MsgId（消息ID）; 我们把这些封装成一个基类，然后 不同的部分，分别封装为各自的类，这样提高代码的重用性。 这个请求消息的基类BaseMessage ，主要是封装了一些共同的字段。 请求消息的基类BaseMessage1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.wyj.wechart.message.req;/** * 请求消息的基类 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:30:00 */public class BaseMessage &#123; // 开发者微信号 private String ToUserName; // 发送方帐号（一个OpenID） private String FromUserName; // 消息创建时间 （整型） private long CreateTime; // 消息类型（text/image/location/link） private String MsgType; // 消息id，64位整型 private long MsgId; public String getToUserName() &#123; return ToUserName; &#125; public void setToUserName(String toUserName) &#123; ToUserName = toUserName; &#125; public String getFromUserName() &#123; return FromUserName; &#125; public void setFromUserName(String fromUserName) &#123; FromUserName = fromUserName; &#125; public long getCreateTime() &#123; return CreateTime; &#125; public void setCreateTime(long createTime) &#123; CreateTime = createTime; &#125; public String getMsgType() &#123; return MsgType; &#125; public void setMsgType(String msgType) &#123; MsgType = msgType; &#125; public long getMsgId() &#123; return MsgId; &#125; public void setMsgId(long msgId) &#123; MsgId = msgId; &#125;&#125; 1.文本消息类Content ，主要是文本消息内容:1234567891011121314151617181920package com.wyj.wechart.message.req;/** * 请求消息之文本消息 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:31:49 */public class TextMessage extends BaseMessage&#123; // 消息内容 private String Content; public String getContent() &#123; return Content; &#125; public void setContent(String content) &#123; Content = content; &#125;&#125; 2.图片消息：123456789101112131415161718192021222324252627282930313233package com.wyj.wechart.message.req;/** * 请求消息之图片消息 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:40:47 */public class ImageMessage extends BaseMessage &#123; // 图片链接 private String PicUrl; //图片消息媒体id，可以调用多媒体文件下载接口拉取数据。 private String MediaId; public String getPicUrl() &#123; return PicUrl; &#125; public void setPicUrl(String picUrl) &#123; PicUrl = picUrl; &#125; public String getMediaId() &#123; return MediaId; &#125; public void setMediaId(String mediaId) &#123; MediaId = mediaId; &#125;&#125; 3.语音消息：1234567891011121314151617181920212223242526272829303132package com.wyj.wechart.message.req;/** * 请求消息之语音消息 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:41:45 */public class VoiceMessage extends BaseMessage &#123; // 语音消息媒体id，可以调用多媒体文件下载接口拉取数据。 private String MediaId; // 语音格式，如amr，speex等 private String Format; public String getMediaId() &#123; return MediaId; &#125; public void setMediaId(String mediaId) &#123; MediaId = mediaId; &#125; public String getFormat() &#123; return Format; &#125; public void setFormat(String format) &#123; Format = format; &#125;&#125; 4.视频消息：123456789101112131415161718192021222324252627282930313233package com.wyj.wechart.message.req;/** * 请求消息之视频消息 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:43:10 */public class VideoMessage extends BaseMessage &#123; // 视频消息媒体id，可以调用多媒体文件下载接口拉取数据。 private String MediaId; // 视频消息缩略图的媒体id，可以调用多媒体文件下载接口拉取数据。 private String ThumbMediaId; public String getMediaId() &#123; return MediaId; &#125; public void setMediaId(String mediaId) &#123; MediaId = mediaId; &#125; public String getThumbMediaId() &#123; return ThumbMediaId; &#125; public void setThumbMediaId(String thumbMediaId) &#123; ThumbMediaId = thumbMediaId; &#125;&#125; 5.地理位置消息:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.wyj.wechart.message.req;/** * 请求消息之地理位置消息 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:44:56 */public class LocationMessage extends BaseMessage &#123; // 地理位置维度 private String Location_X; // 地理位置经度 private String Location_Y; // 地图缩放大小 private String Scale; // 地理位置信息 private String Label; public String getLocation_X() &#123; return Location_X; &#125; public void setLocation_X(String location_X) &#123; Location_X = location_X; &#125; public String getLocation_Y() &#123; return Location_Y; &#125; public void setLocation_Y(String location_Y) &#123; Location_Y = location_Y; &#125; public String getScale() &#123; return Scale; &#125; public void setScale(String scale) &#123; Scale = scale; &#125; public String getLabel() &#123; return Label; &#125; public void setLabel(String label) &#123; Label = label; &#125;&#125; 6.链接消息：1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.wyj.wechart.message.req;/** * 请求消息之链接消息 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:45:29 */public class LinkMessage extends BaseMessage &#123; // 消息标题 private String Title; // 消息描述 private String Description; // 消息链接 private String Url; public String getTitle() &#123; return Title; &#125; public void setTitle(String title) &#123; Title = title; &#125; public String getDescription() &#123; return Description; &#125; public void setDescription(String description) &#123; Description = description; &#125; public String getUrl() &#123; return Url; &#125; public void setUrl(String url) &#123; Url = url; &#125;&#125; 二：封装事件在微信用户和公众号产生交互的过程中，用户的某些操作会使得微信服务器通过事件推送的形式通知到开发者在开发者中心处设置的服务器地址，从而开发者可以获取到该信息。其中，某些事件推送在发生后，是允许开发者回复用户的，某些则不允许，详细内容如下：查看官网详细介绍 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165关注/取消关注事件用户在关注与取消关注公众号时，微信会把这个事件推送到开发者填写的URL。方便开发者给用户下发欢迎消息或者做帐号的解绑。 微信服务器在五秒内收不到响应会断掉连接，并且重新发起请求，总共重试三次 关于重试的消息排重，推荐使用FromUserName + CreateTime 排重。 假如服务器无法保证在五秒内处理并回复，可以直接回复空串，微信服务器不会对此作任何处理，并且不会发起重试。 推送XML数据包示例： &lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[FromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;123456789&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[event]]&gt;&lt;/MsgType&gt;&lt;Event&gt;&lt;![CDATA[subscribe]]&gt;&lt;/Event&gt;&lt;/xml&gt;参数说明： 参数 描述 ToUserName 开发者微信号 FromUserName 发送方帐号（一个OpenID） CreateTime 消息创建时间 （整型） MsgType 消息类型，event Event 事件类型，subscribe(订阅)、unsubscribe(取消订阅) 扫描带参数二维码事件用户扫描带场景值二维码时，可能推送以下两种事件： 1. 如果用户还未关注公众号，则用户可以关注公众号，关注后微信会将带场景值关注事件推送给开发者。 2. 如果用户已经关注公众号，则微信会将带场景值扫描事件推送给开发者。 1. 用户未关注时，进行关注后的事件推送 推送XML数据包示例： &lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[FromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;123456789&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[event]]&gt;&lt;/MsgType&gt;&lt;Event&gt;&lt;![CDATA[subscribe]]&gt;&lt;/Event&gt;&lt;EventKey&gt;&lt;![CDATA[qrscene_123123]]&gt;&lt;/EventKey&gt;&lt;Ticket&gt;&lt;![CDATA[TICKET]]&gt;&lt;/Ticket&gt;&lt;/xml&gt;参数说明： 参数 描述 ToUserName 开发者微信号 FromUserName 发送方帐号（一个OpenID） CreateTime 消息创建时间 （整型） MsgType 消息类型，event Event 事件类型，subscribe EventKey 事件KEY值，qrscene_为前缀，后面为二维码的参数值 Ticket 二维码的ticket，可用来换取二维码图片 2. 用户已关注时的事件推送 推送XML数据包示例： &lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[FromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;123456789&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[event]]&gt;&lt;/MsgType&gt;&lt;Event&gt;&lt;![CDATA[SCAN]]&gt;&lt;/Event&gt;&lt;EventKey&gt;&lt;![CDATA[SCENE_VALUE]]&gt;&lt;/EventKey&gt;&lt;Ticket&gt;&lt;![CDATA[TICKET]]&gt;&lt;/Ticket&gt;&lt;/xml&gt;参数说明： 参数 描述 ToUserName 开发者微信号 FromUserName 发送方帐号（一个OpenID） CreateTime 消息创建时间 （整型） MsgType 消息类型，event Event 事件类型，SCAN EventKey 事件KEY值，是一个32位无符号整数，即创建二维码时的二维码scene_id Ticket 二维码的ticket，可用来换取二维码图片 上报地理位置事件用户同意上报地理位置后，每次进入公众号会话时，都会在进入时上报地理位置，或在进入会话后每5秒上报一次地理位置，公众号可以在公众平台网站中修改以上设置。上报地理位置时，微信会将上报地理位置事件推送到开发者填写的URL。 推送XML数据包示例： &lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;123456789&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[event]]&gt;&lt;/MsgType&gt;&lt;Event&gt;&lt;![CDATA[LOCATION]]&gt;&lt;/Event&gt;&lt;Latitude&gt;23.137466&lt;/Latitude&gt;&lt;Longitude&gt;113.352425&lt;/Longitude&gt;&lt;Precision&gt;119.385040&lt;/Precision&gt;&lt;/xml&gt;参数说明： 参数 描述 ToUserName 开发者微信号 FromUserName 发送方帐号（一个OpenID） CreateTime 消息创建时间 （整型） MsgType 消息类型，event Event 事件类型，LOCATION Latitude 地理位置纬度 Longitude 地理位置经度 Precision 地理位置精度 自定义菜单事件用户点击自定义菜单后，微信会把点击事件推送给开发者，请注意，点击菜单弹出子菜单，不会产生上报。 点击菜单拉取消息时的事件推送 推送XML数据包示例： &lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[FromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;123456789&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[event]]&gt;&lt;/MsgType&gt;&lt;Event&gt;&lt;![CDATA[CLICK]]&gt;&lt;/Event&gt;&lt;EventKey&gt;&lt;![CDATA[EVENTKEY]]&gt;&lt;/EventKey&gt;&lt;/xml&gt;参数说明： 参数 描述 ToUserName 开发者微信号 FromUserName 发送方帐号（一个OpenID） CreateTime 消息创建时间 （整型） MsgType 消息类型，event Event 事件类型，CLICK EventKey 事件KEY值，与自定义菜单接口中KEY值对应 点击菜单跳转链接时的事件推送 推送XML数据包示例： &lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[FromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;123456789&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[event]]&gt;&lt;/MsgType&gt;&lt;Event&gt;&lt;![CDATA[VIEW]]&gt;&lt;/Event&gt;&lt;EventKey&gt;&lt;![CDATA[www.qq.com]]&gt;&lt;/EventKey&gt;&lt;/xml&gt;参数说明： 参数 描述 ToUserName 开发者微信号 FromUserName 发送方帐号（一个OpenID） CreateTime 消息创建时间 （整型） MsgType 消息类型，event Event 事件类型，VIEW EventKey 事件KEY值，设置的跳转URL 其中用户可以向微信服务器发送的消息类型大概可以分为：文本消息，图片消息，语音消息，视频消息，小视频消息，地理位置消息，链接消息。 根据观察可以知道这些消息中，都会传回来这些公共的字段如：123456789ToUserName（开发者微信号）;FromUserName（发送方帐 号，OPEN_ID）;CreateTime（消息的创建时间）;MsgType（消息类型）;MsgId（消息ID）; 我们把这些封装成一个基类，然后 不同的部分，分别封装为各自的类，这样提高代码的重用性。 事件的基类BaseEvent123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.wyj.wechart.message.event;/** * 事件基类 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:35:47 */public class BaseEvent &#123; // 开发者微信号 private String ToUserName; // 发送方帐号（一个OpenID） private String FromUserName; // 消息创建时间 （整型） private long CreateTime; // 消息类型 private String MsgType; // 事件类型 private String Event; public String getToUserName() &#123; return ToUserName; &#125; public void setToUserName(String toUserName) &#123; ToUserName = toUserName; &#125; public String getFromUserName() &#123; return FromUserName; &#125; public void setFromUserName(String fromUserName) &#123; FromUserName = fromUserName; &#125; public long getCreateTime() &#123; return CreateTime; &#125; public void setCreateTime(long createTime) &#123; CreateTime = createTime; &#125; public String getMsgType() &#123; return MsgType; &#125; public void setMsgType(String msgType) &#123; MsgType = msgType; &#125; public String getEvent() &#123; return Event; &#125; public void setEvent(String event) &#123; Event = event; &#125;&#125; 1.关注/取消关注事件1234567891011package com.wyj.wechart.message.event;/** * 关注/取消关注事件 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:36:48 */public class SubscribeEvent extends BaseEvent&#123;&#125; 2.扫描带参数二维码事件1234567891011121314151617181920212223242526272829303132package com.wyj.wechart.message.event;/** * 扫描带参数二维码事件 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:37:41 */public class QRCodeEvent extends BaseEvent&#123; // 事件KEY值 private String EventKey; // 用于换取二维码图片 private String Ticket; public String getEventKey() &#123; return EventKey; &#125; public void setEventKey(String eventKey) &#123; EventKey = eventKey; &#125; public String getTicket() &#123; return Ticket; &#125; public void setTicket(String ticket) &#123; Ticket = ticket; &#125;&#125; 3.上报地理位置事件12345678910111213141516171819202122232425262728293031323334353637383940414243package com.wyj.wechart.message.event;/** * 上报地理位置事件 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:38:36 */public class LocationEvent extends BaseEvent&#123; // 地理位置纬度 private String Latitude; // 地理位置经度 private String Longitude; // 地理位置精度 private String Precision; public String getLatitude() &#123; return Latitude; &#125; public void setLatitude(String latitude) &#123; Latitude = latitude; &#125; public String getLongitude() &#123; return Longitude; &#125; public void setLongitude(String longitude) &#123; Longitude = longitude; &#125; public String getPrecision() &#123; return Precision; &#125; public void setPrecision(String precision) &#123; Precision = precision; &#125;&#125; 4.自定义菜单事件12345678910111213141516171819202122package com.wyj.wechart.message.event;/** * 自定义菜单事件 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:39:34 */public class MenuEvent extends BaseEvent &#123; // 事件KEY值，与自定义菜单接口中KEY值对应 private String EventKey; public String getEventKey() &#123; return EventKey; &#125; public void setEventKey(String eventKey) &#123; EventKey = eventKey; &#125;&#125; 三：封装响应消息当用户发送消息给公众号时（或某些特定的用户操作引发的事件推送时），会产生一个POST请求，开发者可以在响应包（Get）中返回特定XML结构，来对该消息进行响应（现支持回复文本、图片、图文、语音、视频、音乐）。严格来说，发送被动响应消息其实并不是一种接口，而是对微信服务器发过来消息的一次回复。各消息类型需要的XML数据包结构如下：查看官网详细介绍 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142回复文本消息&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;12345678&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt;&lt;Content&gt;&lt;![CDATA[你好]]&gt;&lt;/Content&gt;&lt;/xml&gt;参数 是否必须 描述ToUserName 是 接收方帐号（收到的OpenID）FromUserName 是 开发者微信号CreateTime 是 消息创建时间 （整型）MsgType 是 textContent 是 回复的消息内容（换行：在content中能够换行，微信客户端就支持换行显示）回复图片消息&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;12345678&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[image]]&gt;&lt;/MsgType&gt;&lt;Image&gt;&lt;MediaId&gt;&lt;![CDATA[media_id]]&gt;&lt;/MediaId&gt;&lt;/Image&gt;&lt;/xml&gt;参数 是否必须 说明ToUserName 是 接收方帐号（收到的OpenID）FromUserName 是 开发者微信号CreateTime 是 消息创建时间 （整型）MsgType 是 imageMediaId 是 通过素材管理接口上传多媒体文件，得到的id。回复语音消息&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;12345678&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[voice]]&gt;&lt;/MsgType&gt;&lt;Voice&gt;&lt;MediaId&gt;&lt;![CDATA[media_id]]&gt;&lt;/MediaId&gt;&lt;/Voice&gt;&lt;/xml&gt;参数 是否必须 说明ToUserName 是 接收方帐号（收到的OpenID）FromUserName 是 开发者微信号CreateTime 是 消息创建时间戳 （整型）MsgType 是 语音，voiceMediaId 是 通过素材管理接口上传多媒体文件，得到的id回复视频消息&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;12345678&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[video]]&gt;&lt;/MsgType&gt;&lt;Video&gt;&lt;MediaId&gt;&lt;![CDATA[media_id]]&gt;&lt;/MediaId&gt;&lt;Title&gt;&lt;![CDATA[title]]&gt;&lt;/Title&gt;&lt;Description&gt;&lt;![CDATA[description]]&gt;&lt;/Description&gt;&lt;/Video&gt; &lt;/xml&gt;参数 是否必须 说明ToUserName 是 接收方帐号（收到的OpenID）FromUserName 是 开发者微信号CreateTime 是 消息创建时间 （整型）MsgType 是 videoMediaId 是 通过素材管理接口上传多媒体文件，得到的idTitle 否 视频消息的标题Description 否 视频消息的描述回复音乐消息&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;12345678&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[music]]&gt;&lt;/MsgType&gt;&lt;Music&gt;&lt;Title&gt;&lt;![CDATA[TITLE]]&gt;&lt;/Title&gt;&lt;Description&gt;&lt;![CDATA[DESCRIPTION]]&gt;&lt;/Description&gt;&lt;MusicUrl&gt;&lt;![CDATA[MUSIC_Url]]&gt;&lt;/MusicUrl&gt;&lt;HQMusicUrl&gt;&lt;![CDATA[HQ_MUSIC_Url]]&gt;&lt;/HQMusicUrl&gt;&lt;ThumbMediaId&gt;&lt;![CDATA[media_id]]&gt;&lt;/ThumbMediaId&gt;&lt;/Music&gt;&lt;/xml&gt;参数 是否必须 说明ToUserName 是 接收方帐号（收到的OpenID）FromUserName 是 开发者微信号CreateTime 是 消息创建时间 （整型）MsgType 是 musicTitle 否 音乐标题Description 否 音乐描述MusicURL 否 音乐链接HQMusicUrl 否 高质量音乐链接，WIFI环境优先使用该链接播放音乐ThumbMediaId 否 缩略图的媒体id，通过素材管理接口上传多媒体文件，得到的id回复图文消息&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;12345678&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[news]]&gt;&lt;/MsgType&gt;&lt;ArticleCount&gt;2&lt;/ArticleCount&gt;&lt;Articles&gt;&lt;item&gt;&lt;Title&gt;&lt;![CDATA[title1]]&gt;&lt;/Title&gt; &lt;Description&gt;&lt;![CDATA[description1]]&gt;&lt;/Description&gt;&lt;PicUrl&gt;&lt;![CDATA[picurl]]&gt;&lt;/PicUrl&gt;&lt;Url&gt;&lt;![CDATA[url]]&gt;&lt;/Url&gt;&lt;/item&gt;&lt;item&gt;&lt;Title&gt;&lt;![CDATA[title]]&gt;&lt;/Title&gt;&lt;Description&gt;&lt;![CDATA[description]]&gt;&lt;/Description&gt;&lt;PicUrl&gt;&lt;![CDATA[picurl]]&gt;&lt;/PicUrl&gt;&lt;Url&gt;&lt;![CDATA[url]]&gt;&lt;/Url&gt;&lt;/item&gt;&lt;/Articles&gt;&lt;/xml&gt; 参数 是否必须 说明ToUserName 是 接收方帐号（收到的OpenID）FromUserName 是 开发者微信号CreateTime 是 消息创建时间 （整型）MsgType 是 newsArticleCount 是 图文消息个数，限制为10条以内Articles 是 多条图文消息信息，默认第一个item为大图,注意，如果图文数超过10，则将会无响应Title 否 图文消息标题Description 否 图文消息描述PicUrl 否 图片链接，支持JPG、PNG格式，较好的效果为大图360*200，小图200*200Url 否 点击图文消息跳转链接 同样，把消息回复中定义的所有消息都有的字段提取出来，封装成一个基类， 这些公有的字段包括： 123456789ToUserName（接收方帐号，用户的OPEN_ID）;FromUserName（开发者的微信号）;CreateTime（消 息的创建时间）;MsgType（消息类型）;FuncFlag（消息的星标标识）; 响应消息的基类BaseMessage：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.wyj.wechart.message.resp;/** * 消息基类（公众帐号 -&gt; 普通用户） * * * @author：WangYuanJun * @date：2018年1月23日 下午1:33:50 */public class BaseMessage &#123; // 接收方帐号（收到的OpenID） private String ToUserName; // 开发者微信号 private String FromUserName; // 消息创建时间 （整型） private long CreateTime; // 消息类型 private String MsgType; public String getToUserName() &#123; return ToUserName; &#125; public void setToUserName(String toUserName) &#123; ToUserName = toUserName; &#125; public String getFromUserName() &#123; return FromUserName; &#125; public void setFromUserName(String fromUserName) &#123; FromUserName = fromUserName; &#125; public long getCreateTime() &#123; return CreateTime; &#125; public void setCreateTime(long createTime) &#123; CreateTime = createTime; &#125; public String getMsgType() &#123; return MsgType; &#125; public void setMsgType(String msgType) &#123; MsgType = msgType; &#125;&#125; 1.回复文本消息：12345678910111213141516171819202122package com.wyj.wechart.message.resp;/** * 文本消息 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:34:43 */public class TextMessage extends BaseMessage&#123; // 回复的消息内容 private String Content; public String getContent() &#123; return Content; &#125; public void setContent(String content) &#123; Content = content; &#125;&#125; 2.回复图片消息：12345678910111213141516171819package com.wyj.wechart.message.resp;/** * 图片 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:46:36 */public class Image &#123; private String MediaId; public String getMediaId() &#123; return MediaId; &#125; public void setMediaId(String mediaId) &#123; MediaId = mediaId; &#125;&#125; 1234567891011121314151617181920package com.wyj.wechart.message.resp;/** * 图片消息 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:51:36 */public class ImageMessage extends BaseMessage &#123; private Image Image; public Image getImage() &#123; return Image; &#125; public void setImage(Image image) &#123; Image = image; &#125;&#125; 3.回复语音消息：12345678910111213141516171819202122package com.wyj.wechart.message.resp;/** * 语音model * * * @author：WangYuanJun * @date：2018年1月23日 下午1:52:02 */public class Voice &#123; // 媒体文件id private String MediaId; public String getMediaId() &#123; return MediaId; &#125; public void setMediaId(String mediaId) &#123; MediaId = mediaId; &#125;&#125; 12345678910111213141516171819202122package com.wyj.wechart.message.resp;/** * 语音消息 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:52:49 */public class VoiceMessage extends BaseMessage &#123; // 语音 private Voice Voice; public Voice getVoice() &#123; return Voice; &#125; public void setVoice(Voice voice) &#123; Voice = voice; &#125;&#125; 4.回复视频消息：123456789101112131415161718192021222324252627282930313233package com.wyj.wechart.message.resp;/** * 视频model * * * @author：WangYuanJun * @date：2018年1月23日 下午1:53:28 */public class Video &#123; // 媒体文件id private String MediaId; // 缩略图的媒体id private String ThumbMediaId; public String getMediaId() &#123; return MediaId; &#125; public void setMediaId(String mediaId) &#123; MediaId = mediaId; &#125; public String getThumbMediaId() &#123; return ThumbMediaId; &#125; public void setThumbMediaId(String thumbMediaId) &#123; ThumbMediaId = thumbMediaId; &#125;&#125; 12345678910111213141516171819202122package com.wyj.wechart.message.resp;/** * 视频消息 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:54:03 */public class VideoMessage extends BaseMessage &#123; // 视频 private Video Video; public Video getVideo() &#123; return Video; &#125; public void setVideo(Video video) &#123; Video = video; &#125;&#125; 5.回复音乐消息：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.wyj.wechart.message.resp;/** * 音乐model * * * @author：WangYuanJun * @date：2018年1月23日 下午1:54:50 */public class Music &#123; // 音乐标题 private String Title; // 音乐描述 private String Description; // 音乐链接 private String MusicUrl; // 高质量音乐链接，WIFI环境优先使用该链接播放音乐 private String HQMusicUrl; // 缩略图的媒体id，通过上传多媒体文件得到的id private String ThumbMediaId; public String getTitle() &#123; return Title; &#125; public void setTitle(String title) &#123; Title = title; &#125; public String getDescription() &#123; return Description; &#125; public void setDescription(String description) &#123; Description = description; &#125; public String getMusicUrl() &#123; return MusicUrl; &#125; public void setMusicUrl(String musicUrl) &#123; MusicUrl = musicUrl; &#125; public String getHQMusicUrl() &#123; return HQMusicUrl; &#125; public void setHQMusicUrl(String musicUrl) &#123; HQMusicUrl = musicUrl; &#125; public String getThumbMediaId() &#123; return ThumbMediaId; &#125; public void setThumbMediaId(String thumbMediaId) &#123; ThumbMediaId = thumbMediaId; &#125;&#125; 12345678910111213141516171819202122package com.wyj.wechart.message.resp;/** * 音乐消息 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:55:28 */public class MusicMessage extends BaseMessage &#123; // 音乐 private Music Music; public Music getMusic() &#123; return Music; &#125; public void setMusic(Music music) &#123; Music = music; &#125;&#125; 6.回复图文消息：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.wyj.wechart.message.resp;/** * 图文model * * * @author：WangYuanJun * @date：2018年1月23日 下午1:55:56 */public class Article &#123; // 图文消息名称 private String Title; // 图文消息描述 private String Description; // 图片链接，支持JPG、PNG格式，较好的效果为大图640*320，小图80*80 private String PicUrl; // 点击图文消息跳转链接 private String Url; public String getTitle() &#123; return Title; &#125; public void setTitle(String title) &#123; Title = title; &#125; public String getDescription() &#123; return null == Description ? &quot;&quot; : Description; &#125; public void setDescription(String description) &#123; Description = description; &#125; public String getPicUrl() &#123; return null == PicUrl ? &quot;&quot; : PicUrl; &#125; public void setPicUrl(String picUrl) &#123; PicUrl = picUrl; &#125; public String getUrl() &#123; return null == Url ? &quot;&quot; : Url; &#125; public void setUrl(String url) &#123; Url = url; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435package com.wyj.wechart.message.resp;import java.util.List;/** * 文本消息 * * * @author：WangYuanJun * @date：2018年1月23日 下午1:56:32 */public class NewsMessage extends BaseMessage &#123; // 图文消息个数，限制为10条以内 private int ArticleCount; // 多条图文消息信息，默认第一个item为大图 private List&lt;Article&gt; Articles; public int getArticleCount() &#123; return ArticleCount; &#125; public void setArticleCount(int articleCount) &#123; ArticleCount = articleCount; &#125; public List&lt;Article&gt; getArticles() &#123; return Articles; &#125; public void setArticles(List&lt;Article&gt; articles) &#123; Articles = articles; &#125;&#125; 注：github项目地址：微信公共号开发用例","tags":[{"name":"微信公共号","slug":"微信公共号","permalink":"http://wangyuanjun.cn/tags/微信公共号/"}]},{"title":"微信公共号开发教程java版——启用开发者模式，接入微信公众平台开发(二)","date":"2018-01-25T08:45:30.000Z","path":"2018/01/25/微信公共号开发教程java版——启用开发者模式，接入微信公众平台开发-二/","text":"一：微信公众号对接的基本介绍填写服务器配置信息的介绍在微信公众平台认证之前，我们可以先申请一个测试的公众号来进行测试，这对开发人员来说还是有很大好处的！为什么要申请测试账号？ 主要是因为测试账号比我们没有认证的微信账号权限大一点。足够测试我们的接口了，点击http://mp.weixin.qq.com/debug/cgi-bin/sandbox?t=sandbox/login 二：微信服务器对接的实现代码部分创建java项目 新建一个名SpringBoot项目,名为wyj-wechat-demo。 新建一个servlet类，来接收微信服务器传来信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.wyj.wechart.servlet;import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import com.wyj.wechart.service.CoreService;import com.wyj.wechart.utils.SignUtil;/** * 来接收微信服务器传来信息 * * * @author：WangYuanJun * @date：2018年1月23日 下午2:17:39 */@WebServlet(urlPatterns = &quot;/wechart&quot;, description = &quot;wechart&quot;)public class CoreServlet extends HttpServlet &#123; private static final long serialVersionUID = -8685285401859800066L; /** * 确认请求来自微信服务器 */ @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; System.out.println(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;doGet()&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;); // 微信加密签名 String signature = req.getParameter(&quot;signature&quot;); // 时间戳 String timestamp = req.getParameter(&quot;timestamp&quot;); // 随机数 String nonce = req.getParameter(&quot;nonce&quot;); // 随机字符串 String echostr = req.getParameter(&quot;echostr&quot;); PrintWriter out = resp.getWriter(); // 通过检验signature对请求进行校验，若校验成功则原样返回echostr，表示接入成功，否则接入失败 if (SignUtil.checkSignature(signature, timestamp, nonce)) &#123; out.print(echostr); &#125; out.close(); out = null; &#125; /** * 处理微信服务器发来的消息 */ @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; System.out.println(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;doPost()&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;); // TODO 消息的接收、处理、响应 &#125;&#125; 加密校验程序的工具类。这个校验的方法，可以通过分析官方文档的demo，然后通过java语言来写出。官方php校验代码一览 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package com.wyj.wechart.utils;import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;import java.util.Arrays;/** * 请求校验工具类 * * * @author：WangYuanJun * @date：2018年1月22日 下午3:45:15 */public class SignUtil &#123; // 与接口配置信息中的Token要一致 private static String token = &quot;wechart&quot;; /** * 验证签名 * * @param signature * @param timestamp * @param nonce * @return */ public static boolean checkSignature(String signature, String timestamp, String nonce) &#123; String[] arr = new String[] &#123; token, timestamp, nonce &#125;; // 将token、timestamp、nonce三个参数进行字典序排序 Arrays.sort(arr); StringBuilder content = new StringBuilder(); for (int i = 0; i &lt; arr.length; i++) &#123; content.append(arr[i]); &#125; MessageDigest md = null; String tmpStr = null; try &#123; md = MessageDigest.getInstance(&quot;SHA-1&quot;); // 将三个参数字符串拼接成一个字符串进行sha1加密 byte[] digest = md.digest(content.toString().getBytes()); tmpStr = byteToStr(digest); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; content = null; // 将sha1加密后的字符串可与signature对比，标识该请求来源于微信 return tmpStr != null ? tmpStr.equals(signature.toUpperCase()) : false; &#125; /** * 将字节数组转换为十六进制字符串 * * @param byteArray * @return */ private static String byteToStr(byte[] byteArray) &#123; String strDigest = &quot;&quot;; for (int i = 0; i &lt; byteArray.length; i++) &#123; strDigest += byteToHexStr(byteArray[i]); &#125; return strDigest; &#125; /** * 将字节转换为十六进制字符串 * * @param mByte * @return */ private static String byteToHexStr(byte mByte) &#123; char[] Digit = &#123; &apos;0&apos;, &apos;1&apos;, &apos;2&apos;, &apos;3&apos;, &apos;4&apos;, &apos;5&apos;, &apos;6&apos;, &apos;7&apos;, &apos;8&apos;, &apos;9&apos;, &apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;, &apos;E&apos;, &apos;F&apos; &#125;; char[] tempArr = new char[2]; tempArr[0] = Digit[(mByte &gt;&gt;&gt; 4) &amp; 0X0F]; tempArr[1] = Digit[mByte &amp; 0X0F]; String s = new String(tempArr); return s; &#125; &#125; 修改服务器端口为80端口SpringBoot application.properties 123456789101112server.port=80spring.freemarker.cache=falsespring.freemarker.charset=UTF-8spring.freemarker.check-template-location=truespring.freemarker.content-type=text/htmlspring.freemarker.expose-request-attributes=truespring.freemarker.expose-session-attributes=truespring.freemarker.request-context-attribute=requestspring.freemarker.template-loader-path=classpath:/templatesspring.freemarker.suffix=.htmlspring.mvc.static-path-pattern=/static/** 三：填写服务器配置微信公众号测试环境接入示例： 服务器配置： URL：是开发者用来接收微信消息和事件 的接口URL。（必须以http://开头，目前支持80端口） Token：可由开发者可以任意填写，用作生成签名（该Token会和接口URL中包含的Token进行比对，从而验证安全性）。注意必须为英文或数字，长度为3-32字符。 说明：如果提示“token验证失败”，可以先重次几次，微信服务器有时候不稳定，也有可能映射不稳定。URL改成自己的URL，Token要对应自己在SignUtil里面填写的Token值。 验证服务器地址的有效性开发者提交信息后，微信服务器将发送GET请求到填写的服务器地址URL上，GET请求携带四个参数： 参数 描述 signature 微信加密签名，signature结合了开发者填写的token参数和请求中的timestamp参数、nonce参数 timestamp 时间戳 nonce 随机数 echostr 随机字符串 开发者通过检验signature对请求进行校验（下面有校验方式）。若确认此次GET请求来自微信服务器，请原样返回echostr参数内容，则接入生效，成为开发者成功，否则接入失败。 加密/校验流程如下： 将token、timestamp、nonce三个参数进行字典序排序 将三个参数字符串拼接成一个字符串进行sha1加密 开发者获得加密后的字符串可与signature对比，标识该请求来源于微信 Token校验是否成功成功启用后如图：恭喜，你成功启用开发模式。 启用并设置服务器配置后，用户发给公众号的消息以及开发者需要的事件推送，将被微信转发到该URL中。 成为开发者后，用户每次向公众号发送消息、或者产生自定义菜单、或产生微信支付订单等情况时，开发者填写的服务器配置URL将得到微信服务器推送过来的消息和事件，开发者可以依据自身业务逻辑进行响应，如回复消息。 这些配置可以参照我的其他博客文章进行配置，这里就不多说了。以上介绍也可以参考 微信开发文档。 注：github项目地址：微信公共号开发用例","tags":[{"name":"微信公共号","slug":"微信公共号","permalink":"http://wangyuanjun.cn/tags/微信公共号/"}]},{"title":"微信公共号开发教程java版——基础知识和环境搭建(一)","date":"2018-01-23T08:46:07.000Z","path":"2018/01/23/微信公共号开发教程java版——基础知识和环境搭建-一/","text":"一：微信公共号基础知识简介微信公众号是开发者或商家在微信公众平台上申请的应用账号，该帐号与QQ账号互通，通过公众号，商家可在微信平台上实现和特定群体的文字、图片、语音、视频的全方位沟通、互动 。形成了一种主流的线上线下微信互动营销方式。 分类及区别微信公众号分为订阅号和服务号。1、订阅号，任何组织和个人都可以申请，每天群发一条信息，认证后有自定义菜单。没有高级接口，不能用开发模式。2、选择服务号，只面向企业或组织机构申请注册，申请后自带自定义菜单。认证后可以有高级接口，每周群发一条信息。均不可主动添加微信好友。 通讯机制作为开发者，我们需要面对的主要有两个对象：微信服务器和应用程序（网站）服务器。当微信用户向你的公众平台发送一条消息，实际上这条消息首先发送到微信服务器，由微信服务器向网站服务器发起另外一个请求，网站服务器返回这个请求的结果，再由微信服务器发送到微信客户端。 整个消息通讯流程如下图： 二：微信公共号环境搭建服务器准备 方式一：买的云主机。 方式二：BAE（注册百度账号，然后登录 百度云开发平台 ）。 方式三：SAE（注册新浪微博，然后登录 新浪云SAE ）。 方式五：可以通过免费映射工具。比如：ngrok ，natapp ，花生壳 ，nginx 等; 由于前面三种方式都是发布到公网的的，出现问题不能在本地调试，需要在本地搭建测试环境，我将使用ngrop工具，使本地搭建的服务器能够外网能够访问，将运行在内网的服务器映射到外网去给微信访问。 ngrop工具使用首先到官网https://ngrok.com注册并下载ngrok，得到一串授权码在windows环境下，运行 ngrok -authtoken 你的授权码80，80是你本地Web服务的端口，而之后ngrok会记住你的授权码，直接 http ngrok 80就OK了每次重启ngrop，ip地址都会变 标红的地方是外网地址映射80端口，本地服务端口必须是80端口 三：微信公共号相关资料 申请一个微信号（下载微信客户端，手机注册，或是qq注册） 申请一个微信公众平台接口测试帐号 申请一个微信公众号 注：github项目地址：微信公共号开发用例","tags":[{"name":"微信公共号","slug":"微信公共号","permalink":"http://wangyuanjun.cn/tags/微信公共号/"}]},{"title":"nginx中修改server_name无效，修改为www.wecharttest.com无法访问，通过localhost可以访问","date":"2018-01-22T06:00:00.000Z","path":"2018/01/22/nginx中修改server-name无效，修改为www-wecharttest-com无法访问，通过localhost可以访问/","text":"最近在看微信公共号，需要通过软件Nginx，直接使用自己的内网作为电脑的服务器来进行一系列的操作以及调试(实现内网穿透，将内网的服务器映射到外网给别人访问)但是在Nginx中，把server_name配置成自己的域名www.wecharttest.com无效。解决方法： linux下： sudo vi /etc/host 增加 www.wecharttest.com 127.0.0.1 sudo vi /etc/hosts 增加 127.0.0.1 www.wecharttest.com 然后esc、:wq保存退出即可。 windows下： 修改C:\\Windows\\System32\\drivers\\etc下hosts文件即可，内容如linux下。","tags":[{"name":"nginx","slug":"nginx","permalink":"http://wangyuanjun.cn/tags/nginx/"}]},{"title":"Nginx学习——session共享(二)","date":"2018-01-16T08:04:58.000Z","path":"2018/01/16/Nginx学习——session共享-二/","text":"上一篇博文说到了nginx session共享问题。由于 nginx 是随机分配请求，假设一个用户登录时访问网站登录时被分配到 192.168.43.3:8080 上，然后进行了登录操作，此时该服务器上就会有该用户登录的 session 信息，然后登陆后重定向到网站首页或个人中心时，此时如果被分配到 192.168.43.3:8081 上，那么这台服务器上没有该用户 session 信息，于是又会变成未登录状态，所以由于 nginx 的负载均衡会导致 session 共享的问题。 不使用session，换用cookiesession是存放在服务器端的，cookie是存放在客户端的，我们可以把用户访问页面产生的session放到cookie里面，就是以cookie为中转站。你访问web服务器A，产生了session然后把它放到cookie里面，当你的请求被分配到B服务器时，服务器B先判断服务器有没有这个session，如果没有，再去看看客户端的cookie里面有没有这个session，如果也没有，说明session真的不存，如果cookie里面有，就把cookie里面的sessoin同步到服务器B，这样就可以实现session的同步了。说明：这种方法实现起来简单，方便，也不会加大数据库的负担，但是如果客户端把cookie禁掉了的话，那么session就无从同步了，这样会给网站带来损失；cookie的安全性不高，虽然它已经加了密，但是还是可以伪造的。 session存在数据库（MySQL等）中java可以配置将session保存在数据库中，这种方法是把存放session的表和其他数据库表放在一起，如果mysql也做了集群了话，每个mysql节点都要有这张表，并且这张session表的数据表要实时同步。说明：用数据库来同步session，会加大数据库的IO，增加数据库的负担。而且数据库读写速度较慢，不利于session的适时同步。 ip_hash 策略nginx 提供了 ip_hash 策略，可以保持用户 ip 进行 hash 值计算固定分配到某台服务器上，然后只要是该 ip 则会保持分配到该服务器上，保证用户访问的是同一台服务器，那么 session 问题就不存在了。这也是解决 session 共享的一种方式，也称为黏性 session。但是假设一台 tomcat 服务器挂了的话，那么 session 也会丢失。所以比较好的方案是抽取 session。 upstream_hash为了解决ip_hash的一些问题，可以使用upstream_hash这个第三方模块，这个模块多数情况下是用作url_hash的，但是并不妨碍将它用来做session共享。没试过真心的不明白 session存在memcache或者redis中此种方式将将用户的登录信息存储到redis中，因为是基于内存的读取，因此效率不会是响应效率的瓶颈，cookie中存储着jsessionid，不需要加密或处理，只需要存储redis中的key保存统一客户通过cookie中的key可以准确的登录信息或是其他有效的信息，此种方式，cookie的存储不需要加密计算成本，其次redis将信息存储到缓存中，存取效率高，后面会详细介绍此种方式实现过程。 基于tomcat容器session此种方式在根本上实现共享session，他的实际情况是通过tomcat管理配置将一个tomct下的session复制到其他的tomcat的session池中，实现真实上的session共享；此种方式需要兼容tomcat配置及需要对其进行扩展，依赖性太强。 一：Redis 环境搭建redis 依赖 gcc，先安装：1yum install -y gcc-c++ 下载 redis，我使用的是 redis-3.2.11.tar.gz，上传至 linux /usr/local/redis-src / 中，解压 进入解压后目录 redis-3.2.11，执行 make 命令进行编译 安装到目录 /usr/local/redis 执行：1make PREFIX=/usr/local/redis install 安装完成之后将 redis 配置文件拷贝到安装目录下，redis.conf 是 redis 的配置文件，redis.conf 在 redis 源码目录, port 默认 6379。执行命令：1cp /root/wyj/tools/redis/redis-3.2.11/redis.conf /usr/local/redis/ 在 redis 安装目录启动和关闭 redis： 启动：这种启动方式叫做前端启动，必须保持在当前窗口，如果 ctrl + c 退出，那么 redis 也就退出了，不建议使用 那么后端启动： 首先修改 redis.conf 中 daemonize 的值，打开可以看到默认是 no，修改为 daemonize yes，启动即可。也可以在该配置文件中修改 redis 默认端口 6379 为其他值。1./bin/redis-cli shutdown 至此，redis 服务器搭建完成。 二：下载相关jar 环境为 tomcat7 + jdk1.6 ： 在所有需要共享 session 的服务器的 tomcat 中目录下： lib 目录中添加以下五个 jar 包，注意版本最好一致，不然极容易出现错误，下边的测试是可用的： 下载tomcat-redis-session-manager 下载commons-pool 1.6 下载jedis 2.2 下载tomcat-juli-adapters.jar 下载tomcat-juli.jarconf 目录中 content.xml 中加入：配置 redis 服务123456&lt;Valve className=&quot;com.radiadesign.catalina.session.RedisSessionHandlerValve&quot;/&gt; &lt;Manager className=&quot;com.radiadesign.catalina.session.RedisSessionManager&quot;host=&quot;localhost&quot;port=&quot;6379&quot;database=&quot;0&quot; maxInactiveInterval=&quot;60&quot; /&gt; 环境为 tomcat7 + jdk1.7 或 1.8 ： 在所有需要共享 session 的服务器的 tomcat 中目录下： lib 目录中添加以下五个 jar 包，其中tomcat-redis-session-manager.jar需要重新下载编译打包，不然会报错。 下载tomcat-redis-session-manager,我用的jdk8所以用的是-7-java.jar 下载commons-pool 2.4.1 下载jedis 2.6.2 下载tomcat-juli-adapters.jar 下载tomcat-juli.jar conf 目录中 content.xml 中加入：配置 redis 服务 123456&lt;Valve className=&quot;com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve&quot; /&gt; &lt;Manager className=&quot;com.orangefunction.tomcat.redissessions.RedisSessionManager&quot;host=&quot;localhost&quot; port=&quot;6379&quot; database=&quot;0&quot; maxInactiveInterval=&quot;60&quot;/&gt; 三：配置Tomcat根据我这测试，是 jkd1.8+tomcat7，在 137 和 139 两台 tomcat 中加入 jar 包且进行如上配置： 上传 jar 包修改 content.xml启动 redis 服务，重新启动所有 tomcat，启动 nginx，刷新 nginx 页面, 两台 tomcat 页面可以看到 sessionid 值不变，关闭某台 tomcat，nginx 中 sessionid 不变，说明 session 是共享的。 请注意！！！！ context.xml 配置说明： 12345678910&lt;Valve className=&quot;com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve&quot; /&gt; &lt;Manager className=&quot;com.orangefunction.tomcat.redissessions.RedisSessionManager&quot;//这里是redis服务器地址host=&quot;localhost&quot;//这里是redis端口，redis默认端口是6379port=&quot;6379&quot;//这里是redis数据库中的标识，标识第0个，默认使用0即可database=&quot;0&quot; //需要注意的是这里由于redis过期时间默认设置为60，单位是秒，session过期时间为30分钟，所以需要设置为1800对应30分钟maxInactiveInterval=&quot;1800&quot;/&gt; 四：项目搭建中遇到的问题将相关commons-pool2-2.4.1.jar，tomcat-redis-session-manager-1.2-tomcat-7-java-7.jar，jedis-2.6.2.jar，放到comcat的lib目录下，启动后报错： 查看下载的包tomcat-redis-session-manager-1.2-tomcat-7-java-7.jar或tomcat-redis-session-manager-1.2-tomcat-7.jar相关包的里面并没有类:com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve。从 https://github.com/jcoleman/tomcat-redis-session-manager 直接下载源码，发现源码里面存在相应的类。同时源码（tomcat-redis-session-manager）依赖了tomcat其他的包：tomcat-juli.jar，而tomcat默认是没有这些包的，从 https://mirrors.cnnic.cn/apache/tomcat/tomcat-7/v7.0.82/bin/extras/ 下载tomcat-juli-adapters.jar和tomcat-juli.jar两个包，放在apache-tomcat-7.0.82\\lib目录下，同时将tomcat-juli.jar放在apache-tomcat-7.0.82\\bin目录下同时将编译tomcat-redis-session-manager的源码，通过相应的依赖包common-pool2.2，jedis以及tomcat-juli.jar编译，并打成自己的jar包。打包详情如下：点击 http://download.csdn.net/download/wangyuanjun008/10214996 下载总结这篇文章写下来可真是费了些力气，中间出了好多错，不过一个一个有耐心的解决掉，最后出来的结果还是令人挺有成就感的。毕竟心里的一块大石算是落了。以后有空再尝试一下其他几种方法。 PS : 修改配置文件的时候，一定要先备份再修改，不然出了问题都不能恢复。 参考:Nginx 反向代理，负载均衡，redis session 共享，keepalived 高可用搭建Nginx（负载均衡）+Redis（Session共享）+Tomcat集群tomcat7和redis的sessoin共享问题处理tomcat集群基于redis共享session解决方案","tags":[{"name":"nginx","slug":"nginx","permalink":"http://wangyuanjun.cn/tags/nginx/"}]},{"title":"Nginx学习——反向代理与负载均衡(一)","date":"2018-01-16T08:04:25.000Z","path":"2018/01/16/Nginx学习——反向代理与负载均衡-一/","text":"一：环境配置我本地是Windows系统，使用 Oracle VM VirtualBox 虚拟机安装一个虚拟的Linux系统，安装jdk1.8，nginx,两个tomcat 一般需要用到三台服务器，一台 nginx 服务器，两台正式部署项目的服务器。为了方便操作，我只在一台服务器上面安装了一个nginx和两个tomcat(端口不一样) 二：配置tomcat集群首先在服务器上安装两个 tomcat：这个也是简单，不多说 安装 tomcat：上传解压即可使用，bin 目录下 startup.sh 启动，shutdown.sh 关闭 配置防火墙端口：vim /etc/sysconfig/iptables 编辑，开放 8080 端口，8081 端口，80 端口等一些常用端口，当然后边有用到一些端口都是需要配置开放的，不建议关闭防火墙 编辑好后 service iptables restart 重新加载防火墙配置 如果是自己测试嫌配置麻烦，关闭防火墙： service iptables stop 重启后防火墙打开，即在此次开机状态下有效，完全关闭再使用 chkconfig iptables off , 即会在重启后也关闭防火墙，注意有时候服务都起了但访问出错，可能就是防火墙问题哦 启动 tomcat 访问：192.168.43.3:8080，192.168.43.3:8081，打开 tomcat 首页即成功。 然后编写测试项目，部署到两台 tomcat 上，eclipse 新建 web 项目，项目名为 testproject，在 webapp 下新建一个 jsp 页面为 index.jsp, 添加如下内容 maven导出为 war 包，spring-demo.war，将该 war 包上传到服务器的两台 tomcat 的 webapps 中 此时，重新启动 tomcat，访问 192.168.43.3:8080，192.168.43.3:8081, 显示 index.jsp 内容：两台服务器访问显示如下 至此，两台 tomcat 服务器搭建完成。 三：Nginx的安装配置与测试先使用 yum 命令安装 gcc，安装 pcre，zlib，openssl：1234yum install -y gcc yum install -y pcre pcre-devel yum install -y zlib zlib-devel yum install -y openssl openssl-develplain 在 /root/wyj/tools 目录下新建 nginx 目录，将 nginx-1.17.7.tar.gz 放到此处，解压1tar -zxvf nginx-1.17.7.tar.gz 进入解压后目录依次执行命令：12345./configure make mkae install 此时 nginx 安装完毕，安装目录是 /usr/local/nginx，nginx 默认占用 80 端口其中，sbin 目录为 nginx 执行命令，conf 目录下的 nginx.conf 为默认加载的配置文件 启动 nginx：1./nginx 关闭 nginx：1./nginx -s stop 重启1./nginx -s reload 启动 nginx 后访问 192.168.50.133:80 即可访问 nginx：显示 nginx 欢迎页 至此，nginx 安装完毕。 四：反向代理与负载均衡配置现有一台服务器，为 192.168.43.3，服务器上有一台 tomcat，端口为 8080 和 8081，经过配置 nginx，当访问 192.168.43.3:80 时，即可访问 192.168.43.3:8080，192.168.43.3:8081 中随机一台，此时 192.168.43.3:80 被 nginx 监听，当有请求时，代理到 192.168.43.3:8080，192.168.43.3:8081 随机一台即可，即为 nginx 反向代理功能，同时此时可以通过 nginx 将请求进行转发，保证了一个入口，将所有请求转发到两台服务器上也减轻了任何一台的负载压力，当有大量请求时，可以搭建大量服务器，在入口代理服务器上使用 nginx 进行转发，即是负载均衡功能。 配置即是配置 nginx 安装目录中 conf 目录下的 nginx.conf 文件即可：具体配置如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; #配置被代理的服务器 upstream blank &#123; #ip_hash; server 192.168.43.3:8080 weight=2; server 192.168.43.3:8081 weight=1; &#125; server &#123; #nginx监听80端口，请求该端口时转发到真实目标 listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; #这里配置代理是指上面定义的两个被代理目标，blank名字必须一致 proxy_pass http://blank; root html; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 启动两台 tomcat，重新启动 nginx： 访问 192.168.43.3:80 将会随机访问 192.168.43.3:8080 和 192.168.43.3:8081 其中一台。（问题：每次刷新 nginx 服务器地址 sessionid 会变，session 不能共享。） 尝试不断刷新，两个页面会交替显示，即成功。但发现SessionID并不相同，下一篇博文来通过Redis来实现Session的共享（同步）。","tags":[{"name":"nginx","slug":"nginx","permalink":"http://wangyuanjun.cn/tags/nginx/"}]},{"title":"HTML/CSS基础知识学习笔记","date":"2018-01-11T09:21:16.000Z","path":"2018/01/11/HTML-CSS基础知识学习笔记/","text":"","tags":[]},{"title":"Dubbo学习——Dubbo-admin管理平台搭建(三)","date":"2018-01-11T03:05:23.000Z","path":"2018/01/11/Dubbo学习——Dubbo-admin管理平台搭建-三/","text":"一：前言上一篇博文介绍的是dubbo的使用，包括有注册中心，消费者，提供者的使用，但是并不能看到有哪些消费者和提供者，为了更好的调试，发现问题，解决问题，因此引入dubbo-admin。通过dubbo-admin可以对消费者和提供者进行管理。 二：下载与配置打包dubbo-admin的下载，可自行到官网下载：https://github.com/alibaba/dubbo 但是这里我们只关心dubbo-admin这个文件夹。打包war包，进入dubbo-admin这个文件目录 运行命令： 1mvn package -Dmaven.skip.test=true 打包成功之后，就会发现dubbo-admin下多了个target文件夹，打开target文件夹，发现里面有个war包： 三：安装dubbo-admin 第二步我们得到dubbo-admin-2.5.8-SNAPSHOT.war，把dubbo-admin-2.5.8-SNAPSHOT.war放到tomcat的webapps目录下，然后启动tomcat,启动完成后停tomcat，得到解压后的dubbo-admin 打开刚刚tomcat解压生成的dubbo.properties 123dubbo.registry.address=zookeeper://192.168.99.100:2181dubbo.admin.root.password=rootdubbo.admin.guest.password=guest 修改zookeeper地址为192.168.99.100:2181 帐号：root,密码：root,待会儿登录用 四：运行 先启动zookeeper，然后再启动tomcat帐号：root;密码:root 查看提供者 查看消费者：","tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://wangyuanjun.cn/tags/Dubbo/"}]},{"title":"Dubbo学习——Dubbo简单入门Demo(二)","date":"2018-01-10T15:16:22.000Z","path":"2018/01/10/Dubbo学习——Dubbo简单入门Demo-二/","text":"本文采用Dubbo与Zookeeper、Spring框架的整合。整个项目的代码已经上传到我的github https://github.com/wangyuanjun008/wyj-dubbo-demo.git 欢迎查看。主要是以下几个步骤： 安装Zookeeper,启动； 创建MAVEN项目，构建Dubbo+Zookeeper+Spring实现的简单Demo； 安装Dubbo-admin，实现监控。 一：Zookeeper介绍与安装本Demo中的Dubbo注册中心采用的是Zookeeper。为什么采用Zookeeper呢？123Zookeeper是一个分布式的服务框架，是树型的目录服务的数据存储，能做到集群管理数据 ，这里能很好的作为Dubbo服务的注册中心。Dubbo能与Zookeeper做到集群部署，当提供者出现断电等异常停机时，Zookeeper注册中心能自动删除提供者信息，当提供者重启时，能自动恢复注册数据，以及订阅请求 到官网下载并安装到windows上，可参考博文： http://blog.csdn.net/tlk20071/article/details/52028945我使用的是docker容器，在docker上下载zooleeper镜像,然后使用如下命令创建并启动zookeeper容器，映射与本机的端口号1docker run --name zookeeper -p 2181:2181 -p 2888:2888 -p 3888:3888 -d zookeeper:latest 我之前下载过，所以我直接启动zookeeper容器 二：创建MAVEN项目项目结构：主要分三大模块：dubbo-api : 存放公共接口；dubbo-consumer : 调用远程服务；dubbo-provider : 提供远程服务。 下面将详细叙述代码构建过程。 首先构建MAVEN项目，导入所需要的jar包依赖。需要导入的有spring, dubbo, zookeeper等jar包。(详情参看后面提供的项目代码) 建dubbo-api的MAVEN项目(有独立的pom.xml，用来打包供提供者消费者使用)。在项目中定义服务接口：该接口需单独打包，在服务提供方和消费方共享。 12345678910111213package com.wyj.dubbo.demo;/** * 定义服务接口 * * * @author：WangYuanJun * @date：2018年1月9日 下午9:03:40 */public interface DemoService &#123; String sayHello(String name); &#125; 创建dubbo-provider的MAVEN项目(有独立的pom.xml，用来打包供消费者使用)。 实现公共接口，此实现对消费者隐藏： 123456789101112131415161718package com.wyj.dubbo.demo.provider;import com.wyj.dubbo.demo.DemoService;/** * 服务提供者实现服务定义 * * * @author：WangYuanJun * @date：2018年1月9日 下午9:07:16 */public class DemoServiceImpl implements DemoService &#123; public String sayHello(String name) &#123; return &quot;Hello &quot; + name; &#125;&#125; 需加入公共接口所在的依赖 用Spring配置声明暴露服务 12345678910111213141516171819202122&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;!--定义了提供方应用信息，用于计算依赖关系；在 dubbo-admin 或 dubbo-monitor 会显示这个名字，方便辨识 --&gt; &lt;dubbo:application name=&quot;demotest-provider&quot; owner=&quot;programmer&quot; organization=&quot;dubbox&quot; /&gt; &lt;!--使用 zookeeper 注册中心暴露服务，注意要先开启 zookeeper --&gt; &lt;dubbo:registry address=&quot;zookeeper://192.168.99.100:2181&quot; /&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot; /&gt; &lt;!--使用 dubbo 协议实现定义好的 api.PermissionService 接口 --&gt; &lt;dubbo:service interface=&quot;com.wyj.dubbo.demo.DemoService&quot; ref=&quot;demoService&quot; protocol=&quot;dubbo&quot; /&gt; &lt;!--具体实现该接口的 bean --&gt; &lt;bean id=&quot;demoService&quot; class=&quot;com.wyj.dubbo.demo.provider.DemoServiceImpl&quot; /&gt; &lt;/beans&gt; 启动远程服务： 123456789101112131415161718192021222324package com.wyj.dubbo.demo.provider;import java.io.IOException;import org.springframework.context.support.ClassPathXmlApplicationContext;/** * 启动服务提供者 * * * @author：WangYuanJun * @date：2018年1月9日 下午9:10:38 */public class Provider &#123; public static void main(String[] args) throws IOException &#123; ClassPathXmlApplicationContext classPathXmlApplicationContext = new ClassPathXmlApplicationContext(&quot;dubbo-provider.xml&quot;); System.out.println(classPathXmlApplicationContext.getDisplayName() + &quot;: here&quot;); classPathXmlApplicationContext.start(); System.out.println(&quot;服务已经启动...&quot;); System.in.read(); &#125;&#125; 创建dubbo-consumer的MAVEN项目(可以有多个consumer，但是需要配置好)。 调用所需要的远程服务： 通过Spring配置引用远程服务： 123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;dubbo:application name=&quot;demotest-consumer&quot; owner=&quot;programmer&quot; organization=&quot;dubbox&quot; /&gt; &lt;!--向 zookeeper 订阅 provider 的地址，由 zookeeper 定时推送 --&gt; &lt;dubbo:registry address=&quot;zookeeper://192.168.99.100:2181&quot; /&gt; &lt;!--使用 dubbo 协议调用定义好的 api.demoService 接口 --&gt; &lt;dubbo:reference id=&quot;demoService&quot; interface=&quot;com.wyj.dubbo.demo.DemoService&quot; /&gt; &lt;/beans&gt; 启动Consumer,调用远程服务： 1234567891011121314151617181920212223242526272829303132333435package com.wyj.dubbo.demo.consumer;import org.springframework.context.support.ClassPathXmlApplicationContext;import com.wyj.dubbo.demo.DemoService;/** * 启动服务消费者 * * * @author：WangYuanJun * @date：2018年1月9日 下午10:00:33 */public class Consumer &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext classPathXmlApplicationContext = new ClassPathXmlApplicationContext(&quot;dubbo-consumer.xml&quot;); classPathXmlApplicationContext.start(); DemoService demoService = (DemoService) classPathXmlApplicationContext.getBean(&quot;demoService&quot;); while (true) &#123; try &#123; Thread.sleep(1000); String hello = demoService.sayHello(&quot;world&quot;); System.out.println(hello); &#125; catch (Throwable throwable) &#123; throwable.printStackTrace(); &#125; &#125; &#125;&#125; 运行项目，先确保provider已被运行后再启动consumer模块： 运行提供者： 消费者成功调用提供者所提供的远程服务：","tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://wangyuanjun.cn/tags/Dubbo/"}]},{"title":"使用DaoCloud docker镜像加速器","date":"2018-01-10T06:10:46.000Z","path":"2018/01/10/使用DaoCloud docker镜像加速器/","text":"使用 Docker 的时候，需要经常从官方获取镜像，但是由于显而易见的网络原因，拉取镜像的过程非常耗时，严重影响使用Docker的体验。由于国内访问直接访问dockerhub网速比较慢，拉取镜像的时间就会比较长，甚至下载失败。一般我们会使用镜像加速或者直接从国内的一些平台镜像仓库上拉取。我之前准备用阿里云的加速器的，试了好长时间没有成功，于是改用DaoCloud，下面向大家介绍在windows环境下使用docker toolbox来配置镜像加速器。在docker客户端执行如下命令 docker-machine ssh default sudo sed -i &quot;s|EXTRA_ARGS=&apos;|EXTRA_ARGS=&apos;--registry-mirror=加速地址 |g&quot; /var/lib/boot2docker/profile exit docker-machine restart default 1.使用docker客户端连接名为default的虚拟机2.配置DaoCloud加速器3.退出虚拟机到docker客户端4.名为default的虚拟机重启 如果你想在linux,MC上配置加速器，请参考配置 Docker 加速器","tags":[{"name":"docker","slug":"docker","permalink":"http://wangyuanjun.cn/tags/docker/"}]},{"title":"Quartz学习——SSM和Quartz集成详解(四)","date":"2018-01-08T07:31:45.000Z","path":"2018/01/08/Quartz学习——SSM和Quartz集成详解-四/","text":"下面介绍SSM+Quartz的示例，项目地址: quartz-spring 一：环境介绍 123456工具：Spring Tool Suite + Mysql 框架：Spring+SpringMVC+Mybatis前端: easy ui 日志：logback 构建工具：Maven Quartz版本：2.2.3 二：SSM+Quartz集成详解1.项目结构 2.配置文件介绍（1）：在ApplicationContext.xml中添加下面的配置：123456&lt;bean name=&quot;quartzScheduler&quot; class=&quot;org.springframework.scheduling.quartz.SchedulerFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;!-- 读取spring配置的数据库，不去加载quartz.properties --&gt; &lt;property name=&quot;applicationContextSchedulerContextKey&quot; value=&quot;applicationContextKey&quot; /&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:quartz.properties&quot; /&gt;&lt;/bean&gt; （2）：添加quartz.properties配置文件12345678910111213141516171819202122232425# Default Properties file for use by StdSchedulerFactory # to create a Quartz Scheduler Instance, if a different # properties file is not explicitly specified. # org.quartz.scheduler.instanceName: DefaultQuartzScheduler#org.quartz.scheduler.instanceId = AUTO org.quartz.scheduler.rmi.export: false org.quartz.scheduler.rmi.proxy: false org.quartz.scheduler.wrapJobExecutionInUserTransaction: false org.quartz.threadPool.class: org.quartz.simpl.SimpleThreadPool org.quartz.threadPool.threadCount: 10 org.quartz.threadPool.threadPriority: 5 org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread: true #持久化配置org.quartz.jobStore.misfireThreshold: 60000 org.quartz.jobStore.class: org.quartz.impl.jdbcjobstore.JobStoreTX org.quartz.jobStore.driverDelegateClass: org.quartz.impl.jdbcjobstore.StdJDBCDelegate org.quartz.jobStore.useProperties:true #指定前缀org.quartz.jobStore.tablePrefix: QRTZ_ 3.核心代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238package com.wyj.controller;import java.util.ArrayList;import java.util.List;import java.util.Set;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.apache.commons.lang.StringUtils;import org.quartz.CronTrigger;import org.quartz.JobDataMap;import org.quartz.JobDetail;import org.quartz.JobKey;import org.quartz.Scheduler;import org.quartz.SchedulerException;import org.quartz.Trigger;import org.quartz.TriggerKey;import org.quartz.impl.matchers.GroupMatcher;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.ResponseBody;import com.alibaba.fastjson.JSON;import com.wyj.entity.JobDto;import com.wyj.entity.Retval;import com.wyj.service.QuartzService;/** * 定时任务 Controller * * * @author：WangYuanJun * @date：2018年1月7日 下午10:15:33 */@Controller@RequestMapping(value = &quot;/quartz&quot;)public class QuartzController &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private Scheduler quartzScheduler; @Autowired private QuartzService quartzService; @RequestMapping(&quot;/index&quot;) public String index() &#123; return &quot;/quartz/list&quot;; &#125; /** * 定时列表页 * * @return * @throws SchedulerException */ @ResponseBody @RequestMapping(value = &quot;/list&quot;) public String listJob(HttpServletRequest request, HttpServletResponse response) throws SchedulerException &#123; List&lt;JobDto&gt; jobInfos = this.getSchedulerJobInfo(); return JSON.toJSONString(jobInfos); &#125; /** * 新建job * * @param jobDto * @return */ @ResponseBody @RequestMapping(value = &quot;/add&quot;) public Retval save(JobDto jobDto) &#123; Retval retval = Retval.newInstance(); try &#123; quartzService.addJob(jobDto.getJobName(), jobDto.getJobGroupName(), jobDto.getTriggerName(), jobDto.getTriggerGroupName(), Class.forName(jobDto.getJobClass()), jobDto.getCronExpression()); &#125; catch (Exception e) &#123; logger.error(e.getMessage()); &#125; return retval; &#125; /** * 编辑job * * @param jobDto * @return */ @ResponseBody @RequestMapping(value = &quot;/edit&quot;, method = RequestMethod.POST) public Retval edit(JobDto jobDto) &#123; Retval retval = Retval.newInstance(); try &#123; boolean result = quartzService.modifyJobTime(jobDto.getOldJobName(), jobDto.getOldJobGroupName(), jobDto.getOldTriggerName(), jobDto.getOldTriggerGroupName(), jobDto.getJobName(), jobDto.getJobGroupName(), jobDto.getTriggerName(), jobDto.getTriggerGroupName(), jobDto.getCronExpression()); if (result) &#123; retval.put(&quot;message&quot;, &quot;修改任务成功!&quot;); &#125; else &#123; retval.put(&quot;message&quot;, &quot;修改任务失败!&quot;); &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage()); &#125; return retval; &#125; /** * 暂停job * * @param jobName * @param jobGroupName * @return */ @ResponseBody @RequestMapping(value = &quot;/stopJob&quot;, method = RequestMethod.POST) public Retval stopJob(@RequestParam(&quot;jobName&quot;) String jobName, @RequestParam(&quot;jobGroupName&quot;) String jobGroupName) &#123; Retval retval = Retval.newInstance(); if (StringUtils.isEmpty(jobName) || StringUtils.isEmpty(jobGroupName)) &#123; retval.fail(); retval.put(&quot;message&quot;, &quot;暂停失败&quot;); &#125; else &#123; try &#123; quartzService.pauseJob(jobName, jobGroupName); retval.put(&quot;message&quot;, &quot;暂停成功&quot;); &#125; catch (Exception e) &#123; logger.error(e.getMessage()); &#125; &#125; return retval; &#125; /** * 恢复job * * @param jobName * @param jobGroupName * @return */ @ResponseBody @RequestMapping(value = &quot;/resumeJob&quot;, method = RequestMethod.POST) public Retval resumeJob(@RequestParam(&quot;jobName&quot;) String jobName, @RequestParam(&quot;jobGroupName&quot;) String jobGroupName) &#123; Retval retval = Retval.newInstance(); if (StringUtils.isEmpty(jobName) || StringUtils.isEmpty(jobGroupName)) &#123; retval.fail(); retval.put(&quot;message&quot;, &quot;恢复失败&quot;); &#125; else &#123; try &#123; quartzService.resumeJob(jobName, jobGroupName); retval.put(&quot;message&quot;, &quot;恢复成功&quot;); &#125; catch (Exception e) &#123; logger.error(e.getMessage()); &#125; &#125; return retval; &#125; /** * 删除job * * @param jobName * @param jobGroupName * @param triggerName * @param triggerGroupName * @return */ @RequestMapping(value = &quot;/deleteJob&quot;, method = RequestMethod.POST) @ResponseBody public Retval deleteJob(@RequestParam(&quot;jobName&quot;) String jobName, @RequestParam(&quot;jobGroupName&quot;) String jobGroupName, @RequestParam(&quot;triggerName&quot;) String triggerName, @RequestParam(&quot;triggerGroupName&quot;) String triggerGroupName) &#123; Retval retval = Retval.newInstance(); if (StringUtils.isEmpty(jobName) || StringUtils.isEmpty(jobGroupName) || StringUtils.isEmpty(triggerName) || StringUtils.isEmpty(triggerGroupName)) &#123; retval.fail(); retval.put(&quot;message&quot;, &quot;删除失败&quot;); &#125; else &#123; try &#123; quartzService.removeJob(jobName, jobGroupName, triggerName, triggerGroupName); retval.put(&quot;message&quot;, &quot;删除成功&quot;); &#125; catch (Exception e) &#123; logger.error(e.getMessage()); &#125; &#125; return retval; &#125; private List&lt;JobDto&gt; getSchedulerJobInfo() throws SchedulerException &#123; List&lt;JobDto&gt; jobInfos = new ArrayList&lt;JobDto&gt;(); List&lt;String&gt; triggerGroupNames = quartzScheduler.getTriggerGroupNames(); for (String triggerGroupName : triggerGroupNames) &#123; Set&lt;TriggerKey&gt; triggerKeySet = quartzScheduler.getTriggerKeys(GroupMatcher.triggerGroupEquals(triggerGroupName)); for (TriggerKey triggerKey : triggerKeySet) &#123; Trigger t = quartzScheduler.getTrigger(triggerKey); if (t instanceof CronTrigger) &#123; CronTrigger trigger = (CronTrigger) t; JobKey jobKey = trigger.getJobKey(); JobDetail jd = quartzScheduler.getJobDetail(jobKey); JobDto jobInfo = new JobDto(); jobInfo.setJobName(jobKey.getName()); jobInfo.setJobGroupName(jobKey.getGroup()); jobInfo.setTriggerName(triggerKey.getName()); jobInfo.setTriggerGroupName(triggerKey.getGroup()); jobInfo.setCronExpression(trigger.getCronExpression()); jobInfo.setNextFireTime(trigger.getNextFireTime()); jobInfo.setPreviousFireTime(trigger.getPreviousFireTime()); jobInfo.setStartTime(trigger.getStartTime()); jobInfo.setEndTime(trigger.getEndTime()); jobInfo.setJobClass(jd.getJobClass().getCanonicalName()); // jobInfo.setDuration(Long.parseLong(jd.getDescription())); Trigger.TriggerState triggerState = quartzScheduler.getTriggerState(trigger.getKey()); jobInfo.setJobStatus(triggerState.toString());// NONE无, // NORMAL正常, // PAUSED暂停, // COMPLETE完全, // ERROR错误, // BLOCKED阻塞 JobDataMap map = quartzScheduler.getJobDetail(jobKey).getJobDataMap(); if (null != map &amp;&amp; map.size() != 0) &#123; jobInfo.setCount(Long.valueOf((String) map.get(&quot;count&quot;))); jobInfo.setJobDataMap(map); &#125; else &#123; jobInfo.setJobDataMap(new JobDataMap()); &#125; jobInfos.add(jobInfo); &#125; &#125; &#125; return jobInfos; &#125;&#125; 4.job12345678910111213141516171819202122package com.wyj.job;import java.util.Date;import org.quartz.Job;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;/** * Job任务 * * * @author：WangYuanJun * @date：2018年1月5日 下午10:22:42 */public class HelloWorldJob implements Job &#123; @Override public void execute(JobExecutionContext context) throws JobExecutionException &#123; System.out.println(&quot;----hello world---&quot; + new Date()); &#125;&#125; 三：运行效果介绍","tags":[{"name":"quartz","slug":"quartz","permalink":"http://wangyuanjun.cn/tags/quartz/"}]},{"title":"Quartz学习——Spring和Quartz集成详解(三)","date":"2018-01-08T06:46:30.000Z","path":"2018/01/08/Quartz学习——Spring和Quartz集成详解-三/","text":"下面介绍Spring集成Quartz的示例，项目地址: quartz-spring介绍Spring和Quartz集成存储方式使用的是RAM方式和JDBC方式！ jar包依赖&lt;properties&gt; &lt;!-- 项目构建源码编码方式 --&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;!-- 主要依赖库的版本定义 --&gt; &lt;!-- spring版本号 --&gt; &lt;spring.version&gt;4.0.2.RELEASE&lt;/spring.version&gt; &lt;!-- 日志文件管理包版本 --&gt; &lt;slf4j.version&gt;1.7.7&lt;/slf4j.version&gt; &lt;junit.version&gt;4.11&lt;/junit.version&gt; &lt;jackson.version&gt;2.4.0&lt;/jackson.version&gt; &lt;mysql.version&gt;5.1.30&lt;/mysql.version&gt; &lt;quartz.version&gt;2.2.3&lt;/quartz.version&gt; &lt;fastjson.version&gt;1.1.41&lt;/fastjson.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- spring核心包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-oxm&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 导入java ee jar 包 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax&lt;/groupId&gt; &lt;artifactId&gt;javaee-api&lt;/artifactId&gt; &lt;version&gt;7.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- JSTL标签类 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 日志文件管理包 --&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.logback-extensions&lt;/groupId&gt; &lt;artifactId&gt;logback-ext-spring&lt;/artifactId&gt; &lt;version&gt;0.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 代码直接调用commons-logging会被桥接到slf4j --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 代码直接调用java.util.logging会被桥接到slf4j --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jul-to-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 格式化对象，方便输出日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;${fastjson.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 导入Mysql数据库链接jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- velocity --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity&lt;/artifactId&gt; &lt;version&gt;1.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-tools&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- JSON begin --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;${jackson.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;${jackson.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.module&lt;/groupId&gt; &lt;artifactId&gt;jackson-module-jaxb-annotations&lt;/artifactId&gt; &lt;version&gt;${jackson.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- freemarker --&gt; &lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;2.3.27-incubating&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;${quartz.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz-jobs&lt;/artifactId&gt; &lt;version&gt;${quartz.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 配置文件spring-quartz.xmlRAM存储方式的xml配置文件（1）：配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.0.xsd&quot;&gt; &lt;!-- ====================================RAM版============================================== --&gt; &lt;!-- Spring整合Quartz进行配置遵循下面的步骤： 1：定义工作任务的Job 2：定义触发器Trigger，并将触发器与工作任务绑定 3：定义调度器，并将Trigger注册到Scheduler --&gt; &lt;!-- 1：定义任务的bean ，这里使用JobDetailFactoryBean,也可以使用MethodInvokingJobDetailFactoryBean ，配置类似--&gt; &lt;bean name=&quot;hwJob&quot; class=&quot;org.springframework.scheduling.quartz.JobDetailFactoryBean&quot;&gt; &lt;!-- 指定job的名称 --&gt; &lt;property name=&quot;name&quot; value=&quot;hw_job&quot;/&gt; &lt;!-- 指定job的分组 --&gt; &lt;property name=&quot;group&quot; value=&quot;hw_group&quot;/&gt; &lt;!-- 指定具体的job类 --&gt; &lt;property name=&quot;jobClass&quot; value=&quot;com.wyj.exampleRAM.RAMJob&quot;/&gt; &lt;!-- 必须设置为true，如果为false，当没有活动的触发器与之关联时会在调度器中会删除该任务 --&gt; &lt;property name=&quot;durability&quot; value=&quot;true&quot;/&gt; &lt;!-- 指定spring容器的key，如果不设定在job中的jobmap中是获取不到spring容器的 --&gt; &lt;property name=&quot;applicationContextJobDataKey&quot; value=&quot;applicationContext&quot;/&gt; &lt;/bean&gt; &lt;!-- 2.1：定义触发器的bean，定义一个Simple的Trigger，一个触发器只能和一个任务进行绑定 --&gt; &lt;!-- &lt;bean name=&quot;simpleTrigger&quot; class=&quot;org.springframework.scheduling.quartz.SimpleTriggerFactoryBean&quot;&gt; 指定Trigger的名称 &lt;property name=&quot;name&quot; value=&quot;hw_trigger&quot;/&gt; 指定Trigger的名称 &lt;property name=&quot;group&quot; value=&quot;hw_trigger_group&quot;/&gt; 指定Tirgger绑定的Job &lt;property name=&quot;jobDetail&quot; ref=&quot;hwJob&quot;/&gt; 指定Trigger的延迟时间 1s后运行 &lt;property name=&quot;startDelay&quot; value=&quot;1000&quot;/&gt; 指定Trigger的重复间隔 5s &lt;property name=&quot;repeatInterval&quot; value=&quot;5000&quot;/&gt; 指定Trigger的重复次数 &lt;property name=&quot;repeatCount&quot; value=&quot;5&quot;/&gt; &lt;/bean&gt; --&gt; &lt;!-- 2.2：定义触发器的bean，定义一个Cron的Trigger，一个触发器只能和一个任务进行绑定 --&gt; &lt;bean id=&quot;cronTrigger&quot; class=&quot;org.springframework.scheduling.quartz.CronTriggerFactoryBean&quot;&gt; &lt;!-- 指定Trigger的名称 --&gt; &lt;property name=&quot;name&quot; value=&quot;hw_trigger&quot;/&gt; &lt;!-- 指定Trigger的名称 --&gt; &lt;property name=&quot;group&quot; value=&quot;hw_trigger_group&quot;/&gt; &lt;!-- 指定Tirgger绑定的Job --&gt; &lt;property name=&quot;jobDetail&quot; ref=&quot;hwJob&quot;/&gt; &lt;!-- 指定Cron 的表达式 ，当前是每隔1s运行一次 --&gt; &lt;property name=&quot;cronExpression&quot; value=&quot;0/1 * * * * ?&quot; /&gt; &lt;/bean&gt; &lt;!-- 3.定义调度器，并将Trigger注册到调度器中--&gt; &lt;bean name=&quot;scheduler&quot; class=&quot;org.springframework.scheduling.quartz.SchedulerFactoryBean&quot;&gt; &lt;property name=&quot;triggers&quot;&gt; &lt;list&gt;&lt;!-- &lt;ref bean=&quot;simpleTrigger&quot;/&gt; --&gt; &lt;ref bean=&quot;cronTrigger&quot;/&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; （2）：运行结果CronScheduleBuilder： JDBC存储方式的xml配置文件（1）：配置文件 1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.0.xsd&quot;&gt; &lt;!-- ====================================JDBC版============================================== --&gt; &lt;!-- 持久化数据配置，需要添加quartz.properties --&gt; &lt;bean name=&quot;scheduler&quot; class=&quot;org.springframework.scheduling.quartz.SchedulerFactoryBean&quot;&gt; &lt;property name=&quot;applicationContextSchedulerContextKey&quot; value=&quot;applicationContextKey&quot;/&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:quartz.properties&quot;/&gt; &lt;/bean&gt; &lt;/beans&gt; （2）：quartz.properties123456789101112131415161718192021222324252627282930313233343536# Default Properties file for use by StdSchedulerFactory # to create a Quartz Scheduler Instance, if a different # properties file is not explicitly specified. # #org.quartz.scheduler.instanceName: DefaultQuartzScheduler org.quartz.scheduler.instanceName: DefaultQuartzScheduler#org.quartz.scheduler.instanceId = AUTO org.quartz.scheduler.rmi.export: false org.quartz.scheduler.rmi.proxy: false org.quartz.scheduler.wrapJobExecutionInUserTransaction: false org.quartz.threadPool.class: org.quartz.simpl.SimpleThreadPool org.quartz.threadPool.threadCount: 10 org.quartz.threadPool.threadPriority: 5 org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread: true #创建数据源org.quartz.jobStore.misfireThreshold: 60000 #JDBC连接方式org.quartz.jobStore.class: org.quartz.impl.jdbcjobstore.JobStoreTX #JDBC代理类 org.quartz.jobStore.driverDelegateClass: org.quartz.impl.jdbcjobstore.StdJDBCDelegate org.quartz.jobStore.useProperties:true #指定前缀org.quartz.jobStore.tablePrefix: QRTZ_#数据源名称org.quartz.jobStore.dataSource: qzDS #配置数据源属性 org.quartz.dataSource.qzDS.driver:com.mysql.jdbc.Driverorg.quartz.dataSource.qzDS.URL:jdbc:mysql://192.168.99.100:3306/quartz_test?useUnicode=true&amp;characterEncoding=utf-8org.quartz.dataSource.qzDS.user:rootorg.quartz.dataSource.qzDS.password:adminorg.quartz.dataSource.qzDS.maxConnections:10 （3）：job123456789101112131415161718192021222324252627282930313233package com.wyj.exampleJDBC;import java.text.SimpleDateFormat;import java.util.Date;import org.quartz.Job;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.slf4j.Logger;import org.slf4j.LoggerFactory;/** * JdbcJob * * * @author：WangYuanJun * @date：2017年12月29日 下午10:05:18 */public class JdbcJob implements Job&#123; private Logger logger = LoggerFactory.getLogger(JdbcJob.class); public void execute(JobExecutionContext arg0) throws JobExecutionException &#123; logger.debug(&quot;MyJDBCJob is start ...&quot;); logger.debug(&quot;MyJDBCJob quzrtz &quot;+new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss &quot;).format(new Date())); logger.debug(&quot;MyJDBCJob is end ...&quot;); &#125; &#125; （4）：jobTest123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109package com.wyj.exampleJDBC;import java.util.List;import org.quartz.CronScheduleBuilder;import org.quartz.CronTrigger;import org.quartz.JobBuilder;import org.quartz.JobDetail;import org.quartz.JobKey;import org.quartz.Scheduler;import org.quartz.SchedulerException;import org.quartz.SchedulerFactory;import org.quartz.SimpleScheduleBuilder;import org.quartz.SimpleTrigger;import org.quartz.Trigger;import org.quartz.TriggerBuilder;import org.quartz.impl.StdScheduler;import org.quartz.impl.StdSchedulerFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;/** * JdbcJobtest * * * @author：WangYuanJun * @date：2017年12月29日 下午10:05:26 */public class QuartzJdbcTest &#123; private static Scheduler scheduler; public static void main(String[] args) &#123; ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;spring-quartz.xml&quot;); scheduler = (StdScheduler)ac.getBean(&quot;scheduler&quot;); testStartSchedule(); &#125; /** * 开始一个simpleSchedule()调度 */ public static void testStartSchedule()&#123; try &#123; // 1、创建一个JobDetail实例，指定Quartz JobDetail jobDetail = JobBuilder.newJob(JdbcJob.class) // 任务执行类 .withIdentity(&quot;job_1&quot;, &quot;jGroup1&quot;)// 任务名，任务组 .build(); //触发器类型 //SimpleScheduleBuilder builder = SimpleScheduleBuilder.simpleSchedule().repeatSecondlyForTotalCount(5); // 设置执行次数 CronScheduleBuilder builder = CronScheduleBuilder.cronSchedule(&quot;0/2 * * * * ?&quot;); // 2、创建Trigger Trigger trigger = TriggerBuilder.newTrigger() .withIdentity(&quot;trigger_1&quot;,&quot;triggerGroup1&quot;) .withSchedule(builder) .build(); // 3、创建Scheduler Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler(); scheduler.start(); // 4、调度执行 scheduler.scheduleJob(jobDetail,trigger); try &#123; Thread.sleep(60000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; //关闭调度器 scheduler.shutdown(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 从数据库中找到已经存在的job，并重新开户调度 */ public static void resumeJob()&#123; try &#123; SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); JobKey jobKey = new JobKey(&quot;job1_1&quot;, &quot;jGroup1&quot;); List&lt;? extends Trigger&gt; triggers = scheduler.getTriggersOfJob(jobKey); //SELECT TRIGGER_NAME, TRIGGER_GROUP FROM &#123;0&#125;TRIGGERS WHERE SCHED_NAME = &#123;1&#125; AND JOB_NAME = ? AND JOB_GROUP = ? // 重新恢复在jGroup1组中，名为job1_1的 job的触发器运行 if(triggers.size() &gt; 0)&#123; for (Trigger tg : triggers) &#123; // 根据类型判断 if ((tg instanceof CronTrigger) || (tg instanceof SimpleTrigger)) &#123; // 恢复job运行 scheduler.resumeJob(jobKey); &#125; &#125; scheduler.start(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 运行结果：CronScheduleBuilder：","tags":[{"name":"quartz","slug":"quartz","permalink":"http://wangyuanjun.cn/tags/quartz/"}]},{"title":"Quartz学习——Quartz简单入门Demo(二)","date":"2018-01-03T07:50:18.000Z","path":"2018/01/03/Quartz学习——Quartz简单入门Demo-二/","text":"下面介绍Quartz入门的示例，项目地址: quartz-demo由于Quartz的存储方式分为RAM和JDBC，分别对这两种进行简单的说明。并附上代码！首先需要添加Quartz的依赖 ，我使用的是quartz.2.2.3版本！ &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz-jobs&lt;/artifactId&gt; &lt;version&gt;2.2.3&lt;/version&gt; &lt;/dependency&gt; RAM方式要测试RAMdemo的代码，请先删除demo中这个quartz.properties文件，或者重命名！否则会测试不成功！（1）：Job package com.wyj.exampleRAM; import java.util.Date; import org.quartz.Job; import org.quartz.JobExecutionContext; import org.quartz.JobExecutionException; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * RAMjob * * * @author：WangYuanJun * @date：2017年12月28日 下午10:03:31 */ public class RAMJob implements Job{ private Logger logger = LoggerFactory.getLogger(RAMJob.class); public void execute(JobExecutionContext arg0) throws JobExecutionException { logger.debug(&quot;hello world ! hello Quartz - &quot;+new Date()); } } （2）：JobTest package com.wyj.exampleRAM; import java.util.Date; import org.quartz.CronScheduleBuilder; import org.quartz.JobBuilder; import org.quartz.JobDetail; import org.quartz.Scheduler; import org.quartz.SchedulerException; import org.quartz.SchedulerFactory; import org.quartz.Trigger; import org.quartz.TriggerBuilder; import org.quartz.impl.StdSchedulerFactory; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * RAMtest * * * @author：WangYuanJun * @date：2017年12月28日 下午10:03:50 */ public class RAMQuartzTest { private static Logger logger = LoggerFactory.getLogger(RAMJob.class); public static void main(String[] args) throws SchedulerException { //1.创建Scheduler的工厂 SchedulerFactory sf = new StdSchedulerFactory(); //2.从工厂中获取调度器实例 Scheduler scheduler = sf.getScheduler(); //3.创建JobDetail JobDetail jb = JobBuilder.newJob(RAMJob.class) .withDescription(&quot;this is hello job&quot;)//job的描述 .withIdentity(&quot;helloJob&quot;, &quot;helloGroup&quot;)//job 的name和group .build(); //任务运行的时间，SimpleSchedle类型触发器有效 long time= System.currentTimeMillis() + 3*1000L; //3秒后启动任务 Date statTime = new Date(time); //4.创建Trigger //使用SimpleScheduleBuilder或者CronScheduleBuilder Trigger trigger = TriggerBuilder.newTrigger() .withDescription(&quot;&quot;) .withIdentity(&quot;helloTrigger&quot;, &quot;helloTriggerGroup&quot;) .startAt(statTime)//默认当前时间启动 .withSchedule(CronScheduleBuilder.cronSchedule(&quot;0/2 * * * * ?&quot;))//两秒执行一次 .build(); //5.注册任务和定时器 scheduler.scheduleJob(jb, trigger); //6.启动 调度器 scheduler.start(); logger.debug(&quot;启动时间 ：&quot;+new Date()); } } 运行结果：SimpleScheduleBuilder： CronScheduleBuilder： JDBC方式使用jdbc方式，就要配置quartz.properties文件，并且在开始的时候在数据库中新增表！我使用的数据库是mysql，数据库中表在wyj-quartz-demo项目里面有，需要的请在里面下载！运行 tables_mysql.sql 这个文件。 #配置数据源属性 org.quartz.dataSource.qzDS.driver:com.mysql.jdbc.Driver org.quartz.dataSource.qzDS.URL:jdbc:mysql://192.168.99.100:3306/quartz_test?useUnicode=true&amp;characterEncoding=utf-8 org.quartz.dataSource.qzDS.user:root org.quartz.dataSource.qzDS.password:admin org.quartz.dataSource.qzDS.maxConnections:10 （1）job package com.wyj.exampleJDBC; import java.text.SimpleDateFormat; import java.util.Date; import org.quartz.Job; import org.quartz.JobExecutionContext; import org.quartz.JobExecutionException; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * JdbcJob * * * @author：WangYuanJun * @date：2017年12月28日 下午10:04:03 */ public class JdbcJob implements Job{ private Logger logger = LoggerFactory.getLogger(JdbcJob.class); public void execute(JobExecutionContext arg0) throws JobExecutionException { logger.debug(&quot;MyJDBCJob is start ...&quot;); logger.debug(&quot;MyJDBCJob quzrtz &quot;+new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss &quot;).format(new Date())); logger.debug(&quot;MyJDBCJob is end ...&quot;); } } （2）jobTest package com.wyj.exampleJDBC; import java.util.List; import org.quartz.CronScheduleBuilder; import org.quartz.CronTrigger; import org.quartz.JobBuilder; import org.quartz.JobDetail; import org.quartz.JobKey; import org.quartz.Scheduler; import org.quartz.SchedulerFactory; import org.quartz.SimpleTrigger; import org.quartz.Trigger; import org.quartz.TriggerBuilder; import org.quartz.impl.StdSchedulerFactory; /** * JdbcJobtest * * * @author：WangYuanJun * @date：2017年12月28日 下午10:04:14 */ public class QuartzJdbcTest { public static void main(String[] args) { testStartSchedule(); // resumeJob(); } /** * 开始一个simpleSchedule()调度 */ public static void testStartSchedule(){ try { // 1、创建一个JobDetail实例，指定Quartz JobDetail jobDetail = JobBuilder.newJob(JdbcJob.class) // 任务执行类 .withIdentity(&quot;job_1&quot;, &quot;jGroup1&quot;)// 任务名，任务组 .build(); //触发器类型 // SimpleScheduleBuilder builder = SimpleScheduleBuilder.simpleSchedule().repeatSecondlyForTotalCount(5); // 设置执行次数 CronScheduleBuilder builder = CronScheduleBuilder.cronSchedule(&quot;0/2 * * * * ?&quot;); // 2、创建Trigger Trigger trigger = TriggerBuilder.newTrigger() .withIdentity(&quot;trigger_1&quot;,&quot;triggerGroup1&quot;) .withSchedule(builder) .build(); // 3、创建Scheduler Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler(); scheduler.start(); // 4、调度执行 scheduler.scheduleJob(jobDetail,trigger); try { Thread.sleep(60000); } catch (Exception e) { e.printStackTrace(); } //关闭调度器 scheduler.shutdown(); } catch (Exception e) { e.printStackTrace(); } } /** * 从数据库中找到已经存在的job，并重新开户调度 */ public static void resumeJob(){ try { SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); JobKey jobKey = new JobKey(&quot;job1_1&quot;, &quot;jGroup1&quot;); List&lt;? extends Trigger&gt; triggers = scheduler.getTriggersOfJob(jobKey); //SELECT TRIGGER_NAME, TRIGGER_GROUP FROM {0}TRIGGERS WHERE SCHED_NAME = {1} AND JOB_NAME = ? AND JOB_GROUP = ? // 重新恢复在jGroup1组中，名为job1_1的 job的触发器运行 if(triggers.size() &gt; 0){ for (Trigger tg : triggers) { // 根据类型判断 if ((tg instanceof CronTrigger) || (tg instanceof SimpleTrigger)) { // 恢复job运行 scheduler.resumeJob(jobKey); } } scheduler.start(); } } catch (Exception e) { e.printStackTrace(); } } } 运行结果：数据库信息： 控制台信息： 注意:Cron和Simple类型，Simple类型的如果JobDetail没有设置.storeDurably(true)，则job在运行完成之后会在数据库中删除！","tags":[{"name":"quartz","slug":"quartz","permalink":"http://wangyuanjun.cn/tags/quartz/"}]},{"title":"Docker之创建并进入mysql容器","date":"2018-01-03T02:11:52.000Z","path":"2018/01/03/Docker之创建并进入mysql容器/","text":"本文介绍docker如何创建并进入MYSQL容器。 运行”docker pull mysql”获取mysql镜像[root@localhost ~]# docker pull mysql Using default tag: latest latest: Pulling from library/mysql 85b1f47fba49: Pull complete 5671503d4f93: Pull complete 3b43b3b913cb: Pull complete 4fbb803665d0: Pull complete 05808866e6f9: Pull complete 1d8c65d48cfa: Pull complete e189e187b2b5: Pull complete 02d3e6011ee8: Pull complete d43b32d5ce04: Pull complete 2a809168ab45: Pull complete Digest: sha256:1a2f9361228e9b10b4c77a651b460828514845dc7ac51735b919c2c4aec864b7 Status: Downloaded newer image for mysql:latest 在后台启动mysql容器(–name指定了容器的名称，方便之后进入容器的命令行，MYSQL_ROOT_PASSWORD=admin指定了mysql的root密码，-d表示在后台运行)Administrator@SKY-20170607FIJ MINGW64 ~ $ docker run --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=admin -d mysql c6215e8c1fd73bc395a0c92e93f7e7145baedbe99c7ff639ccc9f5641bddf583 进入容器bash并进入mysql命令行：Administrator@SKY-20170607FIJ MINGW64 ~ $ docker exec -it mysql bash root@c6215e8c1fd7:/# mysql -uroot -padmin mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 5 Server version: 5.7.20 MySQL Community Server (GPL) Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement. mysql&gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) mysql&gt; 退出mysql镜像输入 exit","tags":[{"name":"docker","slug":"docker","permalink":"http://wangyuanjun.cn/tags/docker/"}]},{"title":"常用mysql命令大全","date":"2018-01-03T01:40:56.000Z","path":"2018/01/03/常用mysql命令大全/","text":"1、连接Mysql格式： mysql -h主机地址 -u用户名 －p用户密码 1、连接到本机上的MYSQL。首先打开DOS窗口，然后进入目录mysql\\bin，再键入命令mysql -u root -p，回车后提示你输密码.注意用户名前可以有空格也可以没有空格，但是密码前必须没有空格，否则让你重新输入密码。 如果刚安装好MYSQL，超级用户root是没有密码的，故直接回车即可进入到MYSQL中了，MYSQL的提示符是： mysql&gt; 2、连接到远程主机上的MYSQL。假设远程主机的IP为：110.110.110.110，用户名为root,密码为abcd123。则键入以下命令： mysql -h110.110.110.110 -u root -p 123;（注:u与root之间可以不用加空格，其它也一样） 3、退出MYSQL命令exit （回车） 2、修改密码格式：mysqladmin -u用户名 -p旧密码 password 新密码 1、给root加个密码ab12。首先在DOS下进入目录mysql\\bin，然后键入以下命令 mysqladmin -u root -password ab12 注：因为开始时root没有密码，所以-p旧密码一项就可以省略了。 2、再将root的密码改为djg345。mysqladmin -u root -p ab12 password djg345 3、增加新用户注意：和上面不同，下面的因为是MYSQL环境中的命令，所以后面都带一个分号作为命令结束符 格式：grant select on 数据库.* to 用户名@登录主机 identified by “密码” 1、增加一个用户test1密码为abc，让他可以在任何主机上登录，并对所有数据库有查询、插入、修改、删除的权限。首先用root用户连入MYSQL，然后键入以下命令：grant select,insert,update,delete on *.* to [email=test1@”%]test1@”%[/email]” Identified by “abc”; 但增加的用户是十分危险的，你想如某个人知道test1的密码，那么他就可以在internet上的任何一台电脑上登录你的mysql数据库并对你的数据可以为所欲为了，解决办法见2。 2、增加一个用户test2密码为abc,让他只可以在localhost上登录，并可以对数据库mydb进行查询、插入、修改、删除的操作（localhost指本地主机，即MYSQL数据库所在的那台主机），这样用户即使用知道test2的密码，他也无法从internet上直接访问数据库，只能通过MYSQL主机上的web页来访问了。grant select,insert,update,delete on mydb.* to [email=test2@localhost]test2@localhost[/email] identified by “abc”; 如果你不想test2有密码，可以再打一个命令将密码消掉。 grant select,insert,update,delete on mydb.* to [email=test2@localhost]test2@localhost[/email] identified by “”; 4 数据库4.1 创建数据库注意：创建数据库之前要先连接Mysql服务器 命令：create database &lt;数据库名&gt; 例1：建立一个名为xhkdb的数据库 mysql&gt; create database xhkdb; 例2：创建数据库并分配用户 ①CREATE DATABASE 数据库名; ②GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP,ALTER ON 数据库名.* TO 数据库名@localhost IDENTIFIED BY ‘密码’; ③SET PASSWORD FOR ‘数据库名’@’localhost’ = OLD_PASSWORD(‘密码’); 依次执行3个命令完成数据库创建。注意：中文 “密码”和“数据库”是户自己需要设置的。 4.2 显示数据库命令：show databases （注意：最后有个s） mysql&gt; show databases; 注意：为了不再显示的时候乱码，要修改数据库默认编码。以下以GBK编码页面为例进行说明： 1、修改MYSQL的配置文件：my.ini里面修改default-character-set=gbk2、代码运行时修改： ①Java代码：jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=gbk ②PHP代码：header(“Content-Type:text/html;charset=gb2312”); ③C语言代码：int mysql_set_character_set( MYSQL mysql, char csname)；该函数用于为当前连接设置默认的字符集。字符串csname指定了1个有效的字符集名称。连接校对成为字符集的默认校对。该函数的工作方式与SET NAMES语句类似，但它还能设置mysql- &gt; charset的值，从而影响了由mysql_real_escape_string() 设置的字符集。 4.3 删除数据库命令：drop database &lt;数据库名&gt;例如：删除名为 xhkdb的数据库 mysql&gt; drop database xhkdb; 例子1：删除一个已经确定存在的数据库 mysql&gt; drop database drop_database; Query OK, 0 rows affected (0.00 sec) 例子2：删除一个不确定存在的数据库 mysql&gt; drop database drop_database; ERROR 1008 (HY000): Can’t drop database ‘drop_database’; database doesn’t exist //发生错误，不能删除’drop_database’数据库，该数据库不存在。 mysql&gt; drop database if exists drop_database; Query OK, 0 rows affected, 1 warning (0.00 sec)//产生一个警告说明此数据库不存在 mysql&gt; create database drop_database; Query OK, 1 row affected (0.00 sec) mysql&gt; drop database if exists drop_database;//if exists 判断数据库是否存在，不存在也不产生错误 Query OK, 0 rows affected (0.00 sec) 4.4 连接数据库命令： use &lt;数据库名&gt; 例如：如果xhkdb数据库存在，尝试存取它： mysql&gt; use xhkdb; 屏幕提示：Database changed use 语句可以通告MySQL把db_name数据库作为默认（当前）数据库使用，用于后续语句。该数据库保持为默认数据库，直到语段的结尾，或者直到发布一个不同的USE语句： mysql&gt; USE db1; mysql&gt; SELECT COUNT() FROM mytable; # selects from db1.mytable mysql&gt; USE db2; mysql&gt; SELECT COUNT() FROM mytable; # selects from db2.mytable 使用USE语句为一个特定的当前的数据库做标记，不会阻碍您访问其它数据库中的表。下面的例子可以从db1数据库访问作者表，并从db2数据库访问编辑表： mysql&gt; USE db1; mysql&gt; SELECT author_name,editor_name FROM author,db2.editor -&gt; WHERE author.editor_id = db2.editor.editor_id; USE语句被设立出来，用于与Sybase相兼容。 有些网友问到，连接以后怎么退出。其实，不用退出来，use 数据库后，使用show databases就能查询所有数据库，如果想跳到其他数据库，用 use 其他数据库名字就可以了。 4.5 当前选择的数据库命令：mysql&gt; select database(); MySQL中SELECT命令类似于其他编程语言里的print或者write，你可以用它来显示一个字符串、数字、数学表达式的结果等等。如何使用MySQL中SELECT命令的特殊功能？ 1.显示MYSQL的版本 mysql&gt; select version(); +-----------------------+ | version() | +-----------------------+ | 6.0.4-alpha-community | +-----------------------+ 1 row in set (0.02 sec) 2.显示当前时间 mysql&gt; select now(); +---------------------+ | now() | +---------------------+ | 2009-09-15 22:35:32 | +---------------------+ 1 row in set (0.04 sec) 3.显示年月日 SELECT DAYOFMONTH(CURRENT_DATE); +--------------------------+ | DAYOFMONTH(CURRENT_DATE) | +--------------------------+ | 15 | +--------------------------+ 1 row in set (0.01 sec) SELECT MONTH(CURRENT_DATE); +---------------------+ | MONTH(CURRENT_DATE) | +---------------------+ | 9 | +---------------------+ 1 row in set (0.00 sec) SELECT YEAR(CURRENT_DATE); +--------------------+ | YEAR(CURRENT_DATE) | +--------------------+ | 2009 | +--------------------+ 1 row in set (0.00 sec) 4.显示字符串 mysql&gt; SELECT &quot;welecome to my blog!&quot;; +----------------------+ | welecome to my blog! | +----------------------+ | welecome to my blog! | +----------------------+ 1 row in set (0.00 sec) 5.当计算器用 select ((4 * 4) / 10 ) + 25; +----------------------+ | ((4 * 4) / 10 ) + 25 | +----------------------+ | 26.60 | +----------------------+ 1 row in set (0.00 sec) 6.串接字符串 select CONCAT(f_name, &quot; &quot;, l_name) AS Name from employee_data where title = &apos;Marketing Executive&apos;; +---------------+ | Name | +---------------+ | Monica Sehgal | | Hal Simlai | | Joseph Irvine | +---------------+ 3 rows in set (0.00 sec) 注意：这里用到CONCAT()函数，用来把字符串串接起来。另外，我们还用到以前学到的AS给结果列’CONCAT(f_name, “ “, l_name)’起了个假名。 5 数据库表5.1 创建数据表命令：create table &lt;表名&gt; ( &lt;字段名1&gt; &lt;类型1&gt; [,..&lt;字段名n&gt; &lt;类型n&gt;]); 例如，建立一个名为MyClass的表，字段名 数字类型 数据宽度 是否为空 是否主键 自动增加 默认值id int 4 否 primary key auto_incrementname char 20 否sex int 4 否 0degree double 16 是 mysql&gt; create table MyClass( &gt; id int(4) not null primary key auto_increment, &gt; name char(20) not null, &gt; sex int(4) not null default &apos;0&apos;, &gt; degree double(16,2)); 5.2 删除数据表命令：drop table &lt;表名&gt; 例如：删除表名为 MyClass 的表 mysql&gt; drop table MyClass; DROP TABLE用于取消一个或多个表。您必须有每个表的DROP权限。所有的表数据和表定义会被取消，所以使用本语句要小心！ 注意：对于一个带分区的表，DROP TABLE会永久性地取消表定义，取消各分区，并取消储存在这些分区中的所有数据。DROP TABLE还会取消与被取消的表有关联的分区定义（.par）文件。 对与不存在的表，使用IF EXISTS用于防止错误发生。当使用IF EXISTS时，对于每个不存在的表，会生成一个NOTE。 RESTRICT和CASCADE可以使分区更容易。目前，RESTRICT和CASCADE不起作用。 5.3 表插入数据命令：insert into &lt;表名&gt; [( &lt;字段名1&gt;[,..&lt;字段名n &gt; ])] values ( 值1 )[, ( 值n )] 例如：往表 MyClass中插入二条记录, 这二条记录表示：编号为1的名为Tom的成绩为96.45, 编号为2 的名为Joan 的成绩为82.99， 编号为3 的名为Wang 的成绩为96.5。 mysql&gt; insert into MyClass values(1,’Tom’,96.45),(2,’Joan’,82.99), (2,’Wang’, 96.59); 注意：insert into每次只能向表中插入一条记录。 5.4 查询表中的数据1)、查询所有行命令： select &lt;字段1，字段2，…&gt; from &lt; 表名 &gt; where &lt; 表达式 &gt;例如：查看表 MyClass 中所有数据 mysql&gt; select * from MyClass; 2）、查询前几行数据例如：查看表 MyClass 中前2行数据 mysql&gt; select * from MyClass order by id limit 0,2; select一般配合where使用，以查询更精确更复杂的数据。 5.5 删除表中数据命令：delete from 表名 where 表达式 例如：删除表 MyClass中编号为1 的记录mysql&gt; delete from MyClass where id=1; 下面是一个删除数据前后表的对比。FirstName LastName AgePeter Griffin 35Glenn Quagmire 33下面以PHP代码为例删除 “Persons” 表中所有 LastName=’Griffin’ 的记录： &lt;?php $con = mysql_connect(&quot;localhost&quot;,&quot;peter&quot;,&quot;abc123&quot;); if (!$con) { die(&apos;Could not connect: &apos; . mysql_error()); } mysql_select_db(&quot;my_db&quot;, $con); mysql_query(&quot;DELETE FROM Persons WHERE LastName=&apos;Griffin&apos;&quot;); mysql_close($con); ?&gt; 在这次删除之后，表是这样的： FirstName LastName Age Glenn Quagmire 33 5.6 修改表中数据语法：update 表名 set 字段=新值,… where 条件 mysql&gt; update MyClass set name=&apos;Mary&apos; where id=1; 例子1：单表的MySQL UPDATE语句： UPDATE [LOW_PRIORITY] [IGNORE] tbl_name SET col_name1=expr1 [, col_name2=expr2 ...] [WHERE where_definition] [ORDER BY ...] [LIMIT row_count] 例子2：多表的UPDATE语句： UPDATE [LOW_PRIORITY] [IGNORE] table_references SET col_name1=expr1 [, col_name2=expr2 ...] [WHERE where_definition] UPDATE语法可以用新值更新原有表行中的各列。SET子句指示要修改哪些列和要给予哪些值。WHERE子句指定应更新哪些行。如果没有WHERE子句，则更新所有的行。如果指定了ORDER BY子句，则按照被指定的顺序对行进行更新。LIMIT子句用于给定一个限值，限制可以被更新的行的数目。 5.7 增加字段命令：alter table 表名 add字段 类型 其他;例如：在表MyClass中添加了一个字段passtest，类型为int(4)，默认值为0 mysql&gt; alter table MyClass add passtest int(4) default &apos;0&apos; 加索引 mysql&gt; alter table 表名 add index 索引名 (字段名1[，字段名2 …]); 例子： mysql&gt; alter table employee add index emp_name (name); 加主关键字的索引 mysql&gt; alter table 表名 add primary key (字段名); 例子： mysql&gt; alter table employee add primary key(id); 加唯一限制条件的索引 mysql&gt; alter table 表名 add unique 索引名 (字段名); 例子： mysql&gt; alter table employee add unique emp_name2(cardnumber); 删除某个索引 mysql&gt; alter table 表名 drop index 索引名; 例子： mysql&gt;alter table employee drop index emp_name; 增加字段： mysql&gt; ALTER TABLE table_name ADD field_name field_type; 修改原字段名称及类型： mysql&gt; ALTER TABLE table_name CHANGE old_field_name new_field_name field_type; 删除字段： MySQL ALTER TABLE table_name DROP field_name; 5.8 修改表名命令：rename table 原表名 to 新表名; 例如：在表MyClass名字更改为YouClass mysql&gt; rename table MyClass to YouClass; 当你执行 RENAME 时，你不能有任何锁定的表或活动的事务。你同样也必须有对原初表的 ALTER 和 DROP 权限，以及对新表的 CREATE 和 INSERT 权限。 如果在多表更名中，MySQL 遭遇到任何错误，它将对所有被更名的表进行倒退更名，将每件事物退回到最初状态。 RENAME TABLE 在 MySQL 3.23.23 中被加入。 6、备份数据库命令在DOS的[url=file://\\mysql\\bin]\\mysql\\bin[/url]目录下执行 1.导出整个数据库导出文件默认是存在mysql\\bin目录下 mysqldump -u 用户名 -p 数据库名 &gt; 导出的文件名 mysqldump -u user_name -p123456 database_name &gt; outfile_name.sql 2.导出一个表 mysqldump -u 用户名 -p 数据库名 表名&gt; 导出的文件名 mysqldump -u user_name -p database_name table_name &gt; outfile_name.sql 3.导出一个数据库结构 mysqldump -u user_name -p -d –add-drop-table database_name &gt; outfile_name.sql -d 没有数据 –add-drop-table 在每个create语句之前增加一个drop table 4.带语言参数导出 mysqldump -uroot -p –default-character-set=latin1 –set-charset=gbk –skip-opt database_name &gt; outfile_name.sql 例如，将aaa库备份到文件back_aaa中： [root@test1 root]# cd /home/data/mysql [root@test1 mysql]# mysqldump -u root -p –opt aaa &gt; back_aaa 7.1 一个建库和建表的实例1drop database if exists school; //如果存在SCHOOL则删除 create database school; //建立库SCHOOL use school; //打开库SCHOOL create table teacher //建立表TEACHER ( id int(3) auto_increment not null primary key, name char(10) not null, address varchar(50) default ‘深圳’, year date ); //建表结束 //以下为插入字段 insert into teacher values(”,’allen’,&apos;大连一中’,&apos;1976-10-10′); insert into teacher values(”,’jack’,&apos;大连二中’,&apos;1975-12-23′); 如果你在mysql提示符键入上面的命令也可以，但不方便调试。1、你可以将以上命令原样写入一个文本文件中，假设为school.sql，然后复制到c:\\下，并在DOS状态进入目录[url=file://\\mysql\\bin]\\mysql\\bin[/url]，然后键入以下命令： mysql -uroot -p密码 &lt; c:\\\\school.sql 如果成功，空出一行无任何显示；如有错误，会有提示。（以上命令已经调试，你只要将//的注释去掉即可使用）。 2、或者进入命令行后使用 mysql&gt; source c:\\school.sql; 也可以将school.sql文件导入数据库中。 7.2 一个建库和建表的实例2drop database if exists school; //如果存在SCHOOL则删除 create database school; //建立库SCHOOL use school; //打开库SCHOOL create table teacher //建立表TEACHER ( id int(3) auto_increment not null primary key, name char(10) not null, address varchar(50) default &apos;&apos;深圳&apos;&apos;, year date ); //建表结束 //以下为插入字段 insert into teacher values(&apos;&apos;&apos;&apos;,&apos;&apos;glchengang&apos;&apos;,&apos;&apos;深圳一中&apos;&apos;,&apos;&apos;1976-10-10&apos;&apos;); insert into teacher values(&apos;&apos;&apos;&apos;,&apos;&apos;jack&apos;&apos;,&apos;&apos;深圳一中&apos;&apos;,&apos;&apos;1975-12-23&apos;&apos;); 注：在建表中1、将ID设为长度为3的数字字段:int(3)；并让它每个记录自动加一:auto_increment；并不能为空:not null；而且让他成为主字段primary key。 2、将NAME设为长度为10的字符字段 3、将ADDRESS设为长度50的字符字段，而且缺省值为深圳。 4、将YEAR设为日期字段。 转载:Mysql命令大全","tags":[{"name":"mysql","slug":"mysql","permalink":"http://wangyuanjun.cn/tags/mysql/"}]},{"title":"Dubbo学习——Dubbo介绍(一)","date":"2017-12-28T01:40:51.000Z","path":"2017/12/28/Dubbo学习——Dubbo介绍-一/","text":"互联网的发展，网站应用的规模不断扩大，常规的垂直应用架构已无法应对，分布式服务架构以及流动计算架构势在必行，Dubbo是一个分布式服务框架，在这种情况下诞生的。现在核心业务抽取出来，作为独立的服务，使前端应用能更快速和稳定的响应。Dubbo是Alibaba开源的分布式服务框架，它最大的特点是按照分层的方式来架构，使用这种方式可以使各个层之间解耦合（或者最大限度地松耦合）。从服务模型的角度来看，Dubbo采用的是一种非常简单的模型，要么是提供方提供服务，要么是消费方消费服务，所以基于这一点可以抽象出服务提供方（Provider）和服务消费方（Consumer）两个角色。关于注册中心、协议支持、服务监控等内容，详见后面描述 一：Dubbo背景大规模服务化之前，应用可能只是通过RMI或Hessian等工具，简单的暴露和引用远程服务，通过配置服务的URL地址进行调用，通过F5等硬件进行负载均衡。 当服务越来越多时，服务URL配置管理变得非常困难，F5硬件负载均衡器的单点压力也越来越大。此时需要一个服务注册中心，动态的注册和发现服务，使服务的位置透明。并通过在消费方获取服务提供方地址列表，实现软负载均衡和Failover，降低对F5硬件负载均衡器的依赖，也能减少部分成本。 当进一步发展，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。这时，需要自动画出应用间的依赖关系图，以帮助架构师理清理关系。 接着，服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器？为了解决这些问题，第一步，要将服务现在每天的调用量，响应时间，都统计出来，作为容量规划的参考指标。其次，要可以动态调整权重，在线上，将某台机器的权重一直加大，并在加大的过程中记录响应时间的变化，直到响应时间到达阀值，记录此时的访问量，再以此访问量乘以机器数反推总容量。 二：Dubbo是什么？Dubbo是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案。简单的说，dubbo就是个服务框架，如果没有分布式的需求，其实是不需要用的，只有在分布式的时候，才有dubbo这样的分布式服务框架的需求，并且本质上是个服务调用的东东，说白了就是个远程服务调用的分布式框架（告别WebService模式中的WSdl，以服务者与消费者的方式在dubbo上注册）其核心部分包含: 远程通讯: 提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。 集群容错: 提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。 自动发现: 基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。 三：Dubbo能做什么 透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。 软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点。 服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。 Dubbo采用全Spring配置方式，透明化接入应用，对应用没有任何API侵入，只需用Spring加载Dubbo的配置即可，Dubbo基于Spring的Schema扩展进行加载。之前使用Web Service，我想测试接口可以通过模拟消息的方式通过soapui或LR进行功能测试或性能测试。但现在使用Dubbo，接口之间不能直接交互，我尝试通过模拟消费者地址测试，结果不堪入目，再而使用jmeter通过junit进行测试，但还是需要往dubbo上去注册，如果再不给提供源代码的前提下，这个测试用例不好写啊…. 四：Dubbo的简介节点角色说明： Provider: 暴露服务的服务提供方。 Consumer: 调用远程服务的服务消费方。 Registry: 服务注册与发现的注册中心。 Monitor: 统计服务的调用次调和调用时间的监控中心。 Container: 服务运行容器。 五：总体架构Dubbo的总体架构，如图所示： 主要核心部件 Remoting: 网络通信框架，实现了 sync-over-async 和 request-response 消息机制. RPC: 一个远程过程调用的抽象，支持负载均衡、容灾和集群功能 Registry: 服务目录框架用于服务的注册和服务事件发布和订阅 各个层次Dubbo框架设计一共划分了10个层，而最上面的Service层是留给实际想要使用Dubbo开发分布式服务的开发者实现业务逻辑的接口层。图中左边淡蓝背景的为服务消费方使用的接口，右边淡绿色背景的为服务提供方使用的接口， 位于中轴线上的为双方都用到的接口。下面，结合Dubbo官方文档，我们分别理解一下框架分层架构中，各个层次的设计要点： 服务接口层（Service）：该层是与实际业务逻辑相关的，根据服务提供方和服务消费方的业务设计对应的接口和实现。 配置层（Config）：对外配置接口，以ServiceConfig和ReferenceConfig为中心，可以直接new配置类，也可以通过spring解析配置生成配置类。 服务代理层（Proxy）：服务接口透明代理，生成服务的客户端Stub和服务器端Skeleton，以ServiceProxy为中心，扩展接口为ProxyFactory。 服务注册层（Registry）：封装服务地址的注册与发现，以服务URL为中心，扩展接口为RegistryFactory、Registry和RegistryService。可能没有服务注册中心，此时服务提供方直接暴露服务。 集群层（Cluster）：封装多个提供者的路由及负载均衡，并桥接注册中心，以Invoker为中心，扩展接口为Cluster、Directory、Router和LoadBalance。将多个服务提供方组合为一个服务提供方，实现对服务消费方来透明，只需要与一个服务提供方进行交互。 监控层（Monitor）：RPC调用次数和调用时间监控，以Statistics为中心，扩展接口为MonitorFactory、Monitor和MonitorService。 远程调用层（Protocol）：封将RPC调用，以Invocation和Result为中心，扩展接口为Protocol、Invoker和Exporter。Protocol是服务域，它是Invoker暴露和引用的主功能入口，它负责Invoker的生命周期管理。Invoker是实体域，它是Dubbo的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起invoke调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。 信息交换层（Exchange）：封装请求响应模式，同步转异步，以Request和Response为中心，扩展接口为Exchanger、ExchangeChannel、ExchangeClient和ExchangeServer。 络传输层（Transport）：抽象mina和netty为统一接口，以Message为中心，扩展接口为Channel、Transporter、Client、Server和Codec。 数据序列化层（Serialize）：可复用的一些工具，扩展接口为Serialization、 ObjectInput、ObjectOutput和ThreadPool。从上图可以看出，Dubbo对于服务提供方和服务消费方，从框架的10层中分别提供了各自需要关心和扩展的接口，构建整个服务生态系统（服务提供方和服务消费方本身就是一个以服务为中心的）。根据官方提供的，对于上述各层之间关系的描述，如下所示： 在RPC中，Protocol是核心层，也就是只要有Protocol + Invoker + Exporter就可以完成非透明的RPC调用，然后在Invoker的主过程上Filter拦截点。图中的Consumer和Provider是抽象概念，只是想让看图者更直观的了解哪些类分属于客户端与服务器端，不用Client和Server的原因是Dubbo在很多场景下都使用Provider、Consumer、Registry、Monitor划分逻辑拓普节点，保持统一概念。而Cluster是外围概念，所以Cluster的目的是将多个Invoker伪装成一个Invoker，这样其它人只要关注Protocol层Invoker即可，加上Cluster或者去掉Cluster对其它层都不会造成影响，因为只有一个提供者时，是不需要Cluster的。Proxy层封装了所有接口的透明化代理，而在其它层都以Invoker为中心，只有到了暴露给用户使用时，才用Proxy将Invoker转成接口，或将接口实现转成Invoker，也就是去掉Proxy层RPC是可以Run的，只是不那么透明，不那么看起来像调本地服务一样调远程服务。而Remoting实现是Dubbo协议的实现，如果你选择RMI协议，整个Remoting都不会用上，Remoting内部再划为Transport传输层和Exchange信息交换层，Transport层只负责单向消息传输，是对Mina、Netty、Grizzly的抽象，它也可以扩展UDP传输，而Exchange层是在传输层之上封装了Request-Response语义。Registry和Monitor实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在一起。 从上面的架构图中，我们可以了解到，Dubbo作为一个分布式服务框架，主要具有如下几个核心的要点： 服务定义服务是围绕服务提供方和服务消费方的，服务提供方实现服务，而服务消费方调用服务。 服务注册对于服务提供方，它需要发布服务，而且由于应用系统的复杂性，服务的数量、类型也不断膨胀；对于服务消费方，它最关心如何获取到它所需要的服务，而面对复杂的应用系统，需要管理大量的服务调用。而且，对于服务提供方和服务消费方来说，他们还有可能兼具这两种角色，即既需要提供服务，有需要消费服务。通过将服务统一管理起来，可以有效地优化内部应用对服务发布/使用的流程和管理。服务注册中心可以通过特定协议来完成服务对外的统一。Dubbo提供的注册中心有如下几种类型可供选择： Multicast注册中心 Zookeeper注册中心 Redis注册中心 Simple注册中心 服务监控无论是服务提供方，还是服务消费方，他们都需要对服务调用的实际状态进行有效的监控，从而改进服务质量。 远程通信与信息交换远程通信需要指定通信双方所约定的协议，在保证通信双方理解协议语义的基础上，还要保证高效、稳定的消息传输。Dubbo继承了当前主流的网络通信框架，主要包括如下几个： Mina Netty Grizzly 服务调用下面从Dubbo官网直接拿来，看一下基于RPC层，服务提供方和服务消费方之间的调用关系，如图所示：调用关系说明：面从Dubbo官网直接拿来，看一下基于RPC层，服务提供方和服务消费方之间的调用关系，如图所示：上图中，蓝色的表示与业务有交互，绿色的表示只对Dubbo内部交互。上述图所描述的调用流程如下： 服务容器负责启动，加载，运行服务提供者。 服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者在启动时，向注册中心订阅自己所需的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 Dubbo提供了很多协议，Dubbo协议、RMI协议、Hessian协议，我们查看Dubbo源代码，有各种协议的实现，如图所示：我们之前没用Dubbo之前时，大部分都使用Hessian来使用我们服务的暴露和调用，利用HessianProxyFactory调用远程接口。 注册/注销服务服务的注册与注销，是对服务提供方角色而言，那么注册服务与注销服务的时序图，如图所示： 服务订阅/取消为了满足应用系统的需求，服务消费方的可能需要从服务注册中心订阅指定的有服务提供方发布的服务，在得到通知可以使用服务时，就可以直接调用服务。反过来，如果不需要某一个服务了，可以取消该服务。下面看一下对应的时序图，如图所示： 协议支持Dubbo支持多种协议，如下所示： Dubbo协议 Hessian协议 HTTP协议 RMI协议 WebService协议 Thrift协议 Memcached协议 Redis协议在通信过程中，不同的服务等级一般对应着不同的服务质量，那么选择合适的协议便是一件非常重要的事情。你可以根据你应用的创建来选择。例如，使用RMI协议，一般会受到防火墙的限制，所以对于外部与内部进行通信的场景，就不要使用RMI协议，而是基于HTTP协议或者Hessian协议。 参考补充Dubbo以包结构来组织各个模块，各个模块及其关系，如图所示：可以通过Dubbo的代码（使用Maven管理）组织，与上面的模块进行比较。简单说明各个包的情况： dubbo-common 公共逻辑模块，包括Util类和通用模型。 dubbo-remoting 远程通讯模块，相当于Dubbo协议的实现，如果RPC用RMI协议则不需要使用此包。 dubbo-rpc 远程调用模块，抽象各种协议，以及动态代理，只包含一对一的调用，不关心集群的管理。 dubbo-cluster 集群模块，将多个服务提供方伪装为一个提供方，包括：负载均衡、容错、路由等，集群的地址列表可以是静态配置的，也可以是由注册中心下发。 dubbo-registry 注册中心模块，基于注册中心下发地址的集群方式，以及对各种注册中心的抽象。 dubbo-monitor 监控模块，统计服务调用次数，调用时间的，调用链跟踪的服务。 dubbo-config 配置模块，是Dubbo对外的API，用户通过Config使用Dubbo，隐藏Dubbo所有细节。 dubbo-container 容器模块，是一个Standalone的容器，以简单的Main加载Spring启动，因为服务通常不需要Tomcat/JBoss等Web容器的特性，没必要用Web容器去加载服务。 参考链接https://github.com/alibaba/dubbo参考Dubbo架构设计详解(转载)Dubbo详细介绍与安装使用过程Dubbo实战（一）快速入门dubbo用途介绍","tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://wangyuanjun.cn/tags/Dubbo/"}]},{"title":"Quartz学习———Quartz介绍(一)","date":"2017-12-27T15:02:10.000Z","path":"2017/12/27/Quartz学习——Quartz介绍-一/","text":"一：介绍Quartz是OpenSymphony开源组织在Job scheduling领域又一个开源项目，是完全由java开发的一个开源的任务日程管理系统，“任务进度管理器”就是一个在预先确定（被纳入日程）的时间到达时，负责执行（或者通知）其他软件组件的系统。Quartz用一个小Java库发布文件（.jar文件），这个库文件包含了所有Quartz核心功能。这些功能的主要接口(API)是Scheduler接口。它提供了简单的操作，例如：将任务纳入日程或者从日程中取消，开始/停止/暂停日程进度。 二：quartz核心概念先来看一张图： Job( 任务，即被调度的任务)：要由表示要执行的“作业”的类实现的接口。只有一个方法 void execute(jobExecutionContext context) (jobExecutionContext 提供调度上下文各种信息，运行时数据保存在jobDataMap中) Job有个子接口StatefulJob ,代表有状态任务。 JobDetail：Quartz在每次执行Job时，都重新创建一个Job实例，所以它不直接接受一个Job的实例，相反它接收一个Job实现类，以便运行时通过newInstance()的反射机制实例化Job。因此需要通过一个类来描述Job的实现类及其它相关的静态信息，如Job名字、描述、关联监听器等信息，JobDetail承担了这一角色。 传递给定作业实例的详细信息属性。 JobDetails将使用JobBuilder创建/定义。 Trigger(触发器)：用于定义任务调度时间规则。是一个类，描述触发Job执行的时间触发规则。使用TriggerBuilder实例化实际触发器。主要有SimpleTrigger和CronTrigger这两个子类。当仅需触发一次或者以固定时间间隔周期执行，SimpleTrigger是最适合的选择；而CronTrigger则可以通过Cron表达式定义出各种复杂时间规则的调度方案：如每早晨9:00执行，周一、周三、周五下午5:00执行等； Calendar：org.quartz.Calendar和java.util.Calendar不同，它是一些日历特定时间点的集合（可以简单地将org.quartz.Calendar看作java.util.Calendar的集合——java.util.Calendar代表一个日历时间点，无特殊说明后面的Calendar即指org.quartz.Calendar）。一个Trigger可以和多个Calendar关联，以便排除或包含某些时间点。假设，我们安排每周星期一早上10:00执行任务，但是如果碰到法定的节日，任务则不执行，这时就需要在Trigger触发机制的基础上使用Calendar进行定点排除。 Scheduler(任务调度器)：这是Quartz Scheduler的主要接口，代表一个Quartz的独立运行容器，Trigger和JobDetail可以注册到Scheduler中，两者在Scheduler中拥有各自的组及名称，组及名称是Scheduler查找定位容器中某一对象的依据，Trigger的组及名称必须唯一，JobDetail的组和名称也必须唯一（但可以和Trigger的组和名称相同，因为它们是不同类型的）。Scheduler定义了多个接口方法，允许外部通过组及名称访问和控制容器中Trigger和JobDetail。一旦注册，调度程序负责执行作业，当他们的相关联的触发器触发（当他们的预定时间到达时）。 QuartzSchedulerThread ：负责执行向QuartzScheduler注册的触发Trigger的工作的线程。 ThreadPool：Scheduler使用一个线程池作为任务运行的基础设施，任务通过共享线程池中的线程提供运行效率。 QuartzSchedulerResources：包含创建QuartzScheduler实例所需的所有资源（JobStore，ThreadPool等）。 SchedulerFactory( 调度程序工厂) ：提供用于获取调度程序实例的客户端可用句柄的机制。 JobStore： 通过类实现的接口，这些类要为org.quartz.core.QuartzScheduler的使用提供一个org.quartz.Job和org.quartz.Trigger存储机制。作业和触发器的存储应该以其名称和组的组合为唯一性。 QuartzScheduler ：这是Quartz的核心，它是org.quartz.Scheduler接口的间接实现，包含调度org.quartz.Jobs，注册org.quartz.JobListener实例等的方法。 三：Quartz中的设计模式 Builder模式所有关键组件都有Builder模式来构建 如:JobBuilder、TriggerBuilder Factory模式最终由Scheduler的来进行组合各种组件 如SchedulerFactory 组件模式Quartz项目中大量使用组件模式，插件式设计，可插拔，耦合性低，易扩展，开发者可自行定义自己的Job、Trigger等组件 链式写法Quartz中大量使用链式写法，与jQuery的写法有几分相似，实现也比较简单，如： $(this).addClass(&quot;divCurrColor&quot;).next(&quot;.divContent&quot;).css(&quot;display&quot;,&quot;block&quot;); newTrigger().withIdentity( &quot;trigger3&quot;, &quot;group1&quot;).startAt( startTime) .withSchedule(simpleSchedule().withIntervalInSeconds(10).withRepeatCount(10)).build(); 四：Quartz体系结构三大核心 调度器 任务 触发器 重要组成1）任务： Job：表示一个工作，要执行的具体内容。此接口中只有一个方法。要创建一个任务，必须得实现这个接口。该接口只有一个execute方法，任务每次被调用的时候都会执行这个execute方法的逻辑，类似TimerTask的run方法，在里面编写业务逻辑。123456789public class TestJob implements Job &#123; /**把要执行的操作，写在execute方法中 */ @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd hh:mm:ss&quot;); System.out.println(&quot;I can do something...&quot;); System.out.println(sdf.format(new Date())); &#125; &#125; 生命周期：在每次调度器执行job时，它在调用execute方法前会创建一个新的job实例，当调用完成之后，关联的job对象实例会被释放，释放的实例会被垃圾回收机制回收。 JobBuilder：可向任务传递数据,通常情况下,我们使用它就可向任务类发送数据了，如有特别复杂的传递参数,它提供了一个传递递:JobDataMap对象的方法 1JobDetail jobDetail = JobBuilder.newJob(TestJob.class).withIdentity(&quot;testJob&quot;,&quot;group1&quot;).build(); JobDetail：用来保存我们任务的详细信息。一个JobDetail可以有多个Trigger，但是一个Trigger只能对应一个JobDetail。下面是JobDetail的一些常用的属性和含义： JobStore：负责跟踪所有你给scheduler的“工作数据”：jobs, triggers, calendars, 等。 RAMJobStore：是使用最简单的也是最高效(依据CPU时间)的JobStore 。RAMJobStore 正如它名字描述的一样，它保存数据在RAM。缺点是你的应用结束之后所有的数据也丢失了–这意味着RAMJobStore 不具有保持job和trigger持久的能力。对于一些程序是可以接受的，甚至是期望的，但对于其他的程序可能是灾难性的。使用RAMJobStore配置Quartz：配置如下 1org.quartz.jobStore.class = org.quartz.simpl.RAMJobStore：是使用最简单的也是最高效 JDBCJobStore：以JDBC的方式保存数据在数据库中。它比RAMJobStore的配置复杂一点，也没有RAMJobStore快。然而,性能缺点不是糟透了,特别是如果你在数据库表主键上建立了索引。在机器之间的LAN(在scheduler 和数据库之间)合理的情况下，检索和更新一个被触发的Trigger花费的时间少于10毫秒。几乎适用于所有的数据库，广泛用于 Oracle。PostgreSQL, MySQL, MS SQLServer, HSQLDB, 和DB2。使用JDBCJobStore之前你必须首先创建一系列Quartz要使用的表。你可以发现表创建语句在Quartz发布目录的 “docs/dbTables”下面。你需要确定你的应用要使用的事务类型。如果你不想绑定调度命令(例如增加和移除Trigger)到其他的事务，你可以使用JobStoreTX (最常用的选择)作为你的Jobstore。如果你需要Quartz和其他的事务(例如在J2EE应用服务器中)一起工作，你应该使用JobStoreCMT ，Quartz 将让应用服务器容器管理这个事务。使用JobStoreTx配置Quartz： 123456org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate #配置表的前缀 org.quartz.jobStore.tablePrefix = QRTZ_ #使用JNDI数据源的时候，数据源的名字 org.quartz.jobStore.dataSource = myDS TerracottaJobStore：提供了一个方法：在不使用数据库的情况下使它具有收缩性和强壮性。可以是集群的也可以是非集群的，在这两种情况下为你的job数据提供了一个存储机制用于应用程序重启之间持久,因为数据是存储在Terracotta服务器。它的性能比使用数据库访问JDBCJobStore好一点儿(大约是一个数量级)，但是明显比RAMJobStore慢。使用TerracottaJobStore配置Quartz： 12org.quartz.jobStore.class = org.terracotta.quartz.TerracottaJobStore org.quartz.jobStore.tcConfigUrl = localhost:9510 JobDataMap：中可以包含不限量的（序列化的）数据对象，在job实例执行的时候，可以使用其中的数据；JobDataMap是Java Map接口的一个实现，额外增加了一些便于存取基本类型的数据的方法。 存： 1JobDetail jobDetail = JobBuilder.newJob(TestJob.class).withIdentity(&quot;testJob&quot;,&quot;group1&quot;).usingJobData(&quot;date1&quot;,&quot;存内容&quot;).build(); 取： 123456789public class TestJob implements Job &#123; /**把要执行的操作，写在execute方法中 */ @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; JobKey key = jobExecutionContext.getJobDetail().getKey(); JobDataMap jobDataMap = jobExecutionContext.getJobDetail().getJobDataMap(); String date1 = jobDataMap.getString(&quot;date1&quot;); &#125; &#125; 2）触发器：用来触发执行Job2.1）触发器通用属性： Jobkey：表示job实例的标识，触发器被触发时，该指定的job实例会被执行 StartTime：表示触发器的时间表首次被触发的时间，它的值类型为：java.util.Date EndTime：指定触发器的不再被触发的时间，它的值类型为：java.util.Date 2.2）触发器类型： SimpleTrigger： 主要是针对一些相对简单的时间触发进行配置使用，比如在指定的时间开始然后在一定的时间间隔之内重复执行一个Job，同时可以任意指定重复的次数。用来触发只需执行一次或者在给定时间触发并且重复N次且每次执行延迟一定时间的任务。 下面就是使用一个SimpleTrigger的例子:12345678910111213141516//创建触发器 每3秒钟执行一次(无开始时间和结束时间) Trigger trigger = TriggerBuilder.newTrigger() .withIdentity(&quot;trigger1&quot;, &quot;group3&quot;) .withSchedule( SimpleScheduleBuilder.simpleSchedule() .withIntervalInSeconds(3).repeatForever()).build(); //创建触发器 每3秒钟执行一次(有开始时间和结束时间) long now = new Date().getTime(); Date start = new Date(now+6000); Date end = new Date(now+12000); //创建触发器 每3秒钟执行一次 Trigger trigger = TriggerBuilder.newTrigger() .withIdentity(&quot;trigger1&quot;, &quot;group3&quot;) .startAt(start) .endAt(end) .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(3).repeatForever()).build(); SimpleTrigger具有丰富的构造函数，根据业务需求构造不同的构造函数。 CronTrigger： 可以配置更复杂的触发时刻表，基于日历的作业触发器，而不像SimpleTrigger那样精确指定间隔时间，按照日历触发，例如“每个周五”，每个月10日中午或者10：15分。比SimpleTrigger更加常用。 Cron表达式：用于配置CronTrigger实例，是由7个表达式组成的字符串，描述了时间表的详细信息。 格式为：[秒][分][时][日][月][周][年] Cron表达式特殊字符意义对应表：通配符说明：Cron表达式例子： TriggerBuilder.newTrigger().withIdentity(&quot;trigger2&quot;,&quot;group2&quot;).withSchedule(CronScheduleBuilder.cronSchedule(&quot;0 0 9 ? * 6L *&quot;)).build(); Cron表达式小技巧： ‘L’和‘W’可以一起组合使用 周字段英文字母不区分大小写即MOM与mom相同 利用工具，在线生成cron表达式：cron.qqe2.com/ NthIncludedDayTrigger：是 Quartz 开发团队最新加入到框架中的一个 Trigger。它设计用于在每一间隔类型的第几天执行 Job。例如，你要在每个月的 15 号执行开票的 Job，用 NthIncludedDayTrigger就再合适不过了。 123NthIncludedDayTrigger trigger = new NthIncludedDayTrigger(&quot;NthIncludedDayTrigger&quot;,Scheduler.DEFAULT_GROUP); trigger.setN(15); trigger.setIntervalType(NthIncludedDayTrigger.INTERVAL_TYPE_MONTHLY); 3）调度器Scheduler 代表一个Quartz的独立运行容器，Trigger和JobDetail可以注册到Scheduler中，两者在Scheduler中拥有各自的组及名称，组及名称是Scheduler查找定位容器中某一对象的依据，Trigger的组及名称必须唯一，JobDetail的组和名称也必须唯一（但可以和Trigger的组和名称相同，因为它们是不同类型的）。Scheduler定义了多个接口方法，允许外部通过组及名称访问和控制容器中Trigger和JobDetail。 Scheduler可以将Trigger绑定到某一JobDetail中，这样当Trigger触发时，对应的Job就被执行。一个Job可以对应多个Trigger，但一个Trigger只能对应一个Job。 可以通过SchedulerFactory创建一个Scheduler实例。Scheduler拥有一个SchedulerContext，它类似于ServletContext，保存着Scheduler上下文信息，Job和Trigger都可以访问SchedulerContext内的信息。SchedulerContext内部通过一个Map，以键值对的方式维护这些上下文数据，SchedulerContext为保存和获取数据提供了多个put()和getXxx()的方法。可以通过Scheduler# getContext()获取对应的SchedulerContext实例；123456789SchedulerFactory schedulerfactory=new StdSchedulerFactory(); Scheduler scheduler = schedulerfactory.getScheduler(); DirectSchedulerFactory factory = DirectSchedulerFactory.getInstance(); try &#123; Scheduler scheduler = factory.getScheduler(); &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; 4)SchedulerFactory: 使用一组参数（java.util.Properties）来创建和出书啊Quartz调度器 配置参数一般存储在quartz.properties中 调用getScheduler方法就能创建和初始化调度器 5)quartz.properties: Quartz-Job的quartz.properties配置文件说明，此文件在quartz的jar包有，可直接拿过来使用不过只有基本的几个配置 自己可根据需要进行扩充；另外如果项目中没有对该配置文件重写，则Quartz会加载自己jar包中的quartz.properties文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495# Default Properties file for use by StdSchedulerFactory # to create a Quartz Scheduler Instance, if a different # properties file is not explicitly specified. # # =========================================================================== # Configure Main Scheduler Properties 调度器属性 # =========================================================================== org.quartz.scheduler.instanceName: DefaultQuartzScheduler #org.quartz.scheduler.instanceid:AUTO org.quartz.scheduler.rmi.export: false org.quartz.scheduler.rmi.proxy: false org.quartz.scheduler.wrapJobExecutionInUserTransaction: false # =========================================================================== # Configure ThreadPool 线程池属性 # =========================================================================== #线程池的实现类（一般使用SimpleThreadPool即可满足几乎所有用户的需求） org.quartz.threadPool.class: org.quartz.simpl.SimpleThreadPool #指定线程数，至少为1（无默认值）(一般设置为1-100直接的整数合适) org.quartz.threadPool.threadCount: 10 #设置线程的优先级（最大为java.lang.Thread.MAX_PRIORITY 10，最小为Thread.MIN_PRIORITY 1，默认为5） org.quartz.threadPool.threadPriority: 5 #设置SimpleThreadPool的一些属性 #设置是否为守护线程 #org.quartz.threadpool.makethreadsdaemons = false #org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread: true #org.quartz.threadpool.threadsinheritgroupofinitializingthread=false #线程前缀默认值是：[Scheduler Name]_Worker #org.quartz.threadpool.threadnameprefix=swhJobThead; # 配置全局监听(TriggerListener,JobListener) 则应用程序可以接收和执行 预定的事件通知 # =========================================================================== # Configuring a Global TriggerListener 配置全局的Trigger监听器 # MyTriggerListenerClass 类必须有一个无参数的构造函数，和 属性的set方法，目前2.2.x只支持原始数据类型的值（包括字符串） # =========================================================================== #org.quartz.triggerListener.NAME.class = com.swh.MyTriggerListenerClass #org.quartz.triggerListener.NAME.propName = propValue #org.quartz.triggerListener.NAME.prop2Name = prop2Value # =========================================================================== # Configuring a Global JobListener 配置全局的Job监听器 # MyJobListenerClass 类必须有一个无参数的构造函数，和 属性的set方法，目前2.2.x只支持原始数据类型的值（包括字符串） # =========================================================================== #org.quartz.jobListener.NAME.class = com.swh.MyJobListenerClass #org.quartz.jobListener.NAME.propName = propValue #org.quartz.jobListener.NAME.prop2Name = prop2Value # =========================================================================== # Configure JobStore 存储调度信息（工作，触发器和日历等） # =========================================================================== # 信息保存时间 默认值60秒 org.quartz.jobStore.misfireThreshold: 60000 #保存job和Trigger的状态信息到内存中的类 org.quartz.jobStore.class: org.quartz.simpl.RAMJobStore # =========================================================================== # Configure SchedulerPlugins 插件属性 配置 # =========================================================================== # 自定义插件 #org.quartz.plugin.NAME.class = com.swh.MyPluginClass #org.quartz.plugin.NAME.propName = propValue #org.quartz.plugin.NAME.prop2Name = prop2Value #配置trigger执行历史日志（可以看到类的文档和参数列表） org.quartz.plugin.triggHistory.class = org.quartz.plugins.history.LoggingTriggerHistoryPlugin org.quartz.plugin.triggHistory.triggerFiredMessage = Trigger &#123;1&#125;.&#123;0&#125; fired job &#123;6&#125;.&#123;5&#125; at: &#123;4, date, HH:mm:ss MM/dd/yyyy&#125; org.quartz.plugin.triggHistory.triggerCompleteMessage = Trigger &#123;1&#125;.&#123;0&#125; completed firing job &#123;6&#125;.&#123;5&#125; at &#123;4, date, HH:mm:ss MM/dd/yyyy&#125; with resulting trigger instruction code: &#123;9&#125; #配置job调度插件 quartz_jobs(jobs and triggers内容)的XML文档 #加载 Job 和 Trigger 信息的类 （1.8之前用：org.quartz.plugins.xml.JobInitializationPlugin） org.quartz.plugin.jobInitializer.class = org.quartz.plugins.xml.XMLSchedulingDataProcessorPlugin #指定存放调度器(Job 和 Trigger)信息的xml文件，默认是classpath下quartz_jobs.xml org.quartz.plugin.jobInitializer.fileNames = my_quartz_job2.xml #org.quartz.plugin.jobInitializer.overWriteExistingJobs = false org.quartz.plugin.jobInitializer.failOnFileNotFound = true #自动扫描任务单并发现改动的时间间隔,单位为秒 org.quartz.plugin.jobInitializer.scanInterval = 10 #覆盖任务调度器中同名的jobDetail,避免只修改了CronExpression所造成的不能重新生效情况 org.quartz.plugin.jobInitializer.wrapInUserTransaction = false # =========================================================================== # Sample configuration of ShutdownHookPlugin ShutdownHookPlugin插件的配置样例 # =========================================================================== #org.quartz.plugin.shutdownhook.class = \\org.quartz.plugins.management.ShutdownHookPlugin #org.quartz.plugin.shutdownhook.cleanShutdown = true # # Configure RMI Settings 远程服务调用配置 # #如果你想quartz-scheduler出口本身通过RMI作为服务器，然后设置“出口”标志true(默认值为false)。 #org.quartz.scheduler.rmi.export = false #主机上rmi注册表(默认值localhost) #org.quartz.scheduler.rmi.registryhost = localhost #注册监听端口号（默认值1099） #org.quartz.scheduler.rmi.registryport = 1099 #创建rmi注册，false/never：如果你已经有一个在运行或不想进行创建注册 # true/as_needed:第一次尝试使用现有的注册，然后再回来进行创建 # always:先进行创建一个注册，然后再使用回来使用注册 #org.quartz.scheduler.rmi.createregistry = never #Quartz Scheduler服务端端口，默认是随机分配RMI注册表 #org.quartz.scheduler.rmi.serverport = 1098 #true:链接远程服务调度(客户端),这个也要指定registryhost和registryport，默认为false # 如果export和proxy同时指定为true，则export的设置将被忽略 #org.quartz.scheduler.rmi.proxy = false 五：存储方式RAMJobStore:优点：不要外部数据库，配置容易，运行速度快缺点：因为调度程序信息是存储在被分配给JVM的内存里面，所以，当应用程序停止运行时，所有调度信息将被丢失。另外因为存储到JVM内存里面，所以可以存储多少个Job和Trigger将会受到限制JDBCJobStore:优点：支持集群，因为所有的任务信息都会保存到数据库中，可以控制事物，还有就是如果应用服务器关闭或者重启，任务信息都不会丢失，并且可以恢复因服务器关闭或者重启而导致执行失败的任务缺点：运行速度的快慢取决与连接数据库的快慢 表关系和解释 Tables Means qrtz_blob_triggers Trigger作为Blob类型存储(用于Quartz用户用JDBC创建他们自己定制的Trigger类型，JobStore 并不知道如何存储实例的时候) qrtz_calendars 以Blob类型存储Quartz的Calendar日历信息， quartz可配置一个日历来指定一个时间范围 qrtz_cron_triggers 存储Cron Trigger，包括Cron表达式和时区信息。 qrtz_fired_triggers 存储与已触发的Trigger相关的状态信息，以及相联Job的执行信息 qrtz_job_details 存储每一个已配置的Job的详细信息 qrtz_locks 存储程序的非观锁的信息(假如使用了悲观锁) qrtz_paused_trigger_graps 存储已暂停的Trigger组的信息 qrtz_scheduler_state 存储少量的有关 Scheduler的状态信息，和别的 Scheduler 实例(假如是用于一个集群中) qrtz_simple_triggers 存储简单的 Trigger，包括重复次数，间隔，以及已触的次数 qrtz_triggers 存储已配置的 Trigger的信息 qrzt_simprop_triggers 思想// 1、工厂模式 构建Scheduler的Factory，其中STD为Quartz默认的Factory // 开发者亦可自行实现自己的Factory;Job、Trigger等组件 SchedulerFactory sf = new StdSchedulerFactory(); // 2、通过SchedulerFactory构建Scheduler对象 Scheduler sched = sf.getScheduler(); // 3、org.quartz.DateBuilder.evenMinuteDate -- 通过DateBuilder构建Date Date runTime = evenMinuteDate( new Date()); // 4、org.quartz.JobBuilder.newJob &lt;下一分钟&gt; --通过JobBuilder构建Job JobDetail job = newJob(HelloJob.class).withIdentity(&quot;job1&quot;,&quot;group1&quot;).build(); // 5、通过TriggerBuilder进行构建Trigger Trigger trigger = newTrigger().withIdentity(&quot;trigger1&quot;,&quot;group1&quot;) .startAt(runTime).build(); // 6、工厂模式，组装各个组件&lt;JOB，Trigger&gt; sched.scheduleJob (job, trigger); // 7、start sched.start(); try { Thread.sleep(65L * 1000L); } catch (Exception e) { } // 8、通过Scheduler销毁内置的Trigger和Job sched.shutdown(true); 一句话看懂Quartz 创建调度工厂(); //工厂模式 根据工厂取得调度器实例(); //工厂模式 Builder模式构建子组件 // builder模式, 如JobBuilder、TriggerBuilder、DateBuilder 通过调度器组装子组件 调度器.组装&lt;子组件1,子组件2…&gt; //工厂模式 调度器.start(); //工厂模式 参考:quartz详解2：quartz由浅入深Quartz使用总结Quartz深入浅出(一)Quartz学习——Quartz大致介绍（一）深入解读Quartz任务调度器","tags":[{"name":"quartz","slug":"quartz","permalink":"http://wangyuanjun.cn/tags/quartz/"}]},{"title":"Oracle VM VirtualBox配置虚拟网卡(桥接),实现主机-虚拟机网络互通","date":"2017-12-25T09:01:52.000Z","path":"2017/12/25/Oracle-VM-VirtualBox配置虚拟网卡-桥接-实现主机-虚拟机网络互通/","text":"桥接网卡 首先打开虚拟机 右键点击右下角 网络连接 在弹出框内点击 网络 在设置界面依次点击-网络-连接方式选择 -桥接网卡-确定 编辑网卡 打开centos虚拟机终端，就是命令行 切换到root用户，对网卡文件进行编辑 shell#cd /etc/sysconfig/network-scripts/ shell# vim ifcfg-enp0s3 BOOTPROTO=dhcp,ONBOOT=yes(dhcp为动态获取ip，ONBOOT=yes为开机启动) 保存退出！ 重启服务器shell#service network restart 或者 shell#systemctl restart network (centos7版本命令) 参考:VirtualBox linux虚拟机如何实现“桥接”上网","tags":[{"name":"Oracle VM VirtualBox","slug":"Oracle-VM-VirtualBox","permalink":"http://wangyuanjun.cn/tags/Oracle-VM-VirtualBox/"},{"name":"linux","slug":"linux","permalink":"http://wangyuanjun.cn/tags/linux/"}]},{"title":"解决虚拟机安装linux后首次输入ifconfig IP地址显示为127.0.0.1","date":"2017-12-25T08:34:13.000Z","path":"2017/12/25/解决虚拟机安装linux后首次输入ifconfig-IP地址显示为127-0-0-1/","text":"使用虚拟机Oracle VM VirtualBox安装linux首次输入ifconfig IP地址显示为127.0.0.1，解决方法如下:在linux系统中输入命令: vi /etc/sysconfig/network-scripts/ifcfg-eth0 显示如下: 将其中的ONBOOT=no改为yes,保存并退出。 最后输入命令: service network restart（重启服务命令） 重启服务器,会出现正在配置IP的提示,待自动配置成功后,输入命令ifconfig即可。","tags":[{"name":"Oracle VM VirtualBox","slug":"Oracle-VM-VirtualBox","permalink":"http://wangyuanjun.cn/tags/Oracle-VM-VirtualBox/"},{"name":"linux","slug":"linux","permalink":"http://wangyuanjun.cn/tags/linux/"}]},{"title":"解决项目war包部署到linux系统的tomcat中访问页面报404错误","date":"2017-12-25T05:56:46.000Z","path":"2017/12/25/解决项目war包部署到linux系统的tomcat中访问页面报404错误/","text":"","tags":[]},{"title":"Java Web项目导出war包并部署到linux系统的tomcat中","date":"2017-12-25T04:15:54.000Z","path":"2017/12/25/Java-Web项目导出war包并部署到linux系统的tomcat中/","text":"使用eclpise导出war包右击项目–&gt;Export–&gt;选择WAR file–&gt;选择导出目录,导出，如下图所示: 使用maven导出war包右击项目–&gt;Run as–&gt;Maven install，如下图所示: 将war包部署至tomcat中我的电脑系统是windows，为了模拟linux环境，使用Oracle VM VirtualBox虚拟机及centos6.9搭建linux环境。在linux上安装tomcate及jdk，配置环境变量 将spring-demo.war放到Tomcat的webapps目录下。在windows上安装ssh,通过它将war包上传到linux上 启动tomcat使用 ./catalina.sh run 命令可查看tomcate启动日志 启动没报错，使用 ./startup.sh 命令启动tomcate，如果不能访问请关闭linux防火墙或者到防火墙中添加可访问的域名及端口。","tags":[{"name":"nginx","slug":"nginx","permalink":"http://wangyuanjun.cn/tags/nginx/"}]},{"title":"SpringBoot发布HttpClient服务和客户端调用HttpClient服务","date":"2017-12-23T06:28:27.000Z","path":"2017/12/23/SpringBoot发布HttpClient服务和客户端调用HttpClient服务/","text":"之前在做公司项目的一个功能需要写WebSerice接口，写完之后我们老大说也可以用HttpClient来写接口，所以写了一个接口例子。 添加依赖&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wyj&lt;/groupId&gt; &lt;artifactId&gt;wyj-interface-client&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;wyj-interface-client Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- http --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.1.41&lt;/version&gt; &lt;/dependency&gt; &lt;!--webservice cxf --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.cxf&lt;/groupId&gt; &lt;artifactId&gt;cxf-rt-transports-http&lt;/artifactId&gt; &lt;version&gt;3.1.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.cxf&lt;/groupId&gt; &lt;artifactId&gt;cxf-rt-frontend-jaxws&lt;/artifactId&gt; &lt;version&gt;3.1.8&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;wyj-interface-client&lt;/finalName&gt; &lt;/build&gt; &lt;/project&gt; HttpClient客户端可以传输json和map数据，可以使用get和post请求，详情见备注 package http; import java.io.IOException; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Map.Entry; import org.apache.http.HttpStatus; import org.apache.http.NameValuePair; import org.apache.http.client.ClientProtocolException; import org.apache.http.client.entity.UrlEncodedFormEntity; import org.apache.http.client.methods.CloseableHttpResponse; import org.apache.http.client.methods.HttpGet; import org.apache.http.client.methods.HttpPost; import org.apache.http.entity.ContentType; import org.apache.http.entity.StringEntity; import org.apache.http.impl.client.CloseableHttpClient; import org.apache.http.impl.client.HttpClients; import org.apache.http.message.BasicNameValuePair; import org.apache.http.util.EntityUtils; import org.junit.Test; import com.alibaba.fastjson.JSON; /** * http客户端 * * * @author：WangYuanJun * @date：2017年12月20日 下午8:26:51 */ public class HttpClientTest { /** * post请求传输map数据 * * @param url * @param map * @param encoding * @return * @throws ClientProtocolException * @throws IOException */ public static String sendPostDataByMap(String url, Map&lt;String, String&gt; map, String encoding) throws ClientProtocolException, IOException { String result = &quot;&quot;; // 创建httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); // 创建post方式请求对象 HttpPost httpPost = new HttpPost(url); // 装填参数 List&lt;NameValuePair&gt; nameValuePairs = new ArrayList&lt;NameValuePair&gt;(); if (map != null) { for (Entry&lt;String, String&gt; entry : map.entrySet()) { nameValuePairs.add(new BasicNameValuePair(entry.getKey(), entry.getValue())); } } // 设置参数到请求对象中 httpPost.setEntity(new UrlEncodedFormEntity(nameValuePairs, encoding)); // 设置header信息 // 指定报文头【Content-type】、【User-Agent】 httpPost.setHeader(&quot;Content-type&quot;, &quot;application/x-www-form-urlencoded&quot;); httpPost.setHeader(&quot;User-Agent&quot;, &quot;Mozilla/4.0 (compatible; MSIE 5.0; Windows NT; DigExt)&quot;); // 执行请求操作，并拿到结果（同步阻塞） CloseableHttpResponse response = httpClient.execute(httpPost); // 获取结果实体 // 判断网络连接状态码是否正常(0--200都数正常) if (response.getStatusLine().getStatusCode() == HttpStatus.SC_OK) { result = EntityUtils.toString(response.getEntity(), &quot;utf-8&quot;); } // 释放链接 response.close(); return result; } /** * post请求传输json数据 * * @param url * @param json * @param encoding * @return * @throws ClientProtocolException * @throws IOException */ public static String sendPostDataByJson(String url, String json, String encoding) throws ClientProtocolException, IOException { String result = &quot;&quot;; // 创建httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); // 创建post方式请求对象 HttpPost httpPost = new HttpPost(url); // 设置参数到请求对象中 StringEntity stringEntity = new StringEntity(json, ContentType.APPLICATION_JSON); stringEntity.setContentEncoding(&quot;utf-8&quot;); httpPost.setEntity(stringEntity); // 执行请求操作，并拿到结果（同步阻塞） CloseableHttpResponse response = httpClient.execute(httpPost); // 获取结果实体 // 判断网络连接状态码是否正常(0--200都数正常) if (response.getStatusLine().getStatusCode() == HttpStatus.SC_OK) { result = EntityUtils.toString(response.getEntity(), &quot;utf-8&quot;); } // 释放链接 response.close(); return result; } /** * get请求传输数据 * * @param url * @param encoding * @return * @throws ClientProtocolException * @throws IOException */ public String sendGetData(String url, String encoding) throws ClientProtocolException, IOException { String result = &quot;&quot;; // 创建httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); // 创建get方式请求对象 HttpGet httpGet = new HttpGet(url); httpGet.addHeader(&quot;Content-type&quot;, &quot;application/json&quot;); // 通过请求对象获取响应对象 CloseableHttpResponse response = httpClient.execute(httpGet); // 获取结果实体 // 判断网络连接状态码是否正常(0--200都数正常) if (response.getStatusLine().getStatusCode() == HttpStatus.SC_OK) { result = EntityUtils.toString(response.getEntity(), &quot;utf-8&quot;); } // 释放链接 response.close(); return result; } @Test public void testSendPostDataByMap() throws ClientProtocolException, IOException { String url = &quot;http://localhost:8080/httpService/sendPostDataByMap&quot;; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(&quot;name&quot;, &quot;wyj&quot;); map.put(&quot;city&quot;, &quot;南京&quot;); String body = sendPostDataByMap(url, map, &quot;utf-8&quot;); System.out.println(&quot;响应结果：&quot; + body); } @Test public void testSendPostDataByJson() throws ClientProtocolException, IOException { String url = &quot;http://localhost:8080/httpService/sendPostDataByJson&quot;; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(&quot;name&quot;, &quot;wyj&quot;); map.put(&quot;city&quot;, &quot;南京&quot;); String body = sendPostDataByJson(url, JSON.toJSONString(map), &quot;utf-8&quot;); System.out.println(&quot;响应结果：&quot; + body); } @Test public void testSendGetData() throws ClientProtocolException, IOException { String url = &quot;http://localhost:8080/httpService/sendGetData?name=wyj&amp;city=南京&quot;; String body = sendGetData(url, &quot;utf-8&quot;); System.out.println(&quot;响应结果：&quot; + body); } } HttpClient服务端package com.wyj.http; import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse; import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RestController; import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.JSONObject; /** * http服务端 * * * @author：WangYuanJun * @date：2017年12月21日 下午8:27:08 */ @RestController @RequestMapping(&quot;/httpService&quot;) public class HttpServiceTest { @RequestMapping(value = &quot;/sendPostDataByMap&quot;, method = RequestMethod.POST) public String sendPostDataByMap(HttpServletRequest request, HttpServletResponse response) { String result = &quot;调用成功：数据是 &quot; + &quot;name:&quot; + request.getParameter(&quot;name&quot;) + &quot; city:&quot; + request.getParameter(&quot;city&quot;); return JSON.toJSONString(result); } @RequestMapping(value = &quot;/sendPostDataByJson&quot;, method = RequestMethod.POST) public String sendPostDataByJson(HttpServletRequest request, HttpServletResponse response, @RequestBody String requestBody) { JSONObject jsonObject = JSONObject.parseObject(requestBody); String result = &quot;调用成功：数据是 &quot; + &quot;name:&quot; + jsonObject.getString(&quot;name&quot;) + &quot; city:&quot; + jsonObject.getString(&quot;city&quot;); return JSON.toJSONString(result); } @RequestMapping(value = &quot;/sendGetData&quot;, method = RequestMethod.GET) public String sendGetData(HttpServletRequest request, HttpServletResponse response) { String result = &quot;调用成功：数据是 &quot; + &quot;name:&quot; + request.getParameter(&quot;name&quot;) + &quot; city:&quot; + request.getParameter(&quot;city&quot;); return JSON.toJSONString(result); } } 调用后返回结果输出为 项目地址SpringBoot整合的HttpClient客户端地址SpringBoot整合的HttpClient服务端地址","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://wangyuanjun.cn/tags/SpringBoot/"},{"name":"HttpClient","slug":"HttpClient","permalink":"http://wangyuanjun.cn/tags/HttpClient/"}]},{"title":"SpringBoot整合cxf发布WebService服务和客户端调用WebService服务","date":"2017-12-21T05:19:10.000Z","path":"2017/12/21/SpringBoot整合cxf发布WebService服务和客户端调用WebService服务/","text":"最近在做公司项目的一个功能需要写WebSerice接口，为了系统得学习WebService，决定写一个测试接口的例子。测试项目中使用的是SpringBoot(spring整合cxf需添加cxf-rt-frontend-jaxws，cxf-rt-transports-http依赖) 添加依赖&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wyj&lt;/groupId&gt; &lt;artifactId&gt;wyj-interface-service&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;wyj-interface-service&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- http --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.1.41&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 热部署模块 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 这个需要为 true 热部署才有效 --&gt; &lt;/dependency&gt; &lt;!-- CXF webservice --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.cxf&lt;/groupId&gt; &lt;artifactId&gt;cxf-spring-boot-starter-jaxws&lt;/artifactId&gt; &lt;version&gt;3.1.11&lt;/version&gt; &lt;/dependency&gt; &lt;!-- CXF webservice --&gt; &lt;dependency&gt; &lt;groupId&gt;org.scala-lang&lt;/groupId&gt; &lt;artifactId&gt;scala-library&lt;/artifactId&gt; &lt;version&gt;2.11.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 服务端接口package com.wyj.webservice; import javax.jws.WebMethod; import javax.jws.WebParam; import javax.jws.WebResult; import javax.jws.WebService; /** * webservice测试接口 * * * @author：WangYuanJun * @date：2017年12月19日 下午9:36:49 */ @WebService(name = &quot;TestService&quot;, // 暴露服务名称 targetNamespace = &quot;http://service.wyj.com&quot;// 命名空间,一般是接口的包名倒序 ) public interface TestService { @WebMethod @WebResult(name = &quot;String&quot;, targetNamespace = &quot;&quot;) String sendMessage(@WebParam(name = &quot;username&quot;) String username); } 服务端接口实现package com.wyj.webservice; import javax.jws.WebService; import org.springframework.stereotype.Component; /** * webservice测试接口实现 * * * @author：WangYuanJun * @date：2017年12月19日 下午9:37:20 */ @WebService(serviceName = &quot;TestService&quot;, // 与接口中指定的name一致 targetNamespace = &quot;http://service.wyj.com&quot;, // 与接口中的命名空间一致,一般是接口的包名倒 endpointInterface = &quot;com.wyj.webservice.TestService&quot;// 接口地址 ) @Component public class TestServiceImpl implements TestService { @Override public String sendMessage(String username) { return &quot;hello &quot;+username; } } cxf配置package com.wyj.webservice; import javax.xml.ws.Endpoint; import org.apache.cxf.Bus; import org.apache.cxf.jaxws.EndpointImpl; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * cxf配置 * * * @author：WangYuanJun * @date：2017年12月19日 下午9:38:24 */ @Configuration public class CxfConfig { @Autowired private Bus bus; @Autowired private TestService testService; @Bean public Endpoint endpoint(){ EndpointImpl endpoint = new EndpointImpl(bus, testService); endpoint.publish(&quot;/TestService&quot;); return endpoint; } } 默认服务在Host:port/services/*路径下将TestService接口发布在了路径/services/TestService下,wsdl文档路径为，http://localhost:8080/services/TestService?wsdl TestService的wsdl信息&lt;?xml version=&apos;1.0&apos; encoding=&apos;UTF-8&apos;?&gt;&lt;wsdl:definitions xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:wsdl=&quot;http://schemas.xmlsoap.org/wsdl/&quot; xmlns:tns=&quot;http://service.wyj.com&quot; xmlns:soap=&quot;http://schemas.xmlsoap.org/wsdl/soap/&quot; xmlns:ns1=&quot;http://schemas.xmlsoap.org/soap/http&quot; name=&quot;TestService&quot; targetNamespace=&quot;http://service.wyj.com&quot;&gt; &lt;wsdl:types&gt; &lt;xs:schema xmlns:xs=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:tns=&quot;http://service.wyj.com&quot; elementFormDefault=&quot;unqualified&quot; targetNamespace=&quot;http://service.wyj.com&quot; version=&quot;1.0&quot;&gt; &lt;xs:element name=&quot;sendMessage&quot; type=&quot;tns:sendMessage&quot;/&gt; &lt;xs:element name=&quot;sendMessageResponse&quot; type=&quot;tns:sendMessageResponse&quot;/&gt; &lt;xs:complexType name=&quot;sendMessage&quot;&gt; &lt;xs:sequence&gt; &lt;xs:element minOccurs=&quot;0&quot; name=&quot;username&quot; type=&quot;xs:string&quot;/&gt; &lt;/xs:sequence&gt; &lt;/xs:complexType&gt; &lt;xs:complexType name=&quot;sendMessageResponse&quot;&gt; &lt;xs:sequence&gt; &lt;xs:element minOccurs=&quot;0&quot; name=&quot;String&quot; type=&quot;xs:string&quot;/&gt; &lt;/xs:sequence&gt; &lt;/xs:complexType&gt; &lt;/xs:schema&gt; &lt;/wsdl:types&gt; &lt;wsdl:message name=&quot;sendMessage&quot;&gt; &lt;wsdl:part element=&quot;tns:sendMessage&quot; name=&quot;parameters&quot;&gt; &lt;/wsdl:part&gt; &lt;/wsdl:message&gt; &lt;wsdl:message name=&quot;sendMessageResponse&quot;&gt; &lt;wsdl:part element=&quot;tns:sendMessageResponse&quot; name=&quot;parameters&quot;&gt; &lt;/wsdl:part&gt; &lt;/wsdl:message&gt; &lt;wsdl:portType name=&quot;TestService&quot;&gt; &lt;wsdl:operation name=&quot;sendMessage&quot;&gt; &lt;wsdl:input message=&quot;tns:sendMessage&quot; name=&quot;sendMessage&quot;&gt; &lt;/wsdl:input&gt; &lt;wsdl:output message=&quot;tns:sendMessageResponse&quot; name=&quot;sendMessageResponse&quot;&gt; &lt;/wsdl:output&gt; &lt;/wsdl:operation&gt; &lt;/wsdl:portType&gt; &lt;wsdl:binding name=&quot;TestServiceSoapBinding&quot; type=&quot;tns:TestService&quot;&gt; &lt;soap:binding style=&quot;document&quot; transport=&quot;http://schemas.xmlsoap.org/soap/http&quot;/&gt; &lt;wsdl:operation name=&quot;sendMessage&quot;&gt; &lt;soap:operation soapAction=&quot;&quot; style=&quot;document&quot;/&gt; &lt;wsdl:input name=&quot;sendMessage&quot;&gt; &lt;soap:body use=&quot;literal&quot;/&gt; &lt;/wsdl:input&gt; &lt;wsdl:output name=&quot;sendMessageResponse&quot;&gt; &lt;soap:body use=&quot;literal&quot;/&gt; &lt;/wsdl:output&gt; &lt;/wsdl:operation&gt; &lt;/wsdl:binding&gt; &lt;wsdl:service name=&quot;TestService&quot;&gt; &lt;wsdl:port binding=&quot;tns:TestServiceSoapBinding&quot; name=&quot;TestServiceImplPort&quot;&gt; &lt;soap:address location=&quot;http://localhost:8080/services/TestService&quot;/&gt; &lt;/wsdl:port&gt; &lt;/wsdl:service&gt; &lt;/wsdl:definitions&gt; 基于cxf的客户端调用webservice接口package webservice; import org.apache.cxf.endpoint.Client; import org.apache.cxf.jaxws.endpoint.dynamic.JaxWsDynamicClientFactory; import org.junit.Test; /** * webservice客户端 * * * @author：WangYuanJun * @date：2017年12月19日 下午9:39:49 */ public class WebServiceTest { @Test public void testSend1(){ // 创建动态客户端 JaxWsDynamicClientFactory dcf = JaxWsDynamicClientFactory.newInstance(); Client client = dcf.createClient(&quot;http://localhost:8080/services/TestService?wsdl&quot;); // 需要密码的情况需要加上用户名和密码 // client.getOutInterceptors().add(new ClientLoginInterceptor(USER_NAME,PASS_WORD)); Object[] objects = new Object[0]; try { // invoke(&quot;方法名&quot;,参数1,参数2,参数3....); objects = client.invoke(&quot;sendMessage&quot;, &quot;wyj&quot;); System.out.println(&quot;返回数据:&quot; + objects[0]); } catch (java.lang.Exception e) { e.printStackTrace(); } } } 调用后返回结果输出为 项目地址SpringBoot整合cxf的WebService客户端地址SpringBoot整合cxf的WebService服务端地址","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://wangyuanjun.cn/tags/SpringBoot/"},{"name":"WebService","slug":"WebService","permalink":"http://wangyuanjun.cn/tags/WebService/"}]},{"title":"github-hexo搭建博客之hexo提交百度搜索引擎","date":"2017-12-18T09:13:23.000Z","path":"2017/12/18/github-hexo搭建博客之hexo提交百度搜索引擎/","text":"前几天在整理自己的博客想添加一个评论的功能，希望我写的博客能被广大人员所知，突然发现自己写的博客在百度上搜索不到，那我添加评论功能就没有意义，百度一下才知道github禁止了百度爬虫，晕死。折腾了好久才解决，接下来我向大家介绍我的解决方法。 域名1.注册域名：我是在dnspod中注册域名的，下面我以dnspod为例；2.绑定域名绑定域名分2种情况：CNAME和A记录。 A记录：A记录填写IP，由于不带www方式只能采用A记录，所以必须先才cmd的ping一下你的用户名.github.io的IP，然后到你的域名DNS设置页，将A记录指向你ping出来的IP CNAME：将CNAME指向你的用户名.github.io，这样可以保证无论是否添加www都可以访问 3.跳转在source文件夹中新建一个CNAME文件（无后缀名），然后用文本编辑器打开，在首行添加你的网站域名，如 http://xxxx.com ，注意前面没有 http:// ，也没有www，然后使用hexo g &amp;&amp; hexo d上传部署。在你绑定了新域名之后，原来的你的用户名.github.io并没有失效，而是会自动跳转到你的新域名。 验证网站1.百度搜索引擎入口：百度搜索引擎入口 2.文件验证:先添加域名，然后验证网站，这里统一都使用文件验证，就是下载对应的html文件，放到域名根目录下，也就收博客根目录下的public/下面 。然后部署到服务器,输入地址：http://wangyuanjun008.github.io/baidu_verify_oLfvXCaeZ4.html 能访问到就可以点验证按钮(按照百度的引导步骤就好)。 3.网页抓取:(1.主动推送 2.自动推送 3.sitemap 4.手动提交 )我选择的是自动推送 自动推送很简单，就是在你代码里面嵌入自动推送JS代码，在页面被访问时，页面URL将立即被推送给百度，可将代码添加到\\themes\\landscape\\layout_partial\\after_footer.ejs中的最下面就行。 代码如下： &lt;script&gt; (function(){ var bp = document.createElement(&apos;script&apos;); var curProtocol = window.location.protocol.split(&apos;:&apos;)[0]; if (curProtocol === &apos;https&apos;) { bp.src = &apos;https://zz.bdstatic.com/linksubmit/push.js&apos;; } else { bp.src = &apos;http://push.zhanzhang.baidu.com/push.js&apos;; } var s = document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(bp, s); })(); &lt;/script&gt; 参考: hexo干货系列：（六）hexo提交搜索引擎（百度+谷歌）","tags":[{"name":"hexo","slug":"hexo","permalink":"http://wangyuanjun.cn/tags/hexo/"}]},{"title":"github-hexo搭建博客之畅言实现博客的评论","date":"2017-12-18T07:16:28.000Z","path":"2017/12/18/github-hexo搭建博客之畅言实现博客的评论/","text":"前几天在整理自己的博客想添加一个评论的功能，希望我写的博客能被广大人员所知，解决了域名添加百度搜索引擎之后，我决定用畅言作为我的评论插件。 注册畅言进入畅言官网 , 点击右上角 “免费注册”，并填写注册信息 绑定域名详情见之前的博客github-hexo搭建博客之hexo提交百度搜索引擎 登录并进入畅言后台注册完后，登录进入畅言官网，获取你的畅言 app id 和 app key。 使用畅言系统在主题的目录下_config.yml，添加上changyan_appid和changyan_conf的值。 #Cmments comment: cloudTie: ## 网易云跟帖(productKey) changyan: ## 畅言需在下方配置两个参数，此处不填。 appid: xxxxxxxxxxx appkey: xxxxxxxxxxxxxxxxxxxxxxxx 效果:","tags":[{"name":"hexo","slug":"hexo","permalink":"http://wangyuanjun.cn/tags/hexo/"}]},{"title":"","date":"2017-12-07T14:55:20.293Z","path":"2017/12/07/使用element-ui-select下拉框多选，编辑状态下回显数据/","text":"title: 使用element ui select下拉框多选，编辑状态下回显数据date: 2017-12-07 22:55:20categories: element ui tags: element ui最近在做一个项目,项目的后端是地址: https://github.com/wangyuanjun008/wyj-springboot-security.git前端地址是 https://github.com/wangyuanjun008/wyj-vue-security.git ,使用的前端语言是vue,使用webpack构建vue-cli全家桶在项目中使用的是 element ui 组件库，在使用select多选下拉框时，编辑页面不知道怎么为其赋值回显数据。下拉框的代码如下: &lt;el-form-item label=&quot;可选角色&quot;&gt; &lt;el-select v-model=&quot;commonForm.roles&quot; multiple placeholder=&quot;请选择&quot;&gt; &lt;el-option v-for=&quot;item in rolesItems&quot; :key=&quot;item.id&quot; :label=&quot;item.text&quot; :value=&quot;item.id&quot; &gt;&lt;/el-option&gt; &lt;/el-select&gt; &lt;/el-form-item&gt; 猜想:多选下拉框是多条数据，将数据放到数组里面，将数据赋值给多选下拉框，就会有效果。 验证:将多选数据以数组的形式从后台返回到前台，后台字段类型是List返回结果如下: 查看页面多选回显数据成功 参考地址: https://github.com/wangyuanjun008/wyj-vue-security/blob/master/src/view/user/user.vue","tags":[]},{"title":"webpack引入jquery以及插件的方法(如ztree)","date":"2017-12-06T15:27:16.000Z","path":"2017/12/06/webpack引入jquery以及插件的方法-如ztree/","text":"最近在做一个项目,项目的后端是地址: https://github.com/wangyuanjun008/wyj-springboot-security.git前端地址是 https://github.com/wangyuanjun008/wyj-vue-security.git ,使用的前端语言是vue,使用webpack构建vue-cli全家桶在项目中需要用到树插件，但是我觉得element ui 自带的树组件不好用，最主要的问题就是后台返回到前台的数据用到递归，不太好做，所以想到了用ztree树插件来做。 安装 ztree (会自动下载依赖的 jquery ，所以不用下 jquery ) npm install ztree --save-dev 在需要的地方引入资源 import $ from &apos;jquery&apos; import &apos;ztree&apos; 但是报错说ztree找不到jquery，报错如下: 配置jquery由于 ztree 依赖于 jQuery，所以在代码中 import jQuery from ‘jquery’ 是不够的，这只是解决了自己代码对 jQuery 的依赖，在此处使用了webpack.ProvidePlugin 解决方案：在 webpack.base.conf.js 头部添加 var webpack = require(&apos;webpack&apos;) 在 resolve 后边添加 plugins: [ new webpack.ProvidePlugin({ $: &quot;jquery&quot;, jQuery: &quot;jquery&quot;, &quot;window.jQuery&quot;: &quot;jquery&quot; }) ] 引入ztree在 main.js 中，加入如下代码 import &apos;ztree/css/zTreeStyle/zTreeStyle.css&apos; import &apos;ztree&apos; 项目效果:","tags":[{"name":"webpack","slug":"webpack","permalink":"http://wangyuanjun.cn/tags/webpack/"}]},{"title":"解决element ui select下拉框不回显数据问题","date":"2017-12-05T14:06:34.000Z","path":"2017/12/05/解决element-ui-select下拉框不回显数据问题/","text":"最近在做一个项目,项目的后端是地址: https://github.com/wangyuanjun008/wyj-springboot-security.git前端地址是 https://github.com/wangyuanjun008/wyj-vue-security.git ,使用的前端语言是vue,使用webpack构建vue-cli全家桶在项目中用到 el-select 时遇到一个问题，就是在编辑表单时，下拉框的不显示数据，前台代码如下: &lt;el-select v-model=&quot;commonForm.status&quot; clearable placeholder=&quot;请选择&quot;&gt; &lt;el-option v-for=&quot;item in items&quot; :key=&quot;item.id&quot; :label=&quot;item.text&quot; :value=&quot;item.id&quot; &gt;&lt;/el-option&gt; &lt;/el-select&gt; 在浏览器中查看列表返回的数据: 在浏览器中查看下拉框数据源的数据: 发现select下拉的id和v-model里边的id类型不一致，修改后台下拉框数据源返回类型，下拉框显示数据成功。","tags":[{"name":"element ui","slug":"element-ui","permalink":"http://wangyuanjun.cn/tags/element-ui/"}]},{"title":"解决SpringMVC接收不到axios发送post请求的数据问题","date":"2017-12-04T13:10:03.000Z","path":"2017/12/04/解决SpringMVC接收不到axios发送post请求的数据问题/","text":"最近在做一个项目,项目的后端是地址: https://github.com/wangyuanjun008/wyj-springboot-security.git前端地址是 https://github.com/wangyuanjun008/wyj-vue-security.git ,使用的前端语言是vue,使用webpack构建vue-cli全家桶在项目中需要用到axios与后端接口交互的时候，使用POST请求时，后台接收不到前台传的数据js代码如下: export const addDataGroup = params =&gt; { return axios.post(`/remote/dataGroup/add`, params ); }; 请求的数据是: 后台代码代码如下: 解决如下:方法一 ：在项目中安装qs库作为格式化的依赖： npm install qs --save-dev 修改js代码: export const addDataGroup = params =&gt; { return axios.post(`/remote/dataGroup/add`, qs.stringify(params) ); }; 方法二：如果不想修改前端代码的话，需要对后台的代码做修改：通过翻看axios的文档得知：在axios使用Post发送数据时，默认是直接把json放到请求体中提交到后端的，而后端获取数据的方式有两种，一种是@RequestParam（通过字符串中解析出参数）,另一种是@ResponseBody（从请求体中取参数），很显然，我们的后端用了第一种方式。 参考文档：http://www.jzdlink.com/studynotes/201709141385.html","tags":[{"name":"axios","slug":"axios","permalink":"http://wangyuanjun.cn/tags/axios/"}]},{"title":"在vue中使用axios跨域访问数据，用proxyTable解决跨域问题","date":"2017-12-04T13:04:58.000Z","path":"2017/12/04/在vue中使用axios跨域访问数据，用proxyTable解决跨域问题/","text":"最近在做一个项目,项目的后端是地址: https://github.com/wangyuanjun008/wyj-springboot-security.git前端地址是 https://github.com/wangyuanjun008/wyj-vue-security.git ,使用的前端语言是vue,使用webpack构建vue-cli全家桶在项目中需要用到axios与后端接口交互的时候，遇到了跨域的问题，浏览器报错如下: 能看到是有数据数据返回到前台的，说明前台没有接收到 解决方法: 进入你的vue项目下 -&gt; config -&gt; index.js，里面的dev对象下有一个proxyTable的属性，这个参数主要是一个地址映射表，可以帮助我们将复杂的url简化。 如果请求的地址是 http://127.0.0.1:8081/remote/1 ，使用proxyTable配置，请求的地址变为 /remote/1。在proxyTable中有个参数是changeOrigin，如果设置为true,那么本地会虚拟一个服务端接收你的请求并代你发送该请求，这样就不会有跨域问题了，当然这只适用于开发环境。 参考文档：https://vuejs-templates.github.io/webpack/proxy.html","tags":[{"name":"axios","slug":"axios","permalink":"http://wangyuanjun.cn/tags/axios/"}]},{"title":"使用webpack构建vue-cli项目,写scss脚本语言报错","date":"2017-11-28T06:44:20.000Z","path":"2017/11/28/使用webpack构建vue-cli项目-写scss脚本语言报错/","text":"最近在做一个项目,项目的后端是地址: https://github.com/wangyuanjun008/wyj-springboot-security.git前端地址是 https://github.com/wangyuanjun008/wyj-vue-security.git ,使用的前端语言是vue,但是我在使用webpack构建vue项目的时候，使用scss脚本语言是报错,错误如下: error in ./src/components/home.vue Syntax Error: Unclosed block @ ./node_modules/vue-style-loader!./node_modules/css-loader?{&quot;sourceMap&quot;:false}!./node_modules/vue-loader/lib/style-compiler?{&quot;vue&quot;:true,&quot;id&quot;:&quot;data-v-7cbbe74f&quot;,&quot;scoped&quot;:false,&quot;hasInlineConfig&quot;:false}!./node_modules/vue-loader/lib/selector.js?type=styles&amp;index=0&amp;bustCache!./src/components/home.vue 4:14-317 13:3-17:5 14:22-325 @ ./src/components/home.vue @ ./src/router/index.js @ ./src/main.js @ multi (webpack)-dev-server/client?http://localhost:8080 webpack/hot/dev-server ./src/main.js 后来上网查询，如果你需要使用sass/scss定义样式，那么为了能正常编译，还需要做如下配置： //因为sass-loader依赖于node-sass，所以还要安装node-sass npm install --save-dev node-sass //在项目下，运行下列命令行 npm install --save-dev scss-loader npm install --save-dev sass-loader 因为资源是到国外下载的，如果长时间未响应或者报错，可以试用淘宝镜像 npm install --save node-sass --registry=https://registry.npm.taobao.org --disturl=https://npm.taobao.org/dist --sass-binary-site=http://npm.taobao.org/mirrors/node-sass","tags":[{"name":"webpack","slug":"webpack","permalink":"http://wangyuanjun.cn/tags/webpack/"}]},{"title":"Springboot RedisTemplate 报No qualifying bean of type... 不能按类型装配注入","date":"2017-11-23T09:40:09.000Z","path":"2017/11/23/Springboot-RedisTemplate-报No-qualifying-bean-of-type-不能按类型装配注入/","text":"最近在做一个项目,项目地址: https://github.com/wangyuanjun008/wyj-springboot-security.git在项目中与redis集成，使用的依赖是: &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; 在Controller中使用如下: @Autowired private RedisTemplate&lt;String, DataGroup&gt; redisTemplate; 项目启动报错如下: Description: Field redisTemplate in com.wyj.controller.data.DataGroupController required a bean of type &apos;org.springframework.data.redis.core.RedisTemplate&apos; that could not be found. - Bean method &apos;redisTemplate&apos; in &apos;RedisAutoConfiguration.RedisConfiguration&apos; not loaded because @ConditionalOnMissingBean (names: redisTemplate; SearchStrategy: all) found bean &apos;redisTemplate&apos; Action: Consider revisiting the conditions above or defining a bean of type &apos;org.springframework.data.redis.core.RedisTemplate&apos; in your configuration. 2017-11-23 17:36:38.299 ERROR 5784 --- [ main] o.s.test.context.TestContextManager : Caught exception while allowing TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener@3b2cf7ab] to prepare test instance [com.wyj.WyjSpringbootApplicationTests@6cc8adff] java.lang.IllegalStateException: Failed to load ApplicationContext at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124) ~[spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83) ~[spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:189) ~[spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:131) ~[spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:230) ~[spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:228) [spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:287) [spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12] at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:289) [spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:247) [spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:94) [spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12] at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12] at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12] at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12] at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12] at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) [spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) [spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12] at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:191) [spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:283) [surefire-junit4-2.18.1.jar:2.18.1] at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:173) [surefire-junit4-2.18.1.jar:2.18.1] at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153) [surefire-junit4-2.18.1.jar:2.18.1] at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:128) [surefire-junit4-2.18.1.jar:2.18.1] at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:203) [surefire-booter-2.18.1.jar:2.18.1] at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:155) [surefire-booter-2.18.1.jar:2.18.1] at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103) [surefire-booter-2.18.1.jar:2.18.1] Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;dataGroupController&apos;: Unsatisfied dependency expressed through field &apos;redisTemplate&apos;; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type &apos;org.springframework.data.redis.core.RedisTemplate&lt;java.lang.String, com.wyj.entity.data.DataGroup&gt;&apos; available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543) ~[spring-context-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) ~[spring-boot-1.5.8.RELEASE.jar:1.5.8.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) ~[spring-boot-1.5.8.RELEASE.jar:1.5.8.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) ~[spring-boot-1.5.8.RELEASE.jar:1.5.8.RELEASE] at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:120) ~[spring-boot-test-1.5.8.RELEASE.jar:1.5.8.RELEASE] at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98) ~[spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116) ~[spring-test-4.3.12.RELEASE.jar:4.3.12.RELEASE] ... 26 common frames omitted Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type &apos;org.springframework.data.redis.core.RedisTemplate&lt;java.lang.String, com.wyj.entity.data.DataGroup&gt;&apos; available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1493) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1104) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585) ~[spring-beans-4.3.12.RELEASE.jar:4.3.12.RELEASE] ... 44 common frames omitted 苦思冥想多时，上网查阅资料，看springboot文档，结果如下 If you add a @Bean of your own of any of the auto-configured types it will replace the default (except in the case of RedisTemplate the exclusion is based on the bean name ‘redisTemplate’ not its type). 将代码改成: @Resource private RedisTemplate&lt;String, DataGroup&gt; redisTemplate; 项目启动不报错，完美解决!","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://wangyuanjun.cn/tags/SpringBoot/"}]},{"title":"SpringMVC中使用aop注解无效的问题","date":"2017-09-28T06:47:46.000Z","path":"2017/09/28/SpringMVC中使用aop注解无效的问题/","text":"最近在做一个项目,项目地址: https://github.com/wangyuanjun008/wyj-parent.git写日志注解完，进行测试时，发现日志注解没有生效，代码如下: 定义注解: @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface SysLog { String action() default &quot;&quot;;//动作 } 切面: @Aspect @Component public class SysLogAspect { @Autowired private SysLogService sysLogService; @Pointcut(&quot;@annotation(com.wyj.annotation.SysLog)&quot;) public void pointCut(){} @Around(&quot;pointCut()&quot;) public Object aroud(ProceedingJoinPoint joinPoint) throws Throwable{ // 开始时间 long beginTime = System.currentTimeMillis(); //执行目标方法 Object result = joinPoint.proceed(); //执行时长(毫秒) long time = System.currentTimeMillis() - beginTime; //保存日志 saveSysLog(joinPoint, time); return result; } } applicationContext.xml 配置: &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot; http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd&quot;&gt; &lt;bean id=&quot;propertyConfigurer&quot; class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt; &lt;property name=&quot;locations&quot;&gt; &lt;list&gt; &lt;value&gt;classpath:jdbc.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;context:annotation-config /&gt; &lt;context:component-scan base-package=&quot;com.wyj&quot; use-default-filters=&quot;false&quot;&gt; &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt; &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.web.bind.annotation.ControllerAdvice&quot; /&gt; &lt;/context:component-scan&gt; &lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot; /&gt; &lt;/beans&gt; controller代码: @Controller @RequestMapping(value = &quot;/user&quot;) public class UserController { private Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private UserService userService; @SysLog(action=&quot;新增/编辑用户&quot;) @ResponseBody @RequestMapping(value = &quot;/add&quot;, method = RequestMethod.POST) public Retval save(User user) { Retval retval = Retval.newInstance(); try { if (user.getUserId() == null) { userService.saveUser(user); } else { userService.updateUser(user); } } catch (Exception e) { logger.error(e.getMessage(), e); } return retval; } } 和别人讨论了下，大致是Spring上下文的问题我的AOP配置是这样的：AOP命名空间和挪到SpringMVC自己的配置文件里面，AOP就生效了。 代码如下:springmvc-servlet.xml: &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot; default-lazy-init=&quot;true&quot;&gt; &lt;mvc:annotation-driven /&gt; &lt;mvc:annotation-driven content-negotiation-manager=&quot;contentNegotiationManager&quot;&gt; &lt;mvc:message-converters register-defaults=&quot;true&quot;&gt; &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt; &lt;constructor-arg value=&quot;UTF-8&quot; /&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;&gt; &lt;property name=&quot;prettyPrint&quot; value=&quot;true&quot; /&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt; &lt;/mvc:annotation-driven&gt; &lt;bean id=&quot;contentNegotiationManager&quot; class=&quot;org.springframework.web.accept.ContentNegotiationManagerFactoryBean&quot;&gt; &lt;property name=&quot;ignoreAcceptHeader&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;defaultContentType&quot; value=&quot;application/json&quot; /&gt; &lt;property name=&quot;mediaTypes&quot;&gt; &lt;value&gt; json=application/json xml=application/xml &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;context:component-scan base-package=&quot;com.wyj&quot;&gt;&lt;/context:component-scan&gt; &lt;bean id=&quot;viewResolver&quot; class=&quot;org.springframework.web.servlet.view.UrlBasedViewResolver&quot;&gt; &lt;property name=&quot;viewClass&quot; value=&quot;org.springframework.web.servlet.view.JstlView&quot; /&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/views/&quot; /&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot; /&gt; &lt;/bean&gt; &lt;mvc:resources location=&quot;/resources/**&quot; mapping=&quot;/resources/**&quot; /&gt; &lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot; /&gt; &lt;/beans&gt; 另外以上所述的是对controller进行切面时的配置，如果是对service进行切面，那么 这两个注释就要用在ApplicationContext.xml里面了，注意此时不要开启aop的cglib代理模式。 解释： 1.SpringMVC这个框架简化了很多的配置，但是请注意@Controller和@Service都是SpringMVC框架包里面的，也就是说，这些类的实例化以及注入也是由SpringMVC这个框架完成的（确切的来说是这个框架自己有的上下文的IoC容器完成的）。 2.而对AOP和事务的支持是Spring框架本身完成的，是Spring框架的应用上下文所扫描并处理的。 从1.2可以得出一个结论，如果SpringMVC和Spring本身用的是一个应用上下文，一个Ioc容器，那随便你的和命名空间配置在哪里，无论是Spring的ApplicationContext.xml还是SpringMVC的springmvc-servlet.xml里面，反正都是一个容器，怎么扫描，怎么处理都能找到。 但关键的是以上假设不成立，总的来说SpringMVC的应用上下文的 “ 父 ” 上下文才是Spring的应用上下文。那么这个也就是说Spring的应用上下文初始化完成的时候，它开始扫描到底哪些Bean用了AspectJ的注解，哪些用了Transactional的注解，但是利用SpringMVC注解配置的这些Bean它是找不到的，因为用了这些注解的Bean还没有被实例化甚至是还没有被装载，为什么呢？因为管理这些bean的SpringMVC的上下文可能还没有完成初始化。OK，既然Spring的上下文找不到到底哪些Bean应用了注解，那他自然也没有办法给这些Bean提供声明式AOP和事务的支持了。 至于为什么SpringMVC的应用上下文的 “ 父 ” 上下文才是Spring的应用上下文，这里有大牛为我们详解：http://blog.csdn.net/c289054531/article/details/9196149 另外，Spring中的切面类固然要用@Aspect标注，但也不要忘了用@Componet标注，这样才能被注册到容器中","tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://wangyuanjun.cn/tags/SpringMVC/"}]},{"title":"使用Spring配置shiro时,自定义Realm中属性无法使用注解注入解决办法","date":"2017-09-21T15:30:17.000Z","path":"2017/09/21/使用Spring配置shiro时-自定义Realm中属性无法使用注解注入解决办法/","text":"项目地址: https://github.com/wangyuanjun008/wyj-parent.git最近在使用shiro框架与系统集成的时候，启动报错如下: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;shiroFilter&apos; defined in class path resource [spring-context-shiro.xml]: Cannot resolve reference to bean &apos;securityManager&apos; while setting bean property &apos;securityManager&apos;; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;securityManager&apos; defined in class path resource [spring-context-shiro.xml]: Cannot resolve reference to bean &apos;userRealm&apos; while setting bean property &apos;realm&apos;; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;userRealm&apos;: Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: private com.wyj.service.system.UserService com.wyj.shiro.realm.UserRealm.userService; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [com.wyj.service.system.UserService] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:328) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:107) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1456) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1197) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.context.support.PostProcessorRegistrationDelegate.registerBeanPostProcessors(PostProcessorRegistrationDelegate.java:232) ~[spring-context-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.context.support.AbstractApplicationContext.registerBeanPostProcessors(AbstractApplicationContext.java:618) ~[spring-context-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:467) ~[spring-context-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.web.context.ContextLoader.configureAndRefreshWebApplicationContext(ContextLoader.java:403) ~[spring-web-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.web.context.ContextLoader.initWebApplicationContext(ContextLoader.java:306) ~[spring-web-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.web.context.ContextLoaderListener.contextInitialized(ContextLoaderListener.java:106) [spring-web-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4729) [catalina.jar:na] at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5167) [catalina.jar:na] at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [catalina.jar:na] at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:725) [catalina.jar:na] at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:701) [catalina.jar:na] at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:717) [catalina.jar:na] at org.apache.catalina.startup.HostConfig.deployDescriptor(HostConfig.java:586) [catalina.jar:8.0.26.B] at org.apache.catalina.startup.HostConfig$DeployDescriptor.run(HostConfig.java:1750) [catalina.jar:8.0.26.B] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_77] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_77] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_77] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_77] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_77] Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;securityManager&apos; defined in class path resource [spring-context-shiro.xml]: Cannot resolve reference to bean &apos;userRealm&apos; while setting bean property &apos;realm&apos;; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;userRealm&apos;: Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: private com.wyj.service.system.UserService com.wyj.shiro.realm.UserRealm.userService; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [com.wyj.service.system.UserService] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:328) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:107) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1456) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1197) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:320) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] ... 28 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;userRealm&apos;: Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: private com.wyj.service.system.UserService com.wyj.shiro.realm.UserRealm.userService; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [com.wyj.service.system.UserService] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:292) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:320) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] ... 38 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Could not autowire field: private com.wyj.service.system.UserService com.wyj.shiro.realm.UserRealm.userService; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [com.wyj.service.system.UserService] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:508) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:289) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] ... 46 common frames omitted Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [com.wyj.service.system.UserService] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoSuchBeanDefinitionException(DefaultListableBeanFactory.java:1100) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:960) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:480) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] ... 48 common frames omitted 在shiro.xml的配置是: &lt;bean id=&quot;userRealm&quot; class=&quot;com.wyj.shiro.realm.UserRealm&quot;/&gt; UserRealm.java的代码是: public class UserRealm extends AuthorizingRealm{ @Autowired private UserService userService; @Autowired private RoleService roleService; @Autowired private MenuService menuService; /** * 授权(验证权限时调用) * 为当前登陆成功的用户授予权限和角色，已经登陆成功了 */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) { ... return info; } /** * 认证(登录时调用) * 验证当前登录的用户，获取认证信息 */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { ... return info; } } 纠结了几个小时终于找到了问题所在,因为shiro的realm属于Filter,简单说就是初始化realm时,spring还未加载相关业务Bean,那么解决办法就是将springmvc的配置文件加载提前。 解决办法打开web.xml文件","tags":[{"name":"shiro","slug":"shiro","permalink":"http://wangyuanjun.cn/tags/shiro/"}]},{"title":"树插件ztree异步加载数据与一次性加载全部数据的写法","date":"2017-09-18T13:12:47.000Z","path":"2017/09/18/树插件ztree异步加载数据与一次性加载全部数据的写法/","text":"最近在做一个项目,项目地址: https://github.com/wangyuanjun008/wyj-parent.git用到了ztree树，给大家分享异步加载数据与一次性加载数据的写法 异步加载数据是为了防止大数据量而造成树卡死的情况,代码如下:前台js: &lt;div class=&quot;col-lg-12&quot; style=&quot;height:300px; overflow:scroll;&quot;&gt; &lt;ul id=&quot;treeDemo&quot; class=&quot;ztree&quot;&gt;&lt;/ul&gt; &lt;/div&gt; function setting() { var setting = { async : { enable : true, type : &quot;get&quot;, url : &apos;${ctx}/menu/renderTree&apos;, autoParam : [ &quot;id&quot;, &quot;type&quot; ] }, callback : { onClick : zTreeOnClick } }; return setting; } $.fn.zTree.init($(&quot;#treeDemo&quot;), setting(treeUrl)); 后台java: @ResponseBody @RequestMapping(value = &quot;/renderTree&quot;, method = RequestMethod.GET) public List&lt;Map&lt;String, Object&gt;&gt; renderTree1(Long id, String type) { List&lt;Map&lt;String, Object&gt;&gt; returnList = new ArrayList&lt;Map&lt;String, Object&gt;&gt;(); // 加载根节点 if (StringUtils.isEmpty(id)) { Map&lt;String, Object&gt; root = new HashMap&lt;String, Object&gt;(); root.put(&quot;id&quot;, 0);// 根节点的ID root.put(&quot;name&quot;, &quot;权限管理系统&quot;); // 根节点的名字 root.put(&quot;isParent&quot;, true);//// 设置根节点为父节点 // 加载一级节点 List&lt;Map&lt;String, Object&gt;&gt; returnList1 = new ArrayList&lt;Map&lt;String, Object&gt;&gt;(); List&lt;Menu&gt; menus = menuService.listOneNodeMenus(); for (Menu menu : menus) { Map&lt;String, Object&gt; node = new HashMap&lt;String, Object&gt;(); node.put(&quot;id&quot;, menu.getMenuId()); node.put(&quot;name&quot;, menu.getName()); node.put(&quot;isParent&quot;, menuService.isSubNodeById(menu.getMenuId())); returnList1.add(node); } root.put(&quot;children&quot;, returnList1); returnList.add(root); return returnList; } // 加载子节点 List&lt;Menu&gt; menus = null; if (id != null &amp;&amp; id &gt; 0L) { menus = menuService.listSubMenuByParentId(id); for (Menu menu : menus) { Map&lt;String, Object&gt; node = new HashMap&lt;String, Object&gt;(); node.put(&quot;id&quot;, menu.getMenuId()); node.put(&quot;name&quot;, menu.getName()); node.put(&quot;isParent&quot;, menuService.isSubNodeById(menu.getMenuId())); returnList.add(node); } } return returnList; } 加载全部数据:前台js &lt;div class=&quot;col-lg-12&quot; style=&quot;height:300px; overflow:scroll;&quot;&gt; &lt;ul id=&quot;treeDemo&quot; class=&quot;ztree&quot;&gt;&lt;/ul&gt; &lt;/div&gt; function setting() { var setting = { data : { simpleData : { enable : true, idKey : &quot;menuId&quot;, pIdKey : &quot;parentId&quot;, rootPId : null }, check: { enable: true, chkStyle: &quot;checkbox&quot;, chkboxType: { &quot;Y&quot;: &quot;ps&quot;, &quot;N&quot;: &quot;ps&quot; } } }; return setting; } } var jsonTree = getDataStore(&apos;${ctx}/auth/renderTree&apos;);//获得所有节点 var ztree=$.fn.zTree.init($(&quot;#treeDemo&quot;), setting(),jsonTree); 后台java: @ResponseBody @RequestMapping(value = &quot;/renderTree&quot;, method = RequestMethod.GET) public List&lt;Menu&gt; renderTree() { return menuService.listTree(); } 希望能对大家有所帮助!","tags":[{"name":"jquery","slug":"jquery","permalink":"http://wangyuanjun.cn/tags/jquery/"},{"name":"ztree","slug":"ztree","permalink":"http://wangyuanjun.cn/tags/ztree/"}]},{"title":"在java中调用存储过程","date":"2017-09-14T01:57:48.000Z","path":"2017/09/14/在java中调用存储过程/","text":"最近在做一个需要调用存储过程的功能，大多数的写法是: Connection conn=null; CallableStatement csmt=null; try { conn=JDBCUtils.getConnection(); conn.setAutoCommit(false); csmt=conn.prepareCall(&quot;call prc_1(?,?,?)&quot;); csmt.setInt(1,80); csmt.setString(2,&quot;ioc&quot;); csmt.setString(3,&quot;fhp&quot;); csmt.execute(); conn.commit(); System.out.println(&quot;success insert data&quot;); } catch (SQLException e) { e.printStackTrace(); } 但是在运用的过程是没有效果的，后来找了另外的方法，使用了jpa注解，代码如下: 存储过程需要依赖在实体上，在实体上加上@NamedStoredProcedureQueries注解，@NamedStoredProcedureQuery中name为java的方法名，procedureName为存储过程的名字，@StoredProcedureParameter中mode代表入参，name是参数名，type是参数类型 @Entity Table(name = &quot;d_cp_delivery&quot;) @NamedStoredProcedureQueries({ @NamedStoredProcedureQuery(name = &quot;closePurchaseorder&quot;, procedureName = &quot;SRMANLI.closePurchaseorder&quot;, parameters = { @StoredProcedureParameter(mode = ParameterMode.IN, name = &quot;i_deliveryid&quot;, type = Long.class) }) }) 2.调用方法如下 //java代码 EntityManager em; @Override @PersistenceContext(unitName = &quot;srment&quot;) public void setEntityManager(EntityManager em) { super.setEntityManager(em); this.em = em; } @Override public void closePurchaseorder(Long deliveryId) { Query qry = em.createNativeQuery(&quot;{call srmanli.closePurchaseorder(?1)}&quot;); qry.setParameter(1, deliveryId); qry.executeUpdate(); em.clear(); } //存储过程 procedure closePurchaseorder(i_deliveryid in number) is v_PurchaseorderDtlNum number; -- v_reqtime date := sysdate; --请求时间 v_err_msg clob; --异常 begin end;","tags":[{"name":"java","slug":"java","permalink":"http://wangyuanjun.cn/tags/java/"}]},{"title":"使用select2下拉框ajax加载数据时,编辑赋值的方法","date":"2017-09-13T16:19:44.000Z","path":"2017/09/14/使用select2下拉框ajax加载数据时-编辑赋值的方法/","text":"最近在做一个项目,项目地址: https://github.com/wangyuanjun008/wyj-parent.git使用bootstrap select2下拉框插件，ajax从后台加载数据，保存编辑后，不知道怎么为下拉框赋值，下拉框代码如下: &lt;label class=&quot;col-sm-1 control-label&quot;&gt;使用状态:&lt;/label&gt; &lt;select id=&quot;sel_status&quot; name=&quot;status&quot; class=&quot;col-sm-3 form-control select2&quot;&gt;&lt;/select&gt; $(&quot;#sel_status&quot;).select2({ placeholder : &quot;--请选择--&quot;, dropdownParent : $(&quot;#myModal&quot;), allowClear : true, width : 150, ajax : { url : &apos;${ctx}/dataDict/getData?groupCode=&apos;+&apos;yesOrNo&apos;, dataType : &apos;json&apos;, type : &apos;get&apos;, data: function (params) { return { q: params.term, // search term 请求参数 page: params.page }; }, processResults: function (data, params) { params.page = params.page || 1; return { results: data,//itemList pagination: { more: (params.page * 30) &lt; data.total_count } }; }, cache: true } }); 通过查询api知道，在select4.0之后可以使用 $(“select”).val(“id”).trigger(“change”);为下拉框赋值你会发现下拉框中的数据是点击之后才会加载数据的，使用如上方法 ‘id’是未知的，原因是在编辑的时候下拉框的数据还没有加载出来 解决方法如下: function getDataByGroupCode(groupCode){ var dataStore; $.ajax({ dataType : &apos;json&apos;, type : &apos;get&apos;, url : model.dataURL+groupCode, async : false, success: function(data){ dataStore=data; } }); return dataStore; } var dataStore = getDataByGroupCode(&apos;yesOrNo&apos;); $(&quot;#sel_status&quot;).select2({ placeholder : &quot;--请选择--&quot;, dropdownParent : $(&quot;#myModal&quot;), allowClear : true, width : 150, minimumResultsForSearch: -1, data : dataStore }); 在页面加载的时候就加载下拉框数据，在编辑时就能为其赋值，问题解决!","tags":[{"name":"select2","slug":"select2","permalink":"http://wangyuanjun.cn/tags/select2/"}]},{"title":"mybatis使用PageHelper插件报错Error creating bean with name sqlSessionFactory defined in class path resource [spring-mybatis.xml]","date":"2017-08-17T13:23:57.000Z","path":"2017/08/17/mybatis使用PageHelper插件报错Error-creating-bean-with-name-sqlSessionFactory-defined-in-class-path-resource-spring-mybatis-xml/","text":"最近在做一个项目,项目地址: https://github.com/wangyuanjun008/wyj-parent.git在项目中使用mybatis的分页插件:PageHelper，整合spring后在启动后报错，错误如下: 2017-08-17 21:20:16.618 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] ERROR org.springframework.web.context.ContextLoader - Context initialization failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;sqlSessionFactory&apos; defined in class path resource [spring-mybatis.xml]: Invocation of init method failed; nested exception is org.springframework.core.NestedIOException: Failed to parse config resource: class path resource [mybatis-config.xml]; nested exception is org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: java.lang.ClassCastException: com.github.pagehelper.PageHelper cannot be cast to org.apache.ibatis.plugin.Interceptor at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1553) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:681) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760) ~[spring-context-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482) ~[spring-context-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.web.context.ContextLoader.configureAndRefreshWebApplicationContext(ContextLoader.java:403) ~[spring-web-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.web.context.ContextLoader.initWebApplicationContext(ContextLoader.java:306) ~[spring-web-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.web.context.ContextLoaderListener.contextInitialized(ContextLoaderListener.java:106) [spring-web-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4729) [catalina.jar:na] at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5167) [catalina.jar:na] at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [catalina.jar:na] at org.apache.catalina.core.StandardContext.reload(StandardContext.java:3746) [catalina.jar:na] at org.apache.catalina.loader.WebappLoader.backgroundProcess(WebappLoader.java:292) [catalina.jar:na] at org.apache.catalina.core.StandardContext.backgroundProcess(StandardContext.java:5528) [catalina.jar:na] at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.processChildren(ContainerBase.java:1377) [catalina.jar:na] at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.processChildren(ContainerBase.java:1381) [catalina.jar:na] at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.processChildren(ContainerBase.java:1381) [catalina.jar:na] at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.run(ContainerBase.java:1349) [catalina.jar:na] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_77] Caused by: org.springframework.core.NestedIOException: Failed to parse config resource: class path resource [mybatis-config.xml]; nested exception is org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: java.lang.ClassCastException: com.github.pagehelper.PageHelper cannot be cast to org.apache.ibatis.plugin.Interceptor at org.mybatis.spring.SqlSessionFactoryBean.buildSqlSessionFactory(SqlSessionFactoryBean.java:434) ~[mybatis-spring-1.2.2.jar:1.2.2] at org.mybatis.spring.SqlSessionFactoryBean.afterPropertiesSet(SqlSessionFactoryBean.java:340) ~[mybatis-spring-1.2.2.jar:1.2.2] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1612) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1549) ~[spring-beans-4.0.2.RELEASE.jar:4.0.2.RELEASE] ... 23 common frames omitted Caused by: org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: java.lang.ClassCastException: com.github.pagehelper.PageHelper cannot be cast to org.apache.ibatis.plugin.Interceptor at org.apache.ibatis.builder.xml.XMLConfigBuilder.parseConfiguration(XMLConfigBuilder.java:109) ~[mybatis-3.2.6.jar:3.2.6] at org.apache.ibatis.builder.xml.XMLConfigBuilder.parse(XMLConfigBuilder.java:92) ~[mybatis-3.2.6.jar:3.2.6] at org.mybatis.spring.SqlSessionFactoryBean.buildSqlSessionFactory(SqlSessionFactoryBean.java:428) ~[mybatis-spring-1.2.2.jar:1.2.2] ... 26 common frames omitted Caused by: java.lang.ClassCastException: com.github.pagehelper.PageHelper cannot be cast to org.apache.ibatis.plugin.Interceptor at org.apache.ibatis.builder.xml.XMLConfigBuilder.pluginElement(XMLConfigBuilder.java:142) ~[mybatis-3.2.6.jar:3.2.6] at org.apache.ibatis.builder.xml.XMLConfigBuilder.parseConfiguration(XMLConfigBuilder.java:100) ~[mybatis-3.2.6.jar:3.2.6] ... 28 common frames omitted spring与mybaits集成的配置文件 spring-mybaits.xml &lt;!-- =======================================================================引入配置文件============================================ --&gt; &lt;bean id=&quot;propertyConfigurer&quot; class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt; &lt;property name=&quot;locations&quot;&gt; &lt;list&gt; &lt;value&gt;classpath:jdbc.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- =======================================================================配置数据源============================================ --&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;${driver}&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;${url}&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;${username}&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;${password}&quot; /&gt; &lt;!-- 初始化连接大小 --&gt; &lt;property name=&quot;initialSize&quot; value=&quot;${initialSize}&quot;&gt;&lt;/property&gt; &lt;!-- 连接池最大数量 --&gt; &lt;property name=&quot;maxActive&quot; value=&quot;${maxActive}&quot;&gt;&lt;/property&gt; &lt;!-- 连接池最大空闲 --&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;${maxIdle}&quot;&gt;&lt;/property&gt; &lt;!-- 连接池最小空闲 --&gt; &lt;property name=&quot;minIdle&quot; value=&quot;${minIdle}&quot;&gt;&lt;/property&gt; &lt;!-- 获取连接最大等待时间 --&gt; &lt;property name=&quot;maxWait&quot; value=&quot;${maxWait}&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- ================================================配置sessionfactory============================================================================== --&gt; &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt; &lt;!-- 自动扫描mapping.xml文件 --&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:com/wyj/mapping/auth/*.xml&quot;&gt;&lt;/property&gt; &lt;!-- 引入配置文件 --&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot; /&gt; &lt;/bean&gt; &lt;!-- =================================================装配dao接口================================================================================== --&gt; &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.wyj.dao.auth&quot; /&gt;&lt;!-- DAO接口所在包名，Spring会自动查找其下的类 --&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- =================================================声明式事务管理================================================================================== --&gt; &lt;!-- (事务管理)transaction manager, use JtaTransactionManager for global tx --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;/bean&gt; mybatis-config.xml 配置文件(分页插件) &lt;configuration&gt; &lt;plugins&gt; &lt;!-- com.github.pagehelper为PageHelper类所在包名 --&gt; &lt;plugin interceptor=&quot;com.github.pagehelper.PageHelper&quot;&gt; &lt;!-- 设置数据库类型 Oracle,Mysql,MariaDB,SQLite,Hsqldb,PostgreSQL六种数据库 --&gt; &lt;property name=&quot;dialect&quot; value=&quot;mysql&quot; /&gt; &lt;!-- 该参数默认为false --&gt; &lt;!-- 设置为true时，会将RowBounds第一个参数offset当成pageNum页码使用 --&gt; &lt;!-- 和startPage中的pageNum效果一样--&gt; &lt;property name=&quot;offsetAsPageNum&quot; value=&quot;true&quot;/&gt; &lt;!-- 该参数默认为false --&gt; &lt;!-- 设置为true时，使用RowBounds分页会进行count查询 --&gt; &lt;property name=&quot;rowBoundsWithCount&quot; value=&quot;true&quot;/&gt; &lt;!-- 设置为true时，如果pageSize=0或者RowBounds.limit = 0就会查询出全部的结果 --&gt; &lt;!-- （相当于没有执行分页查询，但是返回结果仍然是Page类型）--&gt; &lt;property name=&quot;pageSizeZero&quot; value=&quot;true&quot;/&gt; &lt;!-- 3.3.0版本可用 - 分页参数合理化，默认false禁用 --&gt; &lt;!-- 启用合理化时，如果pageNum&lt;1会查询第一页，如果pageNum&gt;pages会查询最后一页 --&gt; &lt;!-- 禁用合理化时，如果pageNum&lt;1或pageNum&gt;pages会返回空数据 --&gt; &lt;property name=&quot;reasonable&quot; value=&quot;true&quot;/&gt; &lt;!-- 3.5.0版本可用 - 为了支持startPage(Object params)方法 --&gt; &lt;!-- 增加了一个`params`参数来配置参数映射，用于从Map或ServletRequest中取值 --&gt; &lt;!-- 可以配置pageNum,pageSize,count,pageSizeZero,reasonable,orderBy,不配置映射的用默认值 --&gt; &lt;!-- 不理解该含义的前提下，不要随便复制该配置 --&gt; &lt;property name=&quot;params&quot; value=&quot;pageNum=start;pageSize=limit;&quot;/&gt; &lt;!-- 支持通过Mapper接口参数来传递分页参数 --&gt; &lt;property name=&quot;supportMethodsArguments&quot; value=&quot;true&quot;/&gt; &lt;!-- always总是返回PageInfo类型,check检查返回类型是否为PageInfo,none返回Page --&gt; &lt;property name=&quot;returnPageInfo&quot; value=&quot;check&quot;/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/configuration&gt; 经过查找，原来是与mybaitis的jar包版本相差过大，项目运用的是4.1.1的版本，换上5.0.4的版本，重新运行项目，不再抛错。 修改spring-mybatis.xml配置文件如下 修改 sqlSessionFactory &lt;!-- ================================================配置sessionfactory============================================================================== --&gt; &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt; &lt;!-- 自动扫描mapping.xml文件 --&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:com/wyj/mapping/auth/*.xml&quot;&gt;&lt;/property&gt; &lt;property name=&quot;plugins&quot;&gt; &lt;array&gt; &lt;bean class=&quot;com.github.pagehelper.PageInterceptor&quot;&gt; &lt;property name=&quot;properties&quot;&gt; &lt;value&gt; &lt;!-- helperDialect：有别于3.0+版本，现在必须是helperDialect，否则spring启动加载时会报错 --&gt; helperDialect=mysql &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; 启动不再报错!!!","tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://wangyuanjun.cn/tags/mybatis/"}]},{"title":"使用hexo,换电脑跟新博客","date":"2017-06-29T15:33:55.000Z","path":"2017/06/29/试用hexo-换电脑跟新博客/","text":"转载：https://www.zhihu.com/question/21193762/answer/103097754 从官网Git下载git，在新电脑上安装，因为https速度慢，而且每次都要输入口令，常用的是使用ssh。使用下面方法创建： 打开git bash，在用户主目录下运行：ssh-keygen -t rsa -C “youremail@example.com” 把其中的邮件地址换成自己的邮件地址，然后一路回车 最后完成后，会在用户主目录下生成.ssh目录，里面有id_rsa和id_rsa.pub两个文件，这两个就是SSH key密钥对，id_rsa是私钥，千万不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。 登陆GitHub，打开「Settings」-&gt;「SSH and GPG keys」，然后点击「new SSH key」，填上任意Title，在Key文本框里粘贴公钥id_rsa.pub文件的内容（千万不要粘贴成私钥了！），最后点击「Add SSH Key」，你就应该看到已经添加的Key。注意：不要在git版本库中运行ssh，然后又将它提交，这样就把密码泄露出去了。 下载Node.js，并安装 打开git bash客户端，输入 npm install hexo-cli -g，开始安装hexo 下面就将原来的文件拷贝到新电脑中，但是要注意哪些文件是必须的，哪些文件是可以删除的。 讨论下哪些文件是必须拷贝的：首先是之前自己修改的文件，像站点配置_config.yml，theme文件夹里面的主题，以及source里面自己写的博客文件，这些肯定要拷贝的。除此之外，还有三个文件需要有，就是scaffolds文件夹（文章的模板）、package.json（说明使用哪些包）和.gitignore（限定在提交的时候哪些文件可以忽略）。其实，这三个文件不是我们修改的，所以即使丢失了，也没有关系，我们可以建立一个新的文件夹，然后在里面执行hexo init，就会生成这三个文件，我们只需要将它们拷贝过来使用即可。总结：_config.yml，theme/，source/，scaffolds/，package.json，.gitignore，是需要拷贝的。 再讨论下哪些文件是不必拷贝的，或者说可以删除的：首先是.git文件，无论是在站点根目录下，还是主题目录下的.git文件，都可以删掉。然后是文件夹node_modules（在用npm install会重新生成），public（这个在用hexo g时会重新生成），.deploy_git文件夹（在使用hexo d时也会重新生成），db.json文件。其实上面这些文件也就是是.gitignore文件里面记载的可以忽略的内容。总结：.git/，node_modules/，public/，.deploy_git/，db.json文件需要删除。 在git bash中切换目录到新拷贝的文件夹里，使用 npm install 命令，进行模块安装。很明显我们这里没用hexo init初始化，因为有的文件我们已经拷贝生成过来了，所以不必用hexo init去整体初始化，如果不慎在此时用了hexo init，则站点的配置文件_config.yml里面内容会被清空使用默认值，所以这一步一定要慎重，不要用hexo init。 安装其他的一些必要组件，如果在node_modules里面有的，就不要重复安装了： 为了使用hexo d来部署到git上，需要安装npm install hexo-deployer-git –save 为了建立RSS订阅，需要安装npm install hexo-generator-feed –save 为了建立站点地图，需要安装npm install hexo-generator-sitemap –save插件安装后，有的需要对配置文件_config.yml进行配置，具体怎么配置，可以参考上面插件在github主页上的具体说明7、使用hexo g，然后使用hexo d进行部署，如果都没有出错，就转移成功了！","tags":[{"name":"hexo","slug":"hexo","permalink":"http://wangyuanjun.cn/tags/hexo/"}]},{"title":"Hello World","date":"2017-06-29T15:21:26.034Z","path":"2017/06/29/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]},{"title":"修改Weblogic jdk版本","date":"2017-05-17T08:10:45.000Z","path":"2017/05/17/修改Weblogic-jdk版本/","text":"1、E:\\develop-tools\\toolsInstall\\weblogic是我的weblogic安装目录2、E:\\develop-tools\\toolsInstall\\weblogic\\user_projects\\domains\\base_domain是我的域创建目录 找到E:\\develop-tools\\toolsInstall\\weblogic\\user_projects\\domains\\base_domain\\binsetDomainEnv.cmd,修改红框标注的","tags":[{"name":"weblogic","slug":"weblogic","permalink":"http://wangyuanjun.cn/tags/weblogic/"}]},{"title":"Oracle数据库之PL/SQL游标","date":"2017-04-28T06:35:56.000Z","path":"2017/04/28/Oracle数据库之PL-SQL游标/","text":"原文 http://www.cnblogs.com/zf29506564/p/5772344.html 一：游标概念字面意思是游动的光标，是指向上下文区域的句柄或指针。 在PL/SQL块中执行CRUD操作时，ORACLE会在内存中为其分配上下文区。用数据库语言来描述游标就是：映射在上下文区结果集中一行数据上的位置实体。 用户可以使用游标访问结果集中的任意一行数据，将游标指向某行后，即可对该行数据进行操作。游标为应用提供了一种对具有多行数据查询结果集中的每一行数据分别进行单独处理的方法，是设计嵌入式SQL语句的应用程序的常用编程方式。 在每个用户会话中，可以同时打开多个游标，其最大数量由数据库初始化参数文件中的OPEN_CURSORS参数定义。 游标可分为显式游标和隐式游标两类。 二：显式游标显式游标使用主要有四个步骤： 声明/定义游标打开游标读取数据关闭游标 2.1 声明/定义游标语法： CURSOR cursor_name [(parameter_dec [, parameter_dec ]…)] [RETURN datatype] IS select_statement; 示例： DECLARE CURSOR c1 RETURN departments%ROWTYPE; -- 声明C1游标 CURSOR c2 IS -- 声明C2游标并定义 SELECT employee_id, job_id, salary FROM employees WHERE salary &gt; 2000; CURSOR c1 RETURN departments%ROWTYPE IS -- 定义C1游标 SELECT * FROM departments WHERE department_id = 110; CURSOR c3 RETURN locations%ROWTYPE; -- 声明C3游标 CURSOR c3 IS -- 定义C3游标 SELECT * FROM locations WHERE country_id = &apos;JP&apos;; CURSOR c4(sal number) IS -- 声明C4游标并定义 SELECT employee_id, job_id, salary FROM employees WHERE salary &gt; sal; BEGIN NULL; END; 说明： 在指定参数数据类型时，不能使用长度约束，如C4游标的参数，不能写为number(10,4)这种结构。 [RETURN datatype]是可选的，表示游标返回数据的数据。如果选择，则应该严格与select_statement中的选择列表在次序和数据类型上匹配。一般是记录数据类型（RECORD）或带“%ROWTYPE”的数据。 2.2 打开游标执行游标所对应的SELECT语句，将其查询结果放入工作区，并且指针指向工作区的首部，标识游标结果集。 语法： OPEN cursor_name [ ( cursor_parameter [ [,] actual_cursor_parameter ]... ) ] 示例： OPEN c4 (1300); 2.3 读取数据检索结果集合中的数据行，放入指定的输出变量中。 语法： FETCH { cursor | cursor_variable | :host_cursor_variable } { into_clause | bulk_collect_into_clause [ LIMIT numeric_expression ] } ; 执行FETCH语句时，每次返回一个数据行，然后自动将游标移动指向下一个数据行。当检索到最后一行数据时，如果再次执行FETCH语句，将操作失败，并将游标属性%NOTFOUND置为TRUE。所以每次执行完FETCH语句后，检查游标属性%NOTFOUND就可以判断FETCH语句是否执行成功并返回一个数据行，以便确定是否给对应的变量赋了值。 示例： fetch c4 into eid, jid, sal; 2.4 关闭游标当处理完游标结果集合数据后，应及时关闭游标，以释放该游标所占用的系统资源。 关闭游标后不能再使用FETCH语句获取其中数据。关闭后的游标可以使用OPEN语句重新打开。 语法： CLOSE cursor_name; 完整示例1： DECLARE -- 定义游标 CURSOR c_cursor IS SELECT first_name || last_name, Salary FROM EMPLOYEES WHERE rownum&lt;11; -- 声明变量 v_ename EMPLOYEES.first_name%TYPE; v_sal EMPLOYEES.Salary%TYPE; BEGIN -- 打开游标 OPEN c_cursor; -- 获取数据 FETCH c_cursor INTO v_ename, v_sal; -- 处理数据 WHILE c_cursor%FOUND LOOP DBMS_OUTPUT.PUT_LINE(v_ename||&apos;---&apos;||to_char(v_sal) ); FETCH c_cursor INTO v_ename, v_sal; END LOOP; -- 关闭游标 CLOSE c_cursor; END; 完整示例2： DECLARE -- 定义RECORD记录类型 TYPE emp_record_type IS RECORD( f_name employees.first_name%TYPE, h_date employees.hire_date%TYPE); -- 声明记录变量 v_emp_record EMP_RECORD_TYPE; -- 定义游标，有参数与返回值 CURSOR c3(dept_id NUMBER, j_id VARCHAR2) RETURN EMP_RECORD_TYPE IS SELECT first_name, hire_date FROM employees WHERE department_id = dept_id AND job_id = j_id; BEGIN -- 打开游标，传递参数值 OPEN c3(j_id =&gt; &apos;AD_VP&apos;, dept_id =&gt; 90); LOOP FETCH c3 INTO v_emp_record; -- 获取数据 IF c3%FOUND THEN DBMS_OUTPUT.PUT_LINE(v_emp_record.f_name||&apos;的雇佣日期是&apos;||v_emp_record.h_date); ELSE DBMS_OUTPUT.PUT_LINE(&apos;已经处理完结果集了&apos;); EXIT; -- 处理完则退出循环 END IF; END LOOP; CLOSE c3; --关闭游标 END; 三： 显式游标属性游标的状态（如是否打开，获取了多少行数据等）可以使用游标属性来获取。 游标属性以“%属性名”的形式加在游标名之后。显式游标属性有： 属性名 说明%FOUND 如果记录成功获取，返回TRUE，否则返回FALSE%NOTFOUND 如果记录获取失败，返回TRUE，否则返回FALSE%ROWCOUNT 返回已经从游标中获取的记录数%ISOPEN 如果游标是打开的，返回TRUE，否则返回FALSE示例： DECLARE v_empno EMPLOYEES.EMPLOYEE_ID%TYPE; v_sal EMPLOYEES.Salary%TYPE; -- 定义游标 CURSOR c_cursor IS SELECT EMPLOYEE_ID, Salary FROM EMPLOYEES; BEGIN -- 打开游标 OPEN c_cursor; LOOP -- 获取数据 FETCH c_cursor INTO v_empno, v_sal; EXIT WHEN c_cursor%NOTFOUND; -- 未读取到记录，则退出循环 IF v_sal&lt;=1200 THEN UPDATE EMPLOYEES SET Salary=Salary+50 WHERE EMPLOYEE_ID=v_empno; DBMS_OUTPUT.PUT_LINE(&apos;编码为&apos;||v_empno||&apos;工资已更新!&apos;); END IF; DBMS_OUTPUT.PUT_LINE(&apos;记录数:&apos;|| c_cursor %ROWCOUNT); END LOOP; -- 关闭游标 CLOSE c_cursor; END; 四：基于游标定义记录变量使用%ROWTYPE属性不仅可以基于表和视图定义记录变量，也可以基于游标定义记录变量。当基于游标定义记录变量时，记录成员名实际就是SELECT语句的列名和列别名。 为了简化显式游标的数据处理，建议使用基于游标的记录变量存放游标数据。基于游标定义记录变量，比声明记录类型变量要方便，不容易出错。 示例： DECLARE -- 定义游标 CURSOR emp_cursor IS SELECT ename,sal FROM emp； emp_reocrd emp_cursor%ROWTYPE；-- 游标变量 BEGIN -- 打开游标 OPEN emp_cursor； LOOP -- 获取记录 FETCH emp_cursor INTO emp_record； EXIT WHEN emp_record%NOTFOUND； dbms_ouput.put_line(&apos;雇员名:&apos;||emp_record.ename||&apos;,雇员工资:&apos;||emp_record.sal)； END LOOP； -- 关闭游标 CLOSE emp_cursor； END； 五：隐式游标如果在PL/SQL块中使用了SELECT语句进行操作，PL/SQL会隐含处理游标定义，而对于非查询语句，如修改、删除操作，则由ORACLE系统自动地为这些操作设置游标并创建其工作区。由系统隐含创建的游标称为隐式游标，隐式游标的名字为SQL。 对于隐式游标的操作，如定义、打开、取值及关闭操作，都由ORACLE 系统自动地完成，无需用户进行处理。用户只能通过隐式游标的相关属性，来完成相应的操作。在隐式游标的工作区中，所存放的数据是与用户自定义的显示游标无关的、最新处理的一条SQL语句所包含的数据。 隐式游标的属性： 属性名 说明SQL%FOUND 如果记录成功获取，返回TRUE，否则返回FALSESQL%NOTFOUND 如果记录获取失败，返回TRUE，否则返回FALSESQL%ROWCOUNT 返回已经从游标中获取的记录数SQL%ISOPEN 如果游标是打开的，返回TRUE，否则返回FALSE隐式游标在INSERT，UPDATE，DELETE，SELECT语句中不必明确定义游标。 示例： DECLARE v_rows NUMBER; BEGIN -- 更新表数据 UPDATE employees SET salary = 5000 WHERE department_id = 90 AND job_id = &apos;AD_VP&apos;; -- 获取受影响行数 v_rows := SQL%ROWCOUNT; DBMS_OUTPUT.PUT_LINE(&apos;更新了&apos;||v_rows||&apos;个员工的工资&apos;); END; 六：游标FOR循环游标FOR循环和显示游标的一种快捷使用方式，它使用FOR循环依次读取结果集中的行数据，当FOR循环开始时，游标自动打开（不需要OPEN）,每循环一次系统自动读取游标当前行的数据（不需要FETCH)，当退出FOR循环时，游标被自动关闭（不需要使用CLOSE）使用游标FOR循环的时候不能使用OPEN语句，FETCH语句和CLOSE语句，否则会产生错误。 语法： FOR index_variable IN cursor_name[(value[, value]…)] LOOP -- 游标处理语句 END LOOP; 示例： DECLARE CURSOR emp_cur(vartype number) IS SELECT emp_no,emp_zc FROM cus_emp_basic WHERE com_no=vartype; BEGIN FOR person IN emp_cur(123) LOOP DBMS_OUTPUT.PUT_LINE(&apos;编号:&apos;||person.emp_no||&apos;,地址:&apos;||person.emp_zc); END LOOP; END; 七：使用显示游标修改数据在PL/SQL中依然可以使用UPDATE和DELETE语句更新或删除数据行。显式游标只有在需要获得多行数据的情况下使用。PL/SQL提供了仅仅使用游标就可以执行删除或更新记录的方法。 UPDATE或DELETE语句中的WHERE CURRENT OF子句专门处理要执行UPDATE或DELETE操作的表中取出的最近的数据。要使用这个方法，在声明游标时必须使用FOR UPDATE子句，当使用FOR UPDATE子句打开一个游标时，所有返回集中的数据行都将处于行级（ROW-LEVEL)独占式锁定，其他对象只能查询这些数据行，不能进行UPDATE、DELETE或SELECT…FOR UPDATE操作。 语法： FOR UPDATE [OF [schema.]table.column[,[schema.]table.column].. [NOWAIT] 在多表查询中，使用OF子句来锁定特定的表,如果忽略了OF子句，那么所有表中选择的数据行都将被锁定。如果这些数据行已经被其他会话锁定，那么正常情况下ORACLE将等待，直到数据行解锁。当加上NOWAIT子句时，如果这些行真的被另一个会话锁定，则OPEN立即返回并给出： ORA-00054 ：resource busy and acquire with nowait specified.在UPDATE和DELETE中使用WHERE CURRENT OF子串的语法如下： WHERE{CURRENT OF cursor_name|search_condition} 示例： DELCARE CURSOR c1 IS SELECT empno,salary FROM emp WHERE comm IS NULL FOR UPDATE OF comm; v_comm NUMBER(10,2); BEGIN FOR r1 IN c1 LOOP IF r1.salary&lt;500 THEN v_comm:=r1.salary*0.25; ELSEIF r1.salary&lt;1000 THEN v_comm:=r1.salary*0.20; ELSEIF r1.salary&lt;3000 THEN v_comm:=r1.salary*0.15; ELSE v_comm:=r1.salary*0.12; END IF; UPDATE emp SET comm=v_comm WHERE CURRENT OF c1; END LOOP; END 八：游标变量与游标类似，游标变量指向多行查询的结果集的当前行。但是，游标与游标变量是不同的，就像常量和变量的关系一样。游标是静态的，游标变量是动态的，因为它不与特定的查询绑定在一起。 8.1 声明游标变量语法： TYPE ref_type_name IS REF CURSOR [ RETURN return_type]; 说明： 游标变量类型有强类型定义和弱类型定义两种。强类型定义必须指定游标变量的返回值类型，而弱类型定义则不说明返回值类型。 return_type为游标变量的返回值类型，它必须为记录变量。 示例： -- 定义一个REF CURSOU类型 TYPE ref_cursor_type IS REF CURSOR; -- 声明一个游标变量 cv_ref REF_CURSOR_TYPE; 8.2 游标变量的使用与游标一样，游标变量操作也包括打开、提取和关闭三个步骤。 8.2.1 打开游标变量语法： OPEN {cursor_variable_name | :host_cursor_variable_name} FOR select_statement; 说明： host_cursor_variable_name为PL/SQL主机环境（如OCI: ORACLE Call Interface，Pro*c 程序等）中声明的游标变量。 OPEN…FOR 语句可以在关闭当前的游标变量之前重新打开游标变量，而不会导致CURSOR_ALREAD_OPEN异常错误。新打开游标变量时，前一个查询的内存处理区将被释放。 8.2.2 提取数据语法： FETCH {cursor_variable_name | :host_cursor_variable_name} INTO {variable [, variable]…| record_variable}; 说明： 将提取到的数据放入普通变量和记录变量中存放。 8.2.3 关闭游标语法： CLOSE {cursor_variable_name | :host_cursor_variable_name} 说明： 如果应用程序试图关闭一个未打开的游标变量，则将导致INVALID_CURSOR异常错误。 示例1： DECLARE TYPE ref_type_table IS REF CURSOR; v_cursor ref_type_table; emp_record emp%rowtype; BEGIN OPEN v_cursor FOR select * from emp where deptno=&amp;no; LOOP FETCH v_cursor INTO emp_record; EXIT WHEN v_cursor%NOTFOUND; dbms_output.put_line(&apos;员工号：&apos;||emp_record.ename||&apos;部门号：&apos;||emp_record.deptno); END LOOP; CLOSE v_cursor; END; 示例2： DECLARE emp_record emp%rowtype; TYPE ref_type_table IS REF CURSOR RETURN emp%rowtype; v_cursor ref_type_table; BEGIN OPEN v_cursor FOR select * from emp where deptno=&amp;no; LOOP FETCH v_cursor INTO emp_record; EXIT WHEN v_cursor%NOTFOUND; dbms_output.put_line(&apos;员工号：&apos;||emp_record.ename||&apos;部门号：&apos;||emp_record.deptno); END LOOP; CLOSE v_cursor; END; DECLARE Type emp_record_type IS RECORD( ename emp.ename%TYPE, salary emp.sal%TYPE, deptno emp.deptno%TYPE); emp_record emp_record_type; TYPE ref_type_table IS REF CURSOR RETURN emp_record_type; v_cursor ref_type_table; BEGIN OPEN v_cursor FOR select ename,sal,deptno from emp where deptno=&amp;no; LOOP FETCH v_cursor INTO emp_record; EXIT WHEN v_cursor%NOTFOUND; dbms_output.put_line(&apos;员工号：&apos;||emp_record.ename||&apos;，部门号：&apos;||emp_record.deptno||&apos;，工资：&apos;||emp_record.salary); END LOOP; CLOSE v_cursor; END; 九：使用游标批量获取语法： FETCH ... BULK COLLECT INTO ...[LIMIT row_number]; 说明： 使用BULK COLLECT，我们可以用对数据库的一个来回，返回多行数据。BULK COLLECT减少了PL/SQL和SQL引擎之间的上下文开关数目，因而加速了数据获取的速度。 示例： DECLARE CURSOR emp_cursor(v_deptno number) IS SELECT * FROM EMP WHERE deptno = v_deptno; TYPE type_emp_table IS TABLE OF emp%ROWTYPE INDEX BY BINARY_INTEGER; emp_table type_emp_table; v_dno emp.deptno%TYPE; BEGIN v_dno := &amp;no; OPEN emp_cursor(v_dno); FETCH emp_cursor BULK COLLECT INTO emp_table; CLOSE emp_cursor; FOR i IN 1..emp_table.COUNT LOOP dbms_output.put_line(&apos;员工号：&apos;||emp_table(i).ename||&apos;工资：&apos;||emp_table(i).sal); END LOOP; CLOSE emp_cursor; END; 十：游标表达式游标表达式作用是用于返回嵌套游标。语法： CURSOR(sub_query) 示例： DECLARE CURSOR dept_emp_cursor(v_deptno number) IS SELECT dname,cursor(SELECT * FROM emp e WHERE e.deptno = d.deptno) FROM dept d WHERE deptno = v_deptno; TYPE emp_cursor_type IS REF CURSOR; emp_cursor emp_cursor_type; emp_record emp%ROWTYPE; v_name dept.dname%TYPE; v_dno emp.deptno%TYPE; BEGIN v_dno := &amp;no; OPEN dept_emp_cursor(v_dno); loop FETCH dept_emp_cursor INTO v_name,emp_cursor; EXIT WHEN dept_emp_cursor%NOTFOUND; dbms_output.put_line(&apos;部门名称：&apos;||v_name); LOOP FETCH emp_cursor INTO emp_record; EXIT WHEN emp_cursor%NOTFOUND; dbms_output.put_line(&apos;员工名称：&apos;||emp_record.ename||&apos;，工资：&apos;||emp_record.sal); END LOOP; end loop; CLOSE dept_emp_cursor; END;","tags":[{"name":"oracle","slug":"oracle","permalink":"http://wangyuanjun.cn/tags/oracle/"}]},{"title":"跨Oracle数据库实现表级别的实时同步","date":"2017-04-28T05:49:50.000Z","path":"2017/04/28/跨Oracle数据库实现表级别的实时同步/","text":"一：问题描述有两个Oracle数据库，分别布置在不同的服务器上，系统均为windows2003； 这里暂且说成是一个主数据库和从数据库： (1) 主数据库: oracle_A ； (2) 从数据库: oracle_B ； 在oracle_A中有一个表table_A与oracle_B中的表table_B 结构相同 ； 我是处在oracle_B，oracle_A数据库分配给我有一个访问oracle_A表table_A的用户，该用户 只拥有查询的权限 ； 另外，需要 说明的一点 ，就是在oracle_B处,只需对table_B表进行查询的操作，不进行其他增删改的操作。 场景介绍完了， 我的问题 的是,如何在oracle_A中表table_A发生变化时,实时更新同步到oracle_B的table_B中? 我原来的处理方式: 通过建立远程连接DBLink+JOB定时任务+存储过程的方式,实现了定时同步 更新,但不能做到实时同步 。 二：采用同义词+DB_Link的方式结果步骤之所以能够选择采用同义词的方式，处理这个问题。主要还是源于在问题描述中提到一个点，那就是我们只需要对同步后的表进行 查询 操作。这点是使用同义词方式的重要要素。 下面详细模拟一下整个实验测试的过程： （1）首先在Oracle_A端创建一个对table_A只有查询功能的用户 创建用户sqlplus /nologconn /as sysdba;create user username identified by password; 查看所有的用户列表 用户创建完成后,查看用户是否创建成功select * from all_users; 授予权限 为了能够保证能够登陆,必须赋予如下权限 授予username用户创建session的权限,即登陆权限grant create session to username; 授予username用户使用表空间的权限grant unlimited tablespace to username; oracle对权限管理比较严谨,普通用户之间也是默认不能互相访问的,需要互相授权. 如果scott用户要授权给username用户查看自己的test表的权限;sqlplus scott/tiget@localhost:1521/orcl 授予username用户查看指定的权限grant select on test to username; 撤销权限基本语法同grant,关键字为revoke; （2）验证用户是否可以成功登录，并进行访问授权的表 使用sqlplus登录，并进行查询 sqlplus username/password@localhost:1521/orcl; select * from scott.test; 注意：查询表时，务必带上用户名，说明是哪个用户下的表。 （3）创建远程连接DB_Link 创建远程连接 db_link 1create public database link db32 connect to tianzhi_test identified by &quot;tianzhi_test&quot; using &apos;192.168.56.6:1521/ORCL&apos; 测试远程连接是否成功 1select * from tianzhi_smart.zh_item_news@db32; （4）在Oracle_B端创建同义词 使用sqlplus登录自己的用户 1sqlplus tianzhi_smart/tianzhi_smart@localhost:1521/orcl 创建同义词 1create or replace public synonym TEST1130 for scott.TEST@db32; 3.查询测试1select * from TEST1130; 可以看到这与在Oracle_A源数据库中查到的table_A表中的数据一样.注意事项: 当远程查询的数据库中包含BLOB字段时,会报出如下错误.1ORA-22992: 无法使用从远程表选择的 LOB 定位器 当出现这个错误的时候，那是因为跨库连接查询中的表中存在BLOB类型的字段，所以一定要注意，所有表中存在blob类型字段， 不能用 select * from 连接的表不能将blob类型的字段出现在脚本中。如果这些blob类型的字段一定要导过来，可以先建立临时表再插入本地表，方法如下.在pl/sql中执行 第一步 建临时表12create global temporary table foo ( X BLOB )on commit delete rows; 第二步 插入本地表1insert into foo select blobcolumn from remoteTable@dl_remote ;","tags":[{"name":"oracle","slug":"oracle","permalink":"http://wangyuanjun.cn/tags/oracle/"}]},{"title":" 解决“Dynamic Web Module 3.0 requires Java 1.6 or newer.”错误","date":"2017-03-30T13:23:16.000Z","path":"2017/03/30/解决“Dynamic-Web-Module-3-0-requires-Java-1-6-or-newer-”错误/","text":"eclipse maven在项目的pom.xml的标签中加入：1234567891011&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.6&lt;/source&gt; &lt;target&gt;1.6&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; 保存，项目构建完成后在项目文件夹上点右键，选择Maven-&gt;Update Project Configuration，问题解决。","tags":[{"name":"maven","slug":"maven","permalink":"http://wangyuanjun.cn/tags/maven/"}]},{"title":"Extjs中textfield的悬浮提示","date":"2017-02-22T05:56:35.000Z","path":"2017/02/22/Extjs中textfield的悬浮提示/","text":"在Extjs中有时候我们需要textfield的提示信息，但是我们发现textfield并没有这样的配置项。这时候我们就要另想方法：我们需要在鼠标悬停在textfield组件的时候进行信息的提示，我们就需要在textfield中来监听，这里有两种进行textfield悬停提示的方法： 进行固定信息的提示：需要在监听中用render方法render: function (field, p) { Ext.QuickTips.init(); Ext.QuickTips.register({ target: field.el, text: &apos;这是textfield的固定信息提示！&apos; }) } 进行文本信息提示：提示信息为textfield的文本信息 var updateTip = function (field, t) { Ext.QuickTips.init(); Ext.QuickTips.register({ target: field.el, text: field.getValue() }) }; listeners: { // 鼠标移动到文本框显示悬浮框 render : function(p) { p.getEl().on(&apos;mouseover&apos;, function(p1) { updateTip(p); }); } }","tags":[{"name":"extjs","slug":"extjs","permalink":"http://wangyuanjun.cn/tags/extjs/"}]},{"title":"Redis基础命令","date":"2017-02-21T14:51:21.000Z","path":"2017/02/21/Redis基础命令/","text":"笔者最初接触Redis是因为了解了一些nosql方面的知识，觉得nosql是一个很有意思的方面。像其中的mongodb，redis等等。当初也没有深入的去了解Redis，直到自己前段时间在写一个web项目的时候需要用到缓存来进行性能优化我才仔细的来学习Redis。下面我就来说说我自己在学习Redis过程中的一些心得。 Redis是一个nosql数据库，它采用字典结构以键值对的形式将数据全部存储在内存中所以它读写的速度很快，因此很多项目用Redis做缓存用，我也是基于这个想法来学习Redis的。 Redis支持的数据类型分别是字符串(string)、散列(hash)、列表(list)、集合(set)、有序集合(sorted set)这五种。接下来我将仔细介绍下这几种数据结构的用法和对应的命令。 字符串类型 ：字符串类型是Redis中 最 基本 的数 据类型，是其他四种数据类型的基础。它能存储任何形式的字符串(二进制数据、Json对象、图片等)，它的最大数据容量是512MB。常用命令: set key value //赋值 get key //取值 keys * //查看所有的键 exists key //判断某个键是否存在 del key //删除一个键 type key //获取键的类型 incr/decr key //给键增加/减少一 incrby/decrby key increment/decrement //给键增加/减少一个整数 incrbyfloat key increment //增加浮点数 strlen key //返回键的长度 mset/mget //同时设置或者获取多个值 散列类型 ：散列类型的键值是一种字典结构，存储了字段和字段值的映射。但是字段值只能是字符串，不支持其他数据类型(Redis的其他数据类型也都不支持嵌套，只能是字符串。)。常用命令： hset key field value //赋值。不区分插入和更新操作，当键不存在是会自动建立。 hget key field //取值 hgetall key //取出所有的值 hexists key field //判断字段是否存在 hsetnx key field value //字段不存在时便赋值 hincrby key field increment //增加指定的数字，没有自增 hdel key field //删除一个或者多个字段，返回被删除的个数 hkeys key //只获取字段名 hvals key //只获取字段值 hlen key //只获取字段数量 ## 列表类型 ：列表是个有序的字符串，向两端添加或者删除元素。它是使用双向链表实现的。 常用命令: lpush/rpush list value //向左/右增加元素 lpop/rpop list //从左/右弹出元素 llen list //获列表的元素个数 lrange list start stop //获得列表片段(左边索引为0，如果为负则从右边开始) lrange key -1 0 则为获取所有的元素 lrem list count value //删除列表中前count个值为value的元素 rpoplpush oldlist newlist //将原列表的值放入新列表 集合类型 : 集合中的元素都是不同的，而且没有顺序。它可以求交集、并集、差集。常用命令: sadd set member //增加一个元素给集合(没有则创建) srem set member //删除一个或多个元素 smembers set //返回集合中所有的元素 sismember set member //判断元素是否存在于集合中 sdiff setA setB //求差集 sinter setA setB //求交集 sunion setA setB //求并集 sdiffstore destination setA setB //将求到的差集结果保存在destination中 srandmember set num //随机获取一个或多个元素(看后面加的参数) spop set //从集合中随机弹出一个元素 有序集合: 和集合相比给每个元素都关联了个分数。我们除了可以进行集合的操作外，还可以获取分数最高或者最低的几个元素。常用命令: zadd key score member //加入元素和对应分数，支持整数和双精度浮点，如果存在则修改。其中+inf和-inf代表正负无穷大 zscore key member //获得元素的分数 zrange/zrevrange key start stop //按分数从顺序/逆序排序 zrangebyscore key min (max //返回min和max之间的数左括号代表不包含 zincrby key increment member //给元素增加值 zcount key min max //获取指定范围元素的个数 zcard key //获取集合中元素的数量 zrem key member //删除元素 zremrangebyrank key start stop //按排名范围删除元素 zremrangebyscore key min max //删除分数范围值 zrank key member //元素按分数大小排名 zrevrank key member //从大到小排名 结语:个人学习总结有遗漏错误的地方还希望大家留言斧正，多多交流一起学习。","tags":[{"name":"redis","slug":"redis","permalink":"http://wangyuanjun.cn/tags/redis/"}]},{"title":"阿里巴巴 Java 开发手册 笔记及重点","date":"2017-02-21T13:58:21.000Z","path":"2017/02/21/阿里巴巴-Java-开发手册-笔记及重点/","text":"编程规约1. POJO 类中布尔类型的变量，都不要加 is，否则部分框架解析会引起序列化错误。假设定义一个 boolean 的 isSuccess 属性，它的方法 Getter 被IDE生成为 isSuccess()，RPC等三方框架在反向解析的时候，“以为”对应的属性名称是 success，导致属性获取不到，进而抛出异常。这点也是笔者之前遇到过的，查了很久哪里的错最后发现是这个问题，不过经历一次后基本后面就能避免。 2. 接口类中的方法和属性不要加任何修饰符号。包括在一些开源的代码里，笔者也经常看见在接口方法上声明 public 关键字的，这是冗余的，在Java规范中提到过。关于代码的规范及简洁性诸位可以参考《重构 改善既有代码的设计》 及 代码整洁之道。 3. 方法体内的执行语句组、变量的定义语句组、不同的业务逻辑之间或者不同的语义之间插入一个空行。相同业务逻辑和语义之间不需要插入空行。不过没有必要插入多行空格进行隔开。这样可读性会明显提高，笔者经常看到部分开发人员的代码在很长的代码块里完全没有一个空行，没有按逻辑进行换行，这种习惯是不太好的。 4. 所有的覆写方法，必须加 @Override 注解。这样IDE会检查合法性，有错误的话会及时提示。 5. 所有的相同类型的包装类对象之间值的比较，全部使用 equals 方法比较。比如 Integer 的-128至127之间被缓存的对象可以直接使用==判断，因为被缓存了，是同一对象，地址相等，而这个区间外的却不能使用==判断，这也是面试时的一个常考点。 6. 关于基本数据类型与包装数据类型：所有的POJO类属性必须使用包装数据类型，以便映射数据库中的NULL，局部变量推荐使用基本数据类型。 7. 关于 hashCode 和 equals 的处理，遵循如下规则：只要重写 equals，就必须重写 hashCode，具体原因可参考《Effective java 中文版（第2版）》。 8. 关于 ArrayList 里 subList 结果的注意事项，subList 只是 ArrayList 的一个视图，这部分大家可以参考JDK里的源码。 9. 不要在 foreach 循环里进行元素的 remove/add 操作。remove 元素请使用 Iterator 方式，如果并发操作，需要对 Iterator 对象加锁。 10. 在 JDK7 版本以上，Comparator 要满足自反性，传递性，对称性，不然 Arrays.sort， Collections.sort 会报 IllegalArgumentException 异常。这个在《Effective java 中文版（第2版）》中也有说明，虽然笔者之前看过，但在刚实习时的一个用于省份排序的代码里使用 Comparator 时还是忘了处理值相等的情况，所以，还是要实战后才能加深记忆。 11. 集合初始化时，尽量指定集合初始值大小。这在笔者实习面试时也被问到，这块的话主要考察 ArrayList 的原理，内部机制，诸位看看JDK里 ArrayList 的原理就明白了。 12. 创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。 13. 高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁。概括为一句话就是：尽量降低锁的粒度。 14. 对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会造成死锁。关于并发这块可以参考《Java并发编程实战》，个人认为这本在笔者看过Java并发的书籍里能算上乘之作，另外也可参考《Java并发编程的艺术》。 15. 通过双重检查锁(double-checked locking)(在并发场景)实现延迟初始化的优化问题隐患(可参考 The “Double-Checked Locking is Broken” Declaration)，推荐问题解决方案中较为简单一种(适用于 JDK5 及以上版本)，将目标属性声明为 volatile 型。这部分涉及到两个重点，一是双重检查锁，二是 volatile 的原理及Java的主内存及每个线程的内存之间的关系。volatile只能解决多线程时的内存可见性问题，无法解决线程安全问题。可参考Double checked locking 及 Initialization on demand holder idiom。 16. 注释掉的代码尽量要配合说明，而不是简单的注释掉。如果永久不用，建议直接删除，因为Git等版本控制系统保存了历史代码。 17. 好的命名、代码结构是自解释的，注释力求精简准确、表达到位。避免无用的注释。 18. 善用 TODO 及 FIXME，IDE可以方便的进行扫描。 19. 获取当前毫秒数使用 System.currentTimeMillis()，System.nanoTime()产生的值仅用于比较，同一时刻不同虚拟机System.nanoTime()返回的值可能不一样并且相差很大，笔者的同事已经踩过一次坑，关于 nanoTime 诸位可以看一看JavaDoc。 异常日志1. 不要捕获Java类库中定义的继承自 RuntimeException 的运行时异常类，如：IndexOutOfBoundsException / NullPointerException，这类异常由程序员预检查来规避，保证程序健壮性。说到这里，异常继承结构图也可以看下。 2. 捕获异常是为了处理它，不要捕获了却什么都不处理而抛弃之，如果不想处理它，请将该异常抛给它的调用者。最外层的业务使用者，必须处理异常，将其转化为用户可以理解的内容。 3. 避免出现重复的代码(Don’t Repeat Yourself)，即DRY原则。关于这部分可参考《程序员修炼之道》。 4. 谨慎地记录日志。生产环境禁止输出 debug 日志；有选择地输出 info 日志；如果使用 warn 来记录刚上线时的业务行为信息，一定要注意日志输出量的问题，避免把服务器磁盘撑爆，并记得及时删除这些观察日志。关于日志把server磁盘撑爆的问题，我司也出现过，后面加了相关监控来避免。 MySQL规约1. 表达是与否概念的字段，必须使用 is_xxx 的方式命名，数据类型是 unsigned tinyint (1表示是，0表示否)，此规则同样适用于odps建表。任何字段如果为非负数，必须是 unsigned。因为这样的话可用容量提升了一倍。 2. 表名不使用复数名词。表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于 DO 类名也是单数形式，符合表达习惯。 3. 禁用保留字，如 desc、range、match、delayed 等，禁止在代码里对 SQL 关键字进行单独处理。 4. 唯一索引名为 uk_字段名，普通索引名则为 idx_字段名。这样能让开发人员一眼就知道相关索引。 5. 如果存储的字符串长度几乎相等，使用 char 定长字符串类型。 6. 表必备三字段:id, gmt_create, gmt_modified。其中id必为主键，类型为unsigned bigint、单表时自增、步长为1。gmt_create, gmt_modified 的类型均为 date_time 类型。创建时间与修改时间需要记录笔者理解，不理解的为什么要用 gmt 开头，北京时间应该是GMT + 8:00 啊。 7. 字段允许适当冗余，以提高性能，但是必须考虑数据同步的情况。冗余字段应遵循：不是频繁修改的字段；不是 varchar 超长字段，更不能是 text 字段。比如我司的很多表都冗余了 user_name 这个字段。 8. 单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表。 9. 业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。即使在应用层做了非常完善的校验和控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。 10. 页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。索引文件具有 B-Tree 的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。关于 MySQL 的知识，诸位可参考《高性能MySQL》。 11. 利用延迟关联或者子查询优化超多分页场景。MySQL 并不是跳过 offset 行，而是取 offset+N 行，然后返回放弃前 offset 行，返回 N 行，那当 offset 特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行 SQL 改写。 12. 建组合索引的时候，区分度最高的在最左边。 13. 不要使用 count(列名)或 count(常量)来替代 count(*)，count(*)就是 SQL92 定义 的标准统计行数的语法，跟数据库无关，跟 NULL 和非 NULL 无关。 14. 不得使用外键与级联，一切外键概念必须在应用层解决。外键与级联更新适用于单机低并发，不适合分布式、高并发集群；级联更新是强阻塞，存在数据库更新风暴的风险；外键影响数据库的插入速度。 15. 禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。 16. 数据订正时，删除和修改记录时，要先 select，避免出现误删除，确认无误才能执行更新语句。 工程规约1. 高并发服务器建议调小 TCP 协议的 time_wait 超时时间。 2. 调大服务器所支持的最大文件句柄数(File Descriptor，简写为fd)。 3. 给 JVM 设置-XX:+HeapDumpOnOutOfMemoryError 参数，让 JVM 碰到 OOM 场景时输出 dump 信息。 安全规约1. 隶属于用户个人的页面或者功能必须进行权限控制校验。 2. 用户敏感数据禁止直接展示，必须对展示数据脱敏。 3. 用户输入的 SQL 参数严格使用参数绑定或者 METADATA 字段值限定，防止 SQL 注入， 禁止字符串拼接 SQL 访问数据库。 4.用户请求传入的任何参数必须做有效性验证。 5.表单、AJAX 提交必须执行 CSRF 安全过滤。 6.在使用平台资源，譬如短信、邮件、电话、下单、支付，必须实现正确的防重放限制， 如数量限制、疲劳度控制、验证码校验，避免被滥刷、资损。 7.关于安全这块可以阅读《白帽子讲Web安全》。 阿里巴巴Java开发手册","tags":[{"name":"编码规范","slug":"编码规范","permalink":"http://wangyuanjun.cn/tags/编码规范/"}]},{"title":"spring 读取properties的两种方法","date":"2017-02-21T13:47:12.000Z","path":"2017/02/21/spring-读取properties的两种方法/","text":"1.在配置文件中配置PropertyPlaceholderConfigurer123&lt;bean class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt; &lt;property name=&quot;locations&quot; value=&quot;classpath:com/foo/jdbc.properties&quot;/&gt;&lt;/bean&gt; 然后在需要的地方直接以下方式引用：1&lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url&#125;&quot;/&gt; 2.在配置文件中加入beans的命名空间声明如下：1234567891011&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd&quot;&gt; 用到了1xmlns:context=http://www.springframework.org/schema/context 配置如下：1&lt;context:property-placeholder location=&quot;dbconf.properties&quot;/&gt;","tags":[{"name":"spring","slug":"spring","permalink":"http://wangyuanjun.cn/tags/spring/"}]},{"title":"SpringMVC与LogBack集成","date":"2017-02-14T05:01:16.000Z","path":"2017/02/14/SpringMVC与LogBack集成/","text":"最近在做项目中需要用到日志，本来选取的是Log4j，最后经过对比之后还是发现LogBack在性能上比Log4j有优势。至于有什么好处，请参考下面这篇文章。从Log4j迁移到LogBack的理由 下面废话不多说了，就看一下，如何来把LogBack集成到我们的web项目中吧。本人前台用的是SpringMVC。 jar包配置 如果要使用LogBack做为日志的插件的话，需要的jar包有如下，直接看一下Maven依赖 &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-access&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; Web.xml在web项目中需要通过web.xml来加载我们所需要的LogBack.xml具体如下 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;web-app version=&quot;2.5&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot;&gt; &lt;!-- logback-begin --&gt; &lt;context-param&gt; &lt;param-name&gt;logbackConfigLocation&lt;/param-name&gt; &lt;param-value&gt; classpath:logback.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;com.util.LogbackConfigListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- logback-end --&gt; &lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;servlet&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; classpath:springMVC-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;!-- 这里一定要是/根据Servlet规范来的 --&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; 上面的XML中用到了自定义的监听器，分别是三个类，如下所示 LogbackConfigListener类 package com.util; import javax.servlet.ServletContextEvent; import javax.servlet.ServletContextListener; public class LogbackConfigListener implements ServletContextListener { public void contextInitialized(ServletContextEvent event) { LogbackWebConfigurer.initLogging(event.getServletContext()); } public void contextDestroyed(ServletContextEvent event) { LogbackWebConfigurer.shutdownLogging(event.getServletContext()); } } LogbackConfigurer类 package com.util; import java.io.File; import java.io.FileNotFoundException; import java.net.URL; import org.slf4j.LoggerFactory; import org.springframework.util.ResourceUtils; import org.springframework.util.SystemPropertyUtils; import ch.qos.logback.classic.LoggerContext; import ch.qos.logback.classic.joran.JoranConfigurator; import ch.qos.logback.core.joran.spi.JoranException; public abstract class LogbackConfigurer { /** Pseudo URL prefix for loading from the class path: &quot;classpath:&quot; */ public static final String CLASSPATH_URL_PREFIX = &quot;classpath:&quot;; /** Extension that indicates a logback XML config file: &quot;.xml&quot; */ public static final String XML_FILE_EXTENSION = &quot;.xml&quot;; private static LoggerContext lc = (LoggerContext) LoggerFactory .getILoggerFactory(); private static JoranConfigurator configurator = new JoranConfigurator(); /** * Initialize logback from the given file location, with no config file * refreshing. Assumes an XML file in case of a &quot;.xml&quot; file extension, and a * properties file otherwise. * * @param location * the location of the config file: either a &quot;classpath:&quot; * location (e.g. &quot;classpath:mylogback.properties&quot;), an absolute * file URL (e.g. * &quot;file:C:/logback.properties), or a plain absolute path in the file system (e.g. &quot; * C:/logback.properties&quot;) * @throws FileNotFoundException * if the location specifies an invalid file path */ public static void initLogging(String location) throws FileNotFoundException { String resolvedLocation = SystemPropertyUtils .resolvePlaceholders(location); URL url = ResourceUtils.getURL(resolvedLocation); if (resolvedLocation.toLowerCase().endsWith(XML_FILE_EXTENSION)) { // DOMConfigurator.configure(url); configurator.setContext(lc); lc.reset(); try { configurator.doConfigure(url); } catch (JoranException ex) { throw new FileNotFoundException(url.getPath()); } lc.start(); } // else { // PropertyConfigurator.configure(url); // } } /** * Shut down logback, properly releasing all file locks. * &lt;p&gt; * This isn&apos;t strictly necessary, but recommended for shutting down logback * in a scenario where the host VM stays alive (for example, when shutting * down an application in a J2EE environment). */ public static void shutdownLogging() { lc.stop(); } /** * Set the specified system property to the current working directory. * &lt;p&gt; * This can be used e.g. for test environments, for applications that * leverage logbackWebConfigurer&apos;s &quot;webAppRootKey&quot; support in a web * environment. * * @param key * system property key to use, as expected in logback * configuration (for example: &quot;demo.root&quot;, used as * &quot;${demo.root}/WEB-INF/demo.log&quot;) * @see org.springframework.web.util.logbackWebConfigurer */ public static void setWorkingDirSystemProperty(String key) { System.setProperty(key, new File(&quot;&quot;).getAbsolutePath()); } } LogbackWebConfigurer类 package com.util; import java.io.FileNotFoundException; import javax.servlet.ServletContext; import org.springframework.util.ResourceUtils; import org.springframework.util.SystemPropertyUtils; import org.springframework.web.util.WebUtils; public abstract class LogbackWebConfigurer { /** Parameter specifying the location of the logback config file */ public static final String CONFIG_LOCATION_PARAM = &quot;logbackConfigLocation&quot;; /** * Parameter specifying the refresh interval for checking the logback config * file */ public static final String REFRESH_INTERVAL_PARAM = &quot;logbackRefreshInterval&quot;; /** Parameter specifying whether to expose the web app root system property */ public static final String EXPOSE_WEB_APP_ROOT_PARAM = &quot;logbackExposeWebAppRoot&quot;; /** * Initialize logback, including setting the web app root system property. * * @param servletContext * the current ServletContext * @see WebUtils#setWebAppRootSystemProperty */ public static void initLogging(ServletContext servletContext) { // Expose the web app root system property. if (exposeWebAppRoot(servletContext)) { WebUtils.setWebAppRootSystemProperty(servletContext); } // Only perform custom logback initialization in case of a config file. String location = servletContext .getInitParameter(CONFIG_LOCATION_PARAM); if (location != null) { // Perform actual logback initialization; else rely on logback&apos;s // default initialization. try { // Return a URL (e.g. &quot;classpath:&quot; or &quot;file:&quot;) as-is; // consider a plain file path as relative to the web application // root directory. if (!ResourceUtils.isUrl(location)) { // Resolve system property placeholders before resolving // real path. location = SystemPropertyUtils .resolvePlaceholders(location); location = WebUtils.getRealPath(servletContext, location); } // Write log message to server log. servletContext.log(&quot;Initializing logback from [&quot; + location + &quot;]&quot;); // Initialize without refresh check, i.e. without logback&apos;s // watchdog thread. LogbackConfigurer.initLogging(location); } catch (FileNotFoundException ex) { throw new IllegalArgumentException( &quot;Invalid &apos;logbackConfigLocation&apos; parameter: &quot; + ex.getMessage()); } } } /** * Shut down logback, properly releasing all file locks and resetting the * web app root system property. * * @param servletContext * the current ServletContext * @see WebUtils#removeWebAppRootSystemProperty */ public static void shutdownLogging(ServletContext servletContext) { servletContext.log(&quot;Shutting down logback&quot;); try { LogbackConfigurer.shutdownLogging(); } finally { // Remove the web app root system property. if (exposeWebAppRoot(servletContext)) { WebUtils.removeWebAppRootSystemProperty(servletContext); } } } /** * Return whether to expose the web app root system property, checking the * corresponding ServletContext init parameter. * * @see #EXPOSE_WEB_APP_ROOT_PARAM */ private static boolean exposeWebAppRoot(ServletContext servletContext) { String exposeWebAppRootParam = servletContext .getInitParameter(EXPOSE_WEB_APP_ROOT_PARAM); return (exposeWebAppRootParam == null || Boolean .valueOf(exposeWebAppRootParam)); } } logback.XML配置下面来看一下这个xml是如何配置的 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!-- ROOT 节点 --&gt; &lt;!-- 属性描述 scan：性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --&gt; &lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; &lt;!-- 定义日志文件 输入位置,注意此处的/ --&gt; &lt;property name=&quot;log_dir&quot; value=&quot;E:/logs&quot; /&gt; &lt;!-- 日志最大的历史 60天 --&gt; &lt;property name=&quot;maxHistory&quot; value=&quot;60&quot;&gt;&lt;/property&gt; &lt;!-- 控制台输出日志 --&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 出错日志 appender --&gt; &lt;appender name=&quot;ERROR&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 在多数的Log工具中，级别是可以传递，例如如果指定了日志输出级别为DEBUG， 那么INFO、ERROR级别的log也会出现在日志文件。这种默认给程序的调试带来了很多的麻烦 通过配置Filter 来严格控制日志输入级别 &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;ERROR/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 按天回滚 daily --&gt; &lt;fileNamePattern&gt;${log_dir}/error-log-%d{yyyy-MM-dd}.log &lt;/fileNamePattern&gt; &lt;!-- 日志最大的历史 60天 --&gt; &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- INFO 日志 appender --&gt; &lt;appender name=&quot;INFO&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 按天回滚 daily --&gt; &lt;fileNamePattern&gt;${log_dir}/info-log-%d{yyyy-MM-dd}.log &lt;/fileNamePattern&gt; &lt;!-- 日志最大的历史 60天 --&gt; &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 访问日志 appender --&gt; &lt;appender name=&quot;ACCESS&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 按天回滚 daily --&gt; &lt;fileNamePattern&gt;${log_dir}/access-log-%d{yyyy-MM-dd}.log &lt;/fileNamePattern&gt; &lt;!-- 日志最大的历史 60天 --&gt; &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 系统用户操作日志 appender --&gt; &lt;appender name=&quot;SYS-USER&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 按天回滚 daily --&gt; &lt;fileNamePattern&gt;${log_dir}/sys_user-log-%d{yyyy-MM-dd}.log &lt;/fileNamePattern&gt; &lt;!-- 日志最大的历史 60天 --&gt; &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 打印SQL输出 --&gt; &lt;logger name=&quot;java.sql.Connection&quot; level=&quot;DEBUG&quot; /&gt; &lt;logger name=&quot;java.sql.Statement&quot; level=&quot;DEBUG&quot; /&gt; &lt;logger name=&quot;java.sql.PreparedStatement&quot; level=&quot;DEBUG&quot; /&gt; &lt;!--error错误日志 additivity=&quot;false&quot;表示不向上传递 --&gt; &lt;!-- &lt;logger name=&quot;com.test&quot; level=&quot;error&quot; &gt; --&gt; &lt;!-- &lt;appender-ref ref=&quot;ERROR&quot; /&gt; --&gt; &lt;!-- &lt;/logger&gt; --&gt; &lt;!--info日志 --&gt; &lt;logger name=&quot;com.test&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;INFO&quot; /&gt; &lt;/logger&gt; &lt;!--访问日志 --&gt; &lt;!-- &lt;logger name=&quot;com.test&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt; --&gt; &lt;!-- &lt;appender-ref ref=&quot;ACCESS&quot; /&gt; --&gt; &lt;!-- &lt;/logger&gt; --&gt; &lt;!--系统用户操作日志 --&gt; &lt;!-- &lt;logger name=&quot;com.test&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt; --&gt; &lt;!-- &lt;appender-ref ref=&quot;SYS-USER&quot; /&gt; --&gt; &lt;!-- &lt;/logger&gt; --&gt; &lt;root&gt; &lt;level value=&quot;INFO&quot; /&gt; &lt;appender-ref ref=&quot;stdout&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; 关于这个XML文件的详细讲解请参考http://blog.csdn.net/haidage/article/details/6794509","tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://wangyuanjun.cn/tags/SpringMVC/"}]},{"title":"如何相互转换逗号分隔的字符串和List","date":"2017-01-12T03:01:54.000Z","path":"2017/01/12/如何相互转换逗号分隔的字符串和List/","text":"将逗号分隔的字符串转换为List方法 1： 利用JDK的Arrays类12String str = &quot;a,b,c&quot;; List&lt;String&gt; result = Arrays.asList(str.split(&quot;,&quot;)); 方法 2： 利用Guava的Splitter12String str = &quot;a, b, c&quot;; List&lt;String&gt; result = Splitter.on(&quot;,&quot;).trimResults().splitToList(str); 方法 3： 利用Apache Commons的StringUtils （只是用了split)12String str = &quot;a,b,c&quot;; List&lt;String&gt; result = Arrays.asList(StringUtils.split(str,&quot;,&quot;)); 方法 4: 利用Spring Framework的StringUtils12String str = &quot;a,b,c&quot;; List&lt;String&gt; str = Arrays.asList(StringUtils.commaDelimitedListToStringArray(str)); 将List转换为逗号分隔符方法 1: 不用工具类1234567891011121314151617181920public String listToString(List list, char separator) &#123; StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; list.size(); i++) &#123; if (i == list.size() - 1) &#123; sb.append(list.get(i)); &#125; else &#123; sb.append(list.get(i)); sb.append(separator); &#125; &#125; return sb.toString(); &#125; public String listToString(List list, char separator) &#123; StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; list.size(); i++) &#123; sb.append(list.get(i)).append(separator); &#125; return sb.toString().substring(0,sb.toString().length()-1); &#125; 方法 2： 利用Guava的Joiner12345List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;a&quot;); list.add(&quot;b&quot;); list.add(&quot;c&quot;); String str = Joiner.on(&quot;,&quot;).join(list); 方法 3： 利用Apache Commons的StringUtils12345List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;a&quot;); list.add(&quot;b&quot;); list.add(&quot;c&quot;); String str = StringUtils.join(list.toArray(), &quot;,&quot;); 方法 4：利用Spring Framework的StringUtils12345List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;a&quot;); list.add(&quot;b&quot;); list.add(&quot;c&quot;); String str = StringUtils.collectionToDelimitedString(list, &quot;,&quot;); 比较下来，我的观点就是Guava库和StringUtils更灵活，适用面更广。","tags":[{"name":"java基础","slug":"java基础","permalink":"http://wangyuanjun.cn/tags/java基础/"}]},{"title":"extjs-上传图片","date":"2016-12-10T13:44:29.000Z","path":"2016/12/10/extjs-上传图片/","text":"&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt; &lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt; &lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;!--ExtJs框架开始--&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;/Ext/adapter/ext/ext-base.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;/Ext/ext-all.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;/Ext/src/locale/ext-lang-zh_CN.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;/Ext/resources/css/ext-all.css&quot; /&gt; &lt;!--ExtJs框架结束--&gt; &lt;script type=&quot;text/javascript&quot;&gt; Ext.onReady(function () { //初始化标签中的Ext:Qtip属性。 Ext.QuickTips.init(); Ext.form.Field.prototype.msgTarget = &apos;side&apos;; //创建div组件 var imagebox = new Ext.BoxComponent({ autoEl: { style: &apos;width:150px;height:150px;margin:0px auto;border:1px solid #ccc; text-align:center;padding-top:20px;margin-bottom:10px&apos;, tag: &apos;div&apos;, id: &apos;imageshow&apos;, html: &apos;暂无图片&apos; } }); //创建文本上传域 var file = new Ext.form.TextField({ name: &apos;imgFile&apos;, fieldLabel: &apos;文件上传&apos;, inputType: &apos;file&apos;, allowBlank: false, blankText: &apos;请浏览图片&apos; }); //提交按钮处理方法 var btnsubmitclick = function () { if (form.getForm().isValid()) { form.getForm().submit({ waitTitle: &quot;请稍候&quot;, waitMsg: &apos;正在上传...&apos;, success: function (form, action) { Ext.MessageBox.alert(&quot;提示&quot;, &quot;上传成功！&quot;); document.getElementById(&apos;imageshow&apos;).innerHTML = &apos;&lt;img style=&quot;width:150px;height:150px&quot; src=&quot;&apos; + action.result.path + &apos;&quot;/&gt;&apos;; }, failure: function () { Ext.MessageBox.alert(&quot;提示&quot;, &quot;上传失败！&quot;); } }); } } //重置按钮&quot;点击时&quot;处理方法 var btnresetclick = function () { form.getForm().reset(); } //表单 var form = new Ext.form.FormPanel({ frame: true, fileUpload: true, url: &apos;/App_Ashx/Demo/Upload.ashx&apos;, title: &apos;表单标题&apos;, style: &apos;margin:10px&apos;, items: [imagebox, file], buttons: [{ text: &apos;保存&apos;, handler: btnsubmitclick }, { text: &apos;重置&apos;, handler: btnresetclick }] }); //窗体 var win = new Ext.Window({ title: &apos;窗口&apos;, width: 476, height: 374, resizable: true, modal: true, closable: true, maximizable: true, minimizable: true, buttonAlign: &apos;center&apos;, items: form }); win.show(); }); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; 其中与service交互用上传图片的 一般处理程序文件，源码如下： /App_Ashx/Demo/Upload.ashx using System; using System.Web; using System.IO; using System.Globalization; namespace HZYT.ExtJs.WebSite.App_Ashx.Demo { public class Upload : IHttpHandler { public void ProcessRequest(HttpContext context) { //虚拟目录，建议写在配置文件中 String strPath = &quot;/Upload/Image/&quot;; //文件本地目录 String dirPath = context.Server.MapPath(strPath); //接收文件 HttpPostedFile imgFile = context.Request.Files[&quot;imgFile&quot;]; //取出文件扩展名 String fileExt = Path.GetExtension(imgFile.FileName).ToLower(); //重新命名文件 String newFileName = DateTime.Now.ToString(&quot;yyyyMMddHHmmss_ffff&quot;, DateTimeFormatInfo.InvariantInfo) + fileExt; //文件上传路径 String filePath = dirPath + newFileName; //保存文件 imgFile.SaveAs(filePath); //客户端输出 context.Response.Write(&quot;{success:true,path:&apos;&quot; + strPath + newFileName + &quot;&apos;}&quot;); } public bool IsReusable { get { return false; } } } } 2.效果如下 3.说明： (1)上传域不光可以上传图片，还要以上传其他文件。这里我们以图片为例。 (2)在实际开发中，我们还要对图片格式，大小等进行校验，这个示例测重于上传，没有加入任何校验","tags":[{"name":"extjs","slug":"extjs","permalink":"http://wangyuanjun.cn/tags/extjs/"}]},{"title":"extjs-下拉列表联动","date":"2016-12-10T13:22:32.000Z","path":"2016/12/10/extjs-下拉列表联动/","text":"不管是几级下拉列表的联动实现本质上都是根据某个下拉列表的变化，去动态加载其他下拉列表，如：省、市、地区。 当我们监听到省变化时，向service端发送省的编号，service端根据收到的”省”编号到数据库中查询该省所对应的市信息， 地区同理，抓住这一点，我们只需要监听 combobox 的 select 事件并在其中实现逻辑即可。 1.代码如下： &lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt; &lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt; &lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;!--ExtJs框架开始--&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;/Ext/adapter/ext/ext-base.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;/Ext/ext-all.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;/Ext/src/locale/ext-lang-zh_CN.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;/Ext/resources/css/ext-all.css&quot; /&gt; &lt;!--ExtJs框架结束--&gt; &lt;script type=&quot;text/javascript&quot;&gt; Ext.onReady(function () { //初始化标签中的Ext:Qtip属性。 Ext.QuickTips.init(); Ext.form.Field.prototype.msgTarget = &apos;side&apos;; //----------------------下拉列表开始----------------------// //创建市数据源 var combocitystore = new Ext.data.Store({ //设定读取的地址 proxy: new Ext.data.HttpProxy({ url: &apos;/App_Ashx/Demo/City.ashx&apos; }), //设定读取的格式 reader: new Ext.data.JsonReader({ root: &apos;data&apos; }, [{ name: &apos;id&apos; }, { name: &apos;name&apos;}]) }); //创建区数据源 var comboareastore = new Ext.data.Store({ //设定读取的地址 proxy: new Ext.data.HttpProxy({ url: &apos;/App_Ashx/Demo/Area.ashx&apos; }), reader: new Ext.data.JsonReader({ root: &apos;data&apos; }, [{ name: &apos;id&apos; }, { name: &apos;name&apos;}]) }); //创建市Combobox var comboboxcity = new Ext.form.ComboBox({ id: &apos;comboboxcity&apos;, fieldLabel: &apos;市&apos;, width: 120, store: combocitystore, displayField: &apos;name&apos;, valueField: &apos;id&apos;, triggerAction: &apos;all&apos;, emptyText: &apos;请选择...&apos;, allowBlank: false, blankText: &apos;请选择市&apos;, editable: false, mode: &apos;local&apos;, //该属性和以下方法为了兼容ie8 listeners: { &apos;render&apos;: function () { combocitystore.load(); } } }); //创建区Combobox var comboareacity = new Ext.form.ComboBox({ fieldLabel: &apos;区&apos;, width: 120, store: comboareastore, displayField: &apos;name&apos;, valueField: &apos;id&apos;, triggerAction: &apos;all&apos;, emptyText: &apos;请选择...&apos;, allowBlank: false, blankText: &apos;请选择区&apos;, editable: false }); //联动的实现 comboboxcity.on(&apos;select&apos;, function () { comboareastore.baseParams.id = comboboxcity.getValue(); comboareacity.setValue(&apos;&apos;); comboareastore.load(); }) //----------------------下拉列表结束----------------------// //表单 var form = new Ext.form.FormPanel({ frame: true, title: &apos;表单标题&apos;, style: &apos;margin:10px&apos;, items: [comboboxcity, comboareacity] }); //窗体 var win = new Ext.Window({ title: &apos;窗口&apos;, width: 476, height: 374, resizable: true, modal: true, closable: true, maximizable: true, minimizable: true, buttonAlign: &apos;center&apos;, items: form }); win.show(); }); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;!-- 说明：(1)var combocitystore = new Ext.data.Store():创建一个新的数据源。(2)proxy: new Ext.data.HttpProxy({ url: ‘/App_Ashx/Demo/City.ashx’ })：数据代理为http代理，地址为/App_Ashx/Demo/City.ashx。(3)reader: new Ext.data.JsonReader({ root: ‘data’ },[{ name: ‘id’ }, { name: ‘name’}]):读取json返回值根节点为data，对象列为id和name。 这里要结合client与service观察,我在service端的输出如下：{data:[{id:1,name:’北京’},{id:2,name:’上海’}]}(4)comboboxcity.on(‘select’, function () {}：市选择变化时触发事件。(5)comboareastore.baseParams.id = comboboxcity.getValue()：注意，前面的comboareastore是区的数据源， 当市变化时，我们给区的数据源加上个向service端发送的参数。(6)comboareacity.setValue(‘’)：把区的下拉列表设置为空，由于非空验证，Ext会提示用户“请选择区”，这个地方也可以把加载出来的第一个区 显示在区的下拉列表中，具体请自行实现吧。(7)comboareastore.load()：区的数据源重新加载。–&gt; 其中与service交互用到两个.net 一般处理程序文件，源码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253(1)/App_Ashx/Demo/City.ashxusing System.Web;namespace HZYT.ExtJs.WebSite.App_Ashx.Demo&#123; public class City : IHttpHandler &#123; public void ProcessRequest(HttpContext context) &#123; context.Response.Write(&quot;&#123;data:[&#123;id:1,name:&apos;北京&apos;&#125;,&#123;id:2,name:&apos;上海&apos;&#125;]&#125;&quot;); &#125; public bool IsReusable &#123; get &#123; return false; &#125; &#125; &#125;&#125;(2)/App_Ashx/Demo/Area.ashxusing System.Web;namespace HZYT.ExtJs.WebSite.App_Ashx.Demo&#123; public class Area : IHttpHandler &#123; public void ProcessRequest(HttpContext context) &#123; //接收Client端传来的参数，交根据条件返回 if (context.Request.Form[&quot;id&quot;].ToString() == &quot;1&quot;) &#123; context.Response.Write(&quot;&#123;data:[&#123;id:1,name:&apos;东城区&apos;&#125;,&#123;id:2,name:&apos;西城区&apos;&#125;,&#123;id:2,name:&apos;海淀区&apos;&#125;]&#125;&quot;); &#125; else &#123; context.Response.Write(&quot;&#123;data:[&#123;id:1,name:&apos;杨浦区&apos;&#125;,&#123;id:2,name:&apos;虹口区&apos;&#125;,&#123;id:2,name:&apos;闸北区&apos;&#125;]&#125;&quot;); &#125; &#125; public bool IsReusable &#123; get &#123; return false; &#125; &#125; &#125;&#125; 2.效果如下：","tags":[{"name":"extjs","slug":"extjs","permalink":"http://wangyuanjun.cn/tags/extjs/"}]},{"title":"extjs技巧","date":"2016-12-10T13:00:02.000Z","path":"2016/12/10/extjs技巧/","text":"extjs Ext.form.ComboBox 的设置默认值的问题 Ext.onReady(function(){ var dbConnectionRecord = Ext.data.Record.create([ {name: &apos;dbConnectionKey&apos;,type:&quot;string&quot;,mapping:&quot;dbConnectionKey&quot;}, {name: &apos;name&apos;,type:&quot;string&quot;,mapping:&quot;name&quot;} ]); var dataProxy=new Ext.data.HttpProxy({url:&quot;&lt;%=basePath%&gt;getDBConnection.action&quot;}); var theReader=new Ext.data.JsonReader({totalProperty: &apos;totalProperty&apos;,root:&apos;root&apos;,id:&quot;ecname&quot;},dbConnectionRecord); var dbstore=new Ext.data.Store({proxy:dataProxy,reader:theReader}); dbstore.load(); var dbcombo = new Ext.form.ComboBox({ id:&apos;dbCombo&apos;, renderTo:Ext.getBody(), store: dbstore, valueField:&apos;dbConnectionKey&apos;, displayField:&apos;name&apos;, typeAhead: true, emptyText:&apos;请选择&apos;, readOnly : true, mode: &apos;local&apos;, name:&quot;dbkey&quot;, hiddenName:&apos;dbkey&apos;, editable: false, triggerAction: &apos;all&apos;, selectOnFocus:true }); ////dbcombo.setValue(&quot;4&quot;); 肯定不行，参见后面的代码 }); 实现：写在store load的callback里 dbstore.load({ callback : function(records) { dbcombo.setValue(&quot;4&quot;); } }); //在分页组件前面添加组件 var page = new Ext.PagingToolbar({ store: store, displayInfo: true, pageSize: 10 }); page.insert(0, &apos;-&apos;); page.insert(0, { //添加一个日期组件 xtype: &apos;datefield&apos;, name: &apos;chatdate&apos;, format: &apos;Y-m-d&apos;, value: new Date() }); //树节点(TreeNode)图标动态修改 2009-11-22 15:36:52 var ui = node.getUI(); ui.removeClass(&apos;x-tree-node-leaf&apos;); //去掉之前的根节点样式 ui.addClass(&apos;x-tree-node-expanded&apos;); //设定已展开文件夹样式 //ui.addClass(&apos;x-tree-node-collapsed&apos;);//设定合并的文件夹样式 使用Ext.Ajaxt对象完成异步请求的交互，Ext.Ajax是单实例对象（非常重要，全局单一Ext.Ajax实例！）。注册Ext.Ajax的requestcomplete事件，每个ajax请求成功后首先响应该事件。在该事件的回调函数里面判断访问请求是否超时。使用Ext.Ajax对象的好处是，只需要引入一个包含了几行超时处理代码的js文件，就可以为当前应用增加超时处理功能，原有代码不需要做任何修改。 使用Ext.Ajaxt对象完成异步请求交互，假如checkUserSessionStatus是你的回调方法，每个页面引用： Js代码 Ext.Ajax.on(‘requestcomplete’,checkUserSessionStatus, this); function checkUserSessionStatus(conn,response,options){ //Ext重新封装了response对象 if(typeof response.getResponseHeader.sessionstatus != ‘undefined’){ //发现请求超时，退出处理代码… } } Ext.Ajax.on(‘requestcomplete’,checkUserSessionStatus, this); function checkUserSessionStatus(conn,response,options){ //Ext重新封装了response对象 if(typeof response.getResponseHeader.sessionstatus != ‘undefined’){ //发现请求超时，退出处理代码… } } 可以利用的几个特性：a）所有的ajax请求均带有x-requested-with:XMLHttpRequest头信息b）Ext.Ajax是单实例对象（非常重要，全局单一Ext.Ajax实例！）c）注册Ext.Ajax的requestcomplete事件，每个ajax请求成功后首先响应该事件（概念类似spring的aop拦截）。 对于其他的ajax框架，解决用户访问请求超时这个问题的思路是类似的。 二、如何设置DateField的默认值。 设置DateField的默认值，可以直接给value属性赋值，如：value: ‘01/01/2009’，如果要设置默认值为当天的日期，可以如下设置：value: new Date new Ext.form.DateField({ id: &apos;df&apos;, fieldLabel: &apos;日期&apos;, format: &apos;Y年m月d日&apos;, width: 150, //value: &apos;01/01/2009&apos; value: new Date }) 如何禁用或者启用某个菜单有的时候，有时会根据需要，启用或者禁用某个菜单项，在ExtJS中，可以通过如下的操作进行。 Ext.onReady(function() { Ext.BLANK_IMAGE_URL = &apos;resources/images/default/s.gif&apos;; Ext.QuickTips.init(); var tb = new Ext.Toolbar({ applyTo: &apos;tb&apos;, width: 400 }); var styleMenu = new Ext.menu.Menu({ items: [{ text: &apos;主题选择&apos;, id: &apos;style&apos;, menu: new Ext.menu.Menu({ items: [{ text: &apos;红色主题&apos;, checked: true, group: &apos;theme&apos; }, { text: &apos;蓝色主题&apos;, checked: false, group: &apos;theme&apos; }, { text: &apos;黑色主题&apos;, checked: false, group: &apos;theme&apos; }] }) }, { text: &apos;启用主题&apos;, checked: true, checkHandler: function() { Ext.getCmp(&apos;style&apos;).setDisabled(!this.checked) } }] }); tb.add({ text: &apos;主题&apos;, menu: styleMenu }); }); 一、从form中获取field的三个方法： １、Ext.getCmp(&apos;id&apos;); ２、FormPanel.getForm().findField(&apos;id/name&apos;); ３、Ext.get(&apos;id/name&apos;);//前提是FormPanel在界面上显示出来了。 二、ExtJS如何给textfield赋值的三个方法： var value=&quot;值&quot;; １、 fs.form.findField(id/name).setValue(value); ２、 Ext.get(id/name).setValue(value); ３、 Ext.getCmp(id).setValue(value); 三、Ext grid中得到选择行的方法 在Ext grid中假设有一个名称为grid的对象。 (1)grid.getStore().getRange(0,store.getCount());//得到grid所有的行 (2)grid.getSelectionModel().getSelections()//得到选择所有行 (3)grid.selModel.selections.items;//得到选择所有行 (4)grid.getSelectionModel().getSelected();//得到选择行的第一行 四、formPanel组件load数据时combo的自动赋值 combo有个hiddenName这个属*，这个属性是真正提交的值，在加载的时候你将这个属性的设置到reader中,就可以自动选择到指定的值了，比如说：hiddenName:’value’,那么你的reader中就应该有一个{name:’value’}. 五、ExtJS 重置表单的方法： 有三种方法能实现form表单的重置，假设var fs=new Ext.form.FormPanel({…});(1)fs.form.reset();//重置form(2)fs.getForm().getEl().dom.reset();//重置form(3)Ext.getCmp(‘fs’).form.reset();","tags":[{"name":"extjs","slug":"extjs","permalink":"http://wangyuanjun.cn/tags/extjs/"}]},{"title":"Maven集成 tomcat7-maven-plugin 部署Maven Web项目","date":"2016-12-09T07:54:44.000Z","path":"2016/12/09/Maven集成-tomcat7-maven-plugin-部署Maven-Web项目/","text":"在eclipse中使用tomcat部署项目，我们一般是到网上下载tomcat服务，然后与eclipse集成，这是我之前的做法。其实我们省略这个步骤，使用maven集成tomcat 在项目下pom.xml文件中的标签内加入： &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2-SNAPSHOT&lt;/version&gt; &lt;configuration&gt; &lt;path&gt;/${project.build.finalName}&lt;/path&gt; &lt;!-- 项目名 --&gt; &lt;server&gt;mytomcat7&lt;/server&gt; &lt;!-- 这里是本地tomcat，如果是远程服务器可以改成对应的地址，实现自动部署--&gt; &lt;url&gt;http://localhost:8080/manager/text&lt;/url&gt; &lt;/configuration&gt; &lt;/plugin&gt; 选择项目，然后debug As–&gt;maven build 部署发布成功 插件相关命令 命令 描述 tomcat7:deploy 部署一个web war包 tomcat7:reload 重新加载web war包 tomcat7:start 启动tomcat tomcat7:stop 停止tomcat tomcat7:undeploy 停止一个war包 tomcat7:run 启动嵌入式tomcat ，并运行当前项目 实现自动部署请看以下博文:Maven Tomcat7自动部署Maven tomcat7-maven-plugin 部署Maven Web 项目","tags":[{"name":"maven","slug":"maven","permalink":"http://wangyuanjun.cn/tags/maven/"},{"name":"tomcat","slug":"tomcat","permalink":"http://wangyuanjun.cn/tags/tomcat/"}]},{"title":"解决java.lang.ClassNotFoundException: ch.qos.logback.ext.spring.web.LogbackConfigListener 项目启动报错","date":"2016-12-01T07:08:40.000Z","path":"2016/12/01/解决java-lang-ClassNotFoundException-ch-qos-logback-ext-spring-web-LogbackConfigListener-项目启动报错/","text":"maven项目启动报错，如下: 1-Dec-2016 20:02:55.246 SEVERE [localhost-startStop-1] org.apache.catalina.core.StandardContext.listenerStart Error configuring application listener of class ch.qos.logback.ext.spring.web.LogbackConfigListener java.lang.ClassNotFoundException: ch.qos.logback.ext.spring.web.LogbackConfigListener at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1332) at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1166) at org.apache.catalina.core.DefaultInstanceManager.loadClass(DefaultInstanceManager.java:520) at org.apache.catalina.core.DefaultInstanceManager.loadClassMaybePrivileged(DefaultInstanceManager.java:501) at org.apache.catalina.core.DefaultInstanceManager.newInstance(DefaultInstanceManager.java:120) at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4651) at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5167) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:725) at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:701) at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:717) at org.apache.catalina.startup.HostConfig.deployDescriptor(HostConfig.java:586) at org.apache.catalina.startup.HostConfig$DeployDescriptor.run(HostConfig.java:1750) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) 错误原因tomcat部署过去的项目中lib等jar包没有部署过去 解决方法 选中项目右击Properties 检查tomcat部署过去的项目中lib等jar包有没有部署过去 如果没有添加，加进去，重新启动项目，问题解决!","tags":[{"name":"maven","slug":"maven","permalink":"http://wangyuanjun.cn/tags/maven/"},{"name":"tomcat","slug":"tomcat","permalink":"http://wangyuanjun.cn/tags/tomcat/"}]},{"title":"【Maven】Project configuration is not up-to-date with pom.xml错误解决方法","date":"2016-11-10T08:53:45.000Z","path":"2016/11/10/【Maven】Project-configuration-is-not-up-to-date-with-pom-xml错误解决方法/","text":"导入一个Maven项目之后发现有一个如下的错误：Project configuration is not up-to-date with pom.xml. Run project configuration update 其实这个问题解决非常简单：在项目上右键——【Maven】——【Update Project Configuration……】这时会打开一个（Update Maven Dependencies）的对话框，然后勾选住出错的项目，点击Ok这样就搞定了。","tags":[{"name":"maven","slug":"maven","permalink":"http://wangyuanjun.cn/tags/maven/"}]},{"title":"数据库SQL优化总结","date":"2016-11-08T02:09:02.000Z","path":"2016/11/08/数据库SQL优化总结/","text":"网上关于SQL优化的教程很多，但是比较杂乱。近日有空整理了一下，写出来跟大家分享一下，其中有错误和不足的地方，还请大家纠正补充。 数据库设计方面 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： select id from t where num is null 最好不要给数据库留NULL，尽可能的使用 NOT NULL填充数据库。备注、描述、评论之类的可以设置为 NULL，其他的，最好不要使用NULL。 不要以为 NULL 不需要空间，比如：char(100) 型，在字段建立时，空间就固定了， 不管是否插入值（NULL也包含在内），都是占用 100个字符的空间的，如果是varchar这样的变长字段， null 不占用空间。 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： select id from t where num = 0 并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时,查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。 索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。 应尽可能的避免更新索引数据列，因为索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新索引数据列，那么需要考虑是否应将该索引建为索引。 尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。 尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。 避免频繁创建和删除临时表，以减少系统表资源的消耗。临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件， 最好使用导出表。 临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。 在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。 如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。 与临时表一样，游标并不是不可使用。对小型数据集使用FAST_FORWARD。游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时 间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。 在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。无需在执行存储过程和触发器的每个语句后向客户端发送 DONE_IN_PROC 消息。 SQL语句方面 应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。 应尽量避免在 where 子句中使用 or 来连接条件，如果一个字段有索引，一个字段没有索引，将导致引擎放弃使用索引而进行全表扫描，如： select id from t where num=10 or Name = &apos;admin&apos; 可以这样查询： select id from t where num = 10 union all select id from t where Name = &apos;admin&apos; in 和 not in 也要慎用，否则会导致全表扫描，如： select id from t where num in(1,2,3) 对于连续的数值，能用 between 就不要用 in 了： select id from t where num between 1 and 3 很多时候用 exists 代替 in 是一个好的选择： select num from a where num in(select num from b) 用下面的语句替换： select num from a where exists(select 1 from b where num=a.num) 下面的查询也将导致全表扫描： select id from t where name like ‘%abc%’ 如果在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然 而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描： select id from t where num = @num 可以改为强制查询使用索引： select id from t with(index(索引名)) where num = @num 应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如： select id from t where num/2=100 应改为: select id from t where num=100*2 应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如： select id from t where substring(name,1,3) = ’abc’ -–name以abc开头的id select id from t where datediff(day,createdate,’2005-11-30′) = 0 -–‘2005-11-30’ --生成的id 应改为: select id from t where name like &apos;abc%&apos; select id from t where createdate &gt;= &apos;2005-11-30&apos; and createdate &lt; &apos;2005-12-1&apos; 不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。 不要写一些没有意义的查询，如需要生成一个空表结构： select col1,col2 into #t from t where 1=0 这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样： create table #t(…) 很多时候用 exists 代替 in 是一个好的选择： select num from a where num in(select num from b) 用下面的语句替换： select num from a where exists(select 1 from b where num=a.num) 任何地方都不要使用 select * from t ， 用具体的字段列表代替“*”，不要返回用不到的任何字段。 尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。 尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。 尽量避免大事务操作，提高系统并发能力。 Update 语句，如果只更改1、2个字段，不要Update全部字段，否则频繁调用会引起明显的性能消耗，同时带来大量日志。 对于多张大数据量（这里几百条就算大了）的表JOIN，要先分页再JOIN，否则逻辑读会很高，性能很差。 select count(*) from table；这样不带任何条件的count会引起全表扫描，并且没有任何业务意义，是一定要杜绝的。 尽量避免大事务操作，提高系统并发能力。 尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。 java方面 尽可能的少造对象。 合理摆正系统设计的位置。大量数据操作，和少量数据操作一定是分开的。大量的数据操作，肯定不是ORM框架搞定的。 使用jDBC链接数据库操作数据。 控制好内存，让数据流起来，而不是全部读到内存再处理，而是边读取边处理。 合理利用内存，有的数据要缓存。 如何优化数据库，如何提高数据库的性能? 硬件调整性能 最有可能影响性能的是磁盘和网络吞吐量,解决办法扩大虚拟内存，并保证有足够可以扩充的空间；把数据库服务器上的不必要服务关闭掉；把数据库服务器和主域服务器分开；把SQL数据库服务器的吞吐量调为最大；在具有一个以上处理器的机器上运行SQL。 调整数据库若对该表的查询频率比较高，则建立索引；建立索引时，想尽对该表的所有查询搜索操作， 按照where选择条件建立索引，尽量为整型键建立为有且只有一个簇集索引，数据在物理上按顺序在数据页上，缩短查找范围，为在查询经常使用的全部列建立非簇集索引，能最大地覆盖查询；但是索引不可太多，执行UPDATE DELETE INSERT语句需要用于维护这些索引的开销量急剧增加；避免在索引中有太多的索引键；避免使用大型数据类型的列为索引；保证每个索引键值有少数行。 使用存储过程应用程序的实现过程中，能够采用存储过程实现的对数据库的操作尽量通过存储过程来实现，因为存储过程是存放在数据库服务器上的一次性被设计、编码、测试，并被再次使用，需要执行该任务的应用可以简单地执行存储过程，并且只返回结果集或者数值，这样不仅可以使程序模块化，同时提高响应速度，减少网络流量，并且通过输入参数接受输入，使得在应用中完成逻辑的一致性实现。 应用程序结构和算法建立查询条件索引仅仅是提高速度的前提条件，响应速度的提高还依赖于对索引的使用。因为人们在使用SQL时往往会陷入一个误区，即太关注于所得的结果是否正确，特别是对数据量不是特别大的数据库操作时，是否建立索引和使用索引的好坏对程序的响应速度并不大，因此程序员在书写程序时就忽略了不同的实现方法之间可能存在的性能差异，这种性能差异在数据量特别大时或者大型的或是复杂的数据库环境中（如联机事务处理OLTP或决策支持系统DSS）中表现得尤为明显。在工作实践中发现，不良的SQL往往来自于不恰当的索引设计、不充份的连接条件和不可优化的where子句。在对它们进行适当的优化后，其运行速度有了明显地提高！ 实际案例分析拆分大的 DELETE 或INSERT 语句，批量提交SQL语句。如果你需要在一个在线的网站上去执行一个大的 DELETE 或 INSERT 查询，你需要非常小心，要避免你的操作让你的整个网站停止相应。因为这两个操作是会锁表的，表一锁住了，别的操作都进不来了。Apache 会有很多的子进程或线程。所以，其工作起来相当有效率，而我们的服务器也不希望有太多的子进程，线程和数据库链接，这是极大的占服务器资源的事情，尤其是内存。如果你把你的表锁上一段时间，比如30秒钟，那么对于一个有很高访问量的站点来说，这30秒所积累的访问进程/线程，数据库链接，打开的文件数，可能不仅仅会让你的WEB服务崩溃，还可能会让你的整台服务器马上挂了。所以，如果你有一个大的处理，你一定把其拆分，使用 LIMIT oracle(rownum),sqlserver(top)条件是一个好的方法。下面是一个mysql示例： while(1){ //每次只做1000条 mysql_query(“delete from logs where log_date &lt;= ’2012-11-01’ limit 1000”); if(mysql_affected_rows() == 0){ //删除完成，退出！ break； } //每次暂停一段时间，释放表让其他进程/线程访问。 usleep(50000) } 参考:数据库SQL优化大总结之 百万级数据库优化方案在一个千万级的数据库查寻中，如何提高查询效率？","tags":[{"name":"mysql","slug":"mysql","permalink":"http://wangyuanjun.cn/tags/mysql/"},{"name":"oracle","slug":"oracle","permalink":"http://wangyuanjun.cn/tags/oracle/"}]},{"title":"Tomcat报内存溢出","date":"2016-10-26T13:45:17.000Z","path":"2016/10/26/Tomcat报内存溢出/","text":"1、错误描述 严重：Exception occurred during processing request:null java.lang.reflect.InvocationTargetException. Caused by:java.lang.OutOfMemoryError:Java heap space. 2、错误原因 Tomcat在处理大数据时出现内存溢出 3、解决办法 编辑tomcat的catalina.bat文件，在第一行的后面增加一句： set JAVA_OPTS=-server -Xms512m -Xmx512m -XX:PermSize=128M -XX:MaxPermSize=256M","tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://wangyuanjun.cn/tags/tomcat/"}]},{"title":"Docker的安装","date":"2016-10-26T12:44:32.000Z","path":"2016/10/26/Docker的安装/","text":"一：关于dockerDocker 是一个开源项目，诞生于 2013 年初，最初是 dotCloud 公司内部的一个业余项目。它基于 Google 公司推出的 Go 语言实现。 项目后来加入了 Linux 基金会，遵从了 Apache 2.0 协议，项目代码在 GitHub 上进行维护。 Docker 项目的目标是实现轻量级的操作系统虚拟化解决方案。 Docker 的基础是 Linux 容器（LXC）等技术。 在 LXC 的基础上 Docker 进行了进一步的封装，让用户不需要去关心容器的管理，使得操作更为简便。用户操作 Docker 的容器就像操作一个快速轻量级的虚拟机一样简单。 摘自：http://dockerpool.com/static/books/docker_practice/introduction/what.html 二：安装centos在使用virtualbox安装的时候需要把网络修改成【Bridged A’dapter】，方便获得上网ip，ssh连接到虚拟机。centos7 可以直接使用yum 安装docker最懒的方式，只是为了学习docker省去了折腾环境的麻烦。直接使用iso进行安装就行了。 三：安装docker直接安装就可以了： yum install golang docker device-mapper-event-libs 必须安装 device-mapper-event-libs 否则docker启动不了，报错：Failed to start Docker Application Container Engine。配置&amp;启动服务121:systemctl enable docker2:systemctl start docker docker服务就可以正常启动了。 四：docker hello world虚拟安装一个MySQL，docker非常强大的时image。在官方搜索类库非常多。https://registry.hub.docker.com/search?q=librarydocker的注册中心，里面有很多做好的镜像库。mysql的安装：/mysql/”&gt;https://registry.hub.docker.com//mysql/ 安装mysql过程，设置数据库docker-mysql，版本5.51234567891:# docker run --name docker-mysql -e MYSQL_ROOT_PASSWORD=docker-mysql -d mysql:5.52:Unable to find image &apos;mysql:5.5&apos; locally3:Trying to pull repository docker.io/mysql ...4:2f08318d65b3: Pulling dependent layers 5:511136ea3c5a: Download complete 6:4f903438061c: Download complete 7:1265e16d0c28: Download complete 8:ac1d5afd7b69: Download complete 9:7c89455832dd: Downloading [===========================&gt; ] 4.434 MB/8.077 MB 34s 查看docker镜像：123docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESe59ad4702626 mysql:5.5 &quot;/entrypoint.sh mysq 2 minutes ago Up 2 minutes 3306/tcp docker-mysql 查看mysql的docker服务器，直接登录到mysql容器，就安装好了mysql。同时服务也启动了，测试mysql docker启动成功。123456789101112131415161718192021222324252627docker exec -it docker-mysql bash1 docker exec -it docker-mysql bash2 root@e59ad4702626:/# mysql -uroot -pdocker-mysql3 Welcome to the MySQL monitor. Commands end with ; or \\g.4 Your MySQL connection id is 55 Server version: 5.5.43 MySQL Community Server (GPL)6 7 Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.89 Oracle is a registered trademark of Oracle Corporation and/or its10 affiliates. Other names may be trademarks of their respective11 owners.1213 Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.1415 mysql&gt; show databases;16 +--------------------+17 | Database |18 +--------------------+19 | information_schema |20 | mysql |21 | performance_schema |22 +--------------------+23 3 rows in set (0.00 sec)2425 mysql&gt; 同时这个是一个虚拟的服务器，上面安装的mysql。","tags":[{"name":"docker","slug":"docker","permalink":"http://wangyuanjun.cn/tags/docker/"}]},{"title":"Spring-Aop之xml配置实现日志管理","date":"2016-08-27T15:25:55.000Z","path":"2016/08/27/Spring-Aop之xml配置实现日志管理/","text":"最近项目要做一个日志功能，Spring Aop注解方式我已经实现了，以下是我用xml配置方式来实现。 创建日志注解package com.wyj.annotation; import java.lang.annotation.Documented; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * 日志注解 * * * @author：WangYuanJun * @date：2016年8月27日 下午8:39:42 */ @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface SysLog { String action() default &quot;&quot;;//动作 } 创建切面通知类package com.wyj.aspect; import java.lang.reflect.Method; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import com.wyj.annotation.SysLog; import com.wyj.entity.SysLogEntity; import com.wyj.service.SysLogService; /** * 日志切面通知 * * * @author：WangYuanJun * @date：2016年8月26日 下午8:39:42 */ public class SysLogAspect { @Autowired private SysLogService sysLogService; /** * 环绕通知 * * @param joinPoint * @return * @throws Throwable */ public Object aroud(ProceedingJoinPoint joinPoint) throws Throwable { // 开始时间 long beginTime = System.currentTimeMillis(); // 执行目标方法 Object result = joinPoint.proceed(); // 执行时长(毫秒) long time = System.currentTimeMillis() - beginTime; // 保存日志 saveSysLog(joinPoint, time); return result; } /** * 保存日志 * * @param joinPoint * @param time */ private void saveSysLog(ProceedingJoinPoint joinPoint, long time) { MethodSignature signature = (MethodSignature) joinPoint.getSignature(); Method method = signature.getMethod(); SysLogEntity sysLogEntity = new SysLogEntity(); SysLog sysLog = method.getAnnotation(SysLog.class); if (sysLog != null) { // 注解上的描述 sysLogEntity.setOperation(sysLog.action()); } // 获取目标类名 String className = joinPoint.getTarget().getClass().getName(); // 获取方法名 String methodName = signature.getName(); sysLogEntity.setMethod(className + &quot;.&quot; + methodName + &quot;()&quot;); // 请求的参数 Object[] args = joinPoint.getArgs(); if (args != null &amp;&amp; args.length != 0 &amp;&amp; args[0] != null) { sysLogEntity.setParams(args[0].toString()); } sysLogEntity.setTime(time); // 保存系统日志 sysLogService.save(sysLogEntity); } } AspectJ配置文件&lt;!-- 切面 --&gt; &lt;bean id=&quot;sysLogAspect&quot; class=&quot;com.wyj.aspect.SysLogAspect&quot;&gt;&lt;/bean&gt; &lt;aop:config&gt; &lt;aop:aspect ref=&quot;sysLogAspect&quot;&gt; &lt;aop:pointcut expression=&quot;@annotation(com.wyj.annotation.SysLog)&quot; id=&quot;sysLogPointcut&quot;/&gt; &lt;aop:around method=&quot;aroud&quot; pointcut-ref=&quot;sysLogPointcut&quot;/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt; 日志注解的应用 效果","tags":[{"name":"spring aop","slug":"spring-aop","permalink":"http://wangyuanjun.cn/tags/spring-aop/"},{"name":"spring","slug":"spring","permalink":"http://wangyuanjun.cn/tags/spring/"}]},{"title":"Spring Aop之AspectJ注解配置实现日志管理","date":"2016-08-26T15:25:55.000Z","path":"2016/08/26/Spring-Aop之AspectJ注解配置实现日志管理/","text":"最近项目要做一个日志功能，我用Spring Aop的注解方式来实现。 创建日志注解package com.wyj.annotation; import java.lang.annotation.Documented; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * 日志注解 * * * @author：WangYuanJun * @date：2016年8月26日 下午8:25:35 */ @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface SysLog { String action() default &quot;&quot;;//动作 } 创建切面通知类记录操作的方法名，参数和花费的时间，使用环绕通知 package com.wyj.aspect; import java.lang.reflect.Method; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import com.wyj.annotation.SysLog; import com.wyj.entity.SysLogEntity; import com.wyj.service.SysLogService; /** * 日志切面通知 * * * @author：WangYuanJun * @date：2016年8月26日 下午10:28:57 */ @Aspect @Component public class SysLogAspect { @Autowired private SysLogService sysLogService; /** * 切入点 */ @Pointcut(&quot;@annotation(com.wyj.annotation.SysLog)&quot;) public void pointCut() {} /** * 环绕通知 * * @param joinPoint * @return * @throws Throwable */ @Around(&quot;pointCut()&quot;) public Object aroud(ProceedingJoinPoint joinPoint) throws Throwable { // 开始时间 long beginTime = System.currentTimeMillis(); // 执行目标方法 Object result = joinPoint.proceed(); // 执行时长(毫秒) long time = System.currentTimeMillis() - beginTime; // 保存日志 saveSysLog(joinPoint, time); return result; } /** * 保存日志 * * @param joinPoint * @param time */ private void saveSysLog(ProceedingJoinPoint joinPoint, long time) { MethodSignature signature = (MethodSignature) joinPoint.getSignature(); Method method = signature.getMethod(); SysLogEntity sysLogEntity = new SysLogEntity(); SysLog sysLog = method.getAnnotation(SysLog.class); if (sysLog != null) { // 注解上的描述 sysLogEntity.setOperation(sysLog.action()); } // 获取目标类名 String className = joinPoint.getTarget().getClass().getName(); // 获取方法名 String methodName = signature.getName(); sysLogEntity.setMethod(className + &quot;.&quot; + methodName + &quot;()&quot;); // 请求的参数 Object[] args = joinPoint.getArgs(); if (args != null &amp;&amp; args.length != 0 &amp;&amp; args[0] != null) { sysLogEntity.setParams(args[0].toString()); } sysLogEntity.setTime(time); // 保存系统日志 sysLogService.save(sysLogEntity); } } 扫描和启动aop注解 日志注解的应用 效果","tags":[{"name":"spring aop","slug":"spring-aop","permalink":"http://wangyuanjun.cn/tags/spring-aop/"},{"name":"spring","slug":"spring","permalink":"http://wangyuanjun.cn/tags/spring/"}]},{"title":"ztree实现拖拽功能","date":"2016-07-19T06:09:44.000Z","path":"2016/07/19/ztree实现拖拽功能/","text":"最近在做仓储的功能，需要实现对仓库树的拖拽功能，测试了很长时间才完成，后端使用了SpringMVC + Spring Data Jpa图片和代码展示如下： Jsp程序&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt; &lt;%@ include file=&quot;/common/taglibs.jsp&quot;%&gt; &lt;html&gt; &lt;head lang=&quot;en&quot;&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;renderer&quot; content=&quot;webkit&quot;&gt; &lt;title&gt;物品分类&lt;/title&gt; &lt;style&gt; .ztree * {font-size:14px !important;} &lt;/style&gt; &lt;/head&gt; &lt;body style=&quot;background: #f1f1f1;border:1px solid #f1f1f1;&quot;&gt; &lt;div class=&quot;row&quot; id=&quot;page_content&quot;&gt; &lt;div class=&quot;col-sm-12&quot;&gt; &lt;div class=&quot;ibox float-e-margins&quot;&gt; &lt;div class=&quot;ibox-title&quot;&gt; &lt;h3&gt;物品分类&lt;/h3&gt; &lt;/div&gt; &lt;div class=&quot;ibox-content&quot;&gt; &lt;div class=&quot;col-sm-12 no-padding&quot; id=&quot;tree&quot;&gt; &lt;div class=&quot;zTreeDemoBackground left&quot;&gt; &lt;ul id=&quot;treeDemo&quot; class=&quot;ztree&quot; url=&quot;${ctx}/baseinfo/wpfl/renderTree&quot;&gt;&lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;input type=&quot;hidden&quot; id=&quot;wpflOrCkgl&quot; value=&quot;wpfl&quot;&gt; &lt;script type=&quot;text/javascript&quot;&gt; var wpfl = true; var ckgl = false; var modal = { saveURL : &quot;${ctx}/baseinfo/wpfl&quot;, deleteURL: &quot;${ctx}/baseinfo/wpfl/delete&quot;, sameLevel: &quot;${ctx}/baseinfo/wpfl/sameLevel&quot;, differentLevel:&quot;${ctx}/baseinfo/wpfl/differentLevel&quot;, diffLevel:&quot;${ctx}/baseinfo/wpfl/diffLevel&quot;, checkURL:&quot;${ctx}/baseinfo/wpfl/check&quot; } &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; JS代码var setting = { view: { addHoverDom: addHoverDom, removeHoverDom: removeHoverDom, selectedMulti: false, showLine: false, showIcon: showIconForTree }, edit: { drag: { autoExpandTrigger: true, prev: dropPrev, inner: dropInner, next: dropNext }, enable: true, editNameSelectAll: true, showRemoveBtn : showRemoveBtn, showRenameBtn : showRenameBtn }, data: { simpleData: { enable: true } }, callback: { beforeDrag: beforeDrag, beforeEditName: beforeEditName, beforeRemove: beforeRemove, beforeRename: beforeRename, onRemove: onRemove, onRename: onRename, beforeDrop: beforeDrop, beforeDragOpen: beforeDragOpen, onDrag: onDrag, onDrop: onDrop, onExpand: onExpand, onAsyncSuccess: zTreeOnAsyncSuccess, }, async: { enable: true, type: &quot;get&quot;, //表示异步加载采用 post 方法请求 url: $(&quot;#treeDemo&quot;).attr(&quot;url&quot;), autoParam: [&quot;id&quot;, &quot;type&quot;] //传递节点的id 和 type值给后台(当异步加载数据时) } }; /**数异步加载成功*/ function zTreeOnAsyncSuccess(event, treeId, node, msg) { var treeObj = $.fn.zTree.getZTreeObj(&quot;treeDemo&quot;); var nodes = treeObj.getNodes(); // 异步展开一级子节点 if (nodes.length &gt; 0) { treeObj.expandNode(nodes[0], true, false, false); } } var log, className = &quot;dark&quot;; function beforeDrag(treeId, treeNodes) { return false; } function beforeEditName(treeId, treeNode) { className = (className === &quot;dark&quot; ? &quot;&quot;:&quot;dark&quot;); showLog(&quot;[ &quot;+getTime()+&quot; beforeEditName ]&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &quot; + treeNode.name); var zTree = $.fn.zTree.getZTreeObj(&quot;treeDemo&quot;); zTree.selectNode(treeNode); return; } function beforeRemove(treeId, treeNode) { className = (className === &quot;dark&quot; ? &quot;&quot;:&quot;dark&quot;); showLog(&quot;[ &quot;+getTime()+&quot; beforeRemove ]&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &quot; + treeNode.name); var zTree = $.fn.zTree.getZTreeObj(&quot;treeDemo&quot;); zTree.selectNode(treeNode); var flag = false; if(confirm(&quot;确认删除 节点 -- &quot; + treeNode.name + &quot; 吗？&quot;)){ // 删除节点 flag=delNode(modal,treeNode.id); } return flag; } function onRemove(e, treeId, treeNode) { showLog(&quot;[ &quot;+getTime()+&quot; onRemove ]&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &quot; + treeNode.name); } function beforeRename(treeId, treeNode, newName, isCancel) { className = (className === &quot;dark&quot; ? &quot;&quot;:&quot;dark&quot;); showLog((isCancel ? &quot;&lt;span style=&apos;color:red&apos;&gt;&quot;:&quot;&quot;) + &quot;[ &quot;+getTime()+&quot; beforeRename ]&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &quot; + treeNode.name + (isCancel ? &quot;&lt;/span&gt;&quot;:&quot;&quot;)); if (newName.length == 0) { alert(&quot;节点名称不能为空.&quot;); var zTree = $.fn.zTree.getZTreeObj(&quot;treeDemo&quot;); setTimeout(function(){zTree.editName(treeNode)}, 10); return false; } else if(newName.length &gt; 20){ confirm(&quot;名称长度在20字以内&quot;); return false; } // 修改的名字没变 if(treeNode.name == newName){ return true; } // 判断是否重名 var flag1 = check(newName); if(flag1 == false){ alert(&quot;名称不能重复&quot;); return false; } return true; } function onRename(e, treeId, treeNode, isCancel) { showLog((isCancel ? &quot;&lt;span style=&apos;color:red&apos;&gt;&quot;:&quot;&quot;) + &quot;[ &quot;+getTime()+&quot; onRename ]&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &quot; + treeNode.name + (isCancel ? &quot;&lt;/span&gt;&quot;:&quot;&quot;)); if(treeNode.type == &apos;add&apos;){ // 新增节点 nodeAdd(treeNode); treeNode.type=&apos;edit&apos;; }else{ // 编辑节点 nodeEdit(treeNode); } } function showIconForTree(treeId, treeNode) { return !treeNode.isParent; } function showLog(str) { if (!log) log = $(&quot;#log&quot;); log.append(&quot;&lt;li class=&apos;&quot;+className+&quot;&apos;&gt;&quot;+str+&quot;&lt;/li&gt;&quot;); if(log.children(&quot;li&quot;).length &gt; 8) { log.get(0).removeChild(log.children(&quot;li&quot;)[0]); } } function getTime() { var now= new Date(), h=now.getHours(), m=now.getMinutes(), s=now.getSeconds(), ms=now.getMilliseconds(); return (h+&quot;:&quot;+m+&quot;:&quot;+s+ &quot; &quot; +ms); } var newCount = 1; /** 是否显示编辑按钮 */ function showRenameBtn(treeId, treeNode){ // 根节点不显示编辑按钮 if(treeNode.level == 0){ return false; }else{ return true; } } /** 是否显示删除按钮 */ function showRemoveBtn(treeId, treeNode){ // 根节点不显示删除按钮 if(treeNode.level == 0){ return false; }else{ return true; } } /** 新增节点 */ function addHoverDom(treeId, treeNode) { if(wpfl == true &amp;&amp; treeNode.level == 3){ // 物品分类最多支持三级 return; }else if(ckgl == true &amp;&amp; treeNode.level == 2){ // 仓库管理最多支持二级 return; } var sObj = $(&quot;#&quot; + treeNode.tId + &quot;_span&quot;); if (treeNode.editNameFlag || $(&quot;#addBtn_&quot;+treeNode.tId).length&gt;0) return; var addStr = &quot;&lt;span class=&apos;button add&apos; id=&apos;addBtn_&quot; + treeNode.tId + &quot;&apos; title=&apos;新增&apos; onfocus=&apos;this.blur();&apos;&gt;&lt;/span&gt;&quot;; sObj.after(addStr); var btn = $(&quot;#addBtn_&quot;+treeNode.tId); if (btn) btn.bind(&quot;click&quot;, function(){ var zTree = $.fn.zTree.getZTreeObj(&quot;treeDemo&quot;); var newName = &quot;new node&quot; + (newCount++); zTree.addNodes(treeNode, {id:(100 + newCount), pId:treeNode.id, name:newName,type : &apos;add&apos;}); var newNode=treeNode.children[treeNode.children.length-1]; zTree.editName(newNode); return false; }); } function removeHoverDom(treeId, treeNode) { $(&quot;#addBtn_&quot;+treeNode.tId).unbind().remove(); } function selectAll() { var zTree = $.fn.zTree.getZTreeObj(&quot;treeDemo&quot;); zTree.setting.edit.editNameSelectAll = $(&quot;#selectAll&quot;).attr(&quot;checked&quot;); } function dropPrev(treeId, nodes, targetNode) { var pNode = targetNode.getParentNode(); if (pNode &amp;&amp; pNode.dropInner === false) { return false; } else { for (var i=0,l=curDragNodes.length; i&lt;l; i++) { var curPNode = curDragNodes[i].getParentNode(); if (curPNode &amp;&amp; curPNode !== targetNode.getParentNode() &amp;&amp; curPNode.childOuter === false) { return false; } } } return true; } function dropInner(treeId, nodes, targetNode) { if (targetNode &amp;&amp; targetNode.dropInner === false) { return false; } else { for (var i=0,l=curDragNodes.length; i&lt;l; i++) { if (!targetNode &amp;&amp; curDragNodes[i].dropRoot === false) { return false; } else if (curDragNodes[i].parentTId &amp;&amp; curDragNodes[i].getParentNode() !== targetNode &amp;&amp; curDragNodes[i].getParentNode().childOuter === false) { return false; } } } return true; } function dropNext(treeId, nodes, targetNode) { var pNode = targetNode.getParentNode(); if (pNode &amp;&amp; pNode.dropInner === false) { return false; } else { for (var i=0,l=curDragNodes.length; i&lt;l; i++) { var curPNode = curDragNodes[i].getParentNode(); if (curPNode &amp;&amp; curPNode !== targetNode.getParentNode() &amp;&amp; curPNode.childOuter === false) { return false; } } } return true; } var log, className = &quot;dark&quot;, curDragNodes, autoExpandNode; var dragId ; //拖拽节点的父节点的id /** 拖拽前执行 */ function beforeDrag(treeId, treeNodes) { className = (className === &quot;dark&quot; ? &quot;&quot;:&quot;dark&quot;); showLog(&quot;[ &quot;+getTime()+&quot; beforeDrag ]&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; drag: &quot; + treeNodes.length + &quot; nodes.&quot; ); for (var i=0,l=treeNodes.length; i&lt;l; i++) { dragId = treeNodes[i].pId; if (treeNodes[i].drag === false) { curDragNodes = null; return false; } else if (treeNodes[i].parentTId &amp;&amp; treeNodes[i].getParentNode().childDrag === false) { curDragNodes = null; return false; } } curDragNodes = treeNodes; return true; } function beforeDragOpen(treeId, treeNode) { autoExpandNode = treeNode; return true; } /** 拖拽释放之后执行 */ function beforeDrop(treeId, treeNodes, targetNode, moveType, isCopy) { className = (className === &quot;dark&quot; ? &quot;&quot;:&quot;dark&quot;); showLog(&quot;[ &quot;+getTime()+&quot; beforeDrop ]&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; moveType:&quot; + moveType); showLog(&quot;target: &quot; + (targetNode ? targetNode.name : &quot;root&quot;) + &quot; -- is &quot;+ (isCopy==null? &quot;cancel&quot; : isCopy ? &quot;copy&quot; : &quot;move&quot;)); if(dragId == targetNode.pId &amp;&amp; moveType != &apos;inner&apos;){// 同级位置调整 var data = &apos;pId=&apos;+dragId+&apos;&amp;currentNodeId=&apos;+treeNodes[0].id+&apos;&amp;newNodeId=&apos;+targetNode.id+&apos;&amp;moveType=&apos;+moveType; nodeExchange(data,modal.sameLevel); }else if(moveType == &apos;inner&apos;){ // 一个节点变成另一个节点的子节点 // 不能移到仓库管理第二节点,物品分类第三节点 if((ckgl == true &amp;&amp; targetNode.level == 2) || (wpfl == true &amp;&amp; targetNode.level == 3)){ return false; }else{ var data = &apos;currentNodeId=&apos;+treeNodes[0].id+&apos;&amp;newParentNodeId=&apos;+targetNode.id; } nodeExchange(data,modal.differentLevel); }else if(dragId != targetNode.pId &amp;&amp; moveType != &apos;inner&apos;){ // 不同级之间的调整 var flag1 = canMove(treeNodes[0].id); if(flag1 == false){ alert(&quot;您选择的节点已经被引用，不能被拖动&quot;); return false; } // 物品管理最高3级，仓库管理最高2级 isParent if(ckgl == true &amp;&amp; treeNodes[0].pId == 0 &amp;&amp; targetNode.level == 2){ alert(&quot;最多支持二级分类&quot;); return false; }else if((wpfl == true &amp;&amp; targetNode.level == 3 &amp;&amp; treeNodes[0].isParent == true) || (wpfl == true &amp;&amp; targetNode.level == 2 &amp;&amp; treeNodes[0].pId == 0)){ alert(&quot;最多支持三级分类&quot;); return false; } var data = &apos;currentNodeId=&apos;+treeNodes[0].id+&apos;&amp;newNodeId=&apos;+targetNode.id+&apos;&amp;moveType=&apos;+moveType; nodeExchange(data,modal.diffLevel); } return true; } function onDrag(event, treeId, treeNodes) { className = (className === &quot;dark&quot; ? &quot;&quot;:&quot;dark&quot;); showLog(&quot;[ &quot;+getTime()+&quot; onDrag ]&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; drag: &quot; + treeNodes.length + &quot; nodes.&quot; ); } function onDrop(event, treeId, treeNodes, targetNode, moveType, isCopy) { className = (className === &quot;dark&quot; ? &quot;&quot;:&quot;dark&quot;); showLog(&quot;[ &quot;+getTime()+&quot; onDrop ]&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; moveType:&quot; + moveType); showLog(&quot;target: &quot; + (targetNode ? targetNode.name : &quot;root&quot;) + &quot; -- is &quot;+ (isCopy==null? &quot;cancel&quot; : isCopy ? &quot;copy&quot; : &quot;move&quot;)) } function onExpand(event, treeId, treeNode) { if (treeNode === autoExpandNode) { className = (className === &quot;dark&quot; ? &quot;&quot;:&quot;dark&quot;); showLog(&quot;[ &quot;+getTime()+&quot; onExpand ]&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&quot; + treeNode.name); } } function showLog(str) { if (!log) log = $(&quot;#log&quot;); log.append(&quot;&lt;li class=&apos;&quot;+className+&quot;&apos;&gt;&quot;+str+&quot;&lt;/li&gt;&quot;); if(log.children(&quot;li&quot;).length &gt; 8) { log.get(0).removeChild(log.children(&quot;li&quot;)[0]); } } function getTime() { var now= new Date(), h=now.getHours(), m=now.getMinutes(), s=now.getSeconds(), ms=now.getMilliseconds(); return (h+&quot;:&quot;+m+&quot;:&quot;+s+ &quot; &quot; +ms); } function setTrigger() { var zTree = $.fn.zTree.getZTreeObj(&quot;treeDemo&quot;); zTree.setting.edit.drag.autoExpandTrigger = $(&quot;#callbackTrigger&quot;).attr(&quot;checked&quot;); } /** 鼠标移入移出显示操作图标 */ function over(aa){ $(aa).children(&quot;.hides&quot;).css(&quot;display&quot;,&quot;block&quot;); } function out(aa){ $(aa).children(&quot;.hides&quot;).css(&quot;display&quot;,&quot;none&quot;); } function change_bgcolor(aa){ $(aa).addClass(&quot;active&quot;) .parent().siblings().children().removeClass(&quot;active&quot;); $(&quot;#table-body&quot;).animate({ scrollTop:&apos;0px&apos;, scrollLeft:&apos;0px&apos; },0); } /** 点击物品分类 */ function kind_click(a,b,c){ $(a).addClass(&quot;active&quot;).parent().siblings().children().removeClass(&quot;active&quot;); var oUl = $(a).parent().parent(); var oDiv = oUl.parent(); if(oUl.index() == 0){ $(&quot;.show_kind&quot;).children(&quot;span&quot;).html(&apos;&apos;); $(&quot;.show_kind&quot;).children(&quot;span&quot;).eq(0).html($(a).html()); } else if(oUl.index() == 1){ if(oDiv.children(&quot;ul&quot;).eq(0).find(&quot;.active&quot;).length){ $(&quot;.show_kind&quot;).children(&quot;span&quot;).eq(oUl.index()).html(&quot;-&gt; &quot;+$(a).html()); $(&quot;.show_kind&quot;).children(&quot;span&quot;).eq(2).html(&apos;&apos;); } else{ confirm(&quot;请选中上一级菜单，再点击&quot;); } }else{ if(oUl.index() == 2 &amp;&amp; oDiv.children(&quot;ul&quot;).eq(0).find(&quot;.active&quot;).length &amp;&amp; oDiv.children(&quot;ul&quot;).eq(1).find(&quot;.active&quot;).length){ $(&quot;.show_kind&quot;).children(&quot;span&quot;).eq(oUl.index()).html(&quot;-&gt; &quot;+$(a).html()); } else{ confirm(&quot;请选中上一级菜单，再点击&quot;); } } myKindClick(a,b,c); } /** 删除table记录 */ function delete_tr(p){ var y=p.parentNode.parentNode; y.parentNode.removeChild(y);//只能上找一层parentNode againPx(); } /** 重新排序 */ function againPx(){ var index = 1; $(&quot;td[name=&apos;px&apos;]&quot;).each(function(){ $(this).find(&apos;span&apos;).html(index); index++; }); } /** 新增节点 */ function nodeAdd(treeNode){ $.ajax({ type: &apos;post&apos;, url: modal.saveURL, data: { &apos;id&apos;:null, &apos;sjfl&apos;:treeNode.pId, &apos;mc&apos;:treeNode.name }, dataType: &apos;json&apos;, // async : false, traditional: true, success: function(result) { if (result.success) { var treeObj = $.fn.zTree.getZTreeObj(&quot;treeDemo&quot;); var obj=result.data.obj; treeNode.id = obj[&apos;id&apos;]; treeNode.pId = obj[&apos;sjfl&apos;]; treeObj.updateNode(treeNode); showRemindMsg(); try { mySave(modal); } catch(e) {} } else { alert(result.errorMsg); } }, error: function(XMLHttpRequest, textStatus, errorThrown) { btn.disabled = false; alert(&quot;请求异常&quot;); } }); } /** 编辑节点 */ function nodeEdit(treeNode){ $.ajax({ type: &apos;post&apos;, url: modal.saveURL, data: { &apos;id&apos;:treeNode.id, &apos;sjfl&apos;:treeNode.pId, &apos;mc&apos;:treeNode.name }, dataType: &apos;json&apos;, traditional: true, success: function(result) { // btn.disabled = false; if (result.success) { showRemindMsg(); try { mySave(modal); } catch(e) {} } else { alert(result.errorMsg); } }, error: function(XMLHttpRequest, textStatus, errorThrown) { btn.disabled = false; alert(&quot;请求异常&quot;); } }); } /**执行删除*/ function delNode(modal, id) { var flag=true; $.ajax({ type: &apos;post&apos;, url: modal.deleteURL, data: { ids: id }, async:false, dataType: &apos;json&apos;, traditional: true, success: function(result) { if (result.success) { showRemindMsg(); } else { flag = false; if (result.errorMsg.indexOf(&quot;ConstraintViolationException&quot;) &gt; 0) { alert(&quot;您选择的记录已经被引用，不能被删除&quot;); } } } }); return flag; } /** 节点位置调换 */ function nodeExchange(data,ways){ $.ajax({ type:&quot;get&quot;, data:data, url: ways, dataType:&apos;json&apos;, success: function(result) { if (result.success) { showRemindMsg(); try { mySave(modal); } catch(e) {} } else { alert(result.errorMsg); } }, error: function(XMLHttpRequest, textStatus, errorThrown) { alert(&quot;请求异常&quot;); } }); } /** * 验证节点名字唯一性 * * @param name * @returns {Boolean} */ function check(name){ var flag = true; $.ajax({ type: &apos;post&apos;, url: modal.checkURL, data: { name:name }, dataType: &apos;json&apos;, traditional: true, async:false, success: function(result) { if (result.success) { var check = result.data.check; if(check == false){ flag = false; }else{ flag = true; } try { mySave(modal); } catch(e) {} } else { alert(result.errorMsg); } }, error: function(XMLHttpRequest, textStatus, errorThrown) { btn.disabled = false; alert(&quot;请求异常&quot;); } }); return flag; } /** * 仓库管理二级节点被引用的不能被拖动 * @param kfkwId * @returns {Boolean} */ function canMove(kfkwId){ var flag = true; $.ajax({ type: &apos;get&apos;, url: modal.canMoveURL, data: { id:kfkwId }, dataType: &apos;json&apos;, traditional: true, async:false, success: function(result) { if (result.success) { var can = result.data.canMove; if(can == false){ flag = false; }else{ flag = true; } try { mySave(modal); } catch(e) {} } else { alert(result.errorMsg); } }, error: function(XMLHttpRequest, textStatus, errorThrown) { btn.disabled = false; alert(&quot;请求异常&quot;); } }); return flag; } Controller代码package com.dtyun.ccgl.web.controller.baseinfo; /** * 仓库管理Controller * * @author WangYuanJun */ @Controller @RequestMapping(value = &quot;/baseinfo/ckgl&quot;) @FunctionModule(value = &quot;仓库管理&quot;, entry = &quot;/baseinfo/ckgl&quot;, parent = &quot;基础数据&quot;) public class KfkwController extends BaseController { /** 仓库管理Service */ @Autowired private KfkwService kfkwService; /** 库存历史Service */ @Autowired private KcglHisService kcglHisService; /** 系统配置Service */ @Autowired private CcSysConfigService sysConfigService; private Logger logger = LoggerFactory.getLogger(this.getClass()); @RequestMapping(method = RequestMethod.GET) public String index(Model model) { CcSysConfigEntity sysConfigEntity= sysConfigService.findGjdmcBySchool(AuthUtils.getCurrentSchoolId()); Boolean boolean1 = false; // 设置了仓库根节点名称 if(sysConfigEntity != null){ boolean1 = true; } model.addAttribute(&quot;ssxx&quot;, AuthUtils.getCurrentSchoolId()); model.addAttribute(&quot;booleanSetGjdmc&quot;, boolean1); return &quot;/baseinfo/ckgl/ckgl&quot;; } /** * 添加物品分类 * * @param dto * @param result * @return */ @ResponseBody @RequestMapping(method = RequestMethod.POST) public Retval save(@Valid KfkwDto dto, BindingResult result) { Retval retval = Retval.newInstance(); // 表单校验 if (result.hasErrors()) { retval.fail(getErrorMessage(result)); return retval; } // 保存 try { // 当上级分类为0时，为一级目录 if (dto.getSjfl() == null || dto.getSjfl() == 0) { dto.setSjfl(null); } KfkwEntity kfkwEntity = kfkwService.save(dto); retval.put(&quot;obj&quot;, kfkwEntity); } catch (Exception e) { logger.error(e.getMessage(), e); retval.fail(e.getMessage()); } return retval; } /** * 删除物品分类 * * @param ids * @return */ @ResponseBody @RequestMapping(value = &quot;/delete&quot;, method = RequestMethod.POST) public Retval delete(@RequestParam Long[] ids) { Retval retval = Retval.newInstance(); try { kfkwService.deleteByIds(ids); } catch (DataIntegrityViolationException e) { retval.fail(e.getMessage()); } catch (Exception e) { logger.error(e.getMessage(), e); retval.fail(e.getMessage()); } return retval; } /** * 判断被引用的二级节点能否被移动 * * @param id * @return */ @ResponseBody @RequestMapping(value=&quot;/canMove&quot;,method=RequestMethod.GET) public Retval canMove(@RequestParam Long id){ Retval retval = Retval.newInstance(); Boolean boolean1 = kcglHisService.findKfkwById(id); retval.put(&quot;canMove&quot;, boolean1); return retval; } /** *同级之间拖拽 * * @param pId 拖拽节点父节点id * @param currentNodeId 拖拽节点id * @param newNodeId 目标节点id * @param moveType 拖拽类型 * @return */ @ResponseBody @RequestMapping(value = &quot;/sameLevel&quot;, method = RequestMethod.GET) public Retval sameLevel(@RequestParam Long pId, @RequestParam Long currentNodeId, @RequestParam Long newNodeId, @RequestParam String moveType) { Retval retval = Retval.newInstance(); try { kfkwService.sameLevel(pId, currentNodeId, newNodeId, moveType); } catch (Exception e) { logger.error(e.getMessage(), e); retval.fail(e.getMessage()); } return retval; } /** * 拖拽节点成为目标节点的子节点 * * @param currentNodeId 拖拽节点id * @param newParentNodeId 目标父节点id * @return */ @ResponseBody @RequestMapping(value = &quot;/differentLevel&quot;, method = RequestMethod.GET) public Retval differentLevel(@RequestParam Long currentNodeId, @RequestParam Long newParentNodeId) { Retval retval = Retval.newInstance(); try { kfkwService.differentLevel(currentNodeId, newParentNodeId); } catch (Exception e) { logger.error(e.getMessage(), e); retval.fail(e.getMessage()); } return retval; } /** * 不同级节点为位置调换 * * @param currentNodeId 被拖拽节点id * @param newNodeId 新的节点id * @param moveType * @return */ @ResponseBody @RequestMapping(value = &quot;/diffLevel&quot;, method = RequestMethod.GET) public Retval diffLevel(@RequestParam Long currentNodeId, @RequestParam Long newNodeId,@RequestParam String moveType) { Retval retval = Retval.newInstance(); try { kfkwService.diffLevel(currentNodeId, newNodeId, moveType); } catch (Exception e) { logger.error(e.getMessage(), e); retval.fail(e.getMessage()); } return retval; } /** * 加载树 * * @param id * @param type * @return * @throws Exception */ @ResponseBody @RequestMapping(value = &quot;/renderTree&quot;, method = RequestMethod.GET) public List&lt;Map&lt;String, Object&gt;&gt; renderTree(Long id, String type) throws Exception { List&lt;Map&lt;String, Object&gt;&gt; returnList = new ArrayList&lt;Map&lt;String, Object&gt;&gt;(); CcSysConfigEntity sysConfigEntity= sysConfigService.findGjdmcBySchool(AuthUtils.getCurrentSchoolId()); // 加载根节点 if (StringUtils.isEmpty(id)) { Map&lt;String, Object&gt; root = new HashMap&lt;String, Object&gt;(); root.put(&quot;id&quot;, 0); root.put(&quot;name&quot;, sysConfigEntity.getCckcgjdmc()); root.put(&quot;isParent&quot;, true); // 加载一级节点 List&lt;Map&lt;String, Object&gt;&gt; returnList1 = new ArrayList&lt;Map&lt;String, Object&gt;&gt;(); List&lt;KfkwEntity&gt; list1 = kfkwService.findLeveL1Node(); for (KfkwEntity kfkw : list1) { Map&lt;String, Object&gt; node = new HashMap&lt;String, Object&gt;(); node.put(&quot;id&quot;, kfkw.getId()); node.put(&quot;name&quot;, kfkw.getMc()); Boolean isParent = kfkwService.hasSubNodeById(kfkw.getId()); node.put(&quot;isParent&quot;, isParent); returnList1.add(node); } root.put(&quot;children&quot;, returnList1); returnList.add(root); return returnList; } // 加载子节点 List&lt;KfkwEntity&gt; list = null; if (id != null &amp;&amp; id &gt; 0L) { list = kfkwService.findSubNodeById(id); for (KfkwEntity kfkw : list) { Map&lt;String, Object&gt; node = new HashMap&lt;String, Object&gt;(); node.put(&quot;id&quot;, kfkw.getId()); node.put(&quot;name&quot;, kfkw.getMc()); Boolean isParent = kfkwService.hasSubNodeById(kfkw.getId()); node.put(&quot;isParent&quot;, isParent); returnList.add(node); } } return returnList; } /** * 查重 * * @param name * @return */ @ResponseBody @RequestMapping(value = &quot;/check&quot;, method = RequestMethod.POST) public Retval check(@RequestParam String name) { Retval retval = Retval.newInstance(); Boolean boolean1 = kfkwService.check(name); retval.put(&quot;check&quot;, boolean1); return retval; } } service代码/** * 仓库管理Service * * @author WangYuanJun */ @Service public class KfkwService extends BaseService{ /** 物品分类Dao */ @Autowired private KfkwDao kfkwDao; /** * 找该级的子目录 * * @param sjfl * @return */ public List&lt;KfkwEntity&gt; findByMaxPx(Long sjfl) { Sort sort = new Sort(Direction.DESC,&quot;px&quot;); return kfkwDao.findAll(spc3(sjfl),sort); } public Specification&lt;KfkwEntity&gt; spc3(Long sjfl) { Specification&lt;KfkwEntity&gt; sp = new Specification&lt;KfkwEntity&gt;() { @Override public Predicate toPredicate(Root&lt;KfkwEntity&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) { List&lt;Predicate&gt; predicates = Lists.newArrayList(); if(sjfl == null){ Predicate pSjfl = cb.isNull(root.get(&quot;sjfl&quot;).as(Long.class)); predicates.add(pSjfl); }else{ Predicate pSjfl = cb.equal(root.get(&quot;sjfl&quot;).as(Long.class), sjfl); predicates.add(pSjfl); } Predicate pXx = cb.equal(root.get(&quot;ssxx&quot;).as(Long.class), getSchoolId());// 所属学校 predicates.add(pXx); query.where(cb.and(predicates.toArray(new Predicate[predicates.size()]))); return query.getRestriction(); } }; return sp; } /** * 同级之间拖拽 * * @param pId 父节点 * @param currentNodeId 拖拽的id * @param newNodeId 拖拽新的id */ @Transactional public void sameLevel(Long pId, Long currentNodeId, Long newNodeId, String moveType) { // 将他们中间的影响的记录跟新 if (&quot;next&quot;.equals(moveType)) { KfkwEntity currentKfkw = kfkwDao.findOne(currentNodeId); KfkwEntity newKfkw = kfkwDao.findOne(newNodeId); // 向下拖拽 if(currentKfkw.getPx()&lt;newKfkw.getPx()){ // 跟新受影响的记录 List&lt;KfkwEntity&gt; kfkwList = findInfluenceData(pId, currentKfkw.getPx(), newKfkw.getPx()); for (int i = 0; i &lt; kfkwList.size(); i++) { KfkwEntity kfkw = kfkwList.get(i); if (!(kfkw.getId().equals(currentKfkw.getId())) &amp;&amp; !(kfkw.getId().equals(newKfkw.getId()))) { KfkwEntity kfkwEntity2 = kfkwDao.findOne(kfkw.getId()); kfkwEntity2.setPx(kfkwEntity2.getPx() - 1); kfkwDao.save(kfkwEntity2); } } // 拖拽节点排序变为目标节点的排序 currentKfkw.setPx(newKfkw.getPx()); kfkwDao.save(currentKfkw); // 目标排序节点排序为其排序-1 newKfkw.setPx(newKfkw.getPx() - 1); kfkwDao.save(newKfkw); }else{ // 向上拖拽,movetpe=next // 目标节点wpflList.get(0),去除目标节点,将目标节点的下一个节点变为目标节点 List&lt;KfkwEntity&gt; kfkwList = findInfluenceData(pId, currentKfkw.getPx(), newKfkw.getPx()); kfkwList.remove(0); KfkwEntity kfkwNew=kfkwDao.findOne(kfkwList.get(0).getId()); int kfkwNewPx = kfkwNew.getPx(); for (int i = 0; i &lt; kfkwList.size(); i++) { KfkwEntity kfkw = kfkwList.get(i); if (!(kfkw.getId().equals(currentKfkw.getId())) ) { KfkwEntity kfkwEntity2 = kfkwDao.findOne(kfkw.getId()); kfkwEntity2.setPx(kfkwEntity2.getPx() + 1); kfkwDao.save(kfkwEntity2); } } // 拖拽的排序变为目标节点排序 currentKfkw.setPx(kfkwNewPx); kfkwDao.save(currentKfkw); } } else if (&quot;prev&quot;.equals(moveType)) { KfkwEntity currentKfkw = kfkwDao.findOne(currentNodeId); KfkwEntity newKfkw = kfkwDao.findOne(newNodeId); // 向上拖拽 if(currentKfkw.getPx()&gt;newKfkw.getPx()){ // 跟新受影响的记录 List&lt;KfkwEntity&gt; kfkwList = findInfluenceData(pId, currentKfkw.getPx(), newKfkw.getPx()); for (int i = 0; i &lt; kfkwList.size(); i++) { KfkwEntity kfkw = kfkwList.get(i); if (!(kfkw.getId().equals(currentKfkw.getId())) &amp;&amp; !(kfkw.getId().equals(newKfkw.getId()))) { KfkwEntity kfkwEntity2 = kfkwDao.findOne(kfkw.getId()); kfkwEntity2.setPx(kfkwEntity2.getPx() + 1); kfkwDao.save(kfkwEntity2); } } // 拖拽的排序变为目标节点排序 currentKfkw.setPx(newKfkw.getPx()); kfkwDao.save(currentKfkw); // 目标排序的排序为其排序至+1 newKfkw.setPx(newKfkw.getPx() + 1); kfkwDao.save(newKfkw); }else{ // 向下拖拽,movetype=prev // 跟新受影响的记录 // 目标节点wpflList.get(最大值),去除目标节点,将目标节点的上一个节点变为目标节点 List&lt;KfkwEntity&gt; kfkwList = findInfluenceData(pId, currentKfkw.getPx(), newKfkw.getPx()); kfkwList.remove(kfkwList.size()-1); KfkwEntity kfkwNew=kfkwDao.findOne(kfkwList.get(kfkwList.size()-1).getId()); //新的目标节点 int kfkwNewPx = kfkwNew.getPx(); for (int i = 0; i &lt; kfkwList.size(); i++) { KfkwEntity kfkw = kfkwList.get(i); if (!(kfkw.getId().equals(currentKfkw.getId())) ) { KfkwEntity kfkwEntity2 = kfkwDao.findOne(kfkw.getId()); kfkwEntity2.setPx(kfkwEntity2.getPx() - 1); kfkwDao.save(kfkwEntity2); } } // 拖拽节点排序变为目标节点的排序 currentKfkw.setPx(kfkwNewPx); kfkwDao.save(currentKfkw); } } } public List&lt;KfkwEntity&gt; findInfluenceData(Long sjfl, Integer currentNodePx, Integer newNodePx) { Specification&lt;KfkwEntity&gt; spec = new Specification&lt;KfkwEntity&gt;() { @Override public Predicate toPredicate(Root&lt;KfkwEntity&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) { List&lt;Predicate&gt; predicates = Lists.newArrayList(); if(sjfl != 0){ Predicate p1 = cb.equal(root.get(&quot;sjfl&quot;).as(Long.class), sjfl); predicates.add(p1); }else{ Predicate p1 = cb.isNull(root.get(&quot;sjfl&quot;).as(Long.class)); predicates.add(p1); } Predicate p2 = cb.equal(root.get(&quot;ssxx&quot;).as(Long.class), getSchoolId()); predicates.add(p2); if(currentNodePx&lt;newNodePx){ Predicate p3 = cb.between(root.get(&quot;px&quot;), currentNodePx, newNodePx); predicates.add(p3); }else if(currentNodePx&gt;newNodePx){ Predicate p3 = cb.between(root.get(&quot;px&quot;), newNodePx, currentNodePx); predicates.add(p3);; } query.orderBy(cb.asc(root.get(&quot;px&quot;).as(Long.class))); query.where(cb.and(predicates.toArray(new Predicate[predicates.size()]))); return query.getRestriction(); } }; List&lt;KfkwEntity&gt; wpflList = kfkwDao.findAll(spec); return wpflList; } //成为目标节点的子节点 /** * * @param currentNodeId 拖拽节点id * @param newParentNodeId 目标父节点id * @throws Exception */ @Transactional public void differentLevel(Long currentNodeId,Long newParentNodeId) throws Exception{ KfkwEntity kfkwEntity=kfkwDao.findOne(currentNodeId); // 拖拽节点 List&lt;KfkwEntity&gt; kfkwEntities = null; if(kfkwEntity.getSjfl() != null){ kfkwEntities= findInfluenceData1(kfkwEntity.getSjfl().getId(), kfkwEntity.getPx()); }else{ kfkwEntities= findInfluenceData1(null, kfkwEntity.getPx()); } if(CollectionUtils.isNotEmpty(kfkwEntities)){ // 当前节点为同级最后节点时wpflEntities=[] for (int i = 0; i &lt; kfkwEntities.size(); i++) { KfkwEntity kfkwEntity2= kfkwEntities.get(i); kfkwEntity2.setPx(kfkwEntity2.getPx()-1); kfkwDao.save(kfkwEntity2); } } //当前节点成为目标节点(父节点)的最后一个节点 KfkwDto kfkwDto = new KfkwDto(); List&lt;KfkwEntity&gt; kfkwEntities2= kfkwDao.findByMaxPx(newParentNodeId, getSchoolId()); // 得到目标节点子节点的集合 if(CollectionUtils.isEmpty(kfkwEntities2)){ kfkwDto.setPx(1); }else{ kfkwDto.setPx(kfkwEntities2.get(0).getPx()+1); } kfkwEntity.setSjfl(kfkwDao.findOne(newParentNodeId)); super.save(kfkwEntity, kfkwDto); } public List&lt;KfkwEntity&gt; findInfluenceData1(Long sjfl, Integer currentNodePx) { Specification&lt;KfkwEntity&gt; spec = new Specification&lt;KfkwEntity&gt;() { @Override public Predicate toPredicate(Root&lt;KfkwEntity&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) { List&lt;Predicate&gt; predicates = Lists.newArrayList(); if(sjfl != null){ Predicate p1 = cb.equal(root.get(&quot;sjfl&quot;).as(Long.class), sjfl); predicates.add(p1); }else{ Predicate p1 = cb.isNull(root.get(&quot;sjfl&quot;).as(Long.class)); predicates.add(p1); } Predicate p2 = cb.equal(root.get(&quot;ssxx&quot;).as(Long.class), getSchoolId()); predicates.add(p2); Predicate p3 = cb.greaterThan(root.get(&quot;px&quot;), currentNodePx); predicates.add(p3); query.orderBy(cb.asc(root.get(&quot;px&quot;).as(Long.class))); query.where(cb.and(predicates.toArray(new Predicate[predicates.size()]))); return query.getRestriction(); } }; List&lt;KfkwEntity&gt; wpflList = kfkwDao.findAll(spec); return wpflList; } /** * 不同级节点为位置调换,movetype != inner * * @param currentNodeId * @param newNodeId * @param moveType * @throws Exception */ @Transactional public void diffLevel(Long currentNodeId, Long newNodeId, String moveType) throws Exception { if(&quot;next&quot;.equals(moveType)){ KfkwEntity currentKfkw = kfkwDao.findOne(currentNodeId);// 拖拽节点 KfkwEntity newKfkw = kfkwDao.findOne(newNodeId);//目标节点 KfkwEntity newKfkwSjfl =null; // 移到第一节点 if(newKfkw.getSjfl() != null){ newKfkwSjfl = kfkwDao.findOne(newKfkw.getSjfl().getId()); //目标节点的父类 } List&lt;KfkwEntity&gt; ccKfkwEntities = null; if(newKfkw.getSjfl() != null){ // 目标节点后面的数据排序+1，如果是最后一位不要+1 ccKfkwEntities = this.findInfluenceData2(newKfkw.getSjfl().getId(), newKfkw.getPx()); }else{ ccKfkwEntities = this.findInfluenceData2(null, newKfkw.getPx()); } if(CollectionUtils.isNotEmpty(ccKfkwEntities)){ for (int i = 0; i &lt; ccKfkwEntities.size(); i++) { KfkwEntity ccKfkwEntity=ccKfkwEntities.get(i); ccKfkwEntity.setPx(ccKfkwEntity.getPx()+1); kfkwDao.save(ccKfkwEntity); } } List&lt;KfkwEntity&gt; cckfkwEntities2 = null; if(currentKfkw.getSjfl() != null){ // 当前节点之后的排序值减一，判断是不是最后一个节点，如果是最后一个节点，就不需要-1了 cckfkwEntities2 = this.findInfluenceData2(currentKfkw.getSjfl().getId(), currentKfkw.getPx()); }else{ cckfkwEntities2 = this.findInfluenceData2(null, currentKfkw.getPx()); } if(CollectionUtils.isNotEmpty(cckfkwEntities2)){ for (int i = 0; i &lt; cckfkwEntities2.size(); i++) { KfkwEntity ccKfkwEntity=cckfkwEntities2.get(i); ccKfkwEntity.setPx(ccKfkwEntity.getPx()-1); kfkwDao.save(ccKfkwEntity); } } currentKfkw.setPx(newKfkw.getPx()+1); currentKfkw.setSjfl(newKfkwSjfl); kfkwDao.save(currentKfkw); }else{ KfkwEntity currentKfkw = kfkwDao.findOne(currentNodeId);// 拖拽节点 KfkwEntity newKfkw = kfkwDao.findOne(newNodeId);//目标节点 KfkwEntity newKfkwSjfl =null; // 移到第一节点 if(newKfkw.getSjfl() != null){ newKfkwSjfl = kfkwDao.findOne(newKfkw.getSjfl().getId()); //目标节点的父类 } List&lt;KfkwEntity&gt; ccKfkwEntities2 = null; if(currentKfkw.getSjfl() !=null){ // 当前节点之后的排序值减一，判断是不是最后一个节点，如果是最后一个节点，就不需要-1了 ccKfkwEntities2 = this.findInfluenceData2(currentKfkw.getSjfl().getId(), currentKfkw.getPx()); }else{ ccKfkwEntities2 = this.findInfluenceData2(null, currentKfkw.getPx()); } if(CollectionUtils.isNotEmpty(ccKfkwEntities2)){ for (int i = 0; i &lt; ccKfkwEntities2.size(); i++) { KfkwEntity ccKfkwEntity=ccKfkwEntities2.get(i); ccKfkwEntity.setPx(ccKfkwEntity.getPx()-1); kfkwDao.save(ccKfkwEntity); } } List&lt;KfkwEntity&gt; ccKfkwEntities = null; if(newKfkw.getSjfl() !=null){ // 目标节点之后的排序值加一 ccKfkwEntities = this.findInfluenceData2(newKfkw.getSjfl().getId(), newKfkw.getPx()); }else{ ccKfkwEntities = this.findInfluenceData2(null, newKfkw.getPx()); } if(CollectionUtils.isNotEmpty(ccKfkwEntities)){ for (int i = 0; i &lt; ccKfkwEntities.size(); i++) { KfkwEntity ccKfkwEntity=ccKfkwEntities.get(i); ccKfkwEntity.setPx(ccKfkwEntity.getPx()+1); kfkwDao.save(ccKfkwEntity); } } currentKfkw.setPx(newKfkw.getPx()); currentKfkw.setSjfl(newKfkwSjfl); kfkwDao.save(currentKfkw); // 目标节点的排序值加一 newKfkw.setPx(newKfkw.getPx()+1); kfkwDao.save(newKfkw); } } public List&lt;KfkwEntity&gt; findInfluenceData2(Long sjfl, Integer currentNodePx) { Specification&lt;KfkwEntity&gt; spec = new Specification&lt;KfkwEntity&gt;() { @Override public Predicate toPredicate(Root&lt;KfkwEntity&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) { List&lt;Predicate&gt; predicates = Lists.newArrayList(); if(sjfl != null){ Predicate p1 = cb.equal(root.get(&quot;sjfl&quot;).as(Long.class), sjfl); predicates.add(p1); }else{ Predicate p1 = cb.isNull(root.get(&quot;sjfl&quot;).as(Long.class)); predicates.add(p1); } Predicate p2 = cb.equal(root.get(&quot;ssxx&quot;).as(Long.class), getSchoolId()); predicates.add(p2); Predicate p3 = cb.greaterThan(root.get(&quot;px&quot;), currentNodePx); predicates.add(p3); query.orderBy(cb.asc(root.get(&quot;px&quot;).as(Long.class))); query.where(cb.and(predicates.toArray(new Predicate[predicates.size()]))); return query.getRestriction(); } }; List&lt;KfkwEntity&gt; wpflList = kfkwDao.findAll(spec); return wpflList; } } dao代码/** * 仓库管理Dao * * @author WangYuanJun */ public interface KfkwDao extends JpaRepository&lt;KfkwEntity, Long&gt;, JpaSpecificationExecutor&lt;KfkwEntity&gt; { @Query(&quot;select o from KfkwEntity o where o.sjfl.id=?1 and o.ssxx.id=?2 order by o.px desc&quot;) public List&lt;KfkwEntity&gt; findByMaxPx(Long sjfl,Long ssxx); }","tags":[{"name":"jquery","slug":"jquery","permalink":"http://wangyuanjun.cn/tags/jquery/"},{"name":"ztree","slug":"ztree","permalink":"http://wangyuanjun.cn/tags/ztree/"}]},{"title":"Maven镜像更换为阿里云镜像","date":"2016-05-10T15:53:34.000Z","path":"2016/05/10/Maven镜像更换为阿里云镜像/","text":"每次update Maven Project 的时候，下载速度非常慢，因为maven仓库默认在国外。国内支持maven镜像的有阿里云，开源中国等，这里换为阿里云的，镜像地址: http://maven.aliyun.com/ 。 找到settings.xml文件的mirrors节点，接着在mirrors节点里面加上一个mirror子节点，内容如下: &lt;mirror&gt; &lt;id&gt;aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt; 修改完毕之后，就可以体验下飞一般的感觉了。","tags":[{"name":"maven","slug":"maven","permalink":"http://wangyuanjun.cn/tags/maven/"}]},{"title":"常用Git命令大全","date":"2016-05-06T13:04:33.000Z","path":"2016/05/06/常用Git命令大全/","text":"一、新建代码库 # 在当前目录新建一个Git代码库 $ git init # 新建一个目录，将其初始化为Git代码库 $ git init [project-name] # 下载一个项目和它的整个代码历史 $ git clone [url] 二、配置 Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 # 显示当前的Git配置 $ git config --list # 编辑Git配置文件 $ git config -e [--global] # 设置提交代码时的用户信息 $ git config [--global] user.name &quot;[name]&quot; $ git config [--global] user.email &quot;[email address]&quot; 三、增加/删除文件 # 添加指定文件到暂存区 $ git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录 $ git add [dir] # 添加当前目录的所有文件到暂存区 $ git add . # 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 $ git add -p # 删除工作区文件，并且将这次删除放入暂存区 $ git rm [file1] [file2] ... # 停止追踪指定文件，但该文件会保留在工作区 $ git rm --cached [file] # 改名文件，并且将这个改名放入暂存区 $ git mv [file-original] [file-renamed] 四、代码提交 # 提交暂存区到仓库区 $ git commit -m [message] # 提交暂存区的指定文件到仓库区 $ git commit [file1] [file2] ... -m [message] # 提交工作区自上次commit之后的变化，直接到仓库区 $ git commit -a # 提交时显示所有diff信息 $ git commit -v # 使用一次新的commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [message] # 重做上一次commit，并包括指定文件的新变化 $ git commit --amend [file1] [file2] ... 五、分支 # 列出所有本地分支 $ git branch # 列出所有远程分支 $ git branch -r # 列出所有本地分支和远程分支 $ git branch -a # 新建一个分支，但依然停留在当前分支 $ git branch [branch-name] # 新建一个分支，并切换到该分支 $ git checkout -b [branch] # 新建一个分支，指向指定commit $ git branch [branch] [commit] # 新建一个分支，与指定的远程分支建立追踪关系 $ git branch --track [branch] [remote-branch] # 切换到指定分支，并更新工作区 $ git checkout [branch-name] # 切换到上一个分支 $ git checkout - # 建立追踪关系，在现有分支与指定的远程分支之间 $ git branch --set-upstream [branch] [remote-branch] # 合并指定分支到当前分支 $ git merge [branch] # 选择一个commit，合并进当前分支 $ git cherry-pick [commit] # 删除分支 $ git branch -d [branch-name] # 删除远程分支 $ git push origin --delete [branch-name] $ git branch -dr [remote/branch] 六、标签 # 列出所有tag $ git tag # 新建一个tag在当前commit $ git tag [tag] # 新建一个tag在指定commit $ git tag [tag] [commit] # 删除本地tag $ git tag -d [tag] # 删除远程tag $ git push origin :refs/tags/[tagName] # 查看tag信息 $ git show [tag] # 提交指定tag $ git push [remote] [tag] # 提交所有tag $ git push [remote] --tags # 新建一个分支，指向某个tag $ git checkout -b [branch] [tag] 七、查看信息 # 显示有变更的文件 $ git status # 显示当前分支的版本历史 $ git log # 显示commit历史，以及每次commit发生变更的文件 $ git log --stat # 搜索提交历史，根据关键词 $ git log -S [keyword] # 显示某个commit之后的所有变动，每个commit占据一行 $ git log [tag] HEAD --pretty=format:%s # 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件 $ git log [tag] HEAD --grep feature # 显示某个文件的版本历史，包括文件改名 $ git log --follow [file] $ git whatchanged [file] # 显示指定文件相关的每一次diff $ git log -p [file] # 显示过去5次提交 $ git log -5 --pretty --oneline # 显示所有提交过的用户，按提交次数排序 $ git shortlog -sn # 显示指定文件是什么人在什么时间修改过 $ git blame [file] # 显示暂存区和工作区的差异 $ git diff # 显示暂存区和上一个commit的差异 $ git diff --cached [file] # 显示工作区与当前分支最新commit之间的差异 $ git diff HEAD # 显示两次提交之间的差异 $ git diff [first-branch]...[second-branch] # 显示今天你写了多少行代码 $ git diff --shortstat &quot;@{0 day ago}&quot; # 显示某次提交的元数据和内容变化 $ git show [commit] # 显示某次提交发生变化的文件 $ git show --name-only [commit] # 显示某次提交时，某个文件的内容 $ git show [commit]:[filename] # 显示当前分支的最近几次提交 $ git reflog 八、远程同步 # 下载远程仓库的所有变动 $ git fetch [remote] # 显示所有远程仓库 $ git remote -v # 显示某个远程仓库的信息 $ git remote show [remote] # 增加一个新的远程仓库，并命名 $ git remote add [shortname] [url] # 取回远程仓库的变化，并与本地分支合并 $ git pull [remote] [branch] # 上传本地指定分支到远程仓库 $ git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] --force # 推送所有分支到远程仓库 $ git push [remote] --all 九、撤销 # 恢复暂存区的指定文件到工作区 $ git checkout [file] # 恢复某个commit的指定文件到暂存区和工作区 $ git checkout [commit] [file] # 恢复暂存区的所有文件到工作区 $ git checkout . # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 $ git reset [file] # 重置暂存区与工作区，与上一次commit保持一致 $ git reset --hard # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 $ git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 $ git reset --hard [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变 $ git reset --keep [commit] # 新建一个commit，用来撤销指定commit # 后者的所有变化都将被前者抵消，并且应用到当前分支 $ git revert [commit] # 暂时将未提交的变化移除，稍后再移入 $ git stash $ git stash pop 十、其他 # 生成一个可供发布的压缩包 $ git archive","tags":[{"name":"git","slug":"git","permalink":"http://wangyuanjun.cn/tags/git/"}]},{"title":"test","date":"2016-04-19T15:53:34.000Z","path":"2016/04/19/test/","text":"this is hexo test page","tags":[]}]